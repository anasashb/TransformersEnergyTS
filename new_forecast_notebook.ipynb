{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('seaborn-v0_8')\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# MSE function \n",
    "def MSE(pred, true):\n",
    "    return np.mean((pred-true)**2)\n",
    "\n",
    "random_seed = 100\n",
    "torch.manual_seed = 100\n",
    "np.random.seed = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InformerAPI import InformerTS\n",
    "from CrossformerAPI import CrossformerTS\n",
    "from AutoformerAPI import AutoformerTS\n",
    "from FedformerAPI import FedformerTS\n",
    "from PyraformerAPI import PyraformerTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping models in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'SYNTHh1': './SYNTHDataset/',\n",
    "    'DEWINDh_small': './WINDataset/' ,\n",
    "    'SYNTH_additive' : './SYNTHDataset/' , \n",
    "    'SYNTH_multiplicative' : './SYNTHDataset/' \n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "\n",
    "models = [InformerTS, Crossformer , AutoformerTS, FedformerTS]\n",
    "\n",
    "result_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: FedformerTS\n",
      "Training FedformerTS on SYNTHh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl24_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "Epoch: 1 cost time: 65.16380763053894\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.2622758 Vali Loss: 0.0958696 Test Loss: 0.0979099\n",
      "Validation loss decreased (inf --> 0.095870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 62.752004861831665\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.1016251 Vali Loss: 0.0833852 Test Loss: 0.0804521\n",
      "Validation loss decreased (0.095870 --> 0.083385).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 66.24701738357544\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.0882184 Vali Loss: 0.0720649 Test Loss: 0.0703608\n",
      "Validation loss decreased (0.083385 --> 0.072065).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 67.67151832580566\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.0800565 Vali Loss: 0.0701968 Test Loss: 0.0707113\n",
      "Validation loss decreased (0.072065 --> 0.070197).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 68.2637414932251\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.0747900 Vali Loss: 0.0641990 Test Loss: 0.0651344\n",
      "Validation loss decreased (0.070197 --> 0.064199).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 60.942933082580566\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.0718720 Vali Loss: 0.0651201 Test Loss: 0.0683536\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 70.8675377368927\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.0705077 Vali Loss: 0.0631342 Test Loss: 0.0658791\n",
      "Validation loss decreased (0.064199 --> 0.063134).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 74.24222350120544\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.0695275 Vali Loss: 0.0627513 Test Loss: 0.0653452\n",
      "Validation loss decreased (0.063134 --> 0.062751).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 74.18263983726501\n",
      "Epoch: 9, Steps: 266 | Train Loss: 0.0692555 Vali Loss: 0.0627041 Test Loss: 0.0654047\n",
      "Validation loss decreased (0.062751 --> 0.062704).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 69.2740786075592\n",
      "Epoch: 10, Steps: 266 | Train Loss: 0.0690241 Vali Loss: 0.0625783 Test Loss: 0.0652340\n",
      "Validation loss decreased (0.062704 --> 0.062578).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 66.56735253334045\n",
      "Epoch: 11, Steps: 266 | Train Loss: 0.0687436 Vali Loss: 0.0626013 Test Loss: 0.0652615\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 71.59506297111511\n",
      "Epoch: 12, Steps: 266 | Train Loss: 0.0686818 Vali Loss: 0.0625492 Test Loss: 0.0652689\n",
      "Validation loss decreased (0.062578 --> 0.062549).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 75.96273517608643\n",
      "Epoch: 13, Steps: 266 | Train Loss: 0.0688638 Vali Loss: 0.0626125 Test Loss: 0.0652519\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 67.62385320663452\n",
      "Epoch: 14, Steps: 266 | Train Loss: 0.0686548 Vali Loss: 0.0624748 Test Loss: 0.0652507\n",
      "Validation loss decreased (0.062549 --> 0.062475).  Saving model ...\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 67.02317714691162\n",
      "Epoch: 15, Steps: 266 | Train Loss: 0.0685920 Vali Loss: 0.0624342 Test Loss: 0.0652520\n",
      "Validation loss decreased (0.062475 --> 0.062434).  Saving model ...\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 69.63558053970337\n",
      "Epoch: 16, Steps: 266 | Train Loss: 0.0689014 Vali Loss: 0.0625766 Test Loss: 0.0652526\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.0517578125e-09\n",
      "Epoch: 17 cost time: 78.88778495788574\n",
      "Epoch: 17, Steps: 266 | Train Loss: 0.0686534 Vali Loss: 0.0625213 Test Loss: 0.0652519\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.52587890625e-09\n",
      "Epoch: 18 cost time: 67.18537974357605\n",
      "Epoch: 18, Steps: 266 | Train Loss: 0.0687823 Vali Loss: 0.0624668 Test Loss: 0.0652518\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 1) (89, 32, 24, 1)\n",
      "test shape: (2848, 24, 1) (2848, 24, 1)\n",
      "mse:0.06525204330682755, mae:0.21210964024066925\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl48_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "Epoch: 1 cost time: 85.43302178382874\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.2961777 Vali Loss: 0.1074879 Test Loss: 0.1124147\n",
      "Validation loss decreased (inf --> 0.107488).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 82.71987724304199\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.1159050 Vali Loss: 0.0940088 Test Loss: 0.1005454\n",
      "Validation loss decreased (0.107488 --> 0.094009).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 83.55789017677307\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.0911122 Vali Loss: 0.1160430 Test Loss: 0.1056600\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 82.2547287940979\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.0412276 Vali Loss: 0.1170206 Test Loss: 0.1084039\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 82.77264380455017\n",
      "Epoch: 5, Steps: 265 | Train Loss: 0.0384163 Vali Loss: 0.1198215 Test Loss: 0.1115995\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 1) (88, 32, 48, 1)\n",
      "test shape: (2816, 48, 1) (2816, 48, 1)\n",
      "mse:0.10054542869329453, mae:0.2656591534614563\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 9, 12, 13, 14, 15, 16, 17, 19, 20, 22, 24, 25, 26, 30, 32, 34, 36, 37, 42, 45, 47, 48, 52, 54, 55, 57, 61, 64, 65, 68, 69, 70, 71, 72, 73, 75, 76, 77, 79, 80, 82, 83, 84, 85, 90, 91, 92, 94, 95, 96, 98, 99, 100, 103, 105, 106]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 3, 5, 6, 9, 11, 13, 14, 15, 18, 19, 20, 24, 25, 27, 28, 30, 31, 32, 33, 37, 38, 39, 42, 44, 46, 47, 49, 50, 52, 53, 55, 56, 58, 60, 62, 64, 66, 67, 69, 70, 77, 78, 80, 81, 82, 83, 84, 86, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl168_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "Epoch: 1 cost time: 86.81678175926208\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.3380231 Vali Loss: 0.2696996 Test Loss: 0.3962550\n",
      "Validation loss decreased (inf --> 0.269700).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 96.68281483650208\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.2006405 Vali Loss: 0.2288464 Test Loss: 0.3212085\n",
      "Validation loss decreased (0.269700 --> 0.228846).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 100.87942695617676\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.1030630 Vali Loss: 0.3240111 Test Loss: 0.3204749\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 94.61479115486145\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.0676818 Vali Loss: 0.3299393 Test Loss: 0.3219820\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 94.50968170166016\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.0634867 Vali Loss: 0.3332740 Test Loss: 0.3234389\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 1) (84, 32, 168, 1)\n",
      "test shape: (2688, 168, 1) (2688, 168, 1)\n",
      "mse:0.32120853662490845, mae:0.46684420108795166\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[3, 7, 8, 11, 14, 18, 19, 21, 24, 26, 29, 35, 36, 37, 39, 40, 42, 44, 51, 56, 64, 65, 71, 72, 74, 76, 77, 80, 82, 83, 84, 85, 86, 88, 94, 95, 101, 106, 107, 112, 115, 118, 119, 120, 122, 125, 132, 136, 139, 145, 146, 149, 150, 156, 157, 162, 166, 173, 175, 176, 179, 181, 182, 184]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 3, 4, 7, 11, 17, 18, 20, 22, 24, 25, 29, 36, 38, 41, 42, 45, 46, 48, 52, 60, 64, 67, 68, 74, 76, 86, 90, 92, 96, 97, 100, 101, 103, 104, 105, 111, 115, 122, 123, 126, 130, 131, 134, 137, 138, 140, 143, 145, 146, 148, 151, 157, 162, 165, 169, 171, 174, 176, 177, 178, 179, 182, 191]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl336_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 136.74567246437073\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.6448343 Vali Loss: 0.5773084 Test Loss: 0.9059082\n",
      "Validation loss decreased (inf --> 0.577308).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 138.09175515174866\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.3290007 Vali Loss: 0.5133174 Test Loss: 0.8582950\n",
      "Validation loss decreased (0.577308 --> 0.513317).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 134.61821722984314\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.2994984 Vali Loss: 0.5038191 Test Loss: 0.8561960\n",
      "Validation loss decreased (0.513317 --> 0.503819).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 144.55647802352905\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.2920069 Vali Loss: 0.4927976 Test Loss: 0.8476861\n",
      "Validation loss decreased (0.503819 --> 0.492798).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 138.14357542991638\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.2879341 Vali Loss: 0.4807726 Test Loss: 0.8320661\n",
      "Validation loss decreased (0.492798 --> 0.480773).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 140.39829564094543\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.2848465 Vali Loss: 0.4775362 Test Loss: 0.8332866\n",
      "Validation loss decreased (0.480773 --> 0.477536).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 132.41144371032715\n",
      "Epoch: 7, Steps: 256 | Train Loss: 0.2838261 Vali Loss: 0.4787838 Test Loss: 0.8348544\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 137.89564657211304\n",
      "Epoch: 8, Steps: 256 | Train Loss: 0.2833602 Vali Loss: 0.4777366 Test Loss: 0.8337955\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 136.2236864566803\n",
      "Epoch: 9, Steps: 256 | Train Loss: 0.2823350 Vali Loss: 0.4785407 Test Loss: 0.8333014\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 1) (79, 32, 336, 1)\n",
      "test shape: (2528, 336, 1) (2528, 336, 1)\n",
      "mse:0.8332867622375488, mae:0.7153301239013672\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 15, 16, 22, 29, 30, 33, 40, 49, 55, 56, 57, 61, 69, 70, 74, 75, 81, 82, 84, 106, 107, 111, 125, 127, 130, 131, 140, 144, 148, 153, 155, 160, 161, 176, 186, 194, 202, 219, 222, 227, 247, 248, 253, 257, 258, 259, 270, 283, 286, 294, 296, 306, 327, 331, 338, 340, 343, 350, 365, 368, 369, 370, 383]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[7, 11, 13, 16, 22, 23, 27, 32, 36, 48, 49, 55, 63, 65, 66, 78, 90, 96, 97, 102, 105, 108, 114, 115, 126, 132, 133, 134, 136, 161, 164, 166, 177, 179, 188, 189, 190, 195, 216, 225, 227, 231, 232, 242, 243, 250, 253, 254, 262, 273, 288, 294, 319, 320, 322, 327, 329, 338, 341, 348, 357, 358, 379, 380]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl720_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 155.4706552028656\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.4897954 Vali Loss: 0.2999372 Test Loss: 0.6046879\n",
      "Validation loss decreased (inf --> 0.299937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 154.00870513916016\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.1331194 Vali Loss: 0.2868610 Test Loss: 0.6266771\n",
      "Validation loss decreased (0.299937 --> 0.286861).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 154.89499139785767\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.1080418 Vali Loss: 0.2732387 Test Loss: 0.6049472\n",
      "Validation loss decreased (0.286861 --> 0.273239).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 152.15872359275818\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.1023389 Vali Loss: 0.2575334 Test Loss: 0.5830230\n",
      "Validation loss decreased (0.273239 --> 0.257533).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 154.80844449996948\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.1005052 Vali Loss: 0.2683795 Test Loss: 0.6003717\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 154.23212957382202\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.0997536 Vali Loss: 0.2739580 Test Loss: 0.6109940\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 153.46481704711914\n",
      "Epoch: 7, Steps: 244 | Train Loss: 0.0993424 Vali Loss: 0.2694975 Test Loss: 0.6025179\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 1) (67, 32, 720, 1)\n",
      "test shape: (2144, 720, 1) (2144, 720, 1)\n",
      "mse:0.5830230116844177, mae:0.6152520775794983\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl24_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "Epoch: 1 cost time: 72.37522506713867\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.2114821 Vali Loss: 0.1721330 Test Loss: 0.1754460\n",
      "Validation loss decreased (inf --> 0.172133).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 69.36662220954895\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.1479469 Vali Loss: 0.1574086 Test Loss: 0.1616093\n",
      "Validation loss decreased (0.172133 --> 0.157409).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 69.05121278762817\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.1293245 Vali Loss: 0.1515991 Test Loss: 0.1488951\n",
      "Validation loss decreased (0.157409 --> 0.151599).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 70.27343893051147\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.1240935 Vali Loss: 0.1496561 Test Loss: 0.1461690\n",
      "Validation loss decreased (0.151599 --> 0.149656).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 70.37175345420837\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.1216244 Vali Loss: 0.1465813 Test Loss: 0.1444247\n",
      "Validation loss decreased (0.149656 --> 0.146581).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 73.60788369178772\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.1203851 Vali Loss: 0.1465245 Test Loss: 0.1436537\n",
      "Validation loss decreased (0.146581 --> 0.146525).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 64.40801477432251\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.1197325 Vali Loss: 0.1462581 Test Loss: 0.1430382\n",
      "Validation loss decreased (0.146525 --> 0.146258).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 72.39297080039978\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.1193276 Vali Loss: 0.1464056 Test Loss: 0.1424594\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 77.23398017883301\n",
      "Epoch: 9, Steps: 266 | Train Loss: 0.1190036 Vali Loss: 0.1457477 Test Loss: 0.1425107\n",
      "Validation loss decreased (0.146258 --> 0.145748).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 75.30889296531677\n",
      "Epoch: 10, Steps: 266 | Train Loss: 0.1189171 Vali Loss: 0.1464164 Test Loss: 0.1427033\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 76.40240502357483\n",
      "Epoch: 11, Steps: 266 | Train Loss: 0.1190182 Vali Loss: 0.1461212 Test Loss: 0.1424635\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 66.84464526176453\n",
      "Epoch: 12, Steps: 266 | Train Loss: 0.1188472 Vali Loss: 0.1460604 Test Loss: 0.1424270\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 1) (89, 32, 24, 1)\n",
      "test shape: (2848, 24, 1) (2848, 24, 1)\n",
      "mse:0.14251071214675903, mae:0.2431260049343109\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl48_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "Epoch: 1 cost time: 82.68609857559204\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.2398062 Vali Loss: 0.1913295 Test Loss: 0.1926833\n",
      "Validation loss decreased (inf --> 0.191329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 80.61324048042297\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.1704890 Vali Loss: 0.1738000 Test Loss: 0.1810771\n",
      "Validation loss decreased (0.191329 --> 0.173800).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 76.70012331008911\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.1543370 Vali Loss: 0.1676580 Test Loss: 0.1713296\n",
      "Validation loss decreased (0.173800 --> 0.167658).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 81.129812002182\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.1496196 Vali Loss: 0.1630197 Test Loss: 0.1709165\n",
      "Validation loss decreased (0.167658 --> 0.163020).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 82.08459877967834\n",
      "Epoch: 5, Steps: 265 | Train Loss: 0.1472327 Vali Loss: 0.1646764 Test Loss: 0.1709053\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 77.71331930160522\n",
      "Epoch: 6, Steps: 265 | Train Loss: 0.1464615 Vali Loss: 0.1612807 Test Loss: 0.1679323\n",
      "Validation loss decreased (0.163020 --> 0.161281).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 73.55619144439697\n",
      "Epoch: 7, Steps: 265 | Train Loss: 0.1457253 Vali Loss: 0.1627410 Test Loss: 0.1685767\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 77.71450066566467\n",
      "Epoch: 8, Steps: 265 | Train Loss: 0.1453644 Vali Loss: 0.1615711 Test Loss: 0.1675281\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 70.3328104019165\n",
      "Epoch: 9, Steps: 265 | Train Loss: 0.1450566 Vali Loss: 0.1616879 Test Loss: 0.1673708\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 1) (88, 32, 48, 1)\n",
      "test shape: (2816, 48, 1) (2816, 48, 1)\n",
      "mse:0.16793231666088104, mae:0.26156046986579895\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 4, 6, 8, 9, 11, 13, 15, 16, 17, 18, 19, 23, 25, 26, 28, 29, 31, 36, 37, 38, 39, 40, 46, 47, 49, 50, 51, 54, 55, 57, 59, 61, 62, 64, 65, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 80, 82, 83, 85, 86, 87, 89, 90, 91, 95, 97, 98, 99, 101, 102, 104, 106, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 2, 4, 6, 7, 8, 10, 11, 12, 17, 18, 20, 22, 24, 28, 29, 31, 32, 35, 37, 38, 40, 41, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 74, 76, 78, 79, 82, 83, 85, 87, 88, 92, 93, 94, 95, 96, 98, 99, 100, 103, 105, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl168_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "Epoch: 1 cost time: 94.93490862846375\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.2745222 Vali Loss: 0.2098569 Test Loss: 0.2543777\n",
      "Validation loss decreased (inf --> 0.209857).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 97.88841915130615\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.1953471 Vali Loss: 0.1924711 Test Loss: 0.2247242\n",
      "Validation loss decreased (0.209857 --> 0.192471).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 95.92441177368164\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.1805659 Vali Loss: 0.1887467 Test Loss: 0.2116429\n",
      "Validation loss decreased (0.192471 --> 0.188747).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 90.3724684715271\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.1755724 Vali Loss: 0.1875851 Test Loss: 0.2080587\n",
      "Validation loss decreased (0.188747 --> 0.187585).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 93.48627400398254\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.1732709 Vali Loss: 0.1846453 Test Loss: 0.2064762\n",
      "Validation loss decreased (0.187585 --> 0.184645).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 101.04886054992676\n",
      "Epoch: 6, Steps: 261 | Train Loss: 0.1722411 Vali Loss: 0.1857036 Test Loss: 0.2056105\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 97.431147813797\n",
      "Epoch: 7, Steps: 261 | Train Loss: 0.1715618 Vali Loss: 0.1846945 Test Loss: 0.2047290\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 97.73316025733948\n",
      "Epoch: 8, Steps: 261 | Train Loss: 0.1712891 Vali Loss: 0.1842525 Test Loss: 0.2044976\n",
      "Validation loss decreased (0.184645 --> 0.184253).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 92.30036044120789\n",
      "Epoch: 9, Steps: 261 | Train Loss: 0.1711024 Vali Loss: 0.1845036 Test Loss: 0.2045136\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 95.33031940460205\n",
      "Epoch: 10, Steps: 261 | Train Loss: 0.1709727 Vali Loss: 0.1838423 Test Loss: 0.2043479\n",
      "Validation loss decreased (0.184253 --> 0.183842).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 100.75438523292542\n",
      "Epoch: 11, Steps: 261 | Train Loss: 0.1710100 Vali Loss: 0.1838636 Test Loss: 0.2044161\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 94.86922645568848\n",
      "Epoch: 12, Steps: 261 | Train Loss: 0.1710386 Vali Loss: 0.1841805 Test Loss: 0.2044540\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 97.8796603679657\n",
      "Epoch: 13, Steps: 261 | Train Loss: 0.1708163 Vali Loss: 0.1840257 Test Loss: 0.2044422\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 1) (84, 32, 168, 1)\n",
      "test shape: (2688, 168, 1) (2688, 168, 1)\n",
      "mse:0.20434793829917908, mae:0.2872311472892761\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[5, 6, 8, 16, 18, 21, 22, 27, 30, 31, 35, 37, 41, 44, 49, 51, 56, 60, 62, 63, 68, 71, 76, 79, 83, 86, 87, 88, 89, 93, 94, 96, 101, 104, 106, 107, 108, 112, 114, 115, 118, 120, 121, 123, 124, 125, 126, 127, 132, 137, 144, 145, 150, 152, 156, 157, 159, 160, 162, 171, 173, 176, 178, 186]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 4, 8, 10, 11, 19, 22, 25, 27, 29, 30, 31, 37, 38, 46, 51, 53, 56, 59, 60, 61, 63, 66, 67, 70, 71, 73, 83, 85, 86, 87, 88, 90, 91, 93, 100, 102, 103, 105, 106, 113, 114, 116, 118, 121, 126, 133, 135, 137, 138, 140, 142, 146, 156, 163, 164, 172, 173, 176, 179, 183, 187, 188]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl336_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 137.5448637008667\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.2794518 Vali Loss: 0.2239798 Test Loss: 0.2531980\n",
      "Validation loss decreased (inf --> 0.223980).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 138.03746604919434\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.2040735 Vali Loss: 0.2087817 Test Loss: 0.2273964\n",
      "Validation loss decreased (0.223980 --> 0.208782).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 136.30613660812378\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.1892859 Vali Loss: 0.2050861 Test Loss: 0.2197302\n",
      "Validation loss decreased (0.208782 --> 0.205086).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 136.5584523677826\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.1851019 Vali Loss: 0.2049639 Test Loss: 0.2185452\n",
      "Validation loss decreased (0.205086 --> 0.204964).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 138.26207208633423\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.1828691 Vali Loss: 0.2008395 Test Loss: 0.2144005\n",
      "Validation loss decreased (0.204964 --> 0.200839).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 136.67724227905273\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.1817489 Vali Loss: 0.2006952 Test Loss: 0.2139032\n",
      "Validation loss decreased (0.200839 --> 0.200695).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 137.36968350410461\n",
      "Epoch: 7, Steps: 256 | Train Loss: 0.1812256 Vali Loss: 0.2008900 Test Loss: 0.2141913\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 137.30261611938477\n",
      "Epoch: 8, Steps: 256 | Train Loss: 0.1810299 Vali Loss: 0.2008907 Test Loss: 0.2137832\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 137.29151439666748\n",
      "Epoch: 9, Steps: 256 | Train Loss: 0.1807842 Vali Loss: 0.2006801 Test Loss: 0.2136833\n",
      "Validation loss decreased (0.200695 --> 0.200680).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 135.76942467689514\n",
      "Epoch: 10, Steps: 256 | Train Loss: 0.1808086 Vali Loss: 0.2012542 Test Loss: 0.2137917\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 134.9397096633911\n",
      "Epoch: 11, Steps: 256 | Train Loss: 0.1807386 Vali Loss: 0.2010848 Test Loss: 0.2136818\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 135.7372510433197\n",
      "Epoch: 12, Steps: 256 | Train Loss: 0.1807032 Vali Loss: 0.2007398 Test Loss: 0.2135633\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 1) (79, 32, 336, 1)\n",
      "test shape: (2528, 336, 1) (2528, 336, 1)\n",
      "mse:0.21368330717086792, mae:0.2933596670627594\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[5, 7, 14, 15, 19, 28, 29, 32, 41, 70, 72, 78, 92, 95, 107, 111, 125, 136, 141, 142, 143, 144, 147, 148, 161, 166, 193, 207, 218, 220, 224, 225, 227, 238, 241, 248, 255, 257, 259, 264, 268, 270, 295, 310, 317, 321, 324, 325, 327, 328, 330, 334, 336, 340, 346, 348, 352, 358, 368, 370, 371, 372, 373, 383]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[6, 12, 13, 20, 30, 37, 44, 45, 50, 51, 54, 68, 73, 89, 97, 106, 110, 118, 121, 124, 125, 127, 129, 140, 143, 147, 155, 159, 161, 164, 167, 173, 174, 175, 193, 194, 195, 204, 217, 218, 221, 225, 226, 242, 249, 255, 256, 273, 283, 289, 294, 296, 301, 305, 314, 315, 319, 336, 338, 340, 345, 347, 356, 366]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl720_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 156.19643640518188\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.3164566 Vali Loss: 0.2410156 Test Loss: 0.2578015\n",
      "Validation loss decreased (inf --> 0.241016).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 154.18176746368408\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.2299838 Vali Loss: 0.2263319 Test Loss: 0.2225166\n",
      "Validation loss decreased (0.241016 --> 0.226332).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 152.73677945137024\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.2144654 Vali Loss: 0.2258151 Test Loss: 0.2145904\n",
      "Validation loss decreased (0.226332 --> 0.225815).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 155.5624635219574\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.2087077 Vali Loss: 0.2264275 Test Loss: 0.2124823\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 154.6022527217865\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.2072666 Vali Loss: 0.2284970 Test Loss: 0.2127695\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 151.8677213191986\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.2064574 Vali Loss: 0.2277032 Test Loss: 0.2132132\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 1) (67, 32, 720, 1)\n",
      "test shape: (2144, 720, 1) (2144, 720, 1)\n",
      "mse:0.21459044516086578, mae:0.3042219281196594\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl24_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "Epoch: 1 cost time: 74.73909330368042\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.0427485 Vali Loss: 0.0142050 Test Loss: 0.0156709\n",
      "Validation loss decreased (inf --> 0.014205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 69.94323301315308\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.0170757 Vali Loss: 0.0127911 Test Loss: 0.0131940\n",
      "Validation loss decreased (0.014205 --> 0.012791).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 68.74501371383667\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.0153608 Vali Loss: 0.0132927 Test Loss: 0.0142198\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 70.74430441856384\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.0145853 Vali Loss: 0.0117667 Test Loss: 0.0127431\n",
      "Validation loss decreased (0.012791 --> 0.011767).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 70.42110276222229\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.0141812 Vali Loss: 0.0115002 Test Loss: 0.0124220\n",
      "Validation loss decreased (0.011767 --> 0.011500).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 71.71730923652649\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.0139335 Vali Loss: 0.0118488 Test Loss: 0.0129903\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 69.67986297607422\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.0138513 Vali Loss: 0.0116860 Test Loss: 0.0128233\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 71.06742453575134\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.0137176 Vali Loss: 0.0116691 Test Loss: 0.0128467\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 1) (89, 32, 24, 1)\n",
      "test shape: (2848, 24, 1) (2848, 24, 1)\n",
      "mse:0.012421983294188976, mae:0.09499217569828033\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl48_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "Epoch: 1 cost time: 82.62886786460876\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.0509854 Vali Loss: 0.0180286 Test Loss: 0.0199440\n",
      "Validation loss decreased (inf --> 0.018029).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 75.52333950996399\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.0198787 Vali Loss: 0.0185629 Test Loss: 0.0212041\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 84.1139485836029\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.0123281 Vali Loss: 0.0210622 Test Loss: 0.0228689\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 81.28150939941406\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.0052759 Vali Loss: 0.0212576 Test Loss: 0.0227869\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 1) (88, 32, 48, 1)\n",
      "test shape: (2816, 48, 1) (2816, 48, 1)\n",
      "mse:0.019944023340940475, mae:0.11941598355770111\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 3, 5, 6, 9, 10, 11, 15, 16, 19, 22, 23, 24, 25, 27, 30, 31, 32, 35, 36, 37, 38, 39, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 63, 65, 66, 68, 70, 72, 73, 74, 76, 77, 78, 80, 81, 82, 90, 91, 92, 93, 95, 97, 100, 104, 105, 106]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 5, 7, 9, 10, 11, 13, 14, 16, 17, 18, 20, 23, 26, 27, 28, 29, 32, 33, 34, 35, 37, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 55, 58, 61, 62, 63, 64, 65, 66, 67, 68, 74, 75, 76, 77, 80, 81, 82, 85, 86, 88, 90, 91, 92, 94, 97, 99, 100, 101, 103, 104, 105]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl168_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "Epoch: 1 cost time: 101.84913969039917\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.0728098 Vali Loss: 0.0524281 Test Loss: 0.0772704\n",
      "Validation loss decreased (inf --> 0.052428).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 87.40538740158081\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.0378373 Vali Loss: 0.0468810 Test Loss: 0.0699481\n",
      "Validation loss decreased (0.052428 --> 0.046881).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 94.67370581626892\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.0354153 Vali Loss: 0.0482819 Test Loss: 0.0742178\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 99.83035564422607\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.0346010 Vali Loss: 0.0482900 Test Loss: 0.0741721\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 97.09888434410095\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.0343237 Vali Loss: 0.0470955 Test Loss: 0.0734261\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 1) (84, 32, 168, 1)\n",
      "test shape: (2688, 168, 1) (2688, 168, 1)\n",
      "mse:0.06994808465242386, mae:0.21107102930545807\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 5, 6, 7, 10, 11, 14, 16, 25, 26, 52, 55, 56, 57, 61, 63, 64, 66, 67, 69, 70, 72, 74, 75, 79, 80, 82, 89, 90, 93, 96, 97, 100, 101, 104, 106, 107, 109, 112, 115, 119, 122, 130, 136, 138, 141, 142, 143, 145, 149, 150, 151, 160, 162, 166, 169, 170, 175, 178, 179, 181, 186, 187, 189]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[6, 7, 8, 10, 14, 16, 19, 21, 24, 25, 26, 29, 30, 31, 34, 36, 38, 43, 45, 48, 50, 51, 52, 53, 55, 56, 57, 59, 60, 67, 70, 75, 80, 82, 88, 89, 92, 93, 94, 100, 102, 108, 113, 114, 120, 121, 129, 132, 139, 143, 145, 148, 149, 154, 159, 161, 164, 168, 169, 172, 175, 177, 182, 184]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl336_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 139.30432415008545\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.0890444 Vali Loss: 0.0804638 Test Loss: 0.1426802\n",
      "Validation loss decreased (inf --> 0.080464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 142.93336248397827\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.0406087 Vali Loss: 0.0782275 Test Loss: 0.1404223\n",
      "Validation loss decreased (0.080464 --> 0.078228).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 139.75560426712036\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.0372293 Vali Loss: 0.0703895 Test Loss: 0.1348318\n",
      "Validation loss decreased (0.078228 --> 0.070390).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 137.24430894851685\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.0360870 Vali Loss: 0.0727980 Test Loss: 0.1379151\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 132.64594292640686\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.0355033 Vali Loss: 0.0711329 Test Loss: 0.1348898\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 133.64660000801086\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.0351970 Vali Loss: 0.0719441 Test Loss: 0.1357211\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 1) (79, 32, 336, 1)\n",
      "test shape: (2528, 336, 1) (2528, 336, 1)\n",
      "mse:0.13483181595802307, mae:0.2947820723056793\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 5, 9, 15, 19, 24, 30, 37, 42, 50, 51, 53, 65, 68, 69, 74, 76, 89, 106, 111, 117, 126, 130, 133, 136, 139, 141, 143, 147, 148, 152, 165, 168, 169, 188, 195, 202, 214, 229, 231, 234, 238, 243, 259, 261, 266, 270, 276, 280, 283, 289, 296, 301, 302, 323, 326, 347, 354, 355, 360, 361, 369, 376, 383]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 8, 12, 17, 28, 48, 52, 54, 74, 82, 84, 89, 90, 95, 96, 102, 104, 113, 118, 124, 128, 133, 140, 154, 175, 180, 183, 188, 189, 194, 195, 200, 220, 221, 222, 228, 229, 236, 256, 262, 267, 268, 270, 276, 284, 301, 305, 307, 309, 310, 313, 316, 319, 326, 332, 335, 343, 344, 352, 360, 361, 364, 366, 382]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl720_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 152.01621532440186\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.1149296 Vali Loss: 0.1129449 Test Loss: 0.1426805\n",
      "Validation loss decreased (inf --> 0.112945).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 152.62825512886047\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.0826839 Vali Loss: 0.1087984 Test Loss: 0.1381708\n",
      "Validation loss decreased (0.112945 --> 0.108798).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 155.14176273345947\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.0778196 Vali Loss: 0.1021451 Test Loss: 0.1311690\n",
      "Validation loss decreased (0.108798 --> 0.102145).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 153.52900218963623\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.0742535 Vali Loss: 0.1013670 Test Loss: 0.1308442\n",
      "Validation loss decreased (0.102145 --> 0.101367).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 155.54235672950745\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.0732651 Vali Loss: 0.1009897 Test Loss: 0.1304703\n",
      "Validation loss decreased (0.101367 --> 0.100990).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 153.7102701663971\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.0729032 Vali Loss: 0.1005441 Test Loss: 0.1300553\n",
      "Validation loss decreased (0.100990 --> 0.100544).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 157.08018803596497\n",
      "Epoch: 7, Steps: 244 | Train Loss: 0.0727855 Vali Loss: 0.1004793 Test Loss: 0.1300315\n",
      "Validation loss decreased (0.100544 --> 0.100479).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 153.98673152923584\n",
      "Epoch: 8, Steps: 244 | Train Loss: 0.0726516 Vali Loss: 0.1004297 Test Loss: 0.1300295\n",
      "Validation loss decreased (0.100479 --> 0.100430).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 153.56844282150269\n",
      "Epoch: 9, Steps: 244 | Train Loss: 0.0726203 Vali Loss: 0.1003894 Test Loss: 0.1299749\n",
      "Validation loss decreased (0.100430 --> 0.100389).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 150.32253098487854\n",
      "Epoch: 10, Steps: 244 | Train Loss: 0.0725249 Vali Loss: 0.1003381 Test Loss: 0.1299667\n",
      "Validation loss decreased (0.100389 --> 0.100338).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 154.49593114852905\n",
      "Epoch: 11, Steps: 244 | Train Loss: 0.0725807 Vali Loss: 0.1004587 Test Loss: 0.1299633\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 152.85793685913086\n",
      "Epoch: 12, Steps: 244 | Train Loss: 0.0725438 Vali Loss: 0.1002700 Test Loss: 0.1299639\n",
      "Validation loss decreased (0.100338 --> 0.100270).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 153.1916687488556\n",
      "Epoch: 13, Steps: 244 | Train Loss: 0.0725751 Vali Loss: 0.1003772 Test Loss: 0.1299638\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 155.80803203582764\n",
      "Epoch: 14, Steps: 244 | Train Loss: 0.0725399 Vali Loss: 0.1002643 Test Loss: 0.1299623\n",
      "Validation loss decreased (0.100270 --> 0.100264).  Saving model ...\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 152.84141516685486\n",
      "Epoch: 15, Steps: 244 | Train Loss: 0.0725505 Vali Loss: 0.1004451 Test Loss: 0.1299612\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 152.402583360672\n",
      "Epoch: 16, Steps: 244 | Train Loss: 0.0725537 Vali Loss: 0.1003396 Test Loss: 0.1299620\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.0517578125e-09\n",
      "Epoch: 17 cost time: 153.3291425704956\n",
      "Epoch: 17, Steps: 244 | Train Loss: 0.0725756 Vali Loss: 0.1004241 Test Loss: 0.1299624\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 1) (67, 32, 720, 1)\n",
      "test shape: (2144, 720, 1) (2144, 720, 1)\n",
      "mse:0.12996231019496918, mae:0.2956447899341583\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl24_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "Epoch: 1 cost time: 69.95051741600037\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.1308087 Vali Loss: 0.1202727 Test Loss: 0.2491716\n",
      "Validation loss decreased (inf --> 0.120273).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 75.98225975036621\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.0472134 Vali Loss: 0.0901750 Test Loss: 0.1861937\n",
      "Validation loss decreased (0.120273 --> 0.090175).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 72.48815751075745\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.0376528 Vali Loss: 0.0732488 Test Loss: 0.1485894\n",
      "Validation loss decreased (0.090175 --> 0.073249).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 73.27530145645142\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.0320956 Vali Loss: 0.0780246 Test Loss: 0.1474594\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 71.00189542770386\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.0265166 Vali Loss: 0.0689728 Test Loss: 0.1251354\n",
      "Validation loss decreased (0.073249 --> 0.068973).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 78.45705270767212\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.0213420 Vali Loss: 0.0712450 Test Loss: 0.1276719\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 77.5700056552887\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.0189030 Vali Loss: 0.0723299 Test Loss: 0.1305963\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 73.12382864952087\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.0179049 Vali Loss: 0.0702129 Test Loss: 0.1280869\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 1) (89, 32, 24, 1)\n",
      "test shape: (2848, 24, 1) (2848, 24, 1)\n",
      "mse:0.1251353770494461, mae:0.2924322783946991\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl48_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "Epoch: 1 cost time: 77.13046360015869\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.1540633 Vali Loss: 0.1575222 Test Loss: 0.3175133\n",
      "Validation loss decreased (inf --> 0.157522).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 77.72132277488708\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.0538236 Vali Loss: 0.1161437 Test Loss: 0.2342350\n",
      "Validation loss decreased (0.157522 --> 0.116144).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 77.67883443832397\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.0477480 Vali Loss: 0.1100016 Test Loss: 0.2162289\n",
      "Validation loss decreased (0.116144 --> 0.110002).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 82.24772596359253\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.0436436 Vali Loss: 0.0931480 Test Loss: 0.1790547\n",
      "Validation loss decreased (0.110002 --> 0.093148).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 74.94528245925903\n",
      "Epoch: 5, Steps: 265 | Train Loss: 0.0414734 Vali Loss: 0.0993660 Test Loss: 0.1896061\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 79.74053049087524\n",
      "Epoch: 6, Steps: 265 | Train Loss: 0.0405198 Vali Loss: 0.0971202 Test Loss: 0.1836738\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 80.32368326187134\n",
      "Epoch: 7, Steps: 265 | Train Loss: 0.0400684 Vali Loss: 0.0940984 Test Loss: 0.1789153\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 1) (88, 32, 48, 1)\n",
      "test shape: (2816, 48, 1) (2816, 48, 1)\n",
      "mse:0.17905473709106445, mae:0.3451704978942871\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 3, 4, 5, 7, 10, 11, 12, 13, 15, 16, 18, 20, 23, 24, 25, 28, 30, 31, 32, 35, 38, 40, 42, 43, 45, 46, 47, 49, 51, 53, 55, 57, 59, 62, 63, 67, 68, 70, 72, 74, 75, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 97, 98, 99, 100, 103, 104]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 21, 22, 23, 27, 28, 30, 32, 34, 36, 37, 38, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 55, 60, 61, 63, 65, 66, 67, 70, 71, 73, 74, 75, 76, 77, 79, 81, 85, 86, 87, 90, 94, 95, 96, 98, 100, 102, 103, 104, 105, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl168_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "Epoch: 1 cost time: 97.97330641746521\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.1976855 Vali Loss: 0.2421027 Test Loss: 0.4928890\n",
      "Validation loss decreased (inf --> 0.242103).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 97.70791506767273\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.0966737 Vali Loss: 0.2249172 Test Loss: 0.4601704\n",
      "Validation loss decreased (0.242103 --> 0.224917).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 95.0511064529419\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.0908570 Vali Loss: 0.2199885 Test Loss: 0.4547435\n",
      "Validation loss decreased (0.224917 --> 0.219988).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 92.14805817604065\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.0881951 Vali Loss: 0.2156846 Test Loss: 0.4412629\n",
      "Validation loss decreased (0.219988 --> 0.215685).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 99.12911248207092\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.0867915 Vali Loss: 0.2125939 Test Loss: 0.4389615\n",
      "Validation loss decreased (0.215685 --> 0.212594).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 96.9781174659729\n",
      "Epoch: 6, Steps: 261 | Train Loss: 0.0862095 Vali Loss: 0.2153750 Test Loss: 0.4408803\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 95.90998911857605\n",
      "Epoch: 7, Steps: 261 | Train Loss: 0.0857665 Vali Loss: 0.2133033 Test Loss: 0.4383859\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 94.16781067848206\n",
      "Epoch: 8, Steps: 261 | Train Loss: 0.0856569 Vali Loss: 0.2118819 Test Loss: 0.4364480\n",
      "Validation loss decreased (0.212594 --> 0.211882).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 96.5242006778717\n",
      "Epoch: 9, Steps: 261 | Train Loss: 0.0854081 Vali Loss: 0.2117544 Test Loss: 0.4362144\n",
      "Validation loss decreased (0.211882 --> 0.211754).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 100.98290276527405\n",
      "Epoch: 10, Steps: 261 | Train Loss: 0.0854207 Vali Loss: 0.2114740 Test Loss: 0.4361405\n",
      "Validation loss decreased (0.211754 --> 0.211474).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 98.0153796672821\n",
      "Epoch: 11, Steps: 261 | Train Loss: 0.0853832 Vali Loss: 0.2111922 Test Loss: 0.4361334\n",
      "Validation loss decreased (0.211474 --> 0.211192).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 95.2564446926117\n",
      "Epoch: 12, Steps: 261 | Train Loss: 0.0853101 Vali Loss: 0.2113579 Test Loss: 0.4359778\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 95.11027312278748\n",
      "Epoch: 13, Steps: 261 | Train Loss: 0.0852479 Vali Loss: 0.2117306 Test Loss: 0.4360789\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 93.91485071182251\n",
      "Epoch: 14, Steps: 261 | Train Loss: 0.0854514 Vali Loss: 0.2113732 Test Loss: 0.4360234\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 1) (84, 32, 168, 1)\n",
      "test shape: (2688, 168, 1) (2688, 168, 1)\n",
      "mse:0.43613341450691223, mae:0.5329356789588928\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 6, 8, 11, 15, 17, 20, 23, 24, 25, 27, 28, 40, 41, 42, 43, 45, 48, 50, 54, 55, 60, 63, 64, 66, 70, 80, 82, 85, 87, 88, 90, 93, 95, 96, 98, 100, 107, 116, 117, 119, 124, 125, 126, 130, 133, 137, 141, 142, 148, 155, 158, 159, 160, 161, 164, 167, 171, 172, 173, 178, 183, 186, 189]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 3, 4, 9, 11, 18, 19, 23, 29, 32, 33, 36, 38, 41, 44, 48, 49, 54, 61, 62, 64, 69, 73, 74, 81, 85, 86, 88, 89, 97, 101, 106, 107, 110, 112, 113, 114, 120, 123, 124, 127, 130, 135, 136, 140, 141, 142, 144, 145, 148, 152, 153, 159, 164, 167, 172, 176, 179, 181, 183, 184, 186, 189, 190]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl336_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 132.79359936714172\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.2648095 Vali Loss: 0.4463544 Test Loss: 0.9264024\n",
      "Validation loss decreased (inf --> 0.446354).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 135.37095761299133\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.1390502 Vali Loss: 0.4360401 Test Loss: 0.9363617\n",
      "Validation loss decreased (0.446354 --> 0.436040).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 136.57585835456848\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.1275753 Vali Loss: 0.3993294 Test Loss: 0.8908439\n",
      "Validation loss decreased (0.436040 --> 0.399329).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 138.5202395915985\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.1243966 Vali Loss: 0.4040039 Test Loss: 0.8927992\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 137.71836233139038\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.1228903 Vali Loss: 0.4035740 Test Loss: 0.8934826\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 138.93694853782654\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.1223115 Vali Loss: 0.3986278 Test Loss: 0.8875377\n",
      "Validation loss decreased (0.399329 --> 0.398628).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 138.18405675888062\n",
      "Epoch: 7, Steps: 256 | Train Loss: 0.1219799 Vali Loss: 0.3952074 Test Loss: 0.8812578\n",
      "Validation loss decreased (0.398628 --> 0.395207).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 139.1338140964508\n",
      "Epoch: 8, Steps: 256 | Train Loss: 0.1216923 Vali Loss: 0.3965352 Test Loss: 0.8837749\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 134.12413716316223\n",
      "Epoch: 9, Steps: 256 | Train Loss: 0.1216193 Vali Loss: 0.3953349 Test Loss: 0.8836628\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 142.48729133605957\n",
      "Epoch: 10, Steps: 256 | Train Loss: 0.1214878 Vali Loss: 0.3963095 Test Loss: 0.8835412\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 1) (79, 32, 336, 1)\n",
      "test shape: (2528, 336, 1) (2528, 336, 1)\n",
      "mse:0.8812577128410339, mae:0.7729610800743103\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[5, 6, 18, 24, 25, 34, 35, 45, 46, 54, 58, 60, 61, 64, 66, 67, 68, 78, 84, 85, 103, 104, 113, 114, 120, 144, 169, 183, 198, 203, 205, 216, 217, 220, 223, 224, 225, 228, 247, 251, 258, 261, 267, 270, 272, 273, 276, 277, 278, 289, 290, 291, 307, 312, 313, 321, 324, 328, 355, 359, 360, 361, 372, 378]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[2, 5, 7, 13, 20, 28, 41, 46, 47, 51, 55, 65, 69, 70, 72, 77, 85, 91, 92, 96, 104, 121, 137, 148, 155, 158, 173, 174, 177, 188, 192, 195, 198, 199, 200, 206, 216, 229, 233, 235, 236, 245, 248, 249, 250, 257, 263, 277, 280, 283, 308, 311, 312, 327, 329, 331, 336, 338, 344, 346, 347, 367, 378, 379]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl720_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 154.30475854873657\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.2981822 Vali Loss: 0.5248169 Test Loss: 0.8918412\n",
      "Validation loss decreased (inf --> 0.524817).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 151.5878803730011\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.2168004 Vali Loss: 0.5172841 Test Loss: 0.8857162\n",
      "Validation loss decreased (0.524817 --> 0.517284).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 155.86179161071777\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.2104494 Vali Loss: 0.4971302 Test Loss: 0.8563406\n",
      "Validation loss decreased (0.517284 --> 0.497130).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 155.36655807495117\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.2077307 Vali Loss: 0.4916374 Test Loss: 0.8524553\n",
      "Validation loss decreased (0.497130 --> 0.491637).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 159.1189353466034\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.2060099 Vali Loss: 0.4916977 Test Loss: 0.8526605\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 154.90611910820007\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.2050318 Vali Loss: 0.4901105 Test Loss: 0.8516530\n",
      "Validation loss decreased (0.491637 --> 0.490110).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 159.2449939250946\n",
      "Epoch: 7, Steps: 244 | Train Loss: 0.2045908 Vali Loss: 0.4890855 Test Loss: 0.8493210\n",
      "Validation loss decreased (0.490110 --> 0.489085).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 151.5310025215149\n",
      "Epoch: 8, Steps: 244 | Train Loss: 0.2044672 Vali Loss: 0.4893708 Test Loss: 0.8503516\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 153.23761630058289\n",
      "Epoch: 9, Steps: 244 | Train Loss: 0.2044165 Vali Loss: 0.4884796 Test Loss: 0.8495947\n",
      "Validation loss decreased (0.489085 --> 0.488480).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 156.00878167152405\n",
      "Epoch: 10, Steps: 244 | Train Loss: 0.2042772 Vali Loss: 0.4883519 Test Loss: 0.8493519\n",
      "Validation loss decreased (0.488480 --> 0.488352).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 152.8715627193451\n",
      "Epoch: 11, Steps: 244 | Train Loss: 0.2041214 Vali Loss: 0.4890001 Test Loss: 0.8491154\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 153.7130789756775\n",
      "Epoch: 12, Steps: 244 | Train Loss: 0.2042466 Vali Loss: 0.4883972 Test Loss: 0.8491007\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 155.35788297653198\n",
      "Epoch: 13, Steps: 244 | Train Loss: 0.2042806 Vali Loss: 0.4886141 Test Loss: 0.8490444\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 1) (67, 32, 720, 1)\n",
      "test shape: (2144, 720, 1) (2144, 720, 1)\n",
      "mse:0.8493518829345703, mae:0.7480064630508423\n",
      "\n",
      "Moving to next...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple loop\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "\n",
    "    for dataset_name, dataset_path in datasets.items():\n",
    "        for pred_len in pred_lens:\n",
    "            print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "            # High amount of epochs to accomodate all models\n",
    "            # Early stopping should kick in anyways\n",
    "            model.fit(\n",
    "                data=dataset_name,\n",
    "                data_root_path=dataset_path,\n",
    "                batch_size=32,\n",
    "                epochs=50, # very high\n",
    "                pred_len=pred_len\n",
    "            )\n",
    "\n",
    "            predictions = model.predict()\n",
    "\n",
    "            print(f'\\nMoving to next...\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: AutoformerTS\n",
      "Training AutoformerTS on SYNTHh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'model_id': 'Synth1_96_24', 'data': 'SYNTHh1', 'features': 'S', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 50, 'gpu': 0, 'lradj': 'type1', 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTHh1_ftS_sl96_ll48_pl24_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "\titers: 100, epoch: 1 | loss: 0.3741573\n",
      "\tspeed: 0.0389s/iter; left time: 513.6482s\n",
      "\titers: 200, epoch: 1 | loss: 0.2114526\n",
      "\tspeed: 0.0349s/iter; left time: 457.7411s\n",
      "Epoch: 1 cost time: 9.72855544090271\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.3988442 Vali Loss: 0.2078924 Test Loss: 0.2151814\n",
      "Validation loss decreased (inf --> 0.207892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1431225\n",
      "\tspeed: 0.1507s/iter; left time: 1949.8897s\n",
      "\titers: 200, epoch: 2 | loss: 0.0848296\n",
      "\tspeed: 0.0346s/iter; left time: 444.6977s\n",
      "Epoch: 2 cost time: 9.118820428848267\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    'SYNTHh1': './SYNTHDataset/',\n",
    "    'DEWINDh_small': './WINDataset/' ,\n",
    "    'SYNTH_additive' : './SYNTHDataset/' , \n",
    "    'SYNTH_multiplicative' : './SYNTHDataset/' \n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "\n",
    "models = [AutoformerTS]\n",
    "\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "\n",
    "    for dataset_name, dataset_path in datasets.items():\n",
    "        for pred_len in pred_lens:\n",
    "            print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "            # High amount of epochs to accomodate all models\n",
    "            # Early stopping should kick in anyways\n",
    "            model.fit(\n",
    "                data=dataset_name,\n",
    "                data_root_path=dataset_path,\n",
    "                batch_size=32,\n",
    "                epochs=50, # very high\n",
    "                pred_len=pred_len\n",
    "            )\n",
    "\n",
    "            predictions = model.predict()\n",
    "\n",
    "\n",
    "            print(f'\\nMoving to next...\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: PyraformerTS\n",
      "Training PyraformerTS on DEWINDh_small with pred_len 24\n",
      "[Info] Number of parameters: 8817408\n",
      "train 12092\n",
      "test 5110\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.09406elapse: 0.319 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5088, 24, 1)\n",
      "Epoch 0, mse:0.0073920669965445995, mae:0.06890180706977844, rmse:0.08597712963819504, mape:295757344.0, mspe:2.6446663134058906e+17\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.04042elapse: 0.311 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5088, 24, 1)\n",
      "Epoch 1, mse:0.0039183348417282104, mae:0.04642055183649063, rmse:0.06259660422801971, mape:164454032.0, mspe:8.273740817655398e+16\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03919elapse: 0.304 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5088, 24, 1)\n",
      "Epoch 2, mse:0.00359139870852232, mae:0.042672887444496155, rmse:0.059928279370069504, mape:118800472.0, mspe:4.685553339885158e+16\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03892elapse: 0.303 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5088, 24, 1)\n",
      "Epoch 3, mse:0.0034205883275717497, mae:0.04127037897706032, rmse:0.05848579481244087, mape:114251616.0, mspe:4.261450230215475e+16\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03887elapse: 0.307 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5088, 24, 1)\n",
      "Epoch 4, mse:0.0034931092523038387, mae:0.0416831374168396, rmse:0.059102531522512436, mape:112396728.0, mspe:4.210524802986803e+16\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03896elapse: 0.306 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5088, 24, 1)\n",
      "Epoch 5, mse:0.003417381551116705, mae:0.04127475619316101, rmse:0.058458372950553894, mape:114289032.0, mspe:4.250999715790848e+16\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03885elapse: 0.305 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5088, 24, 1)\n",
      "Epoch 6, mse:0.0034887967631220818, mae:0.04173211753368378, rmse:0.0590660385787487, mape:113352856.0, mspe:4.253085781406515e+16\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03874elapse: 0.310 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5088, 24, 1)\n",
      "Epoch 7, mse:0.0034433617256581783, mae:0.04146295040845871, rmse:0.05868016555905342, mape:114741392.0, mspe:4.299673291666227e+16\n",
      "Iteration best metrics: [0.003417381551116705, 0.04127475619316101, 0.058458372950553894, 114289032.0, 4.250999715790848e+16]\n",
      "train 12092\n",
      "test 5110\n",
      "168 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on DEWINDh_small with pred_len 48\n",
      "[Info] Number of parameters: 8866560\n",
      "train 12068\n",
      "test 5086\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.07739elapse: 0.301 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5056, 48, 1)\n",
      "Epoch 0, mse:0.006538774818181992, mae:0.06182307377457619, rmse:0.08086269348859787, mape:248238720.0, mspe:2.0323905503756288e+17\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03680elapse: 0.308 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5056, 48, 1)\n",
      "Epoch 1, mse:0.004373048897832632, mae:0.04781843349337578, rmse:0.06612902879714966, mape:145673952.0, mspe:6.994550092044698e+16\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03528elapse: 0.307 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5056, 48, 1)\n",
      "Epoch 2, mse:0.003921577241271734, mae:0.0441228412091732, rmse:0.06262249499559402, mape:121434848.0, mspe:4.732314366823629e+16\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03510elapse: 0.306 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5056, 48, 1)\n",
      "Epoch 3, mse:0.0038693633396178484, mae:0.04364275559782982, rmse:0.062204208225011826, mape:116390736.0, mspe:4.341303980169626e+16\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03511elapse: 0.311 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5056, 48, 1)\n",
      "Epoch 4, mse:0.003863227553665638, mae:0.043541401624679565, rmse:0.0621548667550087, mape:114641696.0, mspe:4.238890484996506e+16\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03506elapse: 0.304 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5056, 48, 1)\n",
      "Epoch 5, mse:0.0038690264336764812, mae:0.04355364665389061, rmse:0.062201499938964844, mape:117343736.0, mspe:4.384726099532186e+16\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03515elapse: 0.305 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5056, 48, 1)\n",
      "Epoch 6, mse:0.0038829748518764973, mae:0.04363531991839409, rmse:0.062313519418239594, mape:118365328.0, mspe:4.45646880374784e+16\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03528elapse: 0.309 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(5056, 48, 1)\n",
      "Epoch 7, mse:0.003865922335535288, mae:0.043572794646024704, rmse:0.06217654049396515, mape:115185960.0, mspe:4.278444986309018e+16\n",
      "Iteration best metrics: [0.003863227553665638, 0.043541401624679565, 0.0621548667550087, 114641696.0, 4.238890484996506e+16]\n",
      "train 12068\n",
      "test 5086\n",
      "168 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on DEWINDh_small with pred_len 168\n",
      "[Info] Number of parameters: 9112320\n",
      "train 11948\n",
      "test 4966\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06584elapse: 0.309 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4960, 168, 1)\n",
      "Epoch 0, mse:0.007674406282603741, mae:0.06697967648506165, rmse:0.08760368824005127, mape:257078944.0, mspe:2.1520081383482982e+17\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03176elapse: 0.309 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4960, 168, 1)\n",
      "Epoch 1, mse:0.005412754602730274, mae:0.05322365462779999, rmse:0.07357142865657806, mape:163216528.0, mspe:8.706953552959898e+16\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03063elapse: 0.291 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4960, 168, 1)\n",
      "Epoch 2, mse:0.005087369121611118, mae:0.05076693743467331, rmse:0.07132579386234283, mape:145055456.0, mspe:6.826481149804544e+16\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03049elapse: 0.299 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4960, 168, 1)\n",
      "Epoch 3, mse:0.0050459960475564, mae:0.05070152506232262, rmse:0.07103517651557922, mape:140448304.0, mspe:6.494901514115482e+16\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03045elapse: 0.305 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4960, 168, 1)\n",
      "Epoch 4, mse:0.005050364416092634, mae:0.05057716369628906, rmse:0.07106591761112213, mape:140972784.0, mspe:6.507284763823309e+16\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03053elapse: 0.304 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4960, 168, 1)\n",
      "Epoch 5, mse:0.005048716440796852, mae:0.05062754079699516, rmse:0.07105431705713272, mape:141217632.0, mspe:6.545202453099315e+16\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03054elapse: 0.303 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4960, 168, 1)\n",
      "Epoch 6, mse:0.005048295482993126, mae:0.05059798061847687, rmse:0.07105135917663574, mape:140829680.0, mspe:6.49901566328832e+16\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.03052elapse: 0.305 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4960, 168, 1)\n",
      "Epoch 7, mse:0.005076537374407053, mae:0.050418417900800705, rmse:0.071249820291996, mape:141740320.0, mspe:6.531012310650061e+16\n",
      "Iteration best metrics: [0.0050459960475564, 0.05070152506232262, 0.07103517651557922, 140448304.0, 6.494901514115482e+16]\n",
      "train 11948\n",
      "test 4966\n",
      "168 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on DEWINDh_small with pred_len 336\n",
      "[Info] Number of parameters: 9456384\n",
      "train 11780\n",
      "test 4798\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06259elapse: 0.296 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4768, 336, 1)\n",
      "Epoch 0, mse:0.008779049851000309, mae:0.07191208004951477, rmse:0.09369658678770065, mape:281764064.0, mspe:2.575496552298578e+17\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.02959elapse: 0.300 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4768, 336, 1)\n",
      "Epoch 1, mse:0.0063384114764630795, mae:0.05949108675122261, rmse:0.07961414009332657, mape:193176256.0, mspe:1.2091346550521856e+17\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.02858elapse: 0.304 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4768, 336, 1)\n",
      "Epoch 2, mse:0.006074573379009962, mae:0.05762433260679245, rmse:0.07793954759836197, mape:185068720.0, mspe:1.0922996045919027e+17\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.02845elapse: 0.307 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4768, 336, 1)\n",
      "Epoch 3, mse:0.006055638659745455, mae:0.05726953223347664, rmse:0.07781798392534256, mape:184412064.0, mspe:1.0802305746914509e+17\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.02840elapse: 0.299 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4768, 336, 1)\n",
      "Epoch 4, mse:0.006048116367310286, mae:0.0574568510055542, rmse:0.07776963710784912, mape:185178960.0, mspe:1.0910356816160358e+17\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.02842elapse: 0.290 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4768, 336, 1)\n",
      "Epoch 5, mse:0.006048206239938736, mae:0.05734700709581375, rmse:0.07777021080255508, mape:184229360.0, mspe:1.0790948994390426e+17\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.02838elapse: 0.304 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4768, 336, 1)\n",
      "Epoch 6, mse:0.006046787835657597, mae:0.057311899960041046, rmse:0.07776109129190445, mape:184240864.0, mspe:1.079444423877591e+17\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.02842elapse: 0.307 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4768, 336, 1)\n",
      "Epoch 7, mse:0.006051946431398392, mae:0.05715043470263481, rmse:0.07779425382614136, mape:182934608.0, mspe:1.0640839028401766e+17\n",
      "Iteration best metrics: [0.006046787835657597, 0.057311899960041046, 0.07776109129190445, 184240864.0, 1.079444423877591e+17]\n",
      "train 11780\n",
      "test 4798\n",
      "168 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on DEWINDh_small with pred_len 720\n",
      "[Info] Number of parameters: 10242816\n",
      "train 11396\n",
      "test 4414\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05795elapse: 0.289 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4384, 720, 1)\n",
      "Epoch 0, mse:0.008786574006080627, mae:0.07297232747077942, rmse:0.09373673051595688, mape:285478144.0, mspe:2.6128452443072102e+17\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.02605elapse: 0.288 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4384, 720, 1)\n",
      "Epoch 1, mse:0.0067958165891468525, mae:0.062416836619377136, rmse:0.08243674039840698, mape:217408624.0, mspe:1.485975018453074e+17\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.02514elapse: 0.293 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4384, 720, 1)\n",
      "Epoch 2, mse:0.0065933275036513805, mae:0.061682600528001785, rmse:0.08119931071996689, mape:209309056.0, mspe:1.383012798258217e+17\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.02498elapse: 0.291 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4384, 720, 1)\n",
      "Epoch 3, mse:0.0065722158178687096, mae:0.06129469349980354, rmse:0.08106920123100281, mape:206356992.0, mspe:1.34151808841941e+17\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.02496elapse: 0.291 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4384, 720, 1)\n",
      "Epoch 4, mse:0.006572337821125984, mae:0.06125819310545921, rmse:0.0810699537396431, mape:206162656.0, mspe:1.3374821935507046e+17\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.02502elapse: 0.295 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4384, 720, 1)\n",
      "Epoch 5, mse:0.00656390655785799, mae:0.06131308153271675, rmse:0.08101794123649597, mape:207065360.0, mspe:1.34979431860011e+17\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.02501elapse: 0.288 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4384, 720, 1)\n",
      "Epoch 6, mse:0.0065668560564517975, mae:0.06140758469700813, rmse:0.08103614300489426, mape:207648528.0, mspe:1.357121532807086e+17\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.02498elapse: 0.288 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(4384, 720, 1)\n",
      "Epoch 7, mse:0.0065771895460784435, mae:0.06114271655678749, rmse:0.08109987527132034, mape:206113088.0, mspe:1.3346227761237197e+17\n",
      "Iteration best metrics: [0.00656390655785799, 0.06131308153271675, 0.08101794123649597, 207065360.0, 1.34979431860011e+17]\n",
      "train 11396\n",
      "test 4414\n",
      "168 720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Moving to next...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    'SYNTHh1': './SYNTHDataset/',\n",
    "    'DEWINDh_small': './WINDataset/' ,\n",
    "    'SYNTH_additive' : './SYNTHDataset/' , \n",
    "    'SYNTH_multiplicative' : './SYNTHDataset/' \n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "\n",
    "models = [PyraformerTS]\n",
    "\n",
    "result_dict_pyraformer = {}\n",
    "\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "\n",
    "    for dataset_name, dataset_path in datasets.items():\n",
    "        for pred_len in pred_lens:\n",
    "            print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "            # High amount of epochs to accomodate all models\n",
    "            # Early stopping should kick in anyways\n",
    "            model.fit(\n",
    "                data=dataset_name,\n",
    "                data_root_path=dataset_path,\n",
    "                batch_size=32,\n",
    "                epochs=8, \n",
    "                pred_len=pred_len\n",
    "            )\n",
    "\n",
    "            pred_name = 'prediction_' + f'{transformermodel.__name__}_{dataset_name}_{pred_len}'\n",
    "            true_name = 'true_' + f'{transformermodel.__name__}_{dataset_name}_{pred_len}'\n",
    "            \n",
    "\n",
    "            predictions , trues = model.predict()\n",
    "\n",
    "            result_dict_pyraformer[pred_name] = predictions\n",
    "            result_dict_pyraformer[true_name] = trues\n",
    "            \n",
    "\n",
    "            print(f'\\nMoving to next...\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data_dict_pyraformer.pickle'\n",
    "\n",
    "with open(file_path , 'wb') as file:\n",
    "    pickle.dump(result_dict_pyraformer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5110, 24, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_pyraformer['prediction_PyraformerTS_DEWINDh_small_24'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './results/Pyraformer_results/'\n",
    "os.mkdir(folder_path)\n",
    "\n",
    "for name , array in result_dict_pyraformer.items():\n",
    "    np.save(folder_path+ name + '_pred.npy', array)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ansb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
