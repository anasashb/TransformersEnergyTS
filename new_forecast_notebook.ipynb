{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('seaborn-v0_8')\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# MSE function \n",
    "def MSE(pred, true):\n",
    "    return np.mean((pred-true)**2)\n",
    "\n",
    "random_seed = 100\n",
    "torch.manual_seed = 100\n",
    "np.random.seed = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InformerAPI import InformerTS\n",
    "from CrossformerAPI import CrossformerTS\n",
    "from AutoformerAPI import AutoformerTS\n",
    "from FedformerAPI import FedformerTS\n",
    "from PyraformerAPI import PyraformerTS\n",
    "from LogSparseAPI import LogsparseTS\n",
    "#from TSMixerAPI import TSMixer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping models in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'ETTh1': ['./ETTDataset/' , 'M' , 'OT' , 96 , 7 , 7 , 7] ,\n",
    "    'DEWINDh_small': ['./WINDataset/' , 'S' , 'TARGET' , 168, 1 , 1 , 1] ,\n",
    "    'SYNTHh1': ['./SYNTHDataset/', 'S' , 'TARGET' , 168, 1 , 1 , 1] ,\n",
    "    'SYNTH_additive' : ['./SYNTHDataset/', 'S' , 'TARGET' , 168, 1 , 1 , 1] ,\n",
    "    'SYNTH_additive_reversal' : ['./SYNTHDataset/', 'S' , 'TARGET' , 168, 1 , 1 , 1] ,\n",
    "    'SYNTH_multiplicative' : ['./SYNTHDataset/', 'S' , 'TARGET' , 168, 1 , 1 , 1] ,\n",
    "    'SYNTH_multiplicative_reversal' : ['./SYNTHDataset/', 'S' , 'TARGET' , 168, 1 , 1 , 1]\n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "models = [AutoformerTS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: AutoformerTS\n",
      "Training AutoformerTS on ETTh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'OT', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'data': 'ETTh1', 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "\titers: 100, epoch: 1 | loss: 0.2879450\n",
      "\tspeed: 0.0374s/iter; left time: 195.4952s\n",
      "\titers: 200, epoch: 1 | loss: 0.2767665\n",
      "\tspeed: 0.0356s/iter; left time: 182.3707s\n",
      "Epoch: 1 cost time: 9.771218061447144\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.3361786 Vali Loss: 0.7242097 Test Loss: 0.5203117\n",
      "Validation loss decreased (inf --> 0.724210).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2924454\n",
      "\tspeed: 0.1293s/iter; left time: 640.6110s\n",
      "\titers: 200, epoch: 2 | loss: 0.2821071\n",
      "\tspeed: 0.0352s/iter; left time: 170.6703s\n",
      "Epoch: 2 cost time: 8.98215365409851\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.2852847 Vali Loss: 0.7368805 Test Loss: 0.4932018\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2447995\n",
      "\tspeed: 0.1180s/iter; left time: 553.2337s\n",
      "\titers: 200, epoch: 3 | loss: 0.2444603\n",
      "\tspeed: 0.0342s/iter; left time: 157.0695s\n",
      "Epoch: 3 cost time: 8.814702987670898\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.2576373 Vali Loss: 0.7179383 Test Loss: 0.4785379\n",
      "Validation loss decreased (0.724210 --> 0.717938).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2117856\n",
      "\tspeed: 0.1255s/iter; left time: 555.0958s\n",
      "\titers: 200, epoch: 4 | loss: 0.2520900\n",
      "\tspeed: 0.0337s/iter; left time: 145.7747s\n",
      "Epoch: 4 cost time: 8.99317193031311\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.2374988 Vali Loss: 0.7923480 Test Loss: 0.4745897\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2471772\n",
      "\tspeed: 0.1219s/iter; left time: 506.7054s\n",
      "\titers: 200, epoch: 5 | loss: 0.1883743\n",
      "\tspeed: 0.0351s/iter; left time: 142.3701s\n",
      "Epoch: 5 cost time: 9.158600330352783\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.2262122 Vali Loss: 0.8509969 Test Loss: 0.5083204\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2195345\n",
      "\tspeed: 0.1206s/iter; left time: 469.2519s\n",
      "\titers: 200, epoch: 6 | loss: 0.2323942\n",
      "\tspeed: 0.0354s/iter; left time: 134.2670s\n",
      "Epoch: 6 cost time: 9.048738718032837\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.2207680 Vali Loss: 0.8899320 Test Loss: 0.5340682\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "mse:0.47853782773017883, mae:0.4485307037830353\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on ETTh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'OT', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'data': 'ETTh1', 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_ETTh1_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "\titers: 100, epoch: 1 | loss: 0.3051757\n",
      "\tspeed: 0.0341s/iter; left time: 177.2873s\n",
      "\titers: 200, epoch: 1 | loss: 0.3439164\n",
      "\tspeed: 0.0368s/iter; left time: 187.5117s\n",
      "Epoch: 1 cost time: 9.474007368087769\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.3588470 Vali Loss: 0.7379469 Test Loss: 0.4526164\n",
      "Validation loss decreased (inf --> 0.737947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2774311\n",
      "\tspeed: 0.1362s/iter; left time: 672.1576s\n",
      "\titers: 200, epoch: 2 | loss: 0.3368217\n",
      "\tspeed: 0.0378s/iter; left time: 183.0286s\n",
      "Epoch: 2 cost time: 9.8991219997406\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.3078374 Vali Loss: 0.6867449 Test Loss: 0.4135805\n",
      "Validation loss decreased (0.737947 --> 0.686745).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2344305\n",
      "\tspeed: 0.1357s/iter; left time: 633.8889s\n",
      "\titers: 200, epoch: 3 | loss: 0.2608588\n",
      "\tspeed: 0.0384s/iter; left time: 175.4438s\n",
      "Epoch: 3 cost time: 10.191767454147339\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.2747488 Vali Loss: 0.6978077 Test Loss: 0.4374175\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2255806\n",
      "\tspeed: 0.1367s/iter; left time: 602.2847s\n",
      "\titers: 200, epoch: 4 | loss: 0.2643861\n",
      "\tspeed: 0.0371s/iter; left time: 159.7934s\n",
      "Epoch: 4 cost time: 9.81331205368042\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.2522600 Vali Loss: 0.7108472 Test Loss: 0.4669172\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2571391\n",
      "\tspeed: 0.1271s/iter; left time: 526.4117s\n",
      "\titers: 200, epoch: 5 | loss: 0.2289230\n",
      "\tspeed: 0.0389s/iter; left time: 157.2051s\n",
      "Epoch: 5 cost time: 9.780170917510986\n",
      "Epoch: 5, Steps: 265 | Train Loss: 0.2391903 Vali Loss: 0.7347507 Test Loss: 0.4783042\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (2816, 48, 7) (2816, 48, 7)\n",
      "test shape: (2816, 48, 7) (2816, 48, 7)\n",
      "mse:0.41358044743537903, mae:0.4358625113964081\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on ETTh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'OT', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'data': 'ETTh1', 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_ETTh1_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "\titers: 100, epoch: 1 | loss: 0.4494362\n",
      "\tspeed: 0.0604s/iter; left time: 309.4213s\n",
      "\titers: 200, epoch: 1 | loss: 0.4381880\n",
      "\tspeed: 0.0583s/iter; left time: 292.8255s\n",
      "Epoch: 1 cost time: 15.474979400634766\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.4677282 Vali Loss: 1.0698793 Test Loss: 0.4954297\n",
      "Validation loss decreased (inf --> 1.069879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3866825\n",
      "\tspeed: 0.2079s/iter; left time: 1010.1737s\n",
      "\titers: 200, epoch: 2 | loss: 0.3700078\n",
      "\tspeed: 0.0562s/iter; left time: 267.7425s\n",
      "Epoch: 2 cost time: 14.293169975280762\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.4266372 Vali Loss: 1.0726771 Test Loss: 0.4703319\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4431810\n",
      "\tspeed: 0.2394s/iter; left time: 1101.1428s\n",
      "\titers: 200, epoch: 3 | loss: 0.3930769\n",
      "\tspeed: 0.0578s/iter; left time: 259.9437s\n",
      "Epoch: 3 cost time: 14.532039403915405\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.4009824 Vali Loss: 1.0919298 Test Loss: 0.4981135\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3676075\n",
      "\tspeed: 0.2068s/iter; left time: 897.1635s\n",
      "\titers: 200, epoch: 4 | loss: 0.3524654\n",
      "\tspeed: 0.0557s/iter; left time: 235.9205s\n",
      "Epoch: 4 cost time: 14.61699366569519\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.3697692 Vali Loss: 1.1484097 Test Loss: 0.5475820\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (2688, 168, 7) (2688, 168, 7)\n",
      "test shape: (2688, 168, 7) (2688, 168, 7)\n",
      "mse:0.4954299032688141, mae:0.4759543538093567\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on ETTh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'OT', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'data': 'ETTh1', 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_ETTh1_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.5936797\n",
      "\tspeed: 0.0811s/iter; left time: 407.2980s\n",
      "\titers: 200, epoch: 1 | loss: 0.5110383\n",
      "\tspeed: 0.0796s/iter; left time: 391.6096s\n",
      "Epoch: 1 cost time: 21.053555488586426\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.5532289 Vali Loss: 1.4004278 Test Loss: 0.5240902\n",
      "Validation loss decreased (inf --> 1.400428).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5856047\n",
      "\tspeed: 0.3197s/iter; left time: 1523.5861s\n",
      "\titers: 200, epoch: 2 | loss: 0.4821129\n",
      "\tspeed: 0.0820s/iter; left time: 382.5016s\n",
      "Epoch: 2 cost time: 20.805050373077393\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.5176986 Vali Loss: 1.3879133 Test Loss: 0.5157307\n",
      "Validation loss decreased (1.400428 --> 1.387913).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4961524\n",
      "\tspeed: 0.3226s/iter; left time: 1454.7102s\n",
      "\titers: 200, epoch: 3 | loss: 0.5368906\n",
      "\tspeed: 0.0809s/iter; left time: 356.7119s\n",
      "Epoch: 3 cost time: 21.132527112960815\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.5064261 Vali Loss: 1.4167503 Test Loss: 0.5358295\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5089315\n",
      "\tspeed: 0.3191s/iter; left time: 1357.2570s\n",
      "\titers: 200, epoch: 4 | loss: 0.5061218\n",
      "\tspeed: 0.0826s/iter; left time: 343.0722s\n",
      "Epoch: 4 cost time: 20.951124906539917\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.4992806 Vali Loss: 1.4300305 Test Loss: 0.5386923\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4492778\n",
      "\tspeed: 0.3258s/iter; left time: 1302.1496s\n",
      "\titers: 200, epoch: 5 | loss: 0.4826877\n",
      "\tspeed: 0.0852s/iter; left time: 332.0172s\n",
      "Epoch: 5 cost time: 21.828645944595337\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.4949543 Vali Loss: 1.4315208 Test Loss: 0.5362535\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "mse:0.5157306790351868, mae:0.4991512596607208\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on ETTh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'OT', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'data': 'ETTh1', 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_ETTh1_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "\titers: 100, epoch: 1 | loss: 0.6308783\n",
      "\tspeed: 0.1287s/iter; left time: 615.4880s\n",
      "\titers: 200, epoch: 1 | loss: 0.7123561\n",
      "\tspeed: 0.1276s/iter; left time: 597.2239s\n",
      "Epoch: 1 cost time: 31.228973627090454\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.6644396 Vali Loss: 1.6509809 Test Loss: 0.5283195\n",
      "Validation loss decreased (inf --> 1.650981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6899204\n",
      "\tspeed: 0.4060s/iter; left time: 1842.0218s\n",
      "\titers: 200, epoch: 2 | loss: 0.5835651\n",
      "\tspeed: 0.1295s/iter; left time: 574.5453s\n",
      "Epoch: 2 cost time: 30.876436471939087\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.6308967 Vali Loss: 1.6346858 Test Loss: 0.5226893\n",
      "Validation loss decreased (1.650981 --> 1.634686).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.7155064\n",
      "\tspeed: 0.4150s/iter; left time: 1781.7790s\n",
      "\titers: 200, epoch: 3 | loss: 0.6597000\n",
      "\tspeed: 0.1312s/iter; left time: 550.1535s\n",
      "Epoch: 3 cost time: 31.487828254699707\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.6226924 Vali Loss: 1.6503984 Test Loss: 0.5214353\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5523286\n",
      "\tspeed: 0.4203s/iter; left time: 1701.7225s\n",
      "\titers: 200, epoch: 4 | loss: 0.7018841\n",
      "\tspeed: 0.1261s/iter; left time: 498.0674s\n",
      "Epoch: 4 cost time: 30.886884927749634\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.6176955 Vali Loss: 1.6394510 Test Loss: 0.5209810\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5824240\n",
      "\tspeed: 0.4329s/iter; left time: 1647.3249s\n",
      "\titers: 200, epoch: 5 | loss: 0.7313803\n",
      "\tspeed: 0.1281s/iter; left time: 474.5639s\n",
      "Epoch: 5 cost time: 31.028934240341187\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.6148791 Vali Loss: 1.6477898 Test Loss: 0.5219923\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "mse:0.5226896405220032, mae:0.5224161744117737\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on DEWINDh_small with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'data': 'DEWINDh_small', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_DEWINDh_small_ftS_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.1879472\n",
      "\tspeed: 0.0467s/iter; left time: 368.3357s\n",
      "\titers: 200, epoch: 1 | loss: 0.1880155\n",
      "\tspeed: 0.0463s/iter; left time: 360.5059s\n",
      "\titers: 300, epoch: 1 | loss: 0.2011364\n",
      "\tspeed: 0.0478s/iter; left time: 367.2416s\n",
      "Epoch: 1 cost time: 18.645655870437622\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.2306382 Vali Loss: 0.1942691 Test Loss: 0.1572206\n",
      "Validation loss decreased (inf --> 0.194269).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2013232\n",
      "\tspeed: 0.1505s/iter; left time: 1125.8775s\n",
      "\titers: 200, epoch: 2 | loss: 0.1725045\n",
      "\tspeed: 0.0461s/iter; left time: 340.5560s\n",
      "\titers: 300, epoch: 2 | loss: 0.1742494\n",
      "\tspeed: 0.0475s/iter; left time: 345.7063s\n",
      "Epoch: 2 cost time: 18.95637321472168\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.1641557 Vali Loss: 0.1818044 Test Loss: 0.1696166\n",
      "Validation loss decreased (0.194269 --> 0.181804).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1776782\n",
      "\tspeed: 0.1658s/iter; left time: 1174.4619s\n",
      "\titers: 200, epoch: 3 | loss: 0.1092502\n",
      "\tspeed: 0.0460s/iter; left time: 321.3741s\n",
      "\titers: 300, epoch: 3 | loss: 0.1396679\n",
      "\tspeed: 0.0471s/iter; left time: 324.0282s\n",
      "Epoch: 3 cost time: 18.575137853622437\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.1453874 Vali Loss: 0.1636536 Test Loss: 0.1764268\n",
      "Validation loss decreased (0.181804 --> 0.163654).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1351768\n",
      "\tspeed: 0.1532s/iter; left time: 1023.7051s\n",
      "\titers: 200, epoch: 4 | loss: 0.1735599\n",
      "\tspeed: 0.0458s/iter; left time: 301.7269s\n",
      "\titers: 300, epoch: 4 | loss: 0.1671620\n",
      "\tspeed: 0.0449s/iter; left time: 291.4117s\n",
      "Epoch: 4 cost time: 18.108304023742676\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.1363890 Vali Loss: 0.1557309 Test Loss: 0.1875984\n",
      "Validation loss decreased (0.163654 --> 0.155731).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1385321\n",
      "\tspeed: 0.1572s/iter; left time: 987.8389s\n",
      "\titers: 200, epoch: 5 | loss: 0.1161752\n",
      "\tspeed: 0.0479s/iter; left time: 296.0759s\n",
      "\titers: 300, epoch: 5 | loss: 0.1415356\n",
      "\tspeed: 0.0480s/iter; left time: 292.3049s\n",
      "Epoch: 5 cost time: 19.08552885055542\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.1319582 Vali Loss: 0.1599119 Test Loss: 0.1976715\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1583056\n",
      "\tspeed: 0.1552s/iter; left time: 913.7372s\n",
      "\titers: 200, epoch: 6 | loss: 0.1107758\n",
      "\tspeed: 0.0478s/iter; left time: 276.4420s\n",
      "\titers: 300, epoch: 6 | loss: 0.1089567\n",
      "\tspeed: 0.0475s/iter; left time: 269.9727s\n",
      "Epoch: 6 cost time: 18.86349129676819\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.1290715 Vali Loss: 0.1615270 Test Loss: 0.2023305\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2043276\n",
      "\tspeed: 0.1518s/iter; left time: 832.8563s\n",
      "\titers: 200, epoch: 7 | loss: 0.1643486\n",
      "\tspeed: 0.0467s/iter; left time: 251.4630s\n",
      "\titers: 300, epoch: 7 | loss: 0.0851768\n",
      "\tspeed: 0.0463s/iter; left time: 244.5243s\n",
      "Epoch: 7 cost time: 18.658707857131958\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.1279514 Vali Loss: 0.1611520 Test Loss: 0.1985589\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.18759839236736298, mae:0.28762030601501465\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on DEWINDh_small with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'data': 'DEWINDh_small', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 48, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_DEWINDh_small_ftS_sl168_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.2954328\n",
      "\tspeed: 0.0520s/iter; left time: 408.6064s\n",
      "\titers: 200, epoch: 1 | loss: 0.2550541\n",
      "\tspeed: 0.0508s/iter; left time: 394.5180s\n",
      "\titers: 300, epoch: 1 | loss: 0.2003826\n",
      "\tspeed: 0.0514s/iter; left time: 393.9137s\n",
      "Epoch: 1 cost time: 20.222564220428467\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.2685870 Vali Loss: 0.2476790 Test Loss: 0.1986491\n",
      "Validation loss decreased (inf --> 0.247679).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2237025\n",
      "\tspeed: 0.1629s/iter; left time: 1215.4723s\n",
      "\titers: 200, epoch: 2 | loss: 0.1843551\n",
      "\tspeed: 0.0494s/iter; left time: 363.4350s\n",
      "\titers: 300, epoch: 2 | loss: 0.1914826\n",
      "\tspeed: 0.0478s/iter; left time: 347.1892s\n",
      "Epoch: 2 cost time: 19.341105937957764\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.1872601 Vali Loss: 0.2178869 Test Loss: 0.1739612\n",
      "Validation loss decreased (0.247679 --> 0.217887).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1594315\n",
      "\tspeed: 0.1481s/iter; left time: 1046.4368s\n",
      "\titers: 200, epoch: 3 | loss: 0.1991730\n",
      "\tspeed: 0.0444s/iter; left time: 309.0037s\n",
      "\titers: 300, epoch: 3 | loss: 0.1761413\n",
      "\tspeed: 0.0431s/iter; left time: 295.6139s\n",
      "Epoch: 3 cost time: 17.650967121124268\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.1660969 Vali Loss: 0.1972954 Test Loss: 0.1801857\n",
      "Validation loss decreased (0.217887 --> 0.197295).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1422036\n",
      "\tspeed: 0.1537s/iter; left time: 1024.4944s\n",
      "\titers: 200, epoch: 4 | loss: 0.1191981\n",
      "\tspeed: 0.0473s/iter; left time: 310.5474s\n",
      "\titers: 300, epoch: 4 | loss: 0.1635019\n",
      "\tspeed: 0.0476s/iter; left time: 308.1440s\n",
      "Epoch: 4 cost time: 19.007824897766113\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.1571017 Vali Loss: 0.1913523 Test Loss: 0.1833766\n",
      "Validation loss decreased (0.197295 --> 0.191352).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1511413\n",
      "\tspeed: 0.1685s/iter; left time: 1056.3465s\n",
      "\titers: 200, epoch: 5 | loss: 0.1721254\n",
      "\tspeed: 0.0469s/iter; left time: 289.3003s\n",
      "\titers: 300, epoch: 5 | loss: 0.1964220\n",
      "\tspeed: 0.0465s/iter; left time: 282.0285s\n",
      "Epoch: 5 cost time: 18.785135507583618\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.1526304 Vali Loss: 0.1916203 Test Loss: 0.1900031\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1580312\n",
      "\tspeed: 0.1564s/iter; left time: 918.4628s\n",
      "\titers: 200, epoch: 6 | loss: 0.1510141\n",
      "\tspeed: 0.0489s/iter; left time: 282.2980s\n",
      "\titers: 300, epoch: 6 | loss: 0.1598193\n",
      "\tspeed: 0.0488s/iter; left time: 277.0026s\n",
      "Epoch: 6 cost time: 19.44082498550415\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.1497151 Vali Loss: 0.1894278 Test Loss: 0.1864746\n",
      "Validation loss decreased (0.191352 --> 0.189428).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1490746\n",
      "\tspeed: 0.1588s/iter; left time: 868.8779s\n",
      "\titers: 200, epoch: 7 | loss: 0.1359453\n",
      "\tspeed: 0.0452s/iter; left time: 242.6199s\n",
      "\titers: 300, epoch: 7 | loss: 0.1356516\n",
      "\tspeed: 0.0430s/iter; left time: 226.7249s\n",
      "Epoch: 7 cost time: 17.923726320266724\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.1474164 Vali Loss: 0.1885515 Test Loss: 0.1883655\n",
      "Validation loss decreased (0.189428 --> 0.188552).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1112334\n",
      "\tspeed: 0.1597s/iter; left time: 810.5684s\n",
      "\titers: 200, epoch: 8 | loss: 0.1420163\n",
      "\tspeed: 0.0486s/iter; left time: 241.9169s\n",
      "\titers: 300, epoch: 8 | loss: 0.1318831\n",
      "\tspeed: 0.0492s/iter; left time: 239.8638s\n",
      "Epoch: 8 cost time: 19.375895500183105\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.1464428 Vali Loss: 0.1886014 Test Loss: 0.1847363\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1778838\n",
      "\tspeed: 0.1580s/iter; left time: 738.7889s\n",
      "\titers: 200, epoch: 9 | loss: 0.1648781\n",
      "\tspeed: 0.0489s/iter; left time: 223.6340s\n",
      "\titers: 300, epoch: 9 | loss: 0.1689938\n",
      "\tspeed: 0.0482s/iter; left time: 215.5796s\n",
      "Epoch: 9 cost time: 19.128878355026245\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.1458001 Vali Loss: 0.1883410 Test Loss: 0.1862803\n",
      "Validation loss decreased (0.188552 --> 0.188341).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1172248\n",
      "\tspeed: 0.1546s/iter; left time: 661.3691s\n",
      "\titers: 200, epoch: 10 | loss: 0.1393289\n",
      "\tspeed: 0.0471s/iter; left time: 196.9516s\n",
      "\titers: 300, epoch: 10 | loss: 0.1759012\n",
      "\tspeed: 0.0470s/iter; left time: 191.6802s\n",
      "Epoch: 10 cost time: 18.143301248550415\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.1454494 Vali Loss: 0.1873610 Test Loss: 0.1890353\n",
      "Validation loss decreased (0.188341 --> 0.187361).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1437508\n",
      "\tspeed: 0.1460s/iter; left time: 566.4786s\n",
      "\titers: 200, epoch: 11 | loss: 0.1139562\n",
      "\tspeed: 0.0461s/iter; left time: 174.3601s\n",
      "\titers: 300, epoch: 11 | loss: 0.1527399\n",
      "\tspeed: 0.0454s/iter; left time: 167.2808s\n",
      "Epoch: 11 cost time: 18.224945068359375\n",
      "Epoch: 11, Steps: 398 | Train Loss: 0.1455393 Vali Loss: 0.1881347 Test Loss: 0.1867486\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.1416298\n",
      "\tspeed: 0.1558s/iter; left time: 542.6439s\n",
      "\titers: 200, epoch: 12 | loss: 0.1510541\n",
      "\tspeed: 0.0474s/iter; left time: 160.3583s\n",
      "\titers: 300, epoch: 12 | loss: 0.1396123\n",
      "\tspeed: 0.0472s/iter; left time: 155.0384s\n",
      "Epoch: 12 cost time: 18.828320026397705\n",
      "Epoch: 12, Steps: 398 | Train Loss: 0.1456511 Vali Loss: 0.1875942 Test Loss: 0.1861556\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.1348271\n",
      "\tspeed: 0.1580s/iter; left time: 487.3659s\n",
      "\titers: 200, epoch: 13 | loss: 0.1718378\n",
      "\tspeed: 0.0490s/iter; left time: 146.2225s\n",
      "\titers: 300, epoch: 13 | loss: 0.1197954\n",
      "\tspeed: 0.0483s/iter; left time: 139.3098s\n",
      "Epoch: 13 cost time: 19.23638653755188\n",
      "Epoch: 13, Steps: 398 | Train Loss: 0.1453977 Vali Loss: 0.1876545 Test Loss: 0.1863545\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.1890352964401245, mae:0.2781355381011963\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on DEWINDh_small with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'data': 'DEWINDh_small', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 168, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_DEWINDh_small_ftS_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.2250177\n",
      "\tspeed: 0.0604s/iter; left time: 469.6128s\n",
      "\titers: 200, epoch: 1 | loss: 0.2050779\n",
      "\tspeed: 0.0578s/iter; left time: 443.9682s\n",
      "\titers: 300, epoch: 1 | loss: 0.2078712\n",
      "\tspeed: 0.0586s/iter; left time: 444.3860s\n",
      "Epoch: 1 cost time: 23.284239530563354\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.2390082 Vali Loss: 0.2478995 Test Loss: 0.2141987\n",
      "Validation loss decreased (inf --> 0.247899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1850397\n",
      "\tspeed: 0.1921s/iter; left time: 1418.7078s\n",
      "\titers: 200, epoch: 2 | loss: 0.1755692\n",
      "\tspeed: 0.0610s/iter; left time: 444.2963s\n",
      "\titers: 300, epoch: 2 | loss: 0.1813963\n",
      "\tspeed: 0.0602s/iter; left time: 432.4929s\n",
      "Epoch: 2 cost time: 23.556436777114868\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.1819845 Vali Loss: 0.2216373 Test Loss: 0.2294317\n",
      "Validation loss decreased (0.247899 --> 0.221637).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1356656\n",
      "\tspeed: 0.1918s/iter; left time: 1341.5254s\n",
      "\titers: 200, epoch: 3 | loss: 0.1527245\n",
      "\tspeed: 0.0588s/iter; left time: 405.4203s\n",
      "\titers: 300, epoch: 3 | loss: 0.1538492\n",
      "\tspeed: 0.0586s/iter; left time: 398.0652s\n",
      "Epoch: 3 cost time: 23.229333639144897\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.1672002 Vali Loss: 0.2113539 Test Loss: 0.2108268\n",
      "Validation loss decreased (0.221637 --> 0.211354).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1605982\n",
      "\tspeed: 0.1851s/iter; left time: 1221.4587s\n",
      "\titers: 200, epoch: 4 | loss: 0.1299451\n",
      "\tspeed: 0.0584s/iter; left time: 379.2319s\n",
      "\titers: 300, epoch: 4 | loss: 0.1532980\n",
      "\tspeed: 0.0601s/iter; left time: 384.6333s\n",
      "Epoch: 4 cost time: 23.394829034805298\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.1612520 Vali Loss: 0.2076108 Test Loss: 0.1966330\n",
      "Validation loss decreased (0.211354 --> 0.207611).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1473828\n",
      "\tspeed: 0.1948s/iter; left time: 1209.0092s\n",
      "\titers: 200, epoch: 5 | loss: 0.1543759\n",
      "\tspeed: 0.0608s/iter; left time: 370.9930s\n",
      "\titers: 300, epoch: 5 | loss: 0.1713538\n",
      "\tspeed: 0.0597s/iter; left time: 358.2265s\n",
      "Epoch: 5 cost time: 23.489635229110718\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.1582520 Vali Loss: 0.2044929 Test Loss: 0.1983505\n",
      "Validation loss decreased (0.207611 --> 0.204493).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1805633\n",
      "\tspeed: 0.1828s/iter; left time: 1062.4075s\n",
      "\titers: 200, epoch: 6 | loss: 0.1450066\n",
      "\tspeed: 0.0576s/iter; left time: 328.8224s\n",
      "\titers: 300, epoch: 6 | loss: 0.1590468\n",
      "\tspeed: 0.0576s/iter; left time: 323.0056s\n",
      "Epoch: 6 cost time: 22.353834629058838\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.1570942 Vali Loss: 0.2096996 Test Loss: 0.1995158\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1611879\n",
      "\tspeed: 0.1796s/iter; left time: 972.7850s\n",
      "\titers: 200, epoch: 7 | loss: 0.1723894\n",
      "\tspeed: 0.0571s/iter; left time: 303.7745s\n",
      "\titers: 300, epoch: 7 | loss: 0.1754967\n",
      "\tspeed: 0.0586s/iter; left time: 305.4852s\n",
      "Epoch: 7 cost time: 22.640387773513794\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.1562187 Vali Loss: 0.2092200 Test Loss: 0.1967550\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1505527\n",
      "\tspeed: 0.1838s/iter; left time: 923.2043s\n",
      "\titers: 200, epoch: 8 | loss: 0.1725054\n",
      "\tspeed: 0.0590s/iter; left time: 290.2770s\n",
      "\titers: 300, epoch: 8 | loss: 0.1326495\n",
      "\tspeed: 0.0590s/iter; left time: 284.6238s\n",
      "Epoch: 8 cost time: 23.203739404678345\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.1560142 Vali Loss: 0.2056954 Test Loss: 0.1963832\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.19835054874420166, mae:0.28599783778190613\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on DEWINDh_small with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'data': 'DEWINDh_small', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 336, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_DEWINDh_small_ftS_sl168_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.2676300\n",
      "\tspeed: 0.0898s/iter; left time: 689.7499s\n",
      "\titers: 200, epoch: 1 | loss: 0.2875618\n",
      "\tspeed: 0.0878s/iter; left time: 665.6831s\n",
      "\titers: 300, epoch: 1 | loss: 0.2602168\n",
      "\tspeed: 0.0879s/iter; left time: 657.6399s\n",
      "Epoch: 1 cost time: 34.39821457862854\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.2864226 Vali Loss: 0.2858096 Test Loss: 0.2781618\n",
      "Validation loss decreased (inf --> 0.285810).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2298656\n",
      "\tspeed: 0.2876s/iter; left time: 2096.8946s\n",
      "\titers: 200, epoch: 2 | loss: 0.2180794\n",
      "\tspeed: 0.0877s/iter; left time: 630.6949s\n",
      "\titers: 300, epoch: 2 | loss: 0.2195757\n",
      "\tspeed: 0.0885s/iter; left time: 627.7951s\n",
      "Epoch: 2 cost time: 34.011549949645996\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.2226354 Vali Loss: 0.2532585 Test Loss: 0.2825911\n",
      "Validation loss decreased (0.285810 --> 0.253258).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2225563\n",
      "\tspeed: 0.2856s/iter; left time: 1971.1854s\n",
      "\titers: 200, epoch: 3 | loss: 0.2359263\n",
      "\tspeed: 0.0823s/iter; left time: 559.9645s\n",
      "\titers: 300, epoch: 3 | loss: 0.2001269\n",
      "\tspeed: 0.0772s/iter; left time: 517.3928s\n",
      "Epoch: 3 cost time: 31.294427633285522\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.2060175 Vali Loss: 0.2369647 Test Loss: 0.2752522\n",
      "Validation loss decreased (0.253258 --> 0.236965).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2160693\n",
      "\tspeed: 0.2738s/iter; left time: 1783.4337s\n",
      "\titers: 200, epoch: 4 | loss: 0.2119340\n",
      "\tspeed: 0.0851s/iter; left time: 545.7201s\n",
      "\titers: 300, epoch: 4 | loss: 0.2096220\n",
      "\tspeed: 0.0857s/iter; left time: 540.9703s\n",
      "Epoch: 4 cost time: 33.296664237976074\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.1974585 Vali Loss: 0.2404605 Test Loss: 0.2877727\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1829669\n",
      "\tspeed: 0.2708s/iter; left time: 1658.5858s\n",
      "\titers: 200, epoch: 5 | loss: 0.1969759\n",
      "\tspeed: 0.0887s/iter; left time: 534.2828s\n",
      "\titers: 300, epoch: 5 | loss: 0.2052519\n",
      "\tspeed: 0.0880s/iter; left time: 521.5895s\n",
      "Epoch: 5 cost time: 33.72829508781433\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.1928571 Vali Loss: 0.2306050 Test Loss: 0.2923462\n",
      "Validation loss decreased (0.236965 --> 0.230605).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2082548\n",
      "\tspeed: 0.2827s/iter; left time: 1621.8205s\n",
      "\titers: 200, epoch: 6 | loss: 0.1894281\n",
      "\tspeed: 0.0837s/iter; left time: 471.9085s\n",
      "\titers: 300, epoch: 6 | loss: 0.1954868\n",
      "\tspeed: 0.0826s/iter; left time: 457.3159s\n",
      "Epoch: 6 cost time: 32.351330280303955\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.1907616 Vali Loss: 0.2268233 Test Loss: 0.2990652\n",
      "Validation loss decreased (0.230605 --> 0.226823).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1782099\n",
      "\tspeed: 0.2744s/iter; left time: 1467.3567s\n",
      "\titers: 200, epoch: 7 | loss: 0.1898959\n",
      "\tspeed: 0.0850s/iter; left time: 445.9916s\n",
      "\titers: 300, epoch: 7 | loss: 0.1926059\n",
      "\tspeed: 0.0844s/iter; left time: 434.5526s\n",
      "Epoch: 7 cost time: 32.99626350402832\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.1896689 Vali Loss: 0.2281213 Test Loss: 0.3087325\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1911487\n",
      "\tspeed: 0.2776s/iter; left time: 1376.5276s\n",
      "\titers: 200, epoch: 8 | loss: 0.1819769\n",
      "\tspeed: 0.0825s/iter; left time: 400.6688s\n",
      "\titers: 300, epoch: 8 | loss: 0.2003131\n",
      "\tspeed: 0.0825s/iter; left time: 392.4868s\n",
      "Epoch: 8 cost time: 32.20468592643738\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.1890687 Vali Loss: 0.2280707 Test Loss: 0.3167838\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2195418\n",
      "\tspeed: 0.2777s/iter; left time: 1268.8294s\n",
      "\titers: 200, epoch: 9 | loss: 0.2032604\n",
      "\tspeed: 0.0856s/iter; left time: 382.3467s\n",
      "\titers: 300, epoch: 9 | loss: 0.2166293\n",
      "\tspeed: 0.0886s/iter; left time: 387.3015s\n",
      "Epoch: 9 cost time: 33.67868757247925\n",
      "Epoch: 9, Steps: 389 | Train Loss: 0.1888772 Vali Loss: 0.2293522 Test Loss: 0.3098137\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.29906511306762695, mae:0.3692825734615326\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on DEWINDh_small with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'data': 'DEWINDh_small', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 720, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_DEWINDh_small_ftS_sl168_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.3324706\n",
      "\tspeed: 0.1393s/iter; left time: 1036.7098s\n",
      "\titers: 200, epoch: 1 | loss: 0.2757003\n",
      "\tspeed: 0.1338s/iter; left time: 981.9495s\n",
      "\titers: 300, epoch: 1 | loss: 0.2699082\n",
      "\tspeed: 0.1344s/iter; left time: 973.4980s\n",
      "Epoch: 1 cost time: 51.17605638504028\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.3388614 Vali Loss: 0.2810737 Test Loss: 0.4185686\n",
      "Validation loss decreased (inf --> 0.281074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2370408\n",
      "\tspeed: 0.3876s/iter; left time: 2737.9269s\n",
      "\titers: 200, epoch: 2 | loss: 0.2208134\n",
      "\tspeed: 0.1300s/iter; left time: 905.3021s\n",
      "\titers: 300, epoch: 2 | loss: 0.2408410\n",
      "\tspeed: 0.1306s/iter; left time: 896.3831s\n",
      "Epoch: 2 cost time: 49.0879545211792\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.2345464 Vali Loss: 0.2634892 Test Loss: 0.5953475\n",
      "Validation loss decreased (0.281074 --> 0.263489).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2305294\n",
      "\tspeed: 0.3774s/iter; left time: 2523.6965s\n",
      "\titers: 200, epoch: 3 | loss: 0.1893625\n",
      "\tspeed: 0.1274s/iter; left time: 838.8663s\n",
      "\titers: 300, epoch: 3 | loss: 0.1998353\n",
      "\tspeed: 0.1249s/iter; left time: 810.5216s\n",
      "Epoch: 3 cost time: 47.68355417251587\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.2123130 Vali Loss: 0.2563308 Test Loss: 0.5843624\n",
      "Validation loss decreased (0.263489 --> 0.256331).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2034706\n",
      "\tspeed: 0.3722s/iter; left time: 2348.7119s\n",
      "\titers: 200, epoch: 4 | loss: 0.2069315\n",
      "\tspeed: 0.1276s/iter; left time: 792.1089s\n",
      "\titers: 300, epoch: 4 | loss: 0.2094634\n",
      "\tspeed: 0.1298s/iter; left time: 793.1671s\n",
      "Epoch: 4 cost time: 48.712339878082275\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.2058163 Vali Loss: 0.2550839 Test Loss: 0.6191420\n",
      "Validation loss decreased (0.256331 --> 0.255084).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2080471\n",
      "\tspeed: 0.3681s/iter; left time: 2184.1969s\n",
      "\titers: 200, epoch: 5 | loss: 0.1843627\n",
      "\tspeed: 0.1289s/iter; left time: 751.6858s\n",
      "\titers: 300, epoch: 5 | loss: 0.2074588\n",
      "\tspeed: 0.1275s/iter; left time: 731.0952s\n",
      "Epoch: 5 cost time: 48.488977909088135\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.2027076 Vali Loss: 0.2748521 Test Loss: 0.6782075\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2081933\n",
      "\tspeed: 0.3675s/iter; left time: 2041.8628s\n",
      "\titers: 200, epoch: 6 | loss: 0.1912472\n",
      "\tspeed: 0.1301s/iter; left time: 709.6595s\n",
      "\titers: 300, epoch: 6 | loss: 0.2089219\n",
      "\tspeed: 0.1293s/iter; left time: 692.3370s\n",
      "Epoch: 6 cost time: 48.66227698326111\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.2012932 Vali Loss: 0.2689041 Test Loss: 0.6638484\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2026047\n",
      "\tspeed: 0.3659s/iter; left time: 1894.9604s\n",
      "\titers: 200, epoch: 7 | loss: 0.2069812\n",
      "\tspeed: 0.1306s/iter; left time: 663.1507s\n",
      "\titers: 300, epoch: 7 | loss: 0.1895895\n",
      "\tspeed: 0.1370s/iter; left time: 682.2273s\n",
      "Epoch: 7 cost time: 49.50950884819031\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.2004798 Vali Loss: 0.2597724 Test Loss: 0.6329792\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.6191421151161194, mae:0.6231369972229004\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTHh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'data': 'SYNTHh1', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTHh1_ftS_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.4463296\n",
      "\tspeed: 0.0454s/iter; left time: 358.1126s\n",
      "\titers: 200, epoch: 1 | loss: 0.3419811\n",
      "\tspeed: 0.0463s/iter; left time: 360.4813s\n",
      "\titers: 300, epoch: 1 | loss: 0.2036225\n",
      "\tspeed: 0.0457s/iter; left time: 351.2060s\n",
      "Epoch: 1 cost time: 18.271986961364746\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.3906217 Vali Loss: 0.2267023 Test Loss: 0.2414132\n",
      "Validation loss decreased (inf --> 0.226702).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1438254\n",
      "\tspeed: 0.1540s/iter; left time: 1152.5568s\n",
      "\titers: 200, epoch: 2 | loss: 0.1733589\n",
      "\tspeed: 0.0456s/iter; left time: 336.6613s\n",
      "\titers: 300, epoch: 2 | loss: 0.1477986\n",
      "\tspeed: 0.0448s/iter; left time: 326.0008s\n",
      "Epoch: 2 cost time: 18.06730604171753\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.1528361 Vali Loss: 0.1357263 Test Loss: 0.1374707\n",
      "Validation loss decreased (0.226702 --> 0.135726).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0999496\n",
      "\tspeed: 0.1506s/iter; left time: 1066.5934s\n",
      "\titers: 200, epoch: 3 | loss: 0.0831982\n",
      "\tspeed: 0.0446s/iter; left time: 311.4846s\n",
      "\titers: 300, epoch: 3 | loss: 0.0654550\n",
      "\tspeed: 0.0448s/iter; left time: 308.5826s\n",
      "Epoch: 3 cost time: 17.881171941757202\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0758490 Vali Loss: 0.1264142 Test Loss: 0.1198454\n",
      "Validation loss decreased (0.135726 --> 0.126414).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0489534\n",
      "\tspeed: 0.1494s/iter; left time: 998.3907s\n",
      "\titers: 200, epoch: 4 | loss: 0.0458636\n",
      "\tspeed: 0.0445s/iter; left time: 293.0498s\n",
      "\titers: 300, epoch: 4 | loss: 0.0512691\n",
      "\tspeed: 0.0447s/iter; left time: 289.5965s\n",
      "Epoch: 4 cost time: 17.83573865890503\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0563373 Vali Loss: 0.1182072 Test Loss: 0.1126970\n",
      "Validation loss decreased (0.126414 --> 0.118207).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0478427\n",
      "\tspeed: 0.1384s/iter; left time: 869.9470s\n",
      "\titers: 200, epoch: 5 | loss: 0.0537715\n",
      "\tspeed: 0.0436s/iter; left time: 269.6330s\n",
      "\titers: 300, epoch: 5 | loss: 0.0581147\n",
      "\tspeed: 0.0439s/iter; left time: 267.2380s\n",
      "Epoch: 5 cost time: 17.29510807991028\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0501476 Vali Loss: 0.1083211 Test Loss: 0.1047474\n",
      "Validation loss decreased (0.118207 --> 0.108321).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0418638\n",
      "\tspeed: 0.1509s/iter; left time: 888.1384s\n",
      "\titers: 200, epoch: 6 | loss: 0.0553838\n",
      "\tspeed: 0.0439s/iter; left time: 254.2918s\n",
      "\titers: 300, epoch: 6 | loss: 0.0571449\n",
      "\tspeed: 0.0448s/iter; left time: 254.7107s\n",
      "Epoch: 6 cost time: 17.828445196151733\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0480769 Vali Loss: 0.1089253 Test Loss: 0.1045924\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0488535\n",
      "\tspeed: 0.1579s/iter; left time: 866.1460s\n",
      "\titers: 200, epoch: 7 | loss: 0.0413789\n",
      "\tspeed: 0.0450s/iter; left time: 242.5406s\n",
      "\titers: 300, epoch: 7 | loss: 0.0544881\n",
      "\tspeed: 0.0458s/iter; left time: 242.1945s\n",
      "Epoch: 7 cost time: 18.384265422821045\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0461346 Vali Loss: 0.1104748 Test Loss: 0.1058910\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0417275\n",
      "\tspeed: 0.1471s/iter; left time: 748.6803s\n",
      "\titers: 200, epoch: 8 | loss: 0.0433661\n",
      "\tspeed: 0.0440s/iter; left time: 219.4341s\n",
      "\titers: 300, epoch: 8 | loss: 0.0422932\n",
      "\tspeed: 0.0440s/iter; left time: 214.8651s\n",
      "Epoch: 8 cost time: 17.56369638442993\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0452999 Vali Loss: 0.1104747 Test Loss: 0.1078144\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.10474741458892822, mae:0.2590106129646301\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTHh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'data': 'SYNTHh1', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 48, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTHh1_ftS_sl168_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.5816834\n",
      "\tspeed: 0.0451s/iter; left time: 354.7781s\n",
      "\titers: 200, epoch: 1 | loss: 0.3588666\n",
      "\tspeed: 0.0453s/iter; left time: 351.4639s\n",
      "\titers: 300, epoch: 1 | loss: 0.4207638\n",
      "\tspeed: 0.0458s/iter; left time: 350.8164s\n",
      "Epoch: 1 cost time: 18.17644166946411\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.4642262 Vali Loss: 0.5080765 Test Loss: 0.5321936\n",
      "Validation loss decreased (inf --> 0.508076).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1252396\n",
      "\tspeed: 0.1594s/iter; left time: 1189.7953s\n",
      "\titers: 200, epoch: 2 | loss: 0.1118957\n",
      "\tspeed: 0.0504s/iter; left time: 370.8811s\n",
      "\titers: 300, epoch: 2 | loss: 0.1209167\n",
      "\tspeed: 0.0504s/iter; left time: 366.3936s\n",
      "Epoch: 2 cost time: 19.79041314125061\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.1282798 Vali Loss: 0.2062321 Test Loss: 0.2113677\n",
      "Validation loss decreased (0.508076 --> 0.206232).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0644630\n",
      "\tspeed: 0.1588s/iter; left time: 1121.6005s\n",
      "\titers: 200, epoch: 3 | loss: 0.0938808\n",
      "\tspeed: 0.0483s/iter; left time: 336.4633s\n",
      "\titers: 300, epoch: 3 | loss: 0.0734628\n",
      "\tspeed: 0.0482s/iter; left time: 330.5931s\n",
      "Epoch: 3 cost time: 19.123465538024902\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0816269 Vali Loss: 0.1826499 Test Loss: 0.1847737\n",
      "Validation loss decreased (0.206232 --> 0.182650).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0546870\n",
      "\tspeed: 0.1584s/iter; left time: 1056.1876s\n",
      "\titers: 200, epoch: 4 | loss: 0.0573283\n",
      "\tspeed: 0.0460s/iter; left time: 302.3184s\n",
      "\titers: 300, epoch: 4 | loss: 0.0817176\n",
      "\tspeed: 0.0462s/iter; left time: 298.9072s\n",
      "Epoch: 4 cost time: 18.160759449005127\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0720249 Vali Loss: 0.1513649 Test Loss: 0.1400182\n",
      "Validation loss decreased (0.182650 --> 0.151365).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0724919\n",
      "\tspeed: 0.1475s/iter; left time: 924.4110s\n",
      "\titers: 200, epoch: 5 | loss: 0.0737692\n",
      "\tspeed: 0.0457s/iter; left time: 281.7561s\n",
      "\titers: 300, epoch: 5 | loss: 0.0588976\n",
      "\tspeed: 0.0463s/iter; left time: 280.8173s\n",
      "Epoch: 5 cost time: 18.379644632339478\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0647643 Vali Loss: 0.1583757 Test Loss: 0.1537000\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0665628\n",
      "\tspeed: 0.1526s/iter; left time: 896.0387s\n",
      "\titers: 200, epoch: 6 | loss: 0.0528035\n",
      "\tspeed: 0.0487s/iter; left time: 280.7638s\n",
      "\titers: 300, epoch: 6 | loss: 0.0664926\n",
      "\tspeed: 0.0482s/iter; left time: 273.1502s\n",
      "Epoch: 6 cost time: 19.027936935424805\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0632374 Vali Loss: 0.1563465 Test Loss: 0.1580369\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0740435\n",
      "\tspeed: 0.1574s/iter; left time: 861.7203s\n",
      "\titers: 200, epoch: 7 | loss: 0.0600262\n",
      "\tspeed: 0.0466s/iter; left time: 250.2653s\n",
      "\titers: 300, epoch: 7 | loss: 0.0515680\n",
      "\tspeed: 0.0459s/iter; left time: 241.9588s\n",
      "Epoch: 7 cost time: 18.589717388153076\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0604918 Vali Loss: 0.1564226 Test Loss: 0.1569726\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.14001812040805817, mae:0.30135491490364075\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTHh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'data': 'SYNTHh1', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 168, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTHh1_ftS_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.7712504\n",
      "\tspeed: 0.0563s/iter; left time: 438.3307s\n",
      "\titers: 200, epoch: 1 | loss: 0.7045878\n",
      "\tspeed: 0.0578s/iter; left time: 443.6093s\n",
      "\titers: 300, epoch: 1 | loss: 0.3820086\n",
      "\tspeed: 0.0591s/iter; left time: 447.9068s\n",
      "Epoch: 1 cost time: 22.947330713272095\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.6669402 Vali Loss: 1.0208123 Test Loss: 1.0197421\n",
      "Validation loss decreased (inf --> 1.020812).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3328106\n",
      "\tspeed: 0.1828s/iter; left time: 1350.6563s\n",
      "\titers: 200, epoch: 2 | loss: 0.2713816\n",
      "\tspeed: 0.0595s/iter; left time: 433.6003s\n",
      "\titers: 300, epoch: 2 | loss: 0.3180958\n",
      "\tspeed: 0.0595s/iter; left time: 427.5999s\n",
      "Epoch: 2 cost time: 23.542168378829956\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.2934334 Vali Loss: 0.9655551 Test Loss: 0.9674115\n",
      "Validation loss decreased (1.020812 --> 0.965555).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2391375\n",
      "\tspeed: 0.1937s/iter; left time: 1354.3356s\n",
      "\titers: 200, epoch: 3 | loss: 0.2501220\n",
      "\tspeed: 0.0587s/iter; left time: 404.3758s\n",
      "\titers: 300, epoch: 3 | loss: 0.1916950\n",
      "\tspeed: 0.0588s/iter; left time: 399.5681s\n",
      "Epoch: 3 cost time: 23.241920948028564\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.2088743 Vali Loss: 0.7145337 Test Loss: 0.7409333\n",
      "Validation loss decreased (0.965555 --> 0.714534).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1576379\n",
      "\tspeed: 0.1971s/iter; left time: 1300.5734s\n",
      "\titers: 200, epoch: 4 | loss: 0.1990010\n",
      "\tspeed: 0.0592s/iter; left time: 384.8278s\n",
      "\titers: 300, epoch: 4 | loss: 0.1729020\n",
      "\tspeed: 0.0587s/iter; left time: 375.4767s\n",
      "Epoch: 4 cost time: 23.194359302520752\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.1712786 Vali Loss: 0.6231594 Test Loss: 0.6797254\n",
      "Validation loss decreased (0.714534 --> 0.623159).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1744120\n",
      "\tspeed: 0.1879s/iter; left time: 1166.1663s\n",
      "\titers: 200, epoch: 5 | loss: 0.1395430\n",
      "\tspeed: 0.0585s/iter; left time: 357.3301s\n",
      "\titers: 300, epoch: 5 | loss: 0.1544971\n",
      "\tspeed: 0.0594s/iter; left time: 356.5615s\n",
      "Epoch: 5 cost time: 23.184149503707886\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.1535595 Vali Loss: 0.6460637 Test Loss: 0.6892976\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1490777\n",
      "\tspeed: 0.1894s/iter; left time: 1100.8016s\n",
      "\titers: 200, epoch: 6 | loss: 0.1276385\n",
      "\tspeed: 0.0588s/iter; left time: 335.8256s\n",
      "\titers: 300, epoch: 6 | loss: 0.1760550\n",
      "\tspeed: 0.0585s/iter; left time: 328.1693s\n",
      "Epoch: 6 cost time: 23.164962768554688\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.1447223 Vali Loss: 0.7885972 Test Loss: 0.8284590\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1433447\n",
      "\tspeed: 0.1920s/iter; left time: 1040.0876s\n",
      "\titers: 200, epoch: 7 | loss: 0.1753060\n",
      "\tspeed: 0.0606s/iter; left time: 322.3445s\n",
      "\titers: 300, epoch: 7 | loss: 0.1487395\n",
      "\tspeed: 0.0603s/iter; left time: 314.6255s\n",
      "Epoch: 7 cost time: 23.769026279449463\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.1426774 Vali Loss: 0.6908253 Test Loss: 0.7175871\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.6797253489494324, mae:0.6826778650283813\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTHh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'data': 'SYNTHh1', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 336, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTHh1_ftS_sl168_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.9280313\n",
      "\tspeed: 0.0836s/iter; left time: 642.2214s\n",
      "\titers: 200, epoch: 1 | loss: 1.0873665\n",
      "\tspeed: 0.0852s/iter; left time: 646.2555s\n",
      "\titers: 300, epoch: 1 | loss: 0.8595518\n",
      "\tspeed: 0.0872s/iter; left time: 652.5149s\n",
      "Epoch: 1 cost time: 33.47567343711853\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.9843777 Vali Loss: 1.4435028 Test Loss: 1.6441436\n",
      "Validation loss decreased (inf --> 1.443503).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4128290\n",
      "\tspeed: 0.2851s/iter; left time: 2078.9777s\n",
      "\titers: 200, epoch: 2 | loss: 0.3464241\n",
      "\tspeed: 0.0800s/iter; left time: 575.6123s\n",
      "\titers: 300, epoch: 2 | loss: 0.3022439\n",
      "\tspeed: 0.0782s/iter; left time: 554.3569s\n",
      "Epoch: 2 cost time: 31.89323401451111\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.4079055 Vali Loss: 1.0456051 Test Loss: 1.0646144\n",
      "Validation loss decreased (1.443503 --> 1.045605).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2816575\n",
      "\tspeed: 0.2800s/iter; left time: 1933.1225s\n",
      "\titers: 200, epoch: 3 | loss: 0.3026353\n",
      "\tspeed: 0.0876s/iter; left time: 595.6858s\n",
      "\titers: 300, epoch: 3 | loss: 0.2646596\n",
      "\tspeed: 0.0875s/iter; left time: 586.4949s\n",
      "Epoch: 3 cost time: 33.577574491500854\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.2882976 Vali Loss: 1.0072398 Test Loss: 1.0350249\n",
      "Validation loss decreased (1.045605 --> 1.007240).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2890718\n",
      "\tspeed: 0.2725s/iter; left time: 1774.9737s\n",
      "\titers: 200, epoch: 4 | loss: 0.2663158\n",
      "\tspeed: 0.0827s/iter; left time: 530.2328s\n",
      "\titers: 300, epoch: 4 | loss: 0.2717445\n",
      "\tspeed: 0.0832s/iter; left time: 525.1218s\n",
      "Epoch: 4 cost time: 32.34329605102539\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.2563247 Vali Loss: 1.0144079 Test Loss: 1.0387995\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2456485\n",
      "\tspeed: 0.2719s/iter; left time: 1665.4217s\n",
      "\titers: 200, epoch: 5 | loss: 0.2438172\n",
      "\tspeed: 0.0820s/iter; left time: 494.0403s\n",
      "\titers: 300, epoch: 5 | loss: 0.2241969\n",
      "\tspeed: 0.0865s/iter; left time: 512.2365s\n",
      "Epoch: 5 cost time: 32.801852226257324\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.2446901 Vali Loss: 1.0060275 Test Loss: 1.0221133\n",
      "Validation loss decreased (1.007240 --> 1.006027).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2534458\n",
      "\tspeed: 0.2768s/iter; left time: 1587.5803s\n",
      "\titers: 200, epoch: 6 | loss: 0.2368794\n",
      "\tspeed: 0.0856s/iter; left time: 482.2104s\n",
      "\titers: 300, epoch: 6 | loss: 0.2315222\n",
      "\tspeed: 0.0844s/iter; left time: 467.4347s\n",
      "Epoch: 6 cost time: 32.84742045402527\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.2387911 Vali Loss: 0.9867396 Test Loss: 0.9974543\n",
      "Validation loss decreased (1.006027 --> 0.986740).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2276525\n",
      "\tspeed: 0.2795s/iter; left time: 1494.4944s\n",
      "\titers: 200, epoch: 7 | loss: 0.2433898\n",
      "\tspeed: 0.0885s/iter; left time: 464.1546s\n",
      "\titers: 300, epoch: 7 | loss: 0.2293343\n",
      "\tspeed: 0.0891s/iter; left time: 458.6843s\n",
      "Epoch: 7 cost time: 34.12918400764465\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.2347142 Vali Loss: 0.9883678 Test Loss: 1.0015663\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2305778\n",
      "\tspeed: 0.2830s/iter; left time: 1402.9017s\n",
      "\titers: 200, epoch: 8 | loss: 0.2267559\n",
      "\tspeed: 0.0840s/iter; left time: 408.1525s\n",
      "\titers: 300, epoch: 8 | loss: 0.2359507\n",
      "\tspeed: 0.0861s/iter; left time: 409.8959s\n",
      "Epoch: 8 cost time: 33.06260704994202\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.2333906 Vali Loss: 0.9830040 Test Loss: 0.9963947\n",
      "Validation loss decreased (0.986740 --> 0.983004).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2063394\n",
      "\tspeed: 0.2878s/iter; left time: 1314.7621s\n",
      "\titers: 200, epoch: 9 | loss: 0.2231267\n",
      "\tspeed: 0.0869s/iter; left time: 388.1848s\n",
      "\titers: 300, epoch: 9 | loss: 0.2073562\n",
      "\tspeed: 0.0877s/iter; left time: 383.0114s\n",
      "Epoch: 9 cost time: 33.892295360565186\n",
      "Epoch: 9, Steps: 389 | Train Loss: 0.2311666 Vali Loss: 0.9817151 Test Loss: 0.9940214\n",
      "Validation loss decreased (0.983004 --> 0.981715).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2281723\n",
      "\tspeed: 0.2797s/iter; left time: 1169.2491s\n",
      "\titers: 200, epoch: 10 | loss: 0.2459346\n",
      "\tspeed: 0.0813s/iter; left time: 331.8888s\n",
      "\titers: 300, epoch: 10 | loss: 0.2024810\n",
      "\tspeed: 0.0829s/iter; left time: 329.7602s\n",
      "Epoch: 10 cost time: 32.013450384140015\n",
      "Epoch: 10, Steps: 389 | Train Loss: 0.2313903 Vali Loss: 0.9824564 Test Loss: 0.9955849\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.2340272\n",
      "\tspeed: 0.2708s/iter; left time: 1026.6162s\n",
      "\titers: 200, epoch: 11 | loss: 0.2328580\n",
      "\tspeed: 0.0849s/iter; left time: 313.3418s\n",
      "\titers: 300, epoch: 11 | loss: 0.2353041\n",
      "\tspeed: 0.0837s/iter; left time: 300.4227s\n",
      "Epoch: 11 cost time: 32.73735857009888\n",
      "Epoch: 11, Steps: 389 | Train Loss: 0.2313277 Vali Loss: 0.9817022 Test Loss: 0.9949442\n",
      "Validation loss decreased (0.981715 --> 0.981702).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.2241835\n",
      "\tspeed: 0.2740s/iter; left time: 931.9900s\n",
      "\titers: 200, epoch: 12 | loss: 0.1988149\n",
      "\tspeed: 0.0836s/iter; left time: 275.9328s\n",
      "\titers: 300, epoch: 12 | loss: 0.2334863\n",
      "\tspeed: 0.0844s/iter; left time: 270.3226s\n",
      "Epoch: 12 cost time: 32.69309878349304\n",
      "Epoch: 12, Steps: 389 | Train Loss: 0.2311704 Vali Loss: 0.9827642 Test Loss: 0.9960302\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.2248319\n",
      "\tspeed: 0.2789s/iter; left time: 840.4127s\n",
      "\titers: 200, epoch: 13 | loss: 0.2399310\n",
      "\tspeed: 0.0876s/iter; left time: 255.1646s\n",
      "\titers: 300, epoch: 13 | loss: 0.2540233\n",
      "\tspeed: 0.0873s/iter; left time: 245.6428s\n",
      "Epoch: 13 cost time: 33.96762752532959\n",
      "Epoch: 13, Steps: 389 | Train Loss: 0.2301976 Vali Loss: 0.9820757 Test Loss: 0.9955128\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "\titers: 100, epoch: 14 | loss: 0.2319028\n",
      "\tspeed: 0.2836s/iter; left time: 744.1921s\n",
      "\titers: 200, epoch: 14 | loss: 0.2277490\n",
      "\tspeed: 0.0840s/iter; left time: 212.0502s\n",
      "\titers: 300, epoch: 14 | loss: 0.2451824\n",
      "\tspeed: 0.0870s/iter; left time: 210.9433s\n",
      "Epoch: 14 cost time: 33.44105362892151\n",
      "Epoch: 14, Steps: 389 | Train Loss: 0.2310995 Vali Loss: 0.9819652 Test Loss: 0.9956416\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.9949442148208618, mae:0.8548665642738342\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTHh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'data': 'SYNTHh1', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 720, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTHh1_ftS_sl168_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.7994062\n",
      "\tspeed: 0.1272s/iter; left time: 946.1927s\n",
      "\titers: 200, epoch: 1 | loss: 0.6381419\n",
      "\tspeed: 0.1235s/iter; left time: 906.8673s\n",
      "\titers: 300, epoch: 1 | loss: 0.6111260\n",
      "\tspeed: 0.1260s/iter; left time: 912.0288s\n",
      "Epoch: 1 cost time: 47.495283365249634\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.7370191 Vali Loss: 0.9198216 Test Loss: 1.0416616\n",
      "Validation loss decreased (inf --> 0.919822).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3412654\n",
      "\tspeed: 0.3717s/iter; left time: 2625.6585s\n",
      "\titers: 200, epoch: 2 | loss: 0.3268099\n",
      "\tspeed: 0.1315s/iter; left time: 915.7740s\n",
      "\titers: 300, epoch: 2 | loss: 0.2614763\n",
      "\tspeed: 0.1297s/iter; left time: 889.9952s\n",
      "Epoch: 2 cost time: 49.350903272628784\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.3511983 Vali Loss: 0.7913136 Test Loss: 0.8436883\n",
      "Validation loss decreased (0.919822 --> 0.791314).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2686327\n",
      "\tspeed: 0.3831s/iter; left time: 2561.4683s\n",
      "\titers: 200, epoch: 3 | loss: 0.2418920\n",
      "\tspeed: 0.1260s/iter; left time: 829.9214s\n",
      "\titers: 300, epoch: 3 | loss: 0.2599448\n",
      "\tspeed: 0.1317s/iter; left time: 854.1229s\n",
      "Epoch: 3 cost time: 49.15611004829407\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.2689355 Vali Loss: 0.7642350 Test Loss: 0.8304110\n",
      "Validation loss decreased (0.791314 --> 0.764235).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2858506\n",
      "\tspeed: 0.3865s/iter; left time: 2439.0679s\n",
      "\titers: 200, epoch: 4 | loss: 0.2738389\n",
      "\tspeed: 0.1270s/iter; left time: 788.6239s\n",
      "\titers: 300, epoch: 4 | loss: 0.2590671\n",
      "\tspeed: 0.1299s/iter; left time: 793.5244s\n",
      "Epoch: 4 cost time: 48.71363425254822\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.2543796 Vali Loss: 0.7767296 Test Loss: 0.8465254\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2445178\n",
      "\tspeed: 0.3823s/iter; left time: 2268.4001s\n",
      "\titers: 200, epoch: 5 | loss: 0.2114818\n",
      "\tspeed: 0.1232s/iter; left time: 718.5747s\n",
      "\titers: 300, epoch: 5 | loss: 0.2505624\n",
      "\tspeed: 0.1276s/iter; left time: 731.3865s\n",
      "Epoch: 5 cost time: 48.18253803253174\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.2477850 Vali Loss: 0.8210030 Test Loss: 0.8702035\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2174808\n",
      "\tspeed: 0.3788s/iter; left time: 2104.7536s\n",
      "\titers: 200, epoch: 6 | loss: 0.2423431\n",
      "\tspeed: 0.1270s/iter; left time: 692.9314s\n",
      "\titers: 300, epoch: 6 | loss: 0.2855712\n",
      "\tspeed: 0.1278s/iter; left time: 684.2505s\n",
      "Epoch: 6 cost time: 48.51591777801514\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.2415915 Vali Loss: 0.7978234 Test Loss: 0.8787051\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.8304110765457153, mae:0.7390966415405273\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'data': 'SYNTH_additive', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_ftS_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.0212933\n",
      "\tspeed: 0.0469s/iter; left time: 369.2624s\n",
      "\titers: 200, epoch: 1 | loss: 0.0207465\n",
      "\tspeed: 0.0444s/iter; left time: 345.4591s\n",
      "\titers: 300, epoch: 1 | loss: 0.0212811\n",
      "\tspeed: 0.0447s/iter; left time: 343.4262s\n",
      "Epoch: 1 cost time: 18.030785083770752\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.0411553 Vali Loss: 0.0214794 Test Loss: 0.0206430\n",
      "Validation loss decreased (inf --> 0.021479).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0139708\n",
      "\tspeed: 0.1507s/iter; left time: 1127.5321s\n",
      "\titers: 200, epoch: 2 | loss: 0.0121174\n",
      "\tspeed: 0.0461s/iter; left time: 339.9746s\n",
      "\titers: 300, epoch: 2 | loss: 0.0102935\n",
      "\tspeed: 0.0459s/iter; left time: 334.5611s\n",
      "Epoch: 2 cost time: 18.262213230133057\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0137689 Vali Loss: 0.0195449 Test Loss: 0.0196587\n",
      "Validation loss decreased (0.021479 --> 0.019545).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0117297\n",
      "\tspeed: 0.1546s/iter; left time: 1095.0355s\n",
      "\titers: 200, epoch: 3 | loss: 0.0084505\n",
      "\tspeed: 0.0461s/iter; left time: 321.9451s\n",
      "\titers: 300, epoch: 3 | loss: 0.0108623\n",
      "\tspeed: 0.0438s/iter; left time: 301.3128s\n",
      "Epoch: 3 cost time: 17.89584493637085\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0102432 Vali Loss: 0.0139146 Test Loss: 0.0142202\n",
      "Validation loss decreased (0.019545 --> 0.013915).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0091225\n",
      "\tspeed: 0.1446s/iter; left time: 966.6141s\n",
      "\titers: 200, epoch: 4 | loss: 0.0089752\n",
      "\tspeed: 0.0440s/iter; left time: 290.0128s\n",
      "\titers: 300, epoch: 4 | loss: 0.0072662\n",
      "\tspeed: 0.0446s/iter; left time: 288.9450s\n",
      "Epoch: 4 cost time: 17.489509105682373\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0088167 Vali Loss: 0.0119814 Test Loss: 0.0123981\n",
      "Validation loss decreased (0.013915 --> 0.011981).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0082493\n",
      "\tspeed: 0.1466s/iter; left time: 921.4505s\n",
      "\titers: 200, epoch: 5 | loss: 0.0078246\n",
      "\tspeed: 0.0436s/iter; left time: 269.5448s\n",
      "\titers: 300, epoch: 5 | loss: 0.0077821\n",
      "\tspeed: 0.0441s/iter; left time: 268.0545s\n",
      "Epoch: 5 cost time: 17.451205015182495\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0081804 Vali Loss: 0.0118928 Test Loss: 0.0124734\n",
      "Validation loss decreased (0.011981 --> 0.011893).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0095521\n",
      "\tspeed: 0.1456s/iter; left time: 856.8321s\n",
      "\titers: 200, epoch: 6 | loss: 0.0068376\n",
      "\tspeed: 0.0439s/iter; left time: 254.1766s\n",
      "\titers: 300, epoch: 6 | loss: 0.0115942\n",
      "\tspeed: 0.0440s/iter; left time: 250.0468s\n",
      "Epoch: 6 cost time: 17.50361919403076\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0079547 Vali Loss: 0.0110587 Test Loss: 0.0116354\n",
      "Validation loss decreased (0.011893 --> 0.011059).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0057610\n",
      "\tspeed: 0.1495s/iter; left time: 820.2427s\n",
      "\titers: 200, epoch: 7 | loss: 0.0076783\n",
      "\tspeed: 0.0464s/iter; left time: 250.2081s\n",
      "\titers: 300, epoch: 7 | loss: 0.0072663\n",
      "\tspeed: 0.0479s/iter; left time: 253.0563s\n",
      "Epoch: 7 cost time: 18.73992896080017\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0076193 Vali Loss: 0.0107120 Test Loss: 0.0111987\n",
      "Validation loss decreased (0.011059 --> 0.010712).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0068774\n",
      "\tspeed: 0.1596s/iter; left time: 811.9837s\n",
      "\titers: 200, epoch: 8 | loss: 0.0070425\n",
      "\tspeed: 0.0469s/iter; left time: 233.9624s\n",
      "\titers: 300, epoch: 8 | loss: 0.0099486\n",
      "\tspeed: 0.0473s/iter; left time: 231.0643s\n",
      "Epoch: 8 cost time: 18.747556924819946\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0076762 Vali Loss: 0.0101183 Test Loss: 0.0105971\n",
      "Validation loss decreased (0.010712 --> 0.010118).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0061287\n",
      "\tspeed: 0.1569s/iter; left time: 735.7900s\n",
      "\titers: 200, epoch: 9 | loss: 0.0073745\n",
      "\tspeed: 0.0438s/iter; left time: 201.1956s\n",
      "\titers: 300, epoch: 9 | loss: 0.0075122\n",
      "\tspeed: 0.0439s/iter; left time: 196.9691s\n",
      "Epoch: 9 cost time: 17.79245090484619\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0075718 Vali Loss: 0.0100936 Test Loss: 0.0106499\n",
      "Validation loss decreased (0.010118 --> 0.010094).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0087740\n",
      "\tspeed: 0.1501s/iter; left time: 643.7604s\n",
      "\titers: 200, epoch: 10 | loss: 0.0075209\n",
      "\tspeed: 0.0445s/iter; left time: 186.4779s\n",
      "\titers: 300, epoch: 10 | loss: 0.0081132\n",
      "\tspeed: 0.0441s/iter; left time: 180.4351s\n",
      "Epoch: 10 cost time: 17.802562952041626\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0075629 Vali Loss: 0.0099881 Test Loss: 0.0104830\n",
      "Validation loss decreased (0.010094 --> 0.009988).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0097823\n",
      "\tspeed: 0.1457s/iter; left time: 566.8631s\n",
      "\titers: 200, epoch: 11 | loss: 0.0064841\n",
      "\tspeed: 0.0444s/iter; left time: 168.3909s\n",
      "\titers: 300, epoch: 11 | loss: 0.0079906\n",
      "\tspeed: 0.0443s/iter; left time: 163.5507s\n",
      "Epoch: 11 cost time: 17.650325059890747\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0075721 Vali Loss: 0.0099219 Test Loss: 0.0104339\n",
      "Validation loss decreased (0.009988 --> 0.009922).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0090963\n",
      "\tspeed: 0.1458s/iter; left time: 509.2777s\n",
      "\titers: 200, epoch: 12 | loss: 0.0090810\n",
      "\tspeed: 0.0443s/iter; left time: 150.3014s\n",
      "\titers: 300, epoch: 12 | loss: 0.0084653\n",
      "\tspeed: 0.0437s/iter; left time: 143.9959s\n",
      "Epoch: 12 cost time: 17.60177445411682\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0075396 Vali Loss: 0.0098456 Test Loss: 0.0103570\n",
      "Validation loss decreased (0.009922 --> 0.009846).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0075915\n",
      "\tspeed: 0.1479s/iter; left time: 457.3674s\n",
      "\titers: 200, epoch: 13 | loss: 0.0069642\n",
      "\tspeed: 0.0466s/iter; left time: 139.4120s\n",
      "\titers: 300, epoch: 13 | loss: 0.0060260\n",
      "\tspeed: 0.0464s/iter; left time: 134.1799s\n",
      "Epoch: 13 cost time: 18.59605646133423\n",
      "Epoch: 13, Steps: 399 | Train Loss: 0.0075175 Vali Loss: 0.0099207 Test Loss: 0.0103454\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "\titers: 100, epoch: 14 | loss: 0.0082691\n",
      "\tspeed: 0.1572s/iter; left time: 423.4085s\n",
      "\titers: 200, epoch: 14 | loss: 0.0057541\n",
      "\tspeed: 0.0463s/iter; left time: 120.0063s\n",
      "\titers: 300, epoch: 14 | loss: 0.0107257\n",
      "\tspeed: 0.0454s/iter; left time: 113.3489s\n",
      "Epoch: 14 cost time: 18.185311555862427\n",
      "Epoch: 14, Steps: 399 | Train Loss: 0.0075716 Vali Loss: 0.0098707 Test Loss: 0.0103219\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "\titers: 100, epoch: 15 | loss: 0.0068528\n",
      "\tspeed: 0.1468s/iter; left time: 336.8430s\n",
      "\titers: 200, epoch: 15 | loss: 0.0068538\n",
      "\tspeed: 0.0440s/iter; left time: 96.5012s\n",
      "\titers: 300, epoch: 15 | loss: 0.0083788\n",
      "\tspeed: 0.0466s/iter; left time: 97.5545s\n",
      "Epoch: 15 cost time: 18.111639738082886\n",
      "Epoch: 15, Steps: 399 | Train Loss: 0.0075347 Vali Loss: 0.0098767 Test Loss: 0.0103079\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.010357045568525791, mae:0.07965223491191864\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'data': 'SYNTH_additive', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 48, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_ftS_sl168_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.0464348\n",
      "\tspeed: 0.0442s/iter; left time: 347.2593s\n",
      "\titers: 200, epoch: 1 | loss: 0.0349750\n",
      "\tspeed: 0.0454s/iter; left time: 352.6987s\n",
      "\titers: 300, epoch: 1 | loss: 0.0292767\n",
      "\tspeed: 0.0450s/iter; left time: 344.4962s\n",
      "Epoch: 1 cost time: 17.940324783325195\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0571694 Vali Loss: 0.0150692 Test Loss: 0.0146494\n",
      "Validation loss decreased (inf --> 0.015069).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0174250\n",
      "\tspeed: 0.1533s/iter; left time: 1144.2928s\n",
      "\titers: 200, epoch: 2 | loss: 0.0153933\n",
      "\tspeed: 0.0506s/iter; left time: 372.4548s\n",
      "\titers: 300, epoch: 2 | loss: 0.0152674\n",
      "\tspeed: 0.0497s/iter; left time: 360.6349s\n",
      "Epoch: 2 cost time: 19.34489631652832\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0169059 Vali Loss: 0.0201080 Test Loss: 0.0201849\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0132554\n",
      "\tspeed: 0.1584s/iter; left time: 1119.1200s\n",
      "\titers: 200, epoch: 3 | loss: 0.0100372\n",
      "\tspeed: 0.0458s/iter; left time: 319.1699s\n",
      "\titers: 300, epoch: 3 | loss: 0.0106958\n",
      "\tspeed: 0.0461s/iter; left time: 316.3438s\n",
      "Epoch: 3 cost time: 18.41549301147461\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0113527 Vali Loss: 0.0243640 Test Loss: 0.0244180\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0087900\n",
      "\tspeed: 0.1498s/iter; left time: 998.8563s\n",
      "\titers: 200, epoch: 4 | loss: 0.0075222\n",
      "\tspeed: 0.0456s/iter; left time: 299.3528s\n",
      "\titers: 300, epoch: 4 | loss: 0.0085717\n",
      "\tspeed: 0.0450s/iter; left time: 291.0280s\n",
      "Epoch: 4 cost time: 18.08982229232788\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0091036 Vali Loss: 0.0298589 Test Loss: 0.0301612\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.01464935950934887, mae:0.09644239395856857\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'data': 'SYNTH_additive', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 168, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_ftS_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.0614629\n",
      "\tspeed: 0.0622s/iter; left time: 484.1571s\n",
      "\titers: 200, epoch: 1 | loss: 0.0449527\n",
      "\tspeed: 0.0589s/iter; left time: 452.2354s\n",
      "\titers: 300, epoch: 1 | loss: 0.0382536\n",
      "\tspeed: 0.0629s/iter; left time: 476.7819s\n",
      "Epoch: 1 cost time: 24.535824298858643\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.0811032 Vali Loss: 0.0358422 Test Loss: 0.0373104\n",
      "Validation loss decreased (inf --> 0.035842).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0303459\n",
      "\tspeed: 0.1970s/iter; left time: 1455.1500s\n",
      "\titers: 200, epoch: 2 | loss: 0.0228745\n",
      "\tspeed: 0.0603s/iter; left time: 439.3942s\n",
      "\titers: 300, epoch: 2 | loss: 0.0266767\n",
      "\tspeed: 0.0587s/iter; left time: 421.7742s\n",
      "Epoch: 2 cost time: 23.384711265563965\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0330784 Vali Loss: 0.0342933 Test Loss: 0.0369032\n",
      "Validation loss decreased (0.035842 --> 0.034293).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0313773\n",
      "\tspeed: 0.1884s/iter; left time: 1317.2259s\n",
      "\titers: 200, epoch: 3 | loss: 0.0293804\n",
      "\tspeed: 0.0584s/iter; left time: 402.5312s\n",
      "\titers: 300, epoch: 3 | loss: 0.0308994\n",
      "\tspeed: 0.0587s/iter; left time: 398.5522s\n",
      "Epoch: 3 cost time: 23.25275421142578\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0287342 Vali Loss: 0.0378844 Test Loss: 0.0400876\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0287665\n",
      "\tspeed: 0.1921s/iter; left time: 1267.8641s\n",
      "\titers: 200, epoch: 4 | loss: 0.0327760\n",
      "\tspeed: 0.0602s/iter; left time: 390.9669s\n",
      "\titers: 300, epoch: 4 | loss: 0.0254064\n",
      "\tspeed: 0.0607s/iter; left time: 388.6733s\n",
      "Epoch: 4 cost time: 23.804002046585083\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0264889 Vali Loss: 0.0315744 Test Loss: 0.0346197\n",
      "Validation loss decreased (0.034293 --> 0.031574).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0275437\n",
      "\tspeed: 0.1972s/iter; left time: 1223.8985s\n",
      "\titers: 200, epoch: 5 | loss: 0.0271539\n",
      "\tspeed: 0.0601s/iter; left time: 366.6877s\n",
      "\titers: 300, epoch: 5 | loss: 0.0274065\n",
      "\tspeed: 0.0627s/iter; left time: 376.4518s\n",
      "Epoch: 5 cost time: 23.68771004676819\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0253187 Vali Loss: 0.0328805 Test Loss: 0.0371678\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0279036\n",
      "\tspeed: 0.1813s/iter; left time: 1053.5367s\n",
      "\titers: 200, epoch: 6 | loss: 0.0307361\n",
      "\tspeed: 0.0601s/iter; left time: 343.0033s\n",
      "\titers: 300, epoch: 6 | loss: 0.0250791\n",
      "\tspeed: 0.0602s/iter; left time: 337.5136s\n",
      "Epoch: 6 cost time: 23.43804621696472\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0247512 Vali Loss: 0.0319014 Test Loss: 0.0352945\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0199376\n",
      "\tspeed: 0.1854s/iter; left time: 1004.1389s\n",
      "\titers: 200, epoch: 7 | loss: 0.0259081\n",
      "\tspeed: 0.0554s/iter; left time: 294.6035s\n",
      "\titers: 300, epoch: 7 | loss: 0.0228859\n",
      "\tspeed: 0.0566s/iter; left time: 295.1902s\n",
      "Epoch: 7 cost time: 21.888680934906006\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0244442 Vali Loss: 0.0316621 Test Loss: 0.0347718\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.034619707614183426, mae:0.15002106130123138\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'data': 'SYNTH_additive', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 336, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_ftS_sl168_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.0683630\n",
      "\tspeed: 0.0839s/iter; left time: 644.3395s\n",
      "\titers: 200, epoch: 1 | loss: 0.0681686\n",
      "\tspeed: 0.0853s/iter; left time: 646.2904s\n",
      "\titers: 300, epoch: 1 | loss: 0.0466806\n",
      "\tspeed: 0.0828s/iter; left time: 619.2824s\n",
      "Epoch: 1 cost time: 32.52347946166992\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.0842785 Vali Loss: 0.0669905 Test Loss: 0.0725084\n",
      "Validation loss decreased (inf --> 0.066990).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0386610\n",
      "\tspeed: 0.2729s/iter; left time: 1990.2403s\n",
      "\titers: 200, epoch: 2 | loss: 0.0406437\n",
      "\tspeed: 0.0871s/iter; left time: 626.7794s\n",
      "\titers: 300, epoch: 2 | loss: 0.0404833\n",
      "\tspeed: 0.0867s/iter; left time: 615.0198s\n",
      "Epoch: 2 cost time: 33.39552307128906\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0439180 Vali Loss: 0.0631286 Test Loss: 0.0702326\n",
      "Validation loss decreased (0.066990 --> 0.063129).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0437106\n",
      "\tspeed: 0.2858s/iter; left time: 1972.6859s\n",
      "\titers: 200, epoch: 3 | loss: 0.0415387\n",
      "\tspeed: 0.0858s/iter; left time: 583.6408s\n",
      "\titers: 300, epoch: 3 | loss: 0.0462066\n",
      "\tspeed: 0.0818s/iter; left time: 548.3747s\n",
      "Epoch: 3 cost time: 32.681556224823\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0403549 Vali Loss: 0.0632199 Test Loss: 0.0684648\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0351797\n",
      "\tspeed: 0.2743s/iter; left time: 1786.5521s\n",
      "\titers: 200, epoch: 4 | loss: 0.0367495\n",
      "\tspeed: 0.0824s/iter; left time: 528.3440s\n",
      "\titers: 300, epoch: 4 | loss: 0.0431185\n",
      "\tspeed: 0.0851s/iter; left time: 537.2505s\n",
      "Epoch: 4 cost time: 32.57808446884155\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0389956 Vali Loss: 0.0699030 Test Loss: 0.0749997\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0396971\n",
      "\tspeed: 0.2775s/iter; left time: 1699.7947s\n",
      "\titers: 200, epoch: 5 | loss: 0.0347971\n",
      "\tspeed: 0.0868s/iter; left time: 522.9716s\n",
      "\titers: 300, epoch: 5 | loss: 0.0455524\n",
      "\tspeed: 0.0858s/iter; left time: 508.5223s\n",
      "Epoch: 5 cost time: 33.29609656333923\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0383281 Vali Loss: 0.0675351 Test Loss: 0.0726724\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.07023263722658157, mae:0.22047573328018188\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'data': 'SYNTH_additive', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 720, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_ftS_sl168_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.0686890\n",
      "\tspeed: 0.1320s/iter; left time: 982.4061s\n",
      "\titers: 200, epoch: 1 | loss: 0.0516763\n",
      "\tspeed: 0.1309s/iter; left time: 961.0011s\n",
      "\titers: 300, epoch: 1 | loss: 0.0424977\n",
      "\tspeed: 0.1347s/iter; left time: 975.0414s\n",
      "Epoch: 1 cost time: 50.07832312583923\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.0690194 Vali Loss: 0.0510089 Test Loss: 0.0581771\n",
      "Validation loss decreased (inf --> 0.051009).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0387861\n",
      "\tspeed: 0.3839s/iter; left time: 2711.8333s\n",
      "\titers: 200, epoch: 2 | loss: 0.0376688\n",
      "\tspeed: 0.1248s/iter; left time: 869.1445s\n",
      "\titers: 300, epoch: 2 | loss: 0.0348048\n",
      "\tspeed: 0.1325s/iter; left time: 909.4974s\n",
      "Epoch: 2 cost time: 48.97882032394409\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0387532 Vali Loss: 0.0495014 Test Loss: 0.0575397\n",
      "Validation loss decreased (0.051009 --> 0.049501).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0365545\n",
      "\tspeed: 0.3632s/iter; left time: 2428.8313s\n",
      "\titers: 200, epoch: 3 | loss: 0.0348194\n",
      "\tspeed: 0.1267s/iter; left time: 834.8603s\n",
      "\titers: 300, epoch: 3 | loss: 0.0322835\n",
      "\tspeed: 0.1305s/iter; left time: 846.5016s\n",
      "Epoch: 3 cost time: 48.26672387123108\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0354584 Vali Loss: 0.0470279 Test Loss: 0.0535835\n",
      "Validation loss decreased (0.049501 --> 0.047028).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0353393\n",
      "\tspeed: 0.3680s/iter; left time: 2322.1832s\n",
      "\titers: 200, epoch: 4 | loss: 0.0302033\n",
      "\tspeed: 0.1297s/iter; left time: 805.7372s\n",
      "\titers: 300, epoch: 4 | loss: 0.0311053\n",
      "\tspeed: 0.1358s/iter; left time: 829.6770s\n",
      "Epoch: 4 cost time: 49.411611557006836\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0334970 Vali Loss: 0.0480253 Test Loss: 0.0566268\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0330100\n",
      "\tspeed: 0.3749s/iter; left time: 2224.3060s\n",
      "\titers: 200, epoch: 5 | loss: 0.0308909\n",
      "\tspeed: 0.1307s/iter; left time: 762.1213s\n",
      "\titers: 300, epoch: 5 | loss: 0.0304114\n",
      "\tspeed: 0.1343s/iter; left time: 770.1281s\n",
      "Epoch: 5 cost time: 49.559794664382935\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0320979 Vali Loss: 0.0456477 Test Loss: 0.0528048\n",
      "Validation loss decreased (0.047028 --> 0.045648).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0295566\n",
      "\tspeed: 0.3879s/iter; left time: 2154.9020s\n",
      "\titers: 200, epoch: 6 | loss: 0.0320329\n",
      "\tspeed: 0.1353s/iter; left time: 738.1492s\n",
      "\titers: 300, epoch: 6 | loss: 0.0340883\n",
      "\tspeed: 0.1341s/iter; left time: 718.0888s\n",
      "Epoch: 6 cost time: 50.538188457489014\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0312118 Vali Loss: 0.0467570 Test Loss: 0.0539281\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0319993\n",
      "\tspeed: 0.3848s/iter; left time: 1992.6303s\n",
      "\titers: 200, epoch: 7 | loss: 0.0299679\n",
      "\tspeed: 0.1278s/iter; left time: 649.1907s\n",
      "\titers: 300, epoch: 7 | loss: 0.0281665\n",
      "\tspeed: 0.1330s/iter; left time: 662.2036s\n",
      "Epoch: 7 cost time: 49.28275465965271\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0308140 Vali Loss: 0.0458442 Test Loss: 0.0529294\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0305641\n",
      "\tspeed: 0.3648s/iter; left time: 1751.5620s\n",
      "\titers: 200, epoch: 8 | loss: 0.0310003\n",
      "\tspeed: 0.1235s/iter; left time: 580.7946s\n",
      "\titers: 300, epoch: 8 | loss: 0.0295735\n",
      "\tspeed: 0.1288s/iter; left time: 592.5092s\n",
      "Epoch: 8 cost time: 47.56787824630737\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.0304594 Vali Loss: 0.0461125 Test Loss: 0.0533566\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.052804749459028244, mae:0.18671204149723053\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'data': 'SYNTH_additive_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_reversal_ftS_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.1116124\n",
      "\tspeed: 0.0456s/iter; left time: 359.0944s\n",
      "\titers: 200, epoch: 1 | loss: 0.0707747\n",
      "\tspeed: 0.0455s/iter; left time: 354.3826s\n",
      "\titers: 300, epoch: 1 | loss: 0.0586791\n",
      "\tspeed: 0.0430s/iter; left time: 330.6243s\n",
      "Epoch: 1 cost time: 17.7476749420166\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.1014199 Vali Loss: 0.0820339 Test Loss: 0.0743297\n",
      "Validation loss decreased (inf --> 0.082034).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0394281\n",
      "\tspeed: 0.1369s/iter; left time: 1024.6092s\n",
      "\titers: 200, epoch: 2 | loss: 0.0464148\n",
      "\tspeed: 0.0432s/iter; left time: 318.8893s\n",
      "\titers: 300, epoch: 2 | loss: 0.0285305\n",
      "\tspeed: 0.0442s/iter; left time: 321.7399s\n",
      "Epoch: 2 cost time: 17.036404848098755\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0379738 Vali Loss: 0.0406030 Test Loss: 0.0446094\n",
      "Validation loss decreased (0.082034 --> 0.040603).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0224459\n",
      "\tspeed: 0.1461s/iter; left time: 1034.6055s\n",
      "\titers: 200, epoch: 3 | loss: 0.0297238\n",
      "\tspeed: 0.0447s/iter; left time: 312.3084s\n",
      "\titers: 300, epoch: 3 | loss: 0.0220936\n",
      "\tspeed: 0.0438s/iter; left time: 301.3513s\n",
      "Epoch: 3 cost time: 17.444172382354736\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0232953 Vali Loss: 0.0360198 Test Loss: 0.0400132\n",
      "Validation loss decreased (0.040603 --> 0.036020).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0234612\n",
      "\tspeed: 0.1422s/iter; left time: 950.6688s\n",
      "\titers: 200, epoch: 4 | loss: 0.0129218\n",
      "\tspeed: 0.0431s/iter; left time: 283.8287s\n",
      "\titers: 300, epoch: 4 | loss: 0.0198179\n",
      "\tspeed: 0.0439s/iter; left time: 284.9677s\n",
      "Epoch: 4 cost time: 17.585177183151245\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0175552 Vali Loss: 0.0397335 Test Loss: 0.0450953\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0128220\n",
      "\tspeed: 0.1536s/iter; left time: 965.6882s\n",
      "\titers: 200, epoch: 5 | loss: 0.0144831\n",
      "\tspeed: 0.0445s/iter; left time: 275.3707s\n",
      "\titers: 300, epoch: 5 | loss: 0.0135514\n",
      "\tspeed: 0.0450s/iter; left time: 273.6844s\n",
      "Epoch: 5 cost time: 18.05935025215149\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0154355 Vali Loss: 0.0361552 Test Loss: 0.0386564\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0139026\n",
      "\tspeed: 0.1432s/iter; left time: 842.8039s\n",
      "\titers: 200, epoch: 6 | loss: 0.0144227\n",
      "\tspeed: 0.0490s/iter; left time: 283.3428s\n",
      "\titers: 300, epoch: 6 | loss: 0.0159687\n",
      "\tspeed: 0.0489s/iter; left time: 278.1061s\n",
      "Epoch: 6 cost time: 18.981643438339233\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0141108 Vali Loss: 0.0358826 Test Loss: 0.0383214\n",
      "Validation loss decreased (0.036020 --> 0.035883).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0112147\n",
      "\tspeed: 0.1631s/iter; left time: 894.7791s\n",
      "\titers: 200, epoch: 7 | loss: 0.0124312\n",
      "\tspeed: 0.0462s/iter; left time: 248.6878s\n",
      "\titers: 300, epoch: 7 | loss: 0.0108175\n",
      "\tspeed: 0.0485s/iter; left time: 256.5391s\n",
      "Epoch: 7 cost time: 18.961084842681885\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0136218 Vali Loss: 0.0373962 Test Loss: 0.0401104\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0111029\n",
      "\tspeed: 0.1692s/iter; left time: 861.0565s\n",
      "\titers: 200, epoch: 8 | loss: 0.0106454\n",
      "\tspeed: 0.0477s/iter; left time: 238.1312s\n",
      "\titers: 300, epoch: 8 | loss: 0.0118349\n",
      "\tspeed: 0.0477s/iter; left time: 233.0660s\n",
      "Epoch: 8 cost time: 18.860275506973267\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0135689 Vali Loss: 0.0357617 Test Loss: 0.0388749\n",
      "Validation loss decreased (0.035883 --> 0.035762).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0156432\n",
      "\tspeed: 0.1561s/iter; left time: 732.0663s\n",
      "\titers: 200, epoch: 9 | loss: 0.0124371\n",
      "\tspeed: 0.0454s/iter; left time: 208.2971s\n",
      "\titers: 300, epoch: 9 | loss: 0.0103140\n",
      "\tspeed: 0.0455s/iter; left time: 204.1968s\n",
      "Epoch: 9 cost time: 18.261953830718994\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0135480 Vali Loss: 0.0351879 Test Loss: 0.0384197\n",
      "Validation loss decreased (0.035762 --> 0.035188).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0111189\n",
      "\tspeed: 0.1526s/iter; left time: 654.6647s\n",
      "\titers: 200, epoch: 10 | loss: 0.0224056\n",
      "\tspeed: 0.0456s/iter; left time: 191.2298s\n",
      "\titers: 300, epoch: 10 | loss: 0.0162274\n",
      "\tspeed: 0.0464s/iter; left time: 189.6757s\n",
      "Epoch: 10 cost time: 18.33966875076294\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0132597 Vali Loss: 0.0352462 Test Loss: 0.0387134\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0164273\n",
      "\tspeed: 0.1563s/iter; left time: 608.0246s\n",
      "\titers: 200, epoch: 11 | loss: 0.0132839\n",
      "\tspeed: 0.0462s/iter; left time: 175.2886s\n",
      "\titers: 300, epoch: 11 | loss: 0.0209498\n",
      "\tspeed: 0.0462s/iter; left time: 170.6790s\n",
      "Epoch: 11 cost time: 18.470824480056763\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0132172 Vali Loss: 0.0352409 Test Loss: 0.0385410\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0094807\n",
      "\tspeed: 0.1503s/iter; left time: 524.7561s\n",
      "\titers: 200, epoch: 12 | loss: 0.0150634\n",
      "\tspeed: 0.0464s/iter; left time: 157.3422s\n",
      "\titers: 300, epoch: 12 | loss: 0.0227068\n",
      "\tspeed: 0.0456s/iter; left time: 150.0473s\n",
      "Epoch: 12 cost time: 18.356088399887085\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0133797 Vali Loss: 0.0353514 Test Loss: 0.0385439\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.038419660180807114, mae:0.15233999490737915\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'data': 'SYNTH_additive_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 48, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_reversal_ftS_sl168_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.1016484\n",
      "\tspeed: 0.0441s/iter; left time: 346.7384s\n",
      "\titers: 200, epoch: 1 | loss: 0.0826818\n",
      "\tspeed: 0.0455s/iter; left time: 353.2938s\n",
      "\titers: 300, epoch: 1 | loss: 0.0507327\n",
      "\tspeed: 0.0456s/iter; left time: 348.9913s\n",
      "Epoch: 1 cost time: 18.130813121795654\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.1019570 Vali Loss: 0.0528124 Test Loss: 0.0581021\n",
      "Validation loss decreased (inf --> 0.052812).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0429648\n",
      "\tspeed: 0.1569s/iter; left time: 1171.2131s\n",
      "\titers: 200, epoch: 2 | loss: 0.0381994\n",
      "\tspeed: 0.0481s/iter; left time: 353.9107s\n",
      "\titers: 300, epoch: 2 | loss: 0.0324688\n",
      "\tspeed: 0.0479s/iter; left time: 348.0478s\n",
      "Epoch: 2 cost time: 18.95537805557251\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0336786 Vali Loss: 0.0715640 Test Loss: 0.0771034\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0158177\n",
      "\tspeed: 0.1418s/iter; left time: 1001.8112s\n",
      "\titers: 200, epoch: 3 | loss: 0.0177601\n",
      "\tspeed: 0.0467s/iter; left time: 325.4364s\n",
      "\titers: 300, epoch: 3 | loss: 0.0215502\n",
      "\tspeed: 0.0464s/iter; left time: 318.7728s\n",
      "Epoch: 3 cost time: 18.444633960723877\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0197412 Vali Loss: 0.0563614 Test Loss: 0.0717947\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0145064\n",
      "\tspeed: 0.1550s/iter; left time: 1033.3268s\n",
      "\titers: 200, epoch: 4 | loss: 0.0142238\n",
      "\tspeed: 0.0478s/iter; left time: 314.1371s\n",
      "\titers: 300, epoch: 4 | loss: 0.0174182\n",
      "\tspeed: 0.0469s/iter; left time: 303.0543s\n",
      "Epoch: 4 cost time: 18.895525217056274\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0157482 Vali Loss: 0.0536626 Test Loss: 0.0686325\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.05810206010937691, mae:0.18961700797080994\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'data': 'SYNTH_additive_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 168, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_reversal_ftS_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.1633266\n",
      "\tspeed: 0.0576s/iter; left time: 448.1971s\n",
      "\titers: 200, epoch: 1 | loss: 0.1201461\n",
      "\tspeed: 0.0574s/iter; left time: 441.0700s\n",
      "\titers: 300, epoch: 1 | loss: 0.1512266\n",
      "\tspeed: 0.0572s/iter; left time: 433.6034s\n",
      "Epoch: 1 cost time: 22.63652753829956\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.1825492 Vali Loss: 0.1794220 Test Loss: 0.1603305\n",
      "Validation loss decreased (inf --> 0.179422).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1317747\n",
      "\tspeed: 0.1841s/iter; left time: 1359.7390s\n",
      "\titers: 200, epoch: 2 | loss: 0.1026913\n",
      "\tspeed: 0.0577s/iter; left time: 420.6604s\n",
      "\titers: 300, epoch: 2 | loss: 0.0778040\n",
      "\tspeed: 0.0580s/iter; left time: 417.1566s\n",
      "Epoch: 2 cost time: 23.20224380493164\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.1011940 Vali Loss: 0.1782144 Test Loss: 0.1505446\n",
      "Validation loss decreased (0.179422 --> 0.178214).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0802990\n",
      "\tspeed: 0.2063s/iter; left time: 1442.5877s\n",
      "\titers: 200, epoch: 3 | loss: 0.0902607\n",
      "\tspeed: 0.0642s/iter; left time: 442.8106s\n",
      "\titers: 300, epoch: 3 | loss: 0.0948267\n",
      "\tspeed: 0.0627s/iter; left time: 425.7723s\n",
      "Epoch: 3 cost time: 24.97346591949463\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0861780 Vali Loss: 0.1807123 Test Loss: 0.1834130\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0629842\n",
      "\tspeed: 0.1955s/iter; left time: 1290.2605s\n",
      "\titers: 200, epoch: 4 | loss: 0.0915517\n",
      "\tspeed: 0.0616s/iter; left time: 400.3492s\n",
      "\titers: 300, epoch: 4 | loss: 0.0917645\n",
      "\tspeed: 0.0601s/iter; left time: 384.3259s\n",
      "Epoch: 4 cost time: 23.78748869895935\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0798137 Vali Loss: 0.1934825 Test Loss: 0.1877447\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0575811\n",
      "\tspeed: 0.1868s/iter; left time: 1159.3247s\n",
      "\titers: 200, epoch: 5 | loss: 0.0718418\n",
      "\tspeed: 0.0577s/iter; left time: 352.3497s\n",
      "\titers: 300, epoch: 5 | loss: 0.0922230\n",
      "\tspeed: 0.0587s/iter; left time: 352.5085s\n",
      "Epoch: 5 cost time: 23.280656337738037\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0760448 Vali Loss: 0.2026814 Test Loss: 0.2102983\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.15054461359977722, mae:0.30776119232177734\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'data': 'SYNTH_additive_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 336, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_reversal_ftS_sl168_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.2102457\n",
      "\tspeed: 0.0897s/iter; left time: 688.7923s\n",
      "\titers: 200, epoch: 1 | loss: 0.1893235\n",
      "\tspeed: 0.0850s/iter; left time: 644.2100s\n",
      "\titers: 300, epoch: 1 | loss: 0.1218232\n",
      "\tspeed: 0.0845s/iter; left time: 631.9011s\n",
      "Epoch: 1 cost time: 33.366965770721436\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1963292 Vali Loss: 0.3088475 Test Loss: 0.2921641\n",
      "Validation loss decreased (inf --> 0.308847).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0917575\n",
      "\tspeed: 0.2787s/iter; left time: 2032.5541s\n",
      "\titers: 200, epoch: 2 | loss: 0.0951873\n",
      "\tspeed: 0.0843s/iter; left time: 606.0917s\n",
      "\titers: 300, epoch: 2 | loss: 0.1099481\n",
      "\tspeed: 0.0857s/iter; left time: 607.4579s\n",
      "Epoch: 2 cost time: 33.605427980422974\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.1241414 Vali Loss: 0.2900212 Test Loss: 0.2769194\n",
      "Validation loss decreased (0.308847 --> 0.290021).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1047795\n",
      "\tspeed: 0.2869s/iter; left time: 1980.2466s\n",
      "\titers: 200, epoch: 3 | loss: 0.1025201\n",
      "\tspeed: 0.0794s/iter; left time: 540.4558s\n",
      "\titers: 300, epoch: 3 | loss: 0.1084088\n",
      "\tspeed: 0.0842s/iter; left time: 564.4673s\n",
      "Epoch: 3 cost time: 32.025020360946655\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.1156950 Vali Loss: 0.3079223 Test Loss: 0.2868460\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1101792\n",
      "\tspeed: 0.2712s/iter; left time: 1766.2772s\n",
      "\titers: 200, epoch: 4 | loss: 0.1093474\n",
      "\tspeed: 0.0848s/iter; left time: 543.8905s\n",
      "\titers: 300, epoch: 4 | loss: 0.1161526\n",
      "\tspeed: 0.0847s/iter; left time: 534.8491s\n",
      "Epoch: 4 cost time: 32.853732109069824\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.1121265 Vali Loss: 0.3037292 Test Loss: 0.2798743\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1187072\n",
      "\tspeed: 0.2867s/iter; left time: 1755.9845s\n",
      "\titers: 200, epoch: 5 | loss: 0.1134806\n",
      "\tspeed: 0.0873s/iter; left time: 525.7195s\n",
      "\titers: 300, epoch: 5 | loss: 0.1386798\n",
      "\tspeed: 0.0865s/iter; left time: 512.7086s\n",
      "Epoch: 5 cost time: 33.77160429954529\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.1109395 Vali Loss: 0.3027665 Test Loss: 0.2881911\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.27691933512687683, mae:0.4079340994358063\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'data': 'SYNTH_additive_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 720, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_reversal_ftS_sl168_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.3425818\n",
      "\tspeed: 0.1270s/iter; left time: 944.9230s\n",
      "\titers: 200, epoch: 1 | loss: 0.2815366\n",
      "\tspeed: 0.1355s/iter; left time: 994.5542s\n",
      "\titers: 300, epoch: 1 | loss: 0.2129045\n",
      "\tspeed: 0.1348s/iter; left time: 976.3517s\n",
      "Epoch: 1 cost time: 49.90307307243347\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.2870676 Vali Loss: 0.6954153 Test Loss: 0.4517551\n",
      "Validation loss decreased (inf --> 0.695415).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3008936\n",
      "\tspeed: 0.3843s/iter; left time: 2714.7313s\n",
      "\titers: 200, epoch: 2 | loss: 0.2704085\n",
      "\tspeed: 0.1322s/iter; left time: 920.6693s\n",
      "\titers: 300, epoch: 2 | loss: 0.2455701\n",
      "\tspeed: 0.1323s/iter; left time: 908.2765s\n",
      "Epoch: 2 cost time: 49.182708978652954\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.2427709 Vali Loss: 0.6857174 Test Loss: 0.4481024\n",
      "Validation loss decreased (0.695415 --> 0.685717).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2224709\n",
      "\tspeed: 0.3633s/iter; left time: 2429.5606s\n",
      "\titers: 200, epoch: 3 | loss: 0.2449373\n",
      "\tspeed: 0.1348s/iter; left time: 887.7813s\n",
      "\titers: 300, epoch: 3 | loss: 0.2878642\n",
      "\tspeed: 0.1342s/iter; left time: 870.2607s\n",
      "Epoch: 3 cost time: 49.96109366416931\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.2345510 Vali Loss: 0.6935207 Test Loss: 0.4331803\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2359969\n",
      "\tspeed: 0.3664s/iter; left time: 2312.1903s\n",
      "\titers: 200, epoch: 4 | loss: 0.2373737\n",
      "\tspeed: 0.1347s/iter; left time: 836.3053s\n",
      "\titers: 300, epoch: 4 | loss: 0.2532594\n",
      "\tspeed: 0.1380s/iter; left time: 842.9395s\n",
      "Epoch: 4 cost time: 49.92096734046936\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.2319990 Vali Loss: 0.6971213 Test Loss: 0.4405038\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1757923\n",
      "\tspeed: 0.3660s/iter; left time: 2171.4882s\n",
      "\titers: 200, epoch: 5 | loss: 0.2374484\n",
      "\tspeed: 0.1371s/iter; left time: 799.4408s\n",
      "\titers: 300, epoch: 5 | loss: 0.2375813\n",
      "\tspeed: 0.1351s/iter; left time: 774.5960s\n",
      "Epoch: 5 cost time: 49.75790786743164\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.2298749 Vali Loss: 0.6961741 Test Loss: 0.4440545\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.44810229539871216, mae:0.5544670820236206\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'data': 'SYNTH_multiplicative', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_ftS_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.0807192\n",
      "\tspeed: 0.0499s/iter; left time: 393.4375s\n",
      "\titers: 200, epoch: 1 | loss: 0.0573032\n",
      "\tspeed: 0.0479s/iter; left time: 372.6915s\n",
      "\titers: 300, epoch: 1 | loss: 0.0522093\n",
      "\tspeed: 0.0485s/iter; left time: 372.2649s\n",
      "Epoch: 1 cost time: 19.405887842178345\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.0958705 Vali Loss: 0.1150816 Test Loss: 0.1874675\n",
      "Validation loss decreased (inf --> 0.115082).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0461131\n",
      "\tspeed: 0.1579s/iter; left time: 1181.5074s\n",
      "\titers: 200, epoch: 2 | loss: 0.0403480\n",
      "\tspeed: 0.0474s/iter; left time: 350.0016s\n",
      "\titers: 300, epoch: 2 | loss: 0.0452760\n",
      "\tspeed: 0.0436s/iter; left time: 317.3500s\n",
      "Epoch: 2 cost time: 17.91638684272766\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0380776 Vali Loss: 0.0973048 Test Loss: 0.1634885\n",
      "Validation loss decreased (0.115082 --> 0.097305).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0298782\n",
      "\tspeed: 0.1453s/iter; left time: 1028.8914s\n",
      "\titers: 200, epoch: 3 | loss: 0.0267062\n",
      "\tspeed: 0.0468s/iter; left time: 326.6651s\n",
      "\titers: 300, epoch: 3 | loss: 0.0412021\n",
      "\tspeed: 0.0449s/iter; left time: 308.9667s\n",
      "Epoch: 3 cost time: 18.238226413726807\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0301556 Vali Loss: 0.0836676 Test Loss: 0.1439683\n",
      "Validation loss decreased (0.097305 --> 0.083668).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0326253\n",
      "\tspeed: 0.1561s/iter; left time: 1043.2060s\n",
      "\titers: 200, epoch: 4 | loss: 0.0239265\n",
      "\tspeed: 0.0474s/iter; left time: 312.1929s\n",
      "\titers: 300, epoch: 4 | loss: 0.0298282\n",
      "\tspeed: 0.0475s/iter; left time: 308.1442s\n",
      "Epoch: 4 cost time: 18.986753940582275\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0271229 Vali Loss: 0.0785139 Test Loss: 0.1334105\n",
      "Validation loss decreased (0.083668 --> 0.078514).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0176629\n",
      "\tspeed: 0.1573s/iter; left time: 988.9364s\n",
      "\titers: 200, epoch: 5 | loss: 0.0177301\n",
      "\tspeed: 0.0438s/iter; left time: 271.0495s\n",
      "\titers: 300, epoch: 5 | loss: 0.0278299\n",
      "\tspeed: 0.0439s/iter; left time: 267.1490s\n",
      "Epoch: 5 cost time: 17.793281316757202\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0249840 Vali Loss: 0.0764093 Test Loss: 0.1284124\n",
      "Validation loss decreased (0.078514 --> 0.076409).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0255264\n",
      "\tspeed: 0.1528s/iter; left time: 899.5836s\n",
      "\titers: 200, epoch: 6 | loss: 0.0172610\n",
      "\tspeed: 0.0463s/iter; left time: 267.6396s\n",
      "\titers: 300, epoch: 6 | loss: 0.0229676\n",
      "\tspeed: 0.0478s/iter; left time: 271.8610s\n",
      "Epoch: 6 cost time: 18.704859972000122\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0238582 Vali Loss: 0.0762156 Test Loss: 0.1283749\n",
      "Validation loss decreased (0.076409 --> 0.076216).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0210398\n",
      "\tspeed: 0.1594s/iter; left time: 874.7336s\n",
      "\titers: 200, epoch: 7 | loss: 0.0188155\n",
      "\tspeed: 0.0475s/iter; left time: 256.1143s\n",
      "\titers: 300, epoch: 7 | loss: 0.0286193\n",
      "\tspeed: 0.0474s/iter; left time: 250.4422s\n",
      "Epoch: 7 cost time: 18.82420825958252\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0233411 Vali Loss: 0.0732638 Test Loss: 0.1233467\n",
      "Validation loss decreased (0.076216 --> 0.073264).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0265956\n",
      "\tspeed: 0.1451s/iter; left time: 738.0824s\n",
      "\titers: 200, epoch: 8 | loss: 0.0175012\n",
      "\tspeed: 0.0462s/iter; left time: 230.2879s\n",
      "\titers: 300, epoch: 8 | loss: 0.0179078\n",
      "\tspeed: 0.0463s/iter; left time: 226.4806s\n",
      "Epoch: 8 cost time: 18.035428524017334\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0233027 Vali Loss: 0.0735181 Test Loss: 0.1240013\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0191535\n",
      "\tspeed: 0.1531s/iter; left time: 718.0190s\n",
      "\titers: 200, epoch: 9 | loss: 0.0131860\n",
      "\tspeed: 0.0473s/iter; left time: 217.0465s\n",
      "\titers: 300, epoch: 9 | loss: 0.0201417\n",
      "\tspeed: 0.0475s/iter; left time: 213.4239s\n",
      "Epoch: 9 cost time: 19.03977346420288\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0230919 Vali Loss: 0.0732276 Test Loss: 0.1234766\n",
      "Validation loss decreased (0.073264 --> 0.073228).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0260595\n",
      "\tspeed: 0.1604s/iter; left time: 688.3073s\n",
      "\titers: 200, epoch: 10 | loss: 0.0197198\n",
      "\tspeed: 0.0469s/iter; left time: 196.7131s\n",
      "\titers: 300, epoch: 10 | loss: 0.0315264\n",
      "\tspeed: 0.0416s/iter; left time: 170.1918s\n",
      "Epoch: 10 cost time: 17.680272340774536\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0227034 Vali Loss: 0.0727721 Test Loss: 0.1229689\n",
      "Validation loss decreased (0.073228 --> 0.072772).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0315510\n",
      "\tspeed: 0.1431s/iter; left time: 556.7435s\n",
      "\titers: 200, epoch: 11 | loss: 0.0258551\n",
      "\tspeed: 0.0450s/iter; left time: 170.4621s\n",
      "\titers: 300, epoch: 11 | loss: 0.0184932\n",
      "\tspeed: 0.0452s/iter; left time: 166.8097s\n",
      "Epoch: 11 cost time: 18.134227752685547\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0228742 Vali Loss: 0.0723009 Test Loss: 0.1224627\n",
      "Validation loss decreased (0.072772 --> 0.072301).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0262170\n",
      "\tspeed: 0.1510s/iter; left time: 527.4447s\n",
      "\titers: 200, epoch: 12 | loss: 0.0296045\n",
      "\tspeed: 0.0451s/iter; left time: 152.9289s\n",
      "\titers: 300, epoch: 12 | loss: 0.0271712\n",
      "\tspeed: 0.0442s/iter; left time: 145.6211s\n",
      "Epoch: 12 cost time: 17.637787580490112\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0227140 Vali Loss: 0.0725377 Test Loss: 0.1228477\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0196417\n",
      "\tspeed: 0.1494s/iter; left time: 461.9844s\n",
      "\titers: 200, epoch: 13 | loss: 0.0221909\n",
      "\tspeed: 0.0455s/iter; left time: 136.0455s\n",
      "\titers: 300, epoch: 13 | loss: 0.0250485\n",
      "\tspeed: 0.0450s/iter; left time: 130.0877s\n",
      "Epoch: 13 cost time: 17.784392833709717\n",
      "Epoch: 13, Steps: 399 | Train Loss: 0.0224974 Vali Loss: 0.0728871 Test Loss: 0.1226614\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "\titers: 100, epoch: 14 | loss: 0.0284296\n",
      "\tspeed: 0.1471s/iter; left time: 396.3518s\n",
      "\titers: 200, epoch: 14 | loss: 0.0275775\n",
      "\tspeed: 0.0464s/iter; left time: 120.4052s\n",
      "\titers: 300, epoch: 14 | loss: 0.0188570\n",
      "\tspeed: 0.0457s/iter; left time: 114.0481s\n",
      "Epoch: 14 cost time: 18.30420160293579\n",
      "Epoch: 14, Steps: 399 | Train Loss: 0.0226921 Vali Loss: 0.0723939 Test Loss: 0.1225050\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.12246271222829819, mae:0.27988773584365845\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'data': 'SYNTH_multiplicative', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 48, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_ftS_sl168_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.0702668\n",
      "\tspeed: 0.0456s/iter; left time: 358.1878s\n",
      "\titers: 200, epoch: 1 | loss: 0.0547087\n",
      "\tspeed: 0.0500s/iter; left time: 388.0092s\n",
      "\titers: 300, epoch: 1 | loss: 0.0474716\n",
      "\tspeed: 0.0494s/iter; left time: 378.4150s\n",
      "Epoch: 1 cost time: 19.32977056503296\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0902655 Vali Loss: 0.1118407 Test Loss: 0.1873369\n",
      "Validation loss decreased (inf --> 0.111841).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0252502\n",
      "\tspeed: 0.1686s/iter; left time: 1257.8927s\n",
      "\titers: 200, epoch: 2 | loss: 0.0395282\n",
      "\tspeed: 0.0504s/iter; left time: 370.8221s\n",
      "\titers: 300, epoch: 2 | loss: 0.0271052\n",
      "\tspeed: 0.0499s/iter; left time: 362.6589s\n",
      "Epoch: 2 cost time: 19.92868995666504\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0261269 Vali Loss: 0.1322081 Test Loss: 0.2371496\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0253879\n",
      "\tspeed: 0.1539s/iter; left time: 1087.2842s\n",
      "\titers: 200, epoch: 3 | loss: 0.0170020\n",
      "\tspeed: 0.0461s/iter; left time: 321.2100s\n",
      "\titers: 300, epoch: 3 | loss: 0.0236461\n",
      "\tspeed: 0.0464s/iter; left time: 318.8178s\n",
      "Epoch: 3 cost time: 18.485417127609253\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0193307 Vali Loss: 0.1346275 Test Loss: 0.2350088\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0235545\n",
      "\tspeed: 0.1635s/iter; left time: 1090.0974s\n",
      "\titers: 200, epoch: 4 | loss: 0.0161752\n",
      "\tspeed: 0.0506s/iter; left time: 332.3859s\n",
      "\titers: 300, epoch: 4 | loss: 0.0134992\n",
      "\tspeed: 0.0494s/iter; left time: 319.7684s\n",
      "Epoch: 4 cost time: 20.08879828453064\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0161760 Vali Loss: 0.1389500 Test Loss: 0.2330931\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.18733687698841095, mae:0.3487953543663025\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'data': 'SYNTH_multiplicative', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 168, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_ftS_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.0868328\n",
      "\tspeed: 0.0602s/iter; left time: 468.5315s\n",
      "\titers: 200, epoch: 1 | loss: 0.0751124\n",
      "\tspeed: 0.0621s/iter; left time: 476.9050s\n",
      "\titers: 300, epoch: 1 | loss: 0.0580150\n",
      "\tspeed: 0.0618s/iter; left time: 468.3120s\n",
      "Epoch: 1 cost time: 24.282702445983887\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.0915059 Vali Loss: 0.1689170 Test Loss: 0.2673378\n",
      "Validation loss decreased (inf --> 0.168917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0496121\n",
      "\tspeed: 0.1985s/iter; left time: 1466.4784s\n",
      "\titers: 200, epoch: 2 | loss: 0.0503247\n",
      "\tspeed: 0.0611s/iter; left time: 445.5716s\n",
      "\titers: 300, epoch: 2 | loss: 0.0443375\n",
      "\tspeed: 0.0607s/iter; left time: 436.4834s\n",
      "Epoch: 2 cost time: 23.800981760025024\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0519665 Vali Loss: 0.1547437 Test Loss: 0.2520168\n",
      "Validation loss decreased (0.168917 --> 0.154744).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0390757\n",
      "\tspeed: 0.1863s/iter; left time: 1302.8357s\n",
      "\titers: 200, epoch: 3 | loss: 0.0397006\n",
      "\tspeed: 0.0558s/iter; left time: 384.3752s\n",
      "\titers: 300, epoch: 3 | loss: 0.0354274\n",
      "\tspeed: 0.0602s/iter; left time: 409.2238s\n",
      "Epoch: 3 cost time: 23.1338472366333\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0442314 Vali Loss: 0.1482256 Test Loss: 0.2419406\n",
      "Validation loss decreased (0.154744 --> 0.148226).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0277175\n",
      "\tspeed: 0.1961s/iter; left time: 1294.1818s\n",
      "\titers: 200, epoch: 4 | loss: 0.0353534\n",
      "\tspeed: 0.0556s/iter; left time: 361.6454s\n",
      "\titers: 300, epoch: 4 | loss: 0.0362152\n",
      "\tspeed: 0.0545s/iter; left time: 348.9501s\n",
      "Epoch: 4 cost time: 22.228326082229614\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0404356 Vali Loss: 0.1670956 Test Loss: 0.2785599\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0409214\n",
      "\tspeed: 0.1803s/iter; left time: 1118.6982s\n",
      "\titers: 200, epoch: 5 | loss: 0.0418208\n",
      "\tspeed: 0.0585s/iter; left time: 357.0270s\n",
      "\titers: 300, epoch: 5 | loss: 0.0321347\n",
      "\tspeed: 0.0567s/iter; left time: 340.5191s\n",
      "Epoch: 5 cost time: 22.413238763809204\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0374924 Vali Loss: 0.1592198 Test Loss: 0.2685545\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0388238\n",
      "\tspeed: 0.1788s/iter; left time: 1038.9184s\n",
      "\titers: 200, epoch: 6 | loss: 0.0267189\n",
      "\tspeed: 0.0574s/iter; left time: 328.0297s\n",
      "\titers: 300, epoch: 6 | loss: 0.0342009\n",
      "\tspeed: 0.0593s/iter; left time: 332.8600s\n",
      "Epoch: 6 cost time: 23.13675546646118\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0359061 Vali Loss: 0.1636560 Test Loss: 0.2725803\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.24194058775901794, mae:0.40380343794822693\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'data': 'SYNTH_multiplicative', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 336, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_ftS_sl168_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.1074894\n",
      "\tspeed: 0.0880s/iter; left time: 675.5649s\n",
      "\titers: 200, epoch: 1 | loss: 0.1026780\n",
      "\tspeed: 0.0837s/iter; left time: 634.8128s\n",
      "\titers: 300, epoch: 1 | loss: 0.0831789\n",
      "\tspeed: 0.0842s/iter; left time: 630.2724s\n",
      "Epoch: 1 cost time: 33.093313455581665\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1097633 Vali Loss: 0.2690774 Test Loss: 0.4150747\n",
      "Validation loss decreased (inf --> 0.269077).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0745429\n",
      "\tspeed: 0.2818s/iter; left time: 2054.8098s\n",
      "\titers: 200, epoch: 2 | loss: 0.0773567\n",
      "\tspeed: 0.0844s/iter; left time: 606.7234s\n",
      "\titers: 300, epoch: 2 | loss: 0.0742722\n",
      "\tspeed: 0.0895s/iter; left time: 634.6123s\n",
      "Epoch: 2 cost time: 33.41494679450989\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0773444 Vali Loss: 0.2500485 Test Loss: 0.3879724\n",
      "Validation loss decreased (0.269077 --> 0.250048).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0558074\n",
      "\tspeed: 0.2805s/iter; left time: 1936.4097s\n",
      "\titers: 200, epoch: 3 | loss: 0.0661727\n",
      "\tspeed: 0.0877s/iter; left time: 596.5892s\n",
      "\titers: 300, epoch: 3 | loss: 0.0736716\n",
      "\tspeed: 0.0863s/iter; left time: 578.5646s\n",
      "Epoch: 3 cost time: 33.37964415550232\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0707364 Vali Loss: 0.2762569 Test Loss: 0.4285637\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0652600\n",
      "\tspeed: 0.2876s/iter; left time: 1873.3488s\n",
      "\titers: 200, epoch: 4 | loss: 0.0556339\n",
      "\tspeed: 0.0852s/iter; left time: 546.5605s\n",
      "\titers: 300, epoch: 4 | loss: 0.0599028\n",
      "\tspeed: 0.0862s/iter; left time: 544.2277s\n",
      "Epoch: 4 cost time: 33.17688322067261\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0675802 Vali Loss: 0.2724846 Test Loss: 0.4227966\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0663055\n",
      "\tspeed: 0.2833s/iter; left time: 1735.3765s\n",
      "\titers: 200, epoch: 5 | loss: 0.0679544\n",
      "\tspeed: 0.0882s/iter; left time: 531.6268s\n",
      "\titers: 300, epoch: 5 | loss: 0.0624165\n",
      "\tspeed: 0.0888s/iter; left time: 525.9140s\n",
      "Epoch: 5 cost time: 34.072569370269775\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0650017 Vali Loss: 0.2990510 Test Loss: 0.4733612\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.3879723846912384, mae:0.5100752115249634\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'data': 'SYNTH_multiplicative', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 720, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_ftS_sl168_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.0993140\n",
      "\tspeed: 0.1323s/iter; left time: 984.1784s\n",
      "\titers: 200, epoch: 1 | loss: 0.0917961\n",
      "\tspeed: 0.1374s/iter; left time: 1008.9314s\n",
      "\titers: 300, epoch: 1 | loss: 0.0561059\n",
      "\tspeed: 0.1294s/iter; left time: 937.0746s\n",
      "Epoch: 1 cost time: 49.99919366836548\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.0959764 Vali Loss: 0.2392939 Test Loss: 0.3822205\n",
      "Validation loss decreased (inf --> 0.239294).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0577562\n",
      "\tspeed: 0.3735s/iter; left time: 2638.1092s\n",
      "\titers: 200, epoch: 2 | loss: 0.0522258\n",
      "\tspeed: 0.1357s/iter; left time: 944.7425s\n",
      "\titers: 300, epoch: 2 | loss: 0.0526420\n",
      "\tspeed: 0.1319s/iter; left time: 905.7035s\n",
      "Epoch: 2 cost time: 49.988525390625\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0531868 Vali Loss: 0.1953655 Test Loss: 0.3307510\n",
      "Validation loss decreased (0.239294 --> 0.195366).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0530351\n",
      "\tspeed: 0.3883s/iter; left time: 2596.8774s\n",
      "\titers: 200, epoch: 3 | loss: 0.0409379\n",
      "\tspeed: 0.1244s/iter; left time: 819.6064s\n",
      "\titers: 300, epoch: 3 | loss: 0.0504960\n",
      "\tspeed: 0.1289s/iter; left time: 835.9410s\n",
      "Epoch: 3 cost time: 48.82108926773071\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0461812 Vali Loss: 0.2101905 Test Loss: 0.3477757\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0408030\n",
      "\tspeed: 0.3847s/iter; left time: 2427.3270s\n",
      "\titers: 200, epoch: 4 | loss: 0.0528457\n",
      "\tspeed: 0.1248s/iter; left time: 774.7387s\n",
      "\titers: 300, epoch: 4 | loss: 0.0446990\n",
      "\tspeed: 0.1211s/iter; left time: 739.6269s\n",
      "Epoch: 4 cost time: 48.259905099868774\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0433934 Vali Loss: 0.2314438 Test Loss: 0.7256428\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0494133\n",
      "\tspeed: 0.3921s/iter; left time: 2326.0703s\n",
      "\titers: 200, epoch: 5 | loss: 0.0398107\n",
      "\tspeed: 0.1268s/iter; left time: 739.8789s\n",
      "\titers: 300, epoch: 5 | loss: 0.0380333\n",
      "\tspeed: 0.1259s/iter; left time: 721.9907s\n",
      "Epoch: 5 cost time: 48.775604486465454\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0417143 Vali Loss: 0.3867307 Test Loss: 1.0528324\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.3307509422302246, mae:0.469209223985672\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'data': 'SYNTH_multiplicative_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.0742301\n",
      "\tspeed: 0.0487s/iter; left time: 383.8007s\n",
      "\titers: 200, epoch: 1 | loss: 0.0518181\n",
      "\tspeed: 0.0457s/iter; left time: 355.5172s\n",
      "\titers: 300, epoch: 1 | loss: 0.0500910\n",
      "\tspeed: 0.0479s/iter; left time: 368.1056s\n",
      "Epoch: 1 cost time: 18.889291763305664\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.0799127 Vali Loss: 0.2714935 Test Loss: 0.4694806\n",
      "Validation loss decreased (inf --> 0.271493).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0469464\n",
      "\tspeed: 0.1518s/iter; left time: 1135.7249s\n",
      "\titers: 200, epoch: 2 | loss: 0.0319338\n",
      "\tspeed: 0.0449s/iter; left time: 331.1028s\n",
      "\titers: 300, epoch: 2 | loss: 0.0308230\n",
      "\tspeed: 0.0476s/iter; left time: 346.5925s\n",
      "Epoch: 2 cost time: 18.424617767333984\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0344465 Vali Loss: 0.2244819 Test Loss: 0.4288259\n",
      "Validation loss decreased (0.271493 --> 0.224482).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0312293\n",
      "\tspeed: 0.1596s/iter; left time: 1130.1675s\n",
      "\titers: 200, epoch: 3 | loss: 0.0268173\n",
      "\tspeed: 0.0480s/iter; left time: 335.1430s\n",
      "\titers: 300, epoch: 3 | loss: 0.0200921\n",
      "\tspeed: 0.0477s/iter; left time: 328.4310s\n",
      "Epoch: 3 cost time: 19.018303632736206\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0253965 Vali Loss: 0.2093326 Test Loss: 0.3888722\n",
      "Validation loss decreased (0.224482 --> 0.209333).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0237664\n",
      "\tspeed: 0.1470s/iter; left time: 982.6713s\n",
      "\titers: 200, epoch: 4 | loss: 0.0186893\n",
      "\tspeed: 0.0459s/iter; left time: 302.0925s\n",
      "\titers: 300, epoch: 4 | loss: 0.0408549\n",
      "\tspeed: 0.0448s/iter; left time: 290.4437s\n",
      "Epoch: 4 cost time: 17.544856548309326\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0227341 Vali Loss: 0.2022978 Test Loss: 0.3922454\n",
      "Validation loss decreased (0.209333 --> 0.202298).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0160563\n",
      "\tspeed: 0.1505s/iter; left time: 946.1812s\n",
      "\titers: 200, epoch: 5 | loss: 0.0215688\n",
      "\tspeed: 0.0467s/iter; left time: 288.8658s\n",
      "\titers: 300, epoch: 5 | loss: 0.0140080\n",
      "\tspeed: 0.0461s/iter; left time: 280.3404s\n",
      "Epoch: 5 cost time: 18.55378484725952\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0214563 Vali Loss: 0.2013958 Test Loss: 0.3908371\n",
      "Validation loss decreased (0.202298 --> 0.201396).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0252999\n",
      "\tspeed: 0.1516s/iter; left time: 892.3759s\n",
      "\titers: 200, epoch: 6 | loss: 0.0135351\n",
      "\tspeed: 0.0457s/iter; left time: 264.1961s\n",
      "\titers: 300, epoch: 6 | loss: 0.0191151\n",
      "\tspeed: 0.0458s/iter; left time: 260.5910s\n",
      "Epoch: 6 cost time: 18.21003532409668\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0208005 Vali Loss: 0.1959549 Test Loss: 0.3817401\n",
      "Validation loss decreased (0.201396 --> 0.195955).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0140563\n",
      "\tspeed: 0.1525s/iter; left time: 836.4976s\n",
      "\titers: 200, epoch: 7 | loss: 0.0154749\n",
      "\tspeed: 0.0446s/iter; left time: 240.0614s\n",
      "\titers: 300, epoch: 7 | loss: 0.0158603\n",
      "\tspeed: 0.0450s/iter; left time: 238.0849s\n",
      "Epoch: 7 cost time: 18.14962124824524\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0205186 Vali Loss: 0.1978170 Test Loss: 0.3817783\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0357750\n",
      "\tspeed: 0.1576s/iter; left time: 801.7479s\n",
      "\titers: 200, epoch: 8 | loss: 0.0185196\n",
      "\tspeed: 0.0476s/iter; left time: 237.2293s\n",
      "\titers: 300, epoch: 8 | loss: 0.0169140\n",
      "\tspeed: 0.0479s/iter; left time: 234.0278s\n",
      "Epoch: 8 cost time: 18.87449312210083\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0202847 Vali Loss: 0.1968856 Test Loss: 0.3805034\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0218522\n",
      "\tspeed: 0.1531s/iter; left time: 718.0398s\n",
      "\titers: 200, epoch: 9 | loss: 0.0177717\n",
      "\tspeed: 0.0474s/iter; left time: 217.4156s\n",
      "\titers: 300, epoch: 9 | loss: 0.0178158\n",
      "\tspeed: 0.0471s/iter; left time: 211.3594s\n",
      "Epoch: 9 cost time: 18.376558780670166\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0202293 Vali Loss: 0.1979677 Test Loss: 0.3819179\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.38174009323120117, mae:0.4300791323184967\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'data': 'SYNTH_multiplicative_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 48, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.0881419\n",
      "\tspeed: 0.0462s/iter; left time: 362.9401s\n",
      "\titers: 200, epoch: 1 | loss: 0.0353053\n",
      "\tspeed: 0.0458s/iter; left time: 355.7752s\n",
      "\titers: 300, epoch: 1 | loss: 0.0506566\n",
      "\tspeed: 0.0491s/iter; left time: 376.1034s\n",
      "Epoch: 1 cost time: 18.859236478805542\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0930503 Vali Loss: 0.4155384 Test Loss: 0.6419293\n",
      "Validation loss decreased (inf --> 0.415538).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0422895\n",
      "\tspeed: 0.1623s/iter; left time: 1211.2557s\n",
      "\titers: 200, epoch: 2 | loss: 0.0266684\n",
      "\tspeed: 0.0461s/iter; left time: 339.3717s\n",
      "\titers: 300, epoch: 2 | loss: 0.0307983\n",
      "\tspeed: 0.0461s/iter; left time: 335.1797s\n",
      "Epoch: 2 cost time: 18.548416137695312\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0331501 Vali Loss: 0.3231475 Test Loss: 0.5610135\n",
      "Validation loss decreased (0.415538 --> 0.323147).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0259219\n",
      "\tspeed: 0.1534s/iter; left time: 1083.6556s\n",
      "\titers: 200, epoch: 3 | loss: 0.0221321\n",
      "\tspeed: 0.0451s/iter; left time: 314.4161s\n",
      "\titers: 300, epoch: 3 | loss: 0.0173465\n",
      "\tspeed: 0.0473s/iter; left time: 324.7148s\n",
      "Epoch: 3 cost time: 18.78483271598816\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0263542 Vali Loss: 0.3172082 Test Loss: 0.5664730\n",
      "Validation loss decreased (0.323147 --> 0.317208).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0274402\n",
      "\tspeed: 0.1635s/iter; left time: 1090.3143s\n",
      "\titers: 200, epoch: 4 | loss: 0.0169632\n",
      "\tspeed: 0.0494s/iter; left time: 324.1616s\n",
      "\titers: 300, epoch: 4 | loss: 0.0186806\n",
      "\tspeed: 0.0493s/iter; left time: 318.8598s\n",
      "Epoch: 4 cost time: 19.54899525642395\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0236350 Vali Loss: 0.3172932 Test Loss: 0.5755039\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0236715\n",
      "\tspeed: 0.1648s/iter; left time: 1033.0292s\n",
      "\titers: 200, epoch: 5 | loss: 0.0177516\n",
      "\tspeed: 0.0493s/iter; left time: 304.2631s\n",
      "\titers: 300, epoch: 5 | loss: 0.0194864\n",
      "\tspeed: 0.0490s/iter; left time: 297.4936s\n",
      "Epoch: 5 cost time: 19.748345375061035\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0221062 Vali Loss: 0.3238593 Test Loss: 0.5751892\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0228974\n",
      "\tspeed: 0.1591s/iter; left time: 934.0682s\n",
      "\titers: 200, epoch: 6 | loss: 0.0240571\n",
      "\tspeed: 0.0446s/iter; left time: 257.5393s\n",
      "\titers: 300, epoch: 6 | loss: 0.0141289\n",
      "\tspeed: 0.0444s/iter; left time: 251.6869s\n",
      "Epoch: 6 cost time: 17.822023391723633\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0212873 Vali Loss: 0.3208500 Test Loss: 0.5707312\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.5664730072021484, mae:0.5570381283760071\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'data': 'SYNTH_multiplicative_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 168, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.1304907\n",
      "\tspeed: 0.0555s/iter; left time: 431.6293s\n",
      "\titers: 200, epoch: 1 | loss: 0.0786275\n",
      "\tspeed: 0.0562s/iter; left time: 431.8821s\n",
      "\titers: 300, epoch: 1 | loss: 0.0838257\n",
      "\tspeed: 0.0574s/iter; left time: 434.8884s\n",
      "Epoch: 1 cost time: 22.34692883491516\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.1133954 Vali Loss: 0.5359629 Test Loss: 0.8409821\n",
      "Validation loss decreased (inf --> 0.535963).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0536700\n",
      "\tspeed: 0.1885s/iter; left time: 1392.4541s\n",
      "\titers: 200, epoch: 2 | loss: 0.0850041\n",
      "\tspeed: 0.0583s/iter; left time: 424.6832s\n",
      "\titers: 300, epoch: 2 | loss: 0.0537495\n",
      "\tspeed: 0.0578s/iter; left time: 415.4544s\n",
      "Epoch: 2 cost time: 22.937766790390015\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0664872 Vali Loss: 0.5127056 Test Loss: 0.8253941\n",
      "Validation loss decreased (0.535963 --> 0.512706).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0623479\n",
      "\tspeed: 0.1891s/iter; left time: 1322.6273s\n",
      "\titers: 200, epoch: 3 | loss: 0.0744567\n",
      "\tspeed: 0.0582s/iter; left time: 400.9160s\n",
      "\titers: 300, epoch: 3 | loss: 0.0482659\n",
      "\tspeed: 0.0591s/iter; left time: 401.4315s\n",
      "Epoch: 3 cost time: 23.040998935699463\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0588128 Vali Loss: 0.5161116 Test Loss: 0.8454422\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0462743\n",
      "\tspeed: 0.1886s/iter; left time: 1244.8248s\n",
      "\titers: 200, epoch: 4 | loss: 0.0423637\n",
      "\tspeed: 0.0608s/iter; left time: 395.3304s\n",
      "\titers: 300, epoch: 4 | loss: 0.0666727\n",
      "\tspeed: 0.0581s/iter; left time: 371.7024s\n",
      "Epoch: 4 cost time: 23.424922466278076\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0554845 Vali Loss: 0.5127209 Test Loss: 0.8396013\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0475469\n",
      "\tspeed: 0.1809s/iter; left time: 1122.5290s\n",
      "\titers: 200, epoch: 5 | loss: 0.0426500\n",
      "\tspeed: 0.0592s/iter; left time: 361.2471s\n",
      "\titers: 300, epoch: 5 | loss: 0.0434911\n",
      "\tspeed: 0.0600s/iter; left time: 360.0298s\n",
      "Epoch: 5 cost time: 23.544137716293335\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0528970 Vali Loss: 0.5046974 Test Loss: 0.8416784\n",
      "Validation loss decreased (0.512706 --> 0.504697).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0432896\n",
      "\tspeed: 0.2014s/iter; left time: 1170.1517s\n",
      "\titers: 200, epoch: 6 | loss: 0.0431233\n",
      "\tspeed: 0.0621s/iter; left time: 354.7002s\n",
      "\titers: 300, epoch: 6 | loss: 0.0557149\n",
      "\tspeed: 0.0601s/iter; left time: 337.1684s\n",
      "Epoch: 6 cost time: 24.103524684906006\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0516067 Vali Loss: 0.5063710 Test Loss: 0.8354825\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0536803\n",
      "\tspeed: 0.1746s/iter; left time: 945.6944s\n",
      "\titers: 200, epoch: 7 | loss: 0.0330613\n",
      "\tspeed: 0.0610s/iter; left time: 324.4603s\n",
      "\titers: 300, epoch: 7 | loss: 0.0646046\n",
      "\tspeed: 0.0607s/iter; left time: 316.7784s\n",
      "Epoch: 7 cost time: 23.893460035324097\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0507120 Vali Loss: 0.5052833 Test Loss: 0.8376104\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0468986\n",
      "\tspeed: 0.1884s/iter; left time: 946.4065s\n",
      "\titers: 200, epoch: 8 | loss: 0.0527706\n",
      "\tspeed: 0.0580s/iter; left time: 285.7430s\n",
      "\titers: 300, epoch: 8 | loss: 0.0655742\n",
      "\tspeed: 0.0572s/iter; left time: 276.0584s\n",
      "Epoch: 8 cost time: 22.88869571685791\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0500685 Vali Loss: 0.5076252 Test Loss: 0.8455717\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.841678261756897, mae:0.6557894349098206\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'data': 'SYNTH_multiplicative_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 336, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.1229314\n",
      "\tspeed: 0.0871s/iter; left time: 668.7489s\n",
      "\titers: 200, epoch: 1 | loss: 0.0868356\n",
      "\tspeed: 0.0826s/iter; left time: 626.2547s\n",
      "\titers: 300, epoch: 1 | loss: 0.1157569\n",
      "\tspeed: 0.0825s/iter; left time: 617.3684s\n",
      "Epoch: 1 cost time: 32.90169811248779\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1497730 Vali Loss: 0.8381287 Test Loss: 1.2956282\n",
      "Validation loss decreased (inf --> 0.838129).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0873988\n",
      "\tspeed: 0.2803s/iter; left time: 2044.2853s\n",
      "\titers: 200, epoch: 2 | loss: 0.0591815\n",
      "\tspeed: 0.0869s/iter; left time: 624.7745s\n",
      "\titers: 300, epoch: 2 | loss: 0.0877028\n",
      "\tspeed: 0.0868s/iter; left time: 615.4133s\n",
      "Epoch: 2 cost time: 33.82540202140808\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0958020 Vali Loss: 0.8384969 Test Loss: 1.3088400\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1407710\n",
      "\tspeed: 0.2794s/iter; left time: 1928.6603s\n",
      "\titers: 200, epoch: 3 | loss: 0.1088658\n",
      "\tspeed: 0.0809s/iter; left time: 550.0499s\n",
      "\titers: 300, epoch: 3 | loss: 0.0935345\n",
      "\tspeed: 0.0798s/iter; left time: 534.9887s\n",
      "Epoch: 3 cost time: 32.01332378387451\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0889183 Vali Loss: 0.8226742 Test Loss: 1.2864833\n",
      "Validation loss decreased (0.838129 --> 0.822674).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0640899\n",
      "\tspeed: 0.2891s/iter; left time: 1883.2137s\n",
      "\titers: 200, epoch: 4 | loss: 0.1164530\n",
      "\tspeed: 0.0875s/iter; left time: 561.3487s\n",
      "\titers: 300, epoch: 4 | loss: 0.0739887\n",
      "\tspeed: 0.0852s/iter; left time: 537.7305s\n",
      "Epoch: 4 cost time: 33.931673526763916\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0855548 Vali Loss: 0.8068069 Test Loss: 1.2782497\n",
      "Validation loss decreased (0.822674 --> 0.806807).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0887748\n",
      "\tspeed: 0.2721s/iter; left time: 1666.8408s\n",
      "\titers: 200, epoch: 5 | loss: 0.0556237\n",
      "\tspeed: 0.0820s/iter; left time: 493.7576s\n",
      "\titers: 300, epoch: 5 | loss: 0.0602000\n",
      "\tspeed: 0.0823s/iter; left time: 487.5024s\n",
      "Epoch: 5 cost time: 31.360766649246216\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0837343 Vali Loss: 0.8051268 Test Loss: 1.2851059\n",
      "Validation loss decreased (0.806807 --> 0.805127).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0762283\n",
      "\tspeed: 0.2739s/iter; left time: 1571.2588s\n",
      "\titers: 200, epoch: 6 | loss: 0.0901718\n",
      "\tspeed: 0.0858s/iter; left time: 483.8115s\n",
      "\titers: 300, epoch: 6 | loss: 0.0526806\n",
      "\tspeed: 0.0874s/iter; left time: 484.0022s\n",
      "Epoch: 6 cost time: 33.60284614562988\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0826831 Vali Loss: 0.8079613 Test Loss: 1.2894158\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0679300\n",
      "\tspeed: 0.2909s/iter; left time: 1555.5035s\n",
      "\titers: 200, epoch: 7 | loss: 0.0538052\n",
      "\tspeed: 0.0852s/iter; left time: 446.9110s\n",
      "\titers: 300, epoch: 7 | loss: 0.0891686\n",
      "\tspeed: 0.0829s/iter; left time: 426.9103s\n",
      "Epoch: 7 cost time: 33.312074422836304\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.0822054 Vali Loss: 0.8131982 Test Loss: 1.2960446\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0882906\n",
      "\tspeed: 0.2836s/iter; left time: 1406.1755s\n",
      "\titers: 200, epoch: 8 | loss: 0.1120968\n",
      "\tspeed: 0.0876s/iter; left time: 425.6498s\n",
      "\titers: 300, epoch: 8 | loss: 0.0626916\n",
      "\tspeed: 0.0881s/iter; left time: 418.9765s\n",
      "Epoch: 8 cost time: 34.07402729988098\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.0817880 Vali Loss: 0.8135445 Test Loss: 1.2976394\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:1.28510582447052, mae:0.8719449639320374\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'data': 'SYNTH_multiplicative_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 720, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.1594375\n",
      "\tspeed: 0.1328s/iter; left time: 988.0786s\n",
      "\titers: 200, epoch: 1 | loss: 0.1590692\n",
      "\tspeed: 0.1346s/iter; left time: 988.1272s\n",
      "\titers: 300, epoch: 1 | loss: 0.0898616\n",
      "\tspeed: 0.1347s/iter; left time: 975.5276s\n",
      "Epoch: 1 cost time: 49.80944514274597\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.1317056 Vali Loss: 1.3741511 Test Loss: 2.2733519\n",
      "Validation loss decreased (inf --> 1.374151).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1054707\n",
      "\tspeed: 0.3649s/iter; left time: 2577.3075s\n",
      "\titers: 200, epoch: 2 | loss: 0.1209370\n",
      "\tspeed: 0.1371s/iter; left time: 954.6208s\n",
      "\titers: 300, epoch: 2 | loss: 0.0969860\n",
      "\tspeed: 0.1342s/iter; left time: 921.1127s\n",
      "Epoch: 2 cost time: 49.83900022506714\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0933544 Vali Loss: 1.3610325 Test Loss: 2.3894696\n",
      "Validation loss decreased (1.374151 --> 1.361032).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0611472\n",
      "\tspeed: 0.3641s/iter; left time: 2434.9284s\n",
      "\titers: 200, epoch: 3 | loss: 0.0978760\n",
      "\tspeed: 0.1341s/iter; left time: 883.2334s\n",
      "\titers: 300, epoch: 3 | loss: 0.0898258\n",
      "\tspeed: 0.1352s/iter; left time: 877.1283s\n",
      "Epoch: 3 cost time: 49.52164030075073\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0841725 Vali Loss: 1.3472486 Test Loss: 2.3451574\n",
      "Validation loss decreased (1.361032 --> 1.347249).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0627530\n",
      "\tspeed: 0.3593s/iter; left time: 2266.9293s\n",
      "\titers: 200, epoch: 4 | loss: 0.1136604\n",
      "\tspeed: 0.1265s/iter; left time: 785.4061s\n",
      "\titers: 300, epoch: 4 | loss: 0.1137947\n",
      "\tspeed: 0.1282s/iter; left time: 783.5980s\n",
      "Epoch: 4 cost time: 47.82375431060791\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0791663 Vali Loss: 1.4546336 Test Loss: 2.3038740\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0595120\n",
      "\tspeed: 0.3788s/iter; left time: 2247.1783s\n",
      "\titers: 200, epoch: 5 | loss: 0.1072612\n",
      "\tspeed: 0.1407s/iter; left time: 820.4834s\n",
      "\titers: 300, epoch: 5 | loss: 0.0795538\n",
      "\tspeed: 0.1367s/iter; left time: 783.6679s\n",
      "Epoch: 5 cost time: 51.32486844062805\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0731046 Vali Loss: 1.4190254 Test Loss: 2.5937412\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0488309\n",
      "\tspeed: 0.3699s/iter; left time: 2055.0772s\n",
      "\titers: 200, epoch: 6 | loss: 0.0562434\n",
      "\tspeed: 0.1266s/iter; left time: 690.8707s\n",
      "\titers: 300, epoch: 6 | loss: 0.0471464\n",
      "\tspeed: 0.1292s/iter; left time: 691.8800s\n",
      "Epoch: 6 cost time: 48.495952129364014\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0700309 Vali Loss: 1.5492501 Test Loss: 2.4917474\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:2.3451576232910156, mae:1.30793297290802\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on ETTh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'OT', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'data': 'ETTh1', 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "\titers: 100, epoch: 1 | loss: 0.3350031\n",
      "\tspeed: 0.0379s/iter; left time: 198.1096s\n",
      "\titers: 200, epoch: 1 | loss: 0.3437403\n",
      "\tspeed: 0.0370s/iter; left time: 189.6289s\n",
      "Epoch: 1 cost time: 9.953446626663208\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.3617640 Vali Loss: 0.6259076 Test Loss: 0.4146029\n",
      "Validation loss decreased (inf --> 0.625908).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2583655\n",
      "\tspeed: 0.1396s/iter; left time: 691.6705s\n",
      "\titers: 200, epoch: 2 | loss: 0.3729258\n",
      "\tspeed: 0.0367s/iter; left time: 178.0759s\n",
      "Epoch: 2 cost time: 9.44831132888794\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.3035032 Vali Loss: 0.5906908 Test Loss: 0.4182288\n",
      "Validation loss decreased (0.625908 --> 0.590691).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3526179\n",
      "\tspeed: 0.1346s/iter; left time: 631.0477s\n",
      "\titers: 200, epoch: 3 | loss: 0.2846116\n",
      "\tspeed: 0.0345s/iter; left time: 158.4756s\n",
      "Epoch: 3 cost time: 9.003334522247314\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.2723160 Vali Loss: 0.6117865 Test Loss: 0.4196424\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2575660\n",
      "\tspeed: 0.1207s/iter; left time: 533.8101s\n",
      "\titers: 200, epoch: 4 | loss: 0.2378469\n",
      "\tspeed: 0.0329s/iter; left time: 142.0887s\n",
      "Epoch: 4 cost time: 8.669971704483032\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.2544615 Vali Loss: 0.6291730 Test Loss: 0.4531414\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2267616\n",
      "\tspeed: 0.1350s/iter; left time: 561.3917s\n",
      "\titers: 200, epoch: 5 | loss: 0.2428440\n",
      "\tspeed: 0.0353s/iter; left time: 143.0314s\n",
      "Epoch: 5 cost time: 9.136388778686523\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.2441198 Vali Loss: 0.6387736 Test Loss: 0.4513933\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "mse:0.4182288646697998, mae:0.4328087866306305\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on ETTh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'OT', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'data': 'ETTh1', 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_ETTh1_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "\titers: 100, epoch: 1 | loss: 0.3963910\n",
      "\tspeed: 0.0380s/iter; left time: 197.8406s\n",
      "\titers: 200, epoch: 1 | loss: 0.3501343\n",
      "\tspeed: 0.0375s/iter; left time: 191.3719s\n",
      "Epoch: 1 cost time: 9.970832347869873\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.4030388 Vali Loss: 0.6875486 Test Loss: 0.4558757\n",
      "Validation loss decreased (inf --> 0.687549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2986519\n",
      "\tspeed: 0.1294s/iter; left time: 638.7559s\n",
      "\titers: 200, epoch: 2 | loss: 0.2935923\n",
      "\tspeed: 0.0330s/iter; left time: 159.4902s\n",
      "Epoch: 2 cost time: 8.800190925598145\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.3319139 Vali Loss: 0.7192553 Test Loss: 0.4394707\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3055536\n",
      "\tspeed: 0.1249s/iter; left time: 583.4371s\n",
      "\titers: 200, epoch: 3 | loss: 0.2758413\n",
      "\tspeed: 0.0367s/iter; left time: 167.6758s\n",
      "Epoch: 3 cost time: 9.372741937637329\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.2973943 Vali Loss: 0.7194601 Test Loss: 0.4644088\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2396073\n",
      "\tspeed: 0.1320s/iter; left time: 581.7386s\n",
      "\titers: 200, epoch: 4 | loss: 0.3352402\n",
      "\tspeed: 0.0382s/iter; left time: 164.4737s\n",
      "Epoch: 4 cost time: 10.127148866653442\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.2749084 Vali Loss: 0.7477396 Test Loss: 0.4857221\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (2816, 48, 7) (2816, 48, 7)\n",
      "test shape: (2816, 48, 7) (2816, 48, 7)\n",
      "mse:0.4558757245540619, mae:0.4555194675922394\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on ETTh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'OT', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'data': 'ETTh1', 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_ETTh1_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "\titers: 100, epoch: 1 | loss: 0.4569494\n",
      "\tspeed: 0.0589s/iter; left time: 301.6730s\n",
      "\titers: 200, epoch: 1 | loss: 0.4032928\n",
      "\tspeed: 0.0592s/iter; left time: 297.4541s\n",
      "Epoch: 1 cost time: 15.383484125137329\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.4669391 Vali Loss: 1.0900730 Test Loss: 0.4897761\n",
      "Validation loss decreased (inf --> 1.090073).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4138458\n",
      "\tspeed: 0.2016s/iter; left time: 979.7511s\n",
      "\titers: 200, epoch: 2 | loss: 0.3765217\n",
      "\tspeed: 0.0558s/iter; left time: 265.6645s\n",
      "Epoch: 2 cost time: 14.24795126914978\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.4173543 Vali Loss: 1.0794027 Test Loss: 0.5104578\n",
      "Validation loss decreased (1.090073 --> 1.079403).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4149428\n",
      "\tspeed: 0.2110s/iter; left time: 970.2573s\n",
      "\titers: 200, epoch: 3 | loss: 0.3754700\n",
      "\tspeed: 0.0573s/iter; left time: 257.5975s\n",
      "Epoch: 3 cost time: 14.789433717727661\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.3832855 Vali Loss: 1.0811179 Test Loss: 0.5175145\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3761794\n",
      "\tspeed: 0.2030s/iter; left time: 880.4921s\n",
      "\titers: 200, epoch: 4 | loss: 0.3315541\n",
      "\tspeed: 0.0565s/iter; left time: 239.6162s\n",
      "Epoch: 4 cost time: 14.259881019592285\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.3491985 Vali Loss: 1.1402003 Test Loss: 0.5467769\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2742330\n",
      "\tspeed: 0.2095s/iter; left time: 854.0712s\n",
      "\titers: 200, epoch: 5 | loss: 0.3106745\n",
      "\tspeed: 0.0590s/iter; left time: 234.6980s\n",
      "Epoch: 5 cost time: 15.16505765914917\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.3315496 Vali Loss: 1.1812701 Test Loss: 0.6202512\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (2688, 168, 7) (2688, 168, 7)\n",
      "test shape: (2688, 168, 7) (2688, 168, 7)\n",
      "mse:0.5104580521583557, mae:0.48274368047714233\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on ETTh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'OT', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'data': 'ETTh1', 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_ETTh1_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.5407715\n",
      "\tspeed: 0.0861s/iter; left time: 432.2007s\n",
      "\titers: 200, epoch: 1 | loss: 0.4930281\n",
      "\tspeed: 0.0852s/iter; left time: 419.3672s\n",
      "Epoch: 1 cost time: 21.851548671722412\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.5490899 Vali Loss: 1.4566970 Test Loss: 0.5443269\n",
      "Validation loss decreased (inf --> 1.456697).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5525213\n",
      "\tspeed: 0.3224s/iter; left time: 1536.1755s\n",
      "\titers: 200, epoch: 2 | loss: 0.5171357\n",
      "\tspeed: 0.0799s/iter; left time: 372.8438s\n",
      "Epoch: 2 cost time: 20.688899755477905\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.5132593 Vali Loss: 1.3929950 Test Loss: 0.5000268\n",
      "Validation loss decreased (1.456697 --> 1.392995).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5209914\n",
      "\tspeed: 0.3123s/iter; left time: 1408.0440s\n",
      "\titers: 200, epoch: 3 | loss: 0.4644174\n",
      "\tspeed: 0.0809s/iter; left time: 356.7496s\n",
      "Epoch: 3 cost time: 20.449487924575806\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.4801880 Vali Loss: 1.4079629 Test Loss: 0.4993044\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4207484\n",
      "\tspeed: 0.3138s/iter; left time: 1334.7316s\n",
      "\titers: 200, epoch: 4 | loss: 0.4688427\n",
      "\tspeed: 0.0800s/iter; left time: 332.1352s\n",
      "Epoch: 4 cost time: 20.56812334060669\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.4521036 Vali Loss: 1.4010388 Test Loss: 0.5091251\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5021355\n",
      "\tspeed: 0.3167s/iter; left time: 1265.8469s\n",
      "\titers: 200, epoch: 5 | loss: 0.4488682\n",
      "\tspeed: 0.0823s/iter; left time: 320.7276s\n",
      "Epoch: 5 cost time: 21.338614463806152\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.4350704 Vali Loss: 1.4140110 Test Loss: 0.5328749\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "mse:0.5000270009040833, mae:0.48927026987075806\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on ETTh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'OT', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'data': 'ETTh1', 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_ETTh1_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "\titers: 100, epoch: 1 | loss: 0.6034431\n",
      "\tspeed: 0.1264s/iter; left time: 604.1755s\n",
      "\titers: 200, epoch: 1 | loss: 0.6839440\n",
      "\tspeed: 0.1322s/iter; left time: 618.7173s\n",
      "Epoch: 1 cost time: 31.81335163116455\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.6562528 Vali Loss: 1.6407096 Test Loss: 0.5169175\n",
      "Validation loss decreased (inf --> 1.640710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6183530\n",
      "\tspeed: 0.4140s/iter; left time: 1878.3924s\n",
      "\titers: 200, epoch: 2 | loss: 0.6203642\n",
      "\tspeed: 0.1319s/iter; left time: 585.4160s\n",
      "Epoch: 2 cost time: 31.575406074523926\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.6284610 Vali Loss: 1.6355759 Test Loss: 0.5121846\n",
      "Validation loss decreased (1.640710 --> 1.635576).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5424106\n",
      "\tspeed: 0.4184s/iter; left time: 1796.0534s\n",
      "\titers: 200, epoch: 3 | loss: 0.6582044\n",
      "\tspeed: 0.1347s/iter; left time: 564.9751s\n",
      "Epoch: 3 cost time: 31.887474060058594\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.6207990 Vali Loss: 1.6484911 Test Loss: 0.5200861\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.6666629\n",
      "\tspeed: 0.4429s/iter; left time: 1793.4496s\n",
      "\titers: 200, epoch: 4 | loss: 0.5945017\n",
      "\tspeed: 0.1339s/iter; left time: 528.9218s\n",
      "Epoch: 4 cost time: 32.38261318206787\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.6155918 Vali Loss: 1.6327412 Test Loss: 0.5138777\n",
      "Validation loss decreased (1.635576 --> 1.632741).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5922542\n",
      "\tspeed: 0.4217s/iter; left time: 1604.6622s\n",
      "\titers: 200, epoch: 5 | loss: 0.6505889\n",
      "\tspeed: 0.1276s/iter; left time: 472.7994s\n",
      "Epoch: 5 cost time: 31.206109046936035\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.6130920 Vali Loss: 1.6345499 Test Loss: 0.5122420\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.6639882\n",
      "\tspeed: 0.4108s/iter; left time: 1463.0052s\n",
      "\titers: 200, epoch: 6 | loss: 0.6302395\n",
      "\tspeed: 0.1252s/iter; left time: 433.1466s\n",
      "Epoch: 6 cost time: 30.092228174209595\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.6118530 Vali Loss: 1.6357380 Test Loss: 0.5199575\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.6214004\n",
      "\tspeed: 0.4230s/iter; left time: 1402.9296s\n",
      "\titers: 200, epoch: 7 | loss: 0.5968197\n",
      "\tspeed: 0.1340s/iter; left time: 430.9820s\n",
      "Epoch: 7 cost time: 31.95110821723938\n",
      "Epoch: 7, Steps: 244 | Train Loss: 0.6113248 Vali Loss: 1.6320609 Test Loss: 0.5176426\n",
      "Validation loss decreased (1.632741 --> 1.632061).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.5275323\n",
      "\tspeed: 0.4369s/iter; left time: 1342.6844s\n",
      "\titers: 200, epoch: 8 | loss: 0.6742898\n",
      "\tspeed: 0.1314s/iter; left time: 390.5110s\n",
      "Epoch: 8 cost time: 32.009053230285645\n",
      "Epoch: 8, Steps: 244 | Train Loss: 0.6108619 Vali Loss: 1.6354758 Test Loss: 0.5198112\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.5438420\n",
      "\tspeed: 0.4321s/iter; left time: 1222.4606s\n",
      "\titers: 200, epoch: 9 | loss: 0.6877356\n",
      "\tspeed: 0.1297s/iter; left time: 353.8843s\n",
      "Epoch: 9 cost time: 30.31292223930359\n",
      "Epoch: 9, Steps: 244 | Train Loss: 0.6103979 Vali Loss: 1.6379983 Test Loss: 0.5208365\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.6545905\n",
      "\tspeed: 0.4142s/iter; left time: 1070.7793s\n",
      "\titers: 200, epoch: 10 | loss: 0.7238104\n",
      "\tspeed: 0.1256s/iter; left time: 312.0888s\n",
      "Epoch: 10 cost time: 30.50607991218567\n",
      "Epoch: 10, Steps: 244 | Train Loss: 0.6104909 Vali Loss: 1.6357731 Test Loss: 0.5203702\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "mse:0.5176423788070679, mae:0.5177502036094666\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on DEWINDh_small with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'data': 'DEWINDh_small', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_DEWINDh_small_ftS_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.2153363\n",
      "\tspeed: 0.0436s/iter; left time: 343.5106s\n",
      "\titers: 200, epoch: 1 | loss: 0.1530178\n",
      "\tspeed: 0.0456s/iter; left time: 354.5545s\n",
      "\titers: 300, epoch: 1 | loss: 0.2031541\n",
      "\tspeed: 0.0460s/iter; left time: 353.0101s\n",
      "Epoch: 1 cost time: 18.20892071723938\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.2315268 Vali Loss: 0.2341259 Test Loss: 0.2817961\n",
      "Validation loss decreased (inf --> 0.234126).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1914416\n",
      "\tspeed: 0.1564s/iter; left time: 1170.0517s\n",
      "\titers: 200, epoch: 2 | loss: 0.1984302\n",
      "\tspeed: 0.0461s/iter; left time: 340.5087s\n",
      "\titers: 300, epoch: 2 | loss: 0.1563466\n",
      "\tspeed: 0.0486s/iter; left time: 353.5772s\n",
      "Epoch: 2 cost time: 18.962992668151855\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.1612572 Vali Loss: 0.1881009 Test Loss: 0.1961022\n",
      "Validation loss decreased (0.234126 --> 0.188101).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1447318\n",
      "\tspeed: 0.1647s/iter; left time: 1166.8876s\n",
      "\titers: 200, epoch: 3 | loss: 0.1570950\n",
      "\tspeed: 0.0477s/iter; left time: 333.2285s\n",
      "\titers: 300, epoch: 3 | loss: 0.1169944\n",
      "\tspeed: 0.0478s/iter; left time: 329.0647s\n",
      "Epoch: 3 cost time: 18.997560262680054\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.1441305 Vali Loss: 0.1757415 Test Loss: 0.1847298\n",
      "Validation loss decreased (0.188101 --> 0.175742).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1497929\n",
      "\tspeed: 0.1551s/iter; left time: 1036.4532s\n",
      "\titers: 200, epoch: 4 | loss: 0.1398592\n",
      "\tspeed: 0.0448s/iter; left time: 294.9993s\n",
      "\titers: 300, epoch: 4 | loss: 0.1868481\n",
      "\tspeed: 0.0446s/iter; left time: 289.1604s\n",
      "Epoch: 4 cost time: 17.956048250198364\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.1365369 Vali Loss: 0.1592278 Test Loss: 0.2839131\n",
      "Validation loss decreased (0.175742 --> 0.159228).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1287408\n",
      "\tspeed: 0.1427s/iter; left time: 896.8821s\n",
      "\titers: 200, epoch: 5 | loss: 0.1984923\n",
      "\tspeed: 0.0433s/iter; left time: 268.0512s\n",
      "\titers: 300, epoch: 5 | loss: 0.1593533\n",
      "\tspeed: 0.0472s/iter; left time: 287.3968s\n",
      "Epoch: 5 cost time: 17.961496353149414\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.1316886 Vali Loss: 0.1639816 Test Loss: 0.3616982\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0922295\n",
      "\tspeed: 0.1542s/iter; left time: 907.3477s\n",
      "\titers: 200, epoch: 6 | loss: 0.1589044\n",
      "\tspeed: 0.0458s/iter; left time: 264.7313s\n",
      "\titers: 300, epoch: 6 | loss: 0.1013989\n",
      "\tspeed: 0.0453s/iter; left time: 257.6570s\n",
      "Epoch: 6 cost time: 18.285492658615112\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.1295375 Vali Loss: 0.1567618 Test Loss: 0.2691850\n",
      "Validation loss decreased (0.159228 --> 0.156762).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1341094\n",
      "\tspeed: 0.1501s/iter; left time: 823.7482s\n",
      "\titers: 200, epoch: 7 | loss: 0.0987325\n",
      "\tspeed: 0.0446s/iter; left time: 240.5029s\n",
      "\titers: 300, epoch: 7 | loss: 0.1225712\n",
      "\tspeed: 0.0443s/iter; left time: 234.1924s\n",
      "Epoch: 7 cost time: 17.92305040359497\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.1283787 Vali Loss: 0.1551753 Test Loss: 0.2522349\n",
      "Validation loss decreased (0.156762 --> 0.155175).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1243946\n",
      "\tspeed: 0.1565s/iter; left time: 796.0920s\n",
      "\titers: 200, epoch: 8 | loss: 0.1127557\n",
      "\tspeed: 0.0464s/iter; left time: 231.3652s\n",
      "\titers: 300, epoch: 8 | loss: 0.1271928\n",
      "\tspeed: 0.0479s/iter; left time: 234.2302s\n",
      "Epoch: 8 cost time: 18.909125328063965\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.1275012 Vali Loss: 0.1548722 Test Loss: 0.2661631\n",
      "Validation loss decreased (0.155175 --> 0.154872).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0982407\n",
      "\tspeed: 0.1582s/iter; left time: 741.8403s\n",
      "\titers: 200, epoch: 9 | loss: 0.0885363\n",
      "\tspeed: 0.0459s/iter; left time: 210.4846s\n",
      "\titers: 300, epoch: 9 | loss: 0.1568699\n",
      "\tspeed: 0.0427s/iter; left time: 191.8530s\n",
      "Epoch: 9 cost time: 17.711316108703613\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.1269224 Vali Loss: 0.1570923 Test Loss: 0.2717800\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1214748\n",
      "\tspeed: 0.1417s/iter; left time: 607.8494s\n",
      "\titers: 200, epoch: 10 | loss: 0.0794441\n",
      "\tspeed: 0.0462s/iter; left time: 193.7306s\n",
      "\titers: 300, epoch: 10 | loss: 0.1297878\n",
      "\tspeed: 0.0468s/iter; left time: 191.5535s\n",
      "Epoch: 10 cost time: 18.030800342559814\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.1264245 Vali Loss: 0.1551641 Test Loss: 0.2769729\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1201954\n",
      "\tspeed: 0.1550s/iter; left time: 603.1115s\n",
      "\titers: 200, epoch: 11 | loss: 0.1199176\n",
      "\tspeed: 0.0463s/iter; left time: 175.6766s\n",
      "\titers: 300, epoch: 11 | loss: 0.0952129\n",
      "\tspeed: 0.0479s/iter; left time: 176.9462s\n",
      "Epoch: 11 cost time: 18.623117446899414\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.1261829 Vali Loss: 0.1562628 Test Loss: 0.2754727\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.26616308093070984, mae:0.3522849678993225\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on DEWINDh_small with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'data': 'DEWINDh_small', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 48, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_DEWINDh_small_ftS_sl168_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.2041016\n",
      "\tspeed: 0.0460s/iter; left time: 361.8689s\n",
      "\titers: 200, epoch: 1 | loss: 0.1870528\n",
      "\tspeed: 0.0478s/iter; left time: 370.6165s\n",
      "\titers: 300, epoch: 1 | loss: 0.1742929\n",
      "\tspeed: 0.0468s/iter; left time: 358.8708s\n",
      "Epoch: 1 cost time: 18.78045630455017\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.2382912 Vali Loss: 0.2336921 Test Loss: 0.1894751\n",
      "Validation loss decreased (inf --> 0.233692).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1714610\n",
      "\tspeed: 0.1567s/iter; left time: 1169.0996s\n",
      "\titers: 200, epoch: 2 | loss: 0.1894555\n",
      "\tspeed: 0.0459s/iter; left time: 337.9874s\n",
      "\titers: 300, epoch: 2 | loss: 0.1412674\n",
      "\tspeed: 0.0462s/iter; left time: 335.7510s\n",
      "Epoch: 2 cost time: 18.442137956619263\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.1791534 Vali Loss: 0.2073221 Test Loss: 0.1830328\n",
      "Validation loss decreased (0.233692 --> 0.207322).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2225396\n",
      "\tspeed: 0.1521s/iter; left time: 1074.6026s\n",
      "\titers: 200, epoch: 3 | loss: 0.1161138\n",
      "\tspeed: 0.0457s/iter; left time: 318.4138s\n",
      "\titers: 300, epoch: 3 | loss: 0.1643439\n",
      "\tspeed: 0.0483s/iter; left time: 331.2389s\n",
      "Epoch: 3 cost time: 18.721947193145752\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.1637591 Vali Loss: 0.2040951 Test Loss: 0.1850322\n",
      "Validation loss decreased (0.207322 --> 0.204095).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1972036\n",
      "\tspeed: 0.1617s/iter; left time: 1078.3221s\n",
      "\titers: 200, epoch: 4 | loss: 0.1398482\n",
      "\tspeed: 0.0468s/iter; left time: 307.4500s\n",
      "\titers: 300, epoch: 4 | loss: 0.1581309\n",
      "\tspeed: 0.0461s/iter; left time: 298.3945s\n",
      "Epoch: 4 cost time: 18.600801467895508\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.1569710 Vali Loss: 0.1917871 Test Loss: 0.1798283\n",
      "Validation loss decreased (0.204095 --> 0.191787).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1283072\n",
      "\tspeed: 0.1558s/iter; left time: 976.5771s\n",
      "\titers: 200, epoch: 5 | loss: 0.1930427\n",
      "\tspeed: 0.0490s/iter; left time: 302.0418s\n",
      "\titers: 300, epoch: 5 | loss: 0.2043082\n",
      "\tspeed: 0.0490s/iter; left time: 297.1065s\n",
      "Epoch: 5 cost time: 19.23547077178955\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.1524093 Vali Loss: 0.1940098 Test Loss: 0.1810672\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1353991\n",
      "\tspeed: 0.1594s/iter; left time: 936.0053s\n",
      "\titers: 200, epoch: 6 | loss: 0.1462196\n",
      "\tspeed: 0.0431s/iter; left time: 248.8947s\n",
      "\titers: 300, epoch: 6 | loss: 0.1484045\n",
      "\tspeed: 0.0467s/iter; left time: 265.0508s\n",
      "Epoch: 6 cost time: 18.073242902755737\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.1497060 Vali Loss: 0.1928292 Test Loss: 0.1775527\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1763195\n",
      "\tspeed: 0.1546s/iter; left time: 846.0334s\n",
      "\titers: 200, epoch: 7 | loss: 0.1663432\n",
      "\tspeed: 0.0457s/iter; left time: 245.6049s\n",
      "\titers: 300, epoch: 7 | loss: 0.1110168\n",
      "\tspeed: 0.0446s/iter; left time: 235.3992s\n",
      "Epoch: 7 cost time: 18.03246235847473\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.1485894 Vali Loss: 0.1923027 Test Loss: 0.1826372\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.17982833087444305, mae:0.25516000390052795\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on DEWINDh_small with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'data': 'DEWINDh_small', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 168, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_DEWINDh_small_ftS_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.3101821\n",
      "\tspeed: 0.0578s/iter; left time: 450.1201s\n",
      "\titers: 200, epoch: 1 | loss: 0.2918318\n",
      "\tspeed: 0.0608s/iter; left time: 466.9637s\n",
      "\titers: 300, epoch: 1 | loss: 0.2370651\n",
      "\tspeed: 0.0626s/iter; left time: 474.6186s\n",
      "Epoch: 1 cost time: 23.834728717803955\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.3083345 Vali Loss: 0.2752515 Test Loss: 0.2494988\n",
      "Validation loss decreased (inf --> 0.275252).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2345295\n",
      "\tspeed: 0.1935s/iter; left time: 1429.5361s\n",
      "\titers: 200, epoch: 2 | loss: 0.2178999\n",
      "\tspeed: 0.0574s/iter; left time: 417.9348s\n",
      "\titers: 300, epoch: 2 | loss: 0.2020557\n",
      "\tspeed: 0.0572s/iter; left time: 411.2005s\n",
      "Epoch: 2 cost time: 22.708505392074585\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.1968982 Vali Loss: 0.2298419 Test Loss: 0.2259346\n",
      "Validation loss decreased (0.275252 --> 0.229842).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1645683\n",
      "\tspeed: 0.1829s/iter; left time: 1279.3381s\n",
      "\titers: 200, epoch: 3 | loss: 0.1908608\n",
      "\tspeed: 0.0574s/iter; left time: 395.9349s\n",
      "\titers: 300, epoch: 3 | loss: 0.1987584\n",
      "\tspeed: 0.0584s/iter; left time: 396.8083s\n",
      "Epoch: 3 cost time: 23.16491436958313\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.1779044 Vali Loss: 0.2497154 Test Loss: 0.2054913\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1852568\n",
      "\tspeed: 0.1965s/iter; left time: 1296.6540s\n",
      "\titers: 200, epoch: 4 | loss: 0.1784368\n",
      "\tspeed: 0.0628s/iter; left time: 407.9175s\n",
      "\titers: 300, epoch: 4 | loss: 0.1842805\n",
      "\tspeed: 0.0571s/iter; left time: 365.1238s\n",
      "Epoch: 4 cost time: 23.662724018096924\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.1723000 Vali Loss: 0.2537626 Test Loss: 0.2277729\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1570947\n",
      "\tspeed: 0.1809s/iter; left time: 1122.6606s\n",
      "\titers: 200, epoch: 5 | loss: 0.1648982\n",
      "\tspeed: 0.0571s/iter; left time: 348.3090s\n",
      "\titers: 300, epoch: 5 | loss: 0.2041674\n",
      "\tspeed: 0.0581s/iter; left time: 348.8007s\n",
      "Epoch: 5 cost time: 22.608388423919678\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.1694896 Vali Loss: 0.2421145 Test Loss: 0.2155307\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.22593459486961365, mae:0.30880406498908997\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on DEWINDh_small with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'data': 'DEWINDh_small', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 336, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_DEWINDh_small_ftS_sl168_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.3335251\n",
      "\tspeed: 0.0910s/iter; left time: 699.0347s\n",
      "\titers: 200, epoch: 1 | loss: 0.3264257\n",
      "\tspeed: 0.0841s/iter; left time: 637.5856s\n",
      "\titers: 300, epoch: 1 | loss: 0.2606482\n",
      "\tspeed: 0.0824s/iter; left time: 616.3429s\n",
      "Epoch: 1 cost time: 33.14887976646423\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.3345999 Vali Loss: 0.2775506 Test Loss: 0.2976813\n",
      "Validation loss decreased (inf --> 0.277551).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2261199\n",
      "\tspeed: 0.2775s/iter; left time: 2023.7381s\n",
      "\titers: 200, epoch: 2 | loss: 0.2215020\n",
      "\tspeed: 0.0926s/iter; left time: 665.9820s\n",
      "\titers: 300, epoch: 2 | loss: 0.2159618\n",
      "\tspeed: 0.0871s/iter; left time: 617.3668s\n",
      "Epoch: 2 cost time: 34.560216665267944\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.2250714 Vali Loss: 0.2549257 Test Loss: 0.2560560\n",
      "Validation loss decreased (0.277551 --> 0.254926).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2225392\n",
      "\tspeed: 0.2914s/iter; left time: 2011.6607s\n",
      "\titers: 200, epoch: 3 | loss: 0.2200277\n",
      "\tspeed: 0.0870s/iter; left time: 591.9152s\n",
      "\titers: 300, epoch: 3 | loss: 0.2113243\n",
      "\tspeed: 0.0879s/iter; left time: 589.4295s\n",
      "Epoch: 3 cost time: 34.001957178115845\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.2100397 Vali Loss: 0.2496416 Test Loss: 0.2753002\n",
      "Validation loss decreased (0.254926 --> 0.249642).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2151195\n",
      "\tspeed: 0.2818s/iter; left time: 1835.4198s\n",
      "\titers: 200, epoch: 4 | loss: 0.2182075\n",
      "\tspeed: 0.0807s/iter; left time: 517.7974s\n",
      "\titers: 300, epoch: 4 | loss: 0.1899027\n",
      "\tspeed: 0.0816s/iter; left time: 515.0600s\n",
      "Epoch: 4 cost time: 31.891358137130737\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.2047939 Vali Loss: 0.2409464 Test Loss: 0.2924851\n",
      "Validation loss decreased (0.249642 --> 0.240946).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2078612\n",
      "\tspeed: 0.2731s/iter; left time: 1673.0255s\n",
      "\titers: 200, epoch: 5 | loss: 0.1859199\n",
      "\tspeed: 0.0872s/iter; left time: 525.3187s\n",
      "\titers: 300, epoch: 5 | loss: 0.1817764\n",
      "\tspeed: 0.0875s/iter; left time: 518.6459s\n",
      "Epoch: 5 cost time: 33.30120515823364\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.2009760 Vali Loss: 0.2460048 Test Loss: 0.3143297\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1736218\n",
      "\tspeed: 0.2816s/iter; left time: 1615.3336s\n",
      "\titers: 200, epoch: 6 | loss: 0.1952711\n",
      "\tspeed: 0.0860s/iter; left time: 484.5574s\n",
      "\titers: 300, epoch: 6 | loss: 0.1940176\n",
      "\tspeed: 0.0867s/iter; left time: 479.7383s\n",
      "Epoch: 6 cost time: 33.78691911697388\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.1987281 Vali Loss: 0.2393377 Test Loss: 0.3074801\n",
      "Validation loss decreased (0.240946 --> 0.239338).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1848166\n",
      "\tspeed: 0.2948s/iter; left time: 1576.4636s\n",
      "\titers: 200, epoch: 7 | loss: 0.2048188\n",
      "\tspeed: 0.0854s/iter; left time: 447.9540s\n",
      "\titers: 300, epoch: 7 | loss: 0.2204311\n",
      "\tspeed: 0.0874s/iter; left time: 449.8726s\n",
      "Epoch: 7 cost time: 33.772504568099976\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.1963903 Vali Loss: 0.2411964 Test Loss: 0.3103305\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1860512\n",
      "\tspeed: 0.2797s/iter; left time: 1386.7282s\n",
      "\titers: 200, epoch: 8 | loss: 0.2009994\n",
      "\tspeed: 0.0844s/iter; left time: 409.9099s\n",
      "\titers: 300, epoch: 8 | loss: 0.1929924\n",
      "\tspeed: 0.0833s/iter; left time: 396.3161s\n",
      "Epoch: 8 cost time: 32.38072156906128\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.1949771 Vali Loss: 0.2431552 Test Loss: 0.3118848\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1693078\n",
      "\tspeed: 0.2708s/iter; left time: 1237.1154s\n",
      "\titers: 200, epoch: 9 | loss: 0.1796496\n",
      "\tspeed: 0.0868s/iter; left time: 388.0481s\n",
      "\titers: 300, epoch: 9 | loss: 0.1518235\n",
      "\tspeed: 0.0866s/iter; left time: 378.3502s\n",
      "Epoch: 9 cost time: 33.25571799278259\n",
      "Epoch: 9, Steps: 389 | Train Loss: 0.1933375 Vali Loss: 0.2436658 Test Loss: 0.3181679\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.3074800968170166, mae:0.3750981390476227\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on DEWINDh_small with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'data': 'DEWINDh_small', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 720, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_DEWINDh_small_ftS_sl168_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.2798882\n",
      "\tspeed: 0.1325s/iter; left time: 985.9548s\n",
      "\titers: 200, epoch: 1 | loss: 0.2928615\n",
      "\tspeed: 0.1327s/iter; left time: 974.4232s\n",
      "\titers: 300, epoch: 1 | loss: 0.2723329\n",
      "\tspeed: 0.1340s/iter; left time: 969.9979s\n",
      "Epoch: 1 cost time: 50.0568745136261\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.3092925 Vali Loss: 0.2783732 Test Loss: 0.3890675\n",
      "Validation loss decreased (inf --> 0.278373).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2207557\n",
      "\tspeed: 0.3672s/iter; left time: 2594.1042s\n",
      "\titers: 200, epoch: 2 | loss: 0.2442412\n",
      "\tspeed: 0.1328s/iter; left time: 924.8716s\n",
      "\titers: 300, epoch: 2 | loss: 0.2479455\n",
      "\tspeed: 0.1323s/iter; left time: 908.3301s\n",
      "Epoch: 2 cost time: 49.55273652076721\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.2305313 Vali Loss: 0.2631212 Test Loss: 0.5775212\n",
      "Validation loss decreased (0.278373 --> 0.263121).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2162115\n",
      "\tspeed: 0.3843s/iter; left time: 2569.6706s\n",
      "\titers: 200, epoch: 3 | loss: 0.1974143\n",
      "\tspeed: 0.1333s/iter; left time: 878.0155s\n",
      "\titers: 300, epoch: 3 | loss: 0.1999416\n",
      "\tspeed: 0.1289s/iter; left time: 836.1029s\n",
      "Epoch: 3 cost time: 48.86979079246521\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.2079487 Vali Loss: 0.2527076 Test Loss: 0.5558218\n",
      "Validation loss decreased (0.263121 --> 0.252708).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1934077\n",
      "\tspeed: 0.3742s/iter; left time: 2361.0509s\n",
      "\titers: 200, epoch: 4 | loss: 0.2004488\n",
      "\tspeed: 0.1315s/iter; left time: 816.8868s\n",
      "\titers: 300, epoch: 4 | loss: 0.1848340\n",
      "\tspeed: 0.1271s/iter; left time: 776.6425s\n",
      "Epoch: 4 cost time: 48.93803691864014\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.2007428 Vali Loss: 0.2646124 Test Loss: 0.6760697\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1967108\n",
      "\tspeed: 0.3793s/iter; left time: 2250.4462s\n",
      "\titers: 200, epoch: 5 | loss: 0.1884520\n",
      "\tspeed: 0.1328s/iter; left time: 774.7896s\n",
      "\titers: 300, epoch: 5 | loss: 0.2169927\n",
      "\tspeed: 0.1224s/iter; left time: 702.0006s\n",
      "Epoch: 5 cost time: 48.42880725860596\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.1982823 Vali Loss: 0.2629983 Test Loss: 0.6541824\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2098744\n",
      "\tspeed: 0.3699s/iter; left time: 2054.9631s\n",
      "\titers: 200, epoch: 6 | loss: 0.1798030\n",
      "\tspeed: 0.1273s/iter; left time: 694.3609s\n",
      "\titers: 300, epoch: 6 | loss: 0.1983525\n",
      "\tspeed: 0.1279s/iter; left time: 685.1176s\n",
      "Epoch: 6 cost time: 48.150070667266846\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.1969415 Vali Loss: 0.2735447 Test Loss: 0.7027412\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.5558218955993652, mae:0.5661179423332214\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTHh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'data': 'SYNTHh1', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTHh1_ftS_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.6693859\n",
      "\tspeed: 0.0491s/iter; left time: 387.1556s\n",
      "\titers: 200, epoch: 1 | loss: 0.5943060\n",
      "\tspeed: 0.0463s/iter; left time: 360.6155s\n",
      "\titers: 300, epoch: 1 | loss: 0.2412843\n",
      "\tspeed: 0.0470s/iter; left time: 360.9140s\n",
      "Epoch: 1 cost time: 18.85924768447876\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.4159538 Vali Loss: 0.2005160 Test Loss: 0.2169274\n",
      "Validation loss decreased (inf --> 0.200516).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0969937\n",
      "\tspeed: 0.1536s/iter; left time: 1149.5945s\n",
      "\titers: 200, epoch: 2 | loss: 0.0995747\n",
      "\tspeed: 0.0448s/iter; left time: 330.7044s\n",
      "\titers: 300, epoch: 2 | loss: 0.0830531\n",
      "\tspeed: 0.0431s/iter; left time: 313.9000s\n",
      "Epoch: 2 cost time: 17.466540575027466\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.1145773 Vali Loss: 0.1561815 Test Loss: 0.1545898\n",
      "Validation loss decreased (0.200516 --> 0.156182).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0659090\n",
      "\tspeed: 0.1524s/iter; left time: 1079.6004s\n",
      "\titers: 200, epoch: 3 | loss: 0.0698115\n",
      "\tspeed: 0.0454s/iter; left time: 317.2390s\n",
      "\titers: 300, epoch: 3 | loss: 0.0736639\n",
      "\tspeed: 0.0461s/iter; left time: 317.2104s\n",
      "Epoch: 3 cost time: 18.107242584228516\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0704231 Vali Loss: 0.1518359 Test Loss: 0.1545215\n",
      "Validation loss decreased (0.156182 --> 0.151836).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0567727\n",
      "\tspeed: 0.1540s/iter; left time: 1029.3703s\n",
      "\titers: 200, epoch: 4 | loss: 0.0574577\n",
      "\tspeed: 0.0465s/iter; left time: 306.3449s\n",
      "\titers: 300, epoch: 4 | loss: 0.0682647\n",
      "\tspeed: 0.0455s/iter; left time: 294.9424s\n",
      "Epoch: 4 cost time: 18.48985719680786\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0585418 Vali Loss: 0.1527195 Test Loss: 0.1579937\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0841935\n",
      "\tspeed: 0.1533s/iter; left time: 963.2465s\n",
      "\titers: 200, epoch: 5 | loss: 0.0438799\n",
      "\tspeed: 0.0452s/iter; left time: 279.4096s\n",
      "\titers: 300, epoch: 5 | loss: 0.0448072\n",
      "\tspeed: 0.0493s/iter; left time: 300.2567s\n",
      "Epoch: 5 cost time: 18.689927339553833\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0507129 Vali Loss: 0.1514797 Test Loss: 0.1635168\n",
      "Validation loss decreased (0.151836 --> 0.151480).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0390548\n",
      "\tspeed: 0.1617s/iter; left time: 951.6643s\n",
      "\titers: 200, epoch: 6 | loss: 0.0500500\n",
      "\tspeed: 0.0493s/iter; left time: 285.4957s\n",
      "\titers: 300, epoch: 6 | loss: 0.0414596\n",
      "\tspeed: 0.0488s/iter; left time: 277.6127s\n",
      "Epoch: 6 cost time: 19.424818515777588\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0486269 Vali Loss: 0.1488522 Test Loss: 0.1698644\n",
      "Validation loss decreased (0.151480 --> 0.148852).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0406345\n",
      "\tspeed: 0.1538s/iter; left time: 843.8867s\n",
      "\titers: 200, epoch: 7 | loss: 0.0427530\n",
      "\tspeed: 0.0435s/iter; left time: 234.1327s\n",
      "\titers: 300, epoch: 7 | loss: 0.0726685\n",
      "\tspeed: 0.0456s/iter; left time: 240.9923s\n",
      "Epoch: 7 cost time: 17.68077564239502\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0471285 Vali Loss: 0.1377672 Test Loss: 0.1534364\n",
      "Validation loss decreased (0.148852 --> 0.137767).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0394961\n",
      "\tspeed: 0.1518s/iter; left time: 772.5582s\n",
      "\titers: 200, epoch: 8 | loss: 0.0440786\n",
      "\tspeed: 0.0443s/iter; left time: 220.8318s\n",
      "\titers: 300, epoch: 8 | loss: 0.0378923\n",
      "\tspeed: 0.0443s/iter; left time: 216.5817s\n",
      "Epoch: 8 cost time: 17.762828588485718\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0466563 Vali Loss: 0.1470247 Test Loss: 0.1663425\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0396199\n",
      "\tspeed: 0.1398s/iter; left time: 655.3572s\n",
      "\titers: 200, epoch: 9 | loss: 0.0383864\n",
      "\tspeed: 0.0457s/iter; left time: 209.8268s\n",
      "\titers: 300, epoch: 9 | loss: 0.0380698\n",
      "\tspeed: 0.0454s/iter; left time: 203.6105s\n",
      "Epoch: 9 cost time: 18.04819083213806\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0457578 Vali Loss: 0.1478179 Test Loss: 0.1684788\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0431071\n",
      "\tspeed: 0.1481s/iter; left time: 635.3362s\n",
      "\titers: 200, epoch: 10 | loss: 0.0650162\n",
      "\tspeed: 0.0467s/iter; left time: 195.6931s\n",
      "\titers: 300, epoch: 10 | loss: 0.0483491\n",
      "\tspeed: 0.0462s/iter; left time: 188.9510s\n",
      "Epoch: 10 cost time: 18.26106834411621\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0450979 Vali Loss: 0.1468744 Test Loss: 0.1666170\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.15343642234802246, mae:0.30994969606399536\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTHh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'data': 'SYNTHh1', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 48, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTHh1_ftS_sl168_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.5359637\n",
      "\tspeed: 0.0513s/iter; left time: 403.5862s\n",
      "\titers: 200, epoch: 1 | loss: 0.4924914\n",
      "\tspeed: 0.0512s/iter; left time: 397.3967s\n",
      "\titers: 300, epoch: 1 | loss: 0.4250181\n",
      "\tspeed: 0.0472s/iter; left time: 361.6477s\n",
      "Epoch: 1 cost time: 19.532329082489014\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.4897954 Vali Loss: 0.3590657 Test Loss: 0.3657987\n",
      "Validation loss decreased (inf --> 0.359066).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2234309\n",
      "\tspeed: 0.1534s/iter; left time: 1144.4755s\n",
      "\titers: 200, epoch: 2 | loss: 0.2535810\n",
      "\tspeed: 0.0488s/iter; left time: 359.0043s\n",
      "\titers: 300, epoch: 2 | loss: 0.1562247\n",
      "\tspeed: 0.0491s/iter; left time: 356.9673s\n",
      "Epoch: 2 cost time: 19.101116180419922\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.2159054 Vali Loss: 0.3420572 Test Loss: 0.3243330\n",
      "Validation loss decreased (0.359066 --> 0.342057).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1291814\n",
      "\tspeed: 0.1633s/iter; left time: 1153.9099s\n",
      "\titers: 200, epoch: 3 | loss: 0.1149674\n",
      "\tspeed: 0.0524s/iter; left time: 365.0574s\n",
      "\titers: 300, epoch: 3 | loss: 0.1426910\n",
      "\tspeed: 0.0496s/iter; left time: 340.8219s\n",
      "Epoch: 3 cost time: 20.161836862564087\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.1414697 Vali Loss: 0.1835806 Test Loss: 0.1822861\n",
      "Validation loss decreased (0.342057 --> 0.183581).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1138820\n",
      "\tspeed: 0.1639s/iter; left time: 1092.6366s\n",
      "\titers: 200, epoch: 4 | loss: 0.1121931\n",
      "\tspeed: 0.0482s/iter; left time: 316.3980s\n",
      "\titers: 300, epoch: 4 | loss: 0.1004357\n",
      "\tspeed: 0.0473s/iter; left time: 305.6385s\n",
      "Epoch: 4 cost time: 19.02811312675476\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.1164309 Vali Loss: 0.2802342 Test Loss: 0.2871049\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0973259\n",
      "\tspeed: 0.1451s/iter; left time: 909.5090s\n",
      "\titers: 200, epoch: 5 | loss: 0.0836000\n",
      "\tspeed: 0.0479s/iter; left time: 295.5301s\n",
      "\titers: 300, epoch: 5 | loss: 0.1018243\n",
      "\tspeed: 0.0468s/iter; left time: 284.0435s\n",
      "Epoch: 5 cost time: 18.86957049369812\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.1095122 Vali Loss: 0.2861528 Test Loss: 0.3047393\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0747806\n",
      "\tspeed: 0.1632s/iter; left time: 958.0028s\n",
      "\titers: 200, epoch: 6 | loss: 0.0850827\n",
      "\tspeed: 0.0500s/iter; left time: 288.5594s\n",
      "\titers: 300, epoch: 6 | loss: 0.0848823\n",
      "\tspeed: 0.0489s/iter; left time: 277.4505s\n",
      "Epoch: 6 cost time: 19.585193395614624\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0998178 Vali Loss: 0.2854750 Test Loss: 0.3070954\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.18228603899478912, mae:0.33735305070877075\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTHh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'data': 'SYNTHh1', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 168, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTHh1_ftS_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.8564009\n",
      "\tspeed: 0.0602s/iter; left time: 468.6263s\n",
      "\titers: 200, epoch: 1 | loss: 0.7446069\n",
      "\tspeed: 0.0604s/iter; left time: 463.6456s\n",
      "\titers: 300, epoch: 1 | loss: 0.5170778\n",
      "\tspeed: 0.0587s/iter; left time: 445.3548s\n",
      "Epoch: 1 cost time: 22.99112105369568\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.7559657 Vali Loss: 1.0442803 Test Loss: 1.0916903\n",
      "Validation loss decreased (inf --> 1.044280).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3118881\n",
      "\tspeed: 0.1804s/iter; left time: 1332.9537s\n",
      "\titers: 200, epoch: 2 | loss: 0.2550806\n",
      "\tspeed: 0.0605s/iter; left time: 441.0869s\n",
      "\titers: 300, epoch: 2 | loss: 0.2505657\n",
      "\tspeed: 0.0605s/iter; left time: 435.1190s\n",
      "Epoch: 2 cost time: 23.724674224853516\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.2774786 Vali Loss: 0.9195760 Test Loss: 0.9326136\n",
      "Validation loss decreased (1.044280 --> 0.919576).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1436439\n",
      "\tspeed: 0.1936s/iter; left time: 1353.9174s\n",
      "\titers: 200, epoch: 3 | loss: 0.1577630\n",
      "\tspeed: 0.0544s/iter; left time: 374.9353s\n",
      "\titers: 300, epoch: 3 | loss: 0.1495024\n",
      "\tspeed: 0.0543s/iter; left time: 369.1858s\n",
      "Epoch: 3 cost time: 22.037015438079834\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.1635602 Vali Loss: 0.7219811 Test Loss: 0.7189125\n",
      "Validation loss decreased (0.919576 --> 0.721981).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1501493\n",
      "\tspeed: 0.1869s/iter; left time: 1233.1454s\n",
      "\titers: 200, epoch: 4 | loss: 0.1282030\n",
      "\tspeed: 0.0571s/iter; left time: 371.2847s\n",
      "\titers: 300, epoch: 4 | loss: 0.1136813\n",
      "\tspeed: 0.0568s/iter; left time: 363.7507s\n",
      "Epoch: 4 cost time: 22.564869165420532\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.1400440 Vali Loss: 0.6966218 Test Loss: 0.7007292\n",
      "Validation loss decreased (0.721981 --> 0.696622).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1154669\n",
      "\tspeed: 0.1854s/iter; left time: 1150.6545s\n",
      "\titers: 200, epoch: 5 | loss: 0.1539987\n",
      "\tspeed: 0.0580s/iter; left time: 353.8443s\n",
      "\titers: 300, epoch: 5 | loss: 0.1302022\n",
      "\tspeed: 0.0575s/iter; left time: 345.4855s\n",
      "Epoch: 5 cost time: 22.969456911087036\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.1338849 Vali Loss: 0.6825069 Test Loss: 0.7020012\n",
      "Validation loss decreased (0.696622 --> 0.682507).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1111875\n",
      "\tspeed: 0.1906s/iter; left time: 1107.8433s\n",
      "\titers: 200, epoch: 6 | loss: 0.1063424\n",
      "\tspeed: 0.0634s/iter; left time: 361.9717s\n",
      "\titers: 300, epoch: 6 | loss: 0.1400547\n",
      "\tspeed: 0.0623s/iter; left time: 349.7407s\n",
      "Epoch: 6 cost time: 24.40273427963257\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.1288168 Vali Loss: 0.6670228 Test Loss: 0.6863227\n",
      "Validation loss decreased (0.682507 --> 0.667023).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1115228\n",
      "\tspeed: 0.2007s/iter; left time: 1087.1273s\n",
      "\titers: 200, epoch: 7 | loss: 0.1150543\n",
      "\tspeed: 0.0575s/iter; left time: 305.6751s\n",
      "\titers: 300, epoch: 7 | loss: 0.1939040\n",
      "\tspeed: 0.0598s/iter; left time: 312.0339s\n",
      "Epoch: 7 cost time: 23.598007917404175\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.1253240 Vali Loss: 0.6469443 Test Loss: 0.6659795\n",
      "Validation loss decreased (0.667023 --> 0.646944).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1050020\n",
      "\tspeed: 0.1946s/iter; left time: 977.2552s\n",
      "\titers: 200, epoch: 8 | loss: 0.1282286\n",
      "\tspeed: 0.0611s/iter; left time: 300.6559s\n",
      "\titers: 300, epoch: 8 | loss: 0.1237881\n",
      "\tspeed: 0.0612s/iter; left time: 295.2068s\n",
      "Epoch: 8 cost time: 23.847456216812134\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.1235419 Vali Loss: 0.6638538 Test Loss: 0.6846288\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1263028\n",
      "\tspeed: 0.1979s/iter; left time: 916.2001s\n",
      "\titers: 200, epoch: 9 | loss: 0.1100711\n",
      "\tspeed: 0.0611s/iter; left time: 276.9220s\n",
      "\titers: 300, epoch: 9 | loss: 0.1364847\n",
      "\tspeed: 0.0610s/iter; left time: 270.3369s\n",
      "Epoch: 9 cost time: 23.945184469223022\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.1231687 Vali Loss: 0.6441317 Test Loss: 0.6676133\n",
      "Validation loss decreased (0.646944 --> 0.644132).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1214390\n",
      "\tspeed: 0.1884s/iter; left time: 797.9776s\n",
      "\titers: 200, epoch: 10 | loss: 0.1596770\n",
      "\tspeed: 0.0569s/iter; left time: 235.3705s\n",
      "\titers: 300, epoch: 10 | loss: 0.1100800\n",
      "\tspeed: 0.0547s/iter; left time: 220.9060s\n",
      "Epoch: 10 cost time: 22.05475115776062\n",
      "Epoch: 10, Steps: 394 | Train Loss: 0.1228363 Vali Loss: 0.6408258 Test Loss: 0.6638364\n",
      "Validation loss decreased (0.644132 --> 0.640826).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1567333\n",
      "\tspeed: 0.1825s/iter; left time: 700.8325s\n",
      "\titers: 200, epoch: 11 | loss: 0.1281425\n",
      "\tspeed: 0.0573s/iter; left time: 214.4274s\n",
      "\titers: 300, epoch: 11 | loss: 0.1037724\n",
      "\tspeed: 0.0575s/iter; left time: 209.4873s\n",
      "Epoch: 11 cost time: 22.658146142959595\n",
      "Epoch: 11, Steps: 394 | Train Loss: 0.1220999 Vali Loss: 0.6408985 Test Loss: 0.6654608\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.1486589\n",
      "\tspeed: 0.1874s/iter; left time: 645.9403s\n",
      "\titers: 200, epoch: 12 | loss: 0.1100148\n",
      "\tspeed: 0.0607s/iter; left time: 203.2446s\n",
      "\titers: 300, epoch: 12 | loss: 0.1164228\n",
      "\tspeed: 0.0617s/iter; left time: 200.2695s\n",
      "Epoch: 12 cost time: 23.776795148849487\n",
      "Epoch: 12, Steps: 394 | Train Loss: 0.1209557 Vali Loss: 0.6415345 Test Loss: 0.6668388\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.1147823\n",
      "\tspeed: 0.1865s/iter; left time: 569.3950s\n",
      "\titers: 200, epoch: 13 | loss: 0.1068138\n",
      "\tspeed: 0.0578s/iter; left time: 170.7644s\n",
      "\titers: 300, epoch: 13 | loss: 0.1101239\n",
      "\tspeed: 0.0575s/iter; left time: 164.0571s\n",
      "Epoch: 13 cost time: 22.67345690727234\n",
      "Epoch: 13, Steps: 394 | Train Loss: 0.1213904 Vali Loss: 0.6435623 Test Loss: 0.6668931\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.6638363599777222, mae:0.6715781092643738\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTHh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'data': 'SYNTHh1', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 336, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTHh1_ftS_sl168_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 1.1489643\n",
      "\tspeed: 0.0856s/iter; left time: 657.6881s\n",
      "\titers: 200, epoch: 1 | loss: 1.0577006\n",
      "\tspeed: 0.0877s/iter; left time: 664.9104s\n",
      "\titers: 300, epoch: 1 | loss: 0.7545898\n",
      "\tspeed: 0.0871s/iter; left time: 651.9277s\n",
      "Epoch: 1 cost time: 33.92374920845032\n",
      "Epoch: 1, Steps: 389 | Train Loss: 1.0136141 Vali Loss: 1.3705630 Test Loss: 1.5233198\n",
      "Validation loss decreased (inf --> 1.370563).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4990297\n",
      "\tspeed: 0.2849s/iter; left time: 2077.5773s\n",
      "\titers: 200, epoch: 2 | loss: 0.3699648\n",
      "\tspeed: 0.0857s/iter; left time: 616.0969s\n",
      "\titers: 300, epoch: 2 | loss: 0.3358455\n",
      "\tspeed: 0.0856s/iter; left time: 607.3778s\n",
      "Epoch: 2 cost time: 33.40439820289612\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.4582650 Vali Loss: 1.1202195 Test Loss: 1.1646746\n",
      "Validation loss decreased (1.370563 --> 1.120219).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2950581\n",
      "\tspeed: 0.2775s/iter; left time: 1915.2441s\n",
      "\titers: 200, epoch: 3 | loss: 0.3009227\n",
      "\tspeed: 0.0836s/iter; left time: 568.9642s\n",
      "\titers: 300, epoch: 3 | loss: 0.3170267\n",
      "\tspeed: 0.0850s/iter; left time: 569.9563s\n",
      "Epoch: 3 cost time: 33.45269560813904\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.2993128 Vali Loss: 1.0979549 Test Loss: 1.1391114\n",
      "Validation loss decreased (1.120219 --> 1.097955).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2860463\n",
      "\tspeed: 0.2905s/iter; left time: 1892.2289s\n",
      "\titers: 200, epoch: 4 | loss: 0.2331197\n",
      "\tspeed: 0.0848s/iter; left time: 544.2102s\n",
      "\titers: 300, epoch: 4 | loss: 0.2509092\n",
      "\tspeed: 0.0833s/iter; left time: 525.9490s\n",
      "Epoch: 4 cost time: 33.01550364494324\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.2721654 Vali Loss: 1.1235417 Test Loss: 1.1443318\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2554167\n",
      "\tspeed: 0.2834s/iter; left time: 1735.8200s\n",
      "\titers: 200, epoch: 5 | loss: 0.2248755\n",
      "\tspeed: 0.0848s/iter; left time: 510.8418s\n",
      "\titers: 300, epoch: 5 | loss: 0.2264405\n",
      "\tspeed: 0.0859s/iter; left time: 508.8980s\n",
      "Epoch: 5 cost time: 33.50133681297302\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.2579683 Vali Loss: 1.0972323 Test Loss: 1.1040819\n",
      "Validation loss decreased (1.097955 --> 1.097232).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2603289\n",
      "\tspeed: 0.2741s/iter; left time: 1572.3243s\n",
      "\titers: 200, epoch: 6 | loss: 0.2459952\n",
      "\tspeed: 0.0848s/iter; left time: 477.6939s\n",
      "\titers: 300, epoch: 6 | loss: 0.2604222\n",
      "\tspeed: 0.0902s/iter; left time: 499.5935s\n",
      "Epoch: 6 cost time: 33.5398473739624\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.2516523 Vali Loss: 1.1197476 Test Loss: 1.1316050\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2520754\n",
      "\tspeed: 0.2784s/iter; left time: 1488.5215s\n",
      "\titers: 200, epoch: 7 | loss: 0.2573263\n",
      "\tspeed: 0.0854s/iter; left time: 447.9901s\n",
      "\titers: 300, epoch: 7 | loss: 0.2375032\n",
      "\tspeed: 0.0840s/iter; left time: 432.3804s\n",
      "Epoch: 7 cost time: 32.80689358711243\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.2479786 Vali Loss: 1.1175265 Test Loss: 1.1261542\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2426415\n",
      "\tspeed: 0.2911s/iter; left time: 1443.4115s\n",
      "\titers: 200, epoch: 8 | loss: 0.2280308\n",
      "\tspeed: 0.0872s/iter; left time: 423.6759s\n",
      "\titers: 300, epoch: 8 | loss: 0.2496201\n",
      "\tspeed: 0.0898s/iter; left time: 427.2615s\n",
      "Epoch: 8 cost time: 34.443440437316895\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.2456448 Vali Loss: 1.1096216 Test Loss: 1.1138982\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:1.1040819883346558, mae:0.886641263961792\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTHh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'data': 'SYNTHh1', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 720, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTHh1_ftS_sl168_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.8795495\n",
      "\tspeed: 0.1276s/iter; left time: 949.7114s\n",
      "\titers: 200, epoch: 1 | loss: 0.6715187\n",
      "\tspeed: 0.1255s/iter; left time: 921.0715s\n",
      "\titers: 300, epoch: 1 | loss: 0.6364730\n",
      "\tspeed: 0.1349s/iter; left time: 976.8547s\n",
      "Epoch: 1 cost time: 49.179311990737915\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.7548897 Vali Loss: 1.0993011 Test Loss: 1.1398621\n",
      "Validation loss decreased (inf --> 1.099301).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3461992\n",
      "\tspeed: 0.3857s/iter; left time: 2724.3615s\n",
      "\titers: 200, epoch: 2 | loss: 0.4503223\n",
      "\tspeed: 0.1268s/iter; left time: 883.1282s\n",
      "\titers: 300, epoch: 2 | loss: 0.3546881\n",
      "\tspeed: 0.1267s/iter; left time: 869.6319s\n",
      "Epoch: 2 cost time: 48.67248582839966\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.3921812 Vali Loss: 0.9493849 Test Loss: 1.0477424\n",
      "Validation loss decreased (1.099301 --> 0.949385).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2966664\n",
      "\tspeed: 0.3738s/iter; left time: 2499.9011s\n",
      "\titers: 200, epoch: 3 | loss: 0.2881968\n",
      "\tspeed: 0.1293s/iter; left time: 851.8271s\n",
      "\titers: 300, epoch: 3 | loss: 0.3915858\n",
      "\tspeed: 0.1336s/iter; left time: 866.3761s\n",
      "Epoch: 3 cost time: 49.26835227012634\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.3514382 Vali Loss: 0.8494632 Test Loss: 0.9605396\n",
      "Validation loss decreased (0.949385 --> 0.849463).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2961258\n",
      "\tspeed: 0.3749s/iter; left time: 2365.9045s\n",
      "\titers: 200, epoch: 4 | loss: 0.3035481\n",
      "\tspeed: 0.1281s/iter; left time: 795.5525s\n",
      "\titers: 300, epoch: 4 | loss: 0.3396502\n",
      "\tspeed: 0.1342s/iter; left time: 820.0432s\n",
      "Epoch: 4 cost time: 49.60827922821045\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.3440464 Vali Loss: 0.9695832 Test Loss: 1.1418786\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4038786\n",
      "\tspeed: 0.3762s/iter; left time: 2232.0144s\n",
      "\titers: 200, epoch: 5 | loss: 0.4201639\n",
      "\tspeed: 0.1259s/iter; left time: 734.6177s\n",
      "\titers: 300, epoch: 5 | loss: 0.2972027\n",
      "\tspeed: 0.1341s/iter; left time: 768.5342s\n",
      "Epoch: 5 cost time: 48.85467505455017\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.3930818 Vali Loss: 0.8987529 Test Loss: 0.9790223\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3057268\n",
      "\tspeed: 0.3787s/iter; left time: 2104.2136s\n",
      "\titers: 200, epoch: 6 | loss: 0.2926455\n",
      "\tspeed: 0.1235s/iter; left time: 674.0845s\n",
      "\titers: 300, epoch: 6 | loss: 0.3127218\n",
      "\tspeed: 0.1295s/iter; left time: 693.7809s\n",
      "Epoch: 6 cost time: 48.11342978477478\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.3262004 Vali Loss: 0.9067625 Test Loss: 1.0171001\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.960539698600769, mae:0.7957104444503784\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'data': 'SYNTH_additive', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_ftS_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.0391602\n",
      "\tspeed: 0.0455s/iter; left time: 358.9188s\n",
      "\titers: 200, epoch: 1 | loss: 0.0303121\n",
      "\tspeed: 0.0435s/iter; left time: 338.5384s\n",
      "\titers: 300, epoch: 1 | loss: 0.0198119\n",
      "\tspeed: 0.0450s/iter; left time: 345.4926s\n",
      "Epoch: 1 cost time: 17.863908052444458\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.0487112 Vali Loss: 0.0223882 Test Loss: 0.0219829\n",
      "Validation loss decreased (inf --> 0.022388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0195631\n",
      "\tspeed: 0.1594s/iter; left time: 1192.8741s\n",
      "\titers: 200, epoch: 2 | loss: 0.0150193\n",
      "\tspeed: 0.0466s/iter; left time: 343.9542s\n",
      "\titers: 300, epoch: 2 | loss: 0.0134610\n",
      "\tspeed: 0.0471s/iter; left time: 342.7705s\n",
      "Epoch: 2 cost time: 18.861868858337402\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0168280 Vali Loss: 0.0209592 Test Loss: 0.0201164\n",
      "Validation loss decreased (0.022388 --> 0.020959).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0143825\n",
      "\tspeed: 0.1551s/iter; left time: 1098.5033s\n",
      "\titers: 200, epoch: 3 | loss: 0.0145219\n",
      "\tspeed: 0.0471s/iter; left time: 328.9475s\n",
      "\titers: 300, epoch: 3 | loss: 0.0145996\n",
      "\tspeed: 0.0439s/iter; left time: 302.1792s\n",
      "Epoch: 3 cost time: 17.835530519485474\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0120252 Vali Loss: 0.0153719 Test Loss: 0.0157286\n",
      "Validation loss decreased (0.020959 --> 0.015372).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0100925\n",
      "\tspeed: 0.1436s/iter; left time: 959.7986s\n",
      "\titers: 200, epoch: 4 | loss: 0.0102031\n",
      "\tspeed: 0.0446s/iter; left time: 293.8065s\n",
      "\titers: 300, epoch: 4 | loss: 0.0106514\n",
      "\tspeed: 0.0442s/iter; left time: 286.8303s\n",
      "Epoch: 4 cost time: 17.980434894561768\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0103290 Vali Loss: 0.0118582 Test Loss: 0.0118877\n",
      "Validation loss decreased (0.015372 --> 0.011858).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0099521\n",
      "\tspeed: 0.1557s/iter; left time: 978.2807s\n",
      "\titers: 200, epoch: 5 | loss: 0.0114464\n",
      "\tspeed: 0.0474s/iter; left time: 293.1084s\n",
      "\titers: 300, epoch: 5 | loss: 0.0111276\n",
      "\tspeed: 0.0454s/iter; left time: 276.0432s\n",
      "Epoch: 5 cost time: 18.38156294822693\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0094199 Vali Loss: 0.0121336 Test Loss: 0.0123248\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0107516\n",
      "\tspeed: 0.1469s/iter; left time: 864.9276s\n",
      "\titers: 200, epoch: 6 | loss: 0.0087890\n",
      "\tspeed: 0.0450s/iter; left time: 260.3435s\n",
      "\titers: 300, epoch: 6 | loss: 0.0084007\n",
      "\tspeed: 0.0476s/iter; left time: 270.7440s\n",
      "Epoch: 6 cost time: 18.326642274856567\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0090301 Vali Loss: 0.0112091 Test Loss: 0.0117034\n",
      "Validation loss decreased (0.011858 --> 0.011209).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0117292\n",
      "\tspeed: 0.1522s/iter; left time: 835.2490s\n",
      "\titers: 200, epoch: 7 | loss: 0.0076254\n",
      "\tspeed: 0.0474s/iter; left time: 255.1372s\n",
      "\titers: 300, epoch: 7 | loss: 0.0086976\n",
      "\tspeed: 0.0472s/iter; left time: 249.6489s\n",
      "Epoch: 7 cost time: 18.680015087127686\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0087622 Vali Loss: 0.0108254 Test Loss: 0.0114552\n",
      "Validation loss decreased (0.011209 --> 0.010825).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0092512\n",
      "\tspeed: 0.1570s/iter; left time: 798.8900s\n",
      "\titers: 200, epoch: 8 | loss: 0.0077260\n",
      "\tspeed: 0.0487s/iter; left time: 242.9570s\n",
      "\titers: 300, epoch: 8 | loss: 0.0066332\n",
      "\tspeed: 0.0454s/iter; left time: 221.8391s\n",
      "Epoch: 8 cost time: 18.56949257850647\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0086939 Vali Loss: 0.0110501 Test Loss: 0.0114975\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0088198\n",
      "\tspeed: 0.1516s/iter; left time: 710.7862s\n",
      "\titers: 200, epoch: 9 | loss: 0.0096592\n",
      "\tspeed: 0.0479s/iter; left time: 219.6831s\n",
      "\titers: 300, epoch: 9 | loss: 0.0090163\n",
      "\tspeed: 0.0480s/iter; left time: 215.2791s\n",
      "Epoch: 9 cost time: 19.0509352684021\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0086470 Vali Loss: 0.0106847 Test Loss: 0.0112040\n",
      "Validation loss decreased (0.010825 --> 0.010685).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0096945\n",
      "\tspeed: 0.1590s/iter; left time: 682.0687s\n",
      "\titers: 200, epoch: 10 | loss: 0.0089246\n",
      "\tspeed: 0.0495s/iter; left time: 207.4855s\n",
      "\titers: 300, epoch: 10 | loss: 0.0103062\n",
      "\tspeed: 0.0464s/iter; left time: 189.9557s\n",
      "Epoch: 10 cost time: 18.969216108322144\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0086289 Vali Loss: 0.0106323 Test Loss: 0.0111033\n",
      "Validation loss decreased (0.010685 --> 0.010632).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0083327\n",
      "\tspeed: 0.1507s/iter; left time: 586.4000s\n",
      "\titers: 200, epoch: 11 | loss: 0.0074431\n",
      "\tspeed: 0.0445s/iter; left time: 168.7889s\n",
      "\titers: 300, epoch: 11 | loss: 0.0103390\n",
      "\tspeed: 0.0494s/iter; left time: 182.4769s\n",
      "Epoch: 11 cost time: 18.459474802017212\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0086298 Vali Loss: 0.0106894 Test Loss: 0.0111081\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0079102\n",
      "\tspeed: 0.1551s/iter; left time: 541.7351s\n",
      "\titers: 200, epoch: 12 | loss: 0.0076365\n",
      "\tspeed: 0.0473s/iter; left time: 160.5916s\n",
      "\titers: 300, epoch: 12 | loss: 0.0079347\n",
      "\tspeed: 0.0484s/iter; left time: 159.4888s\n",
      "Epoch: 12 cost time: 18.996251583099365\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0085880 Vali Loss: 0.0106604 Test Loss: 0.0111143\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0073752\n",
      "\tspeed: 0.1544s/iter; left time: 477.5406s\n",
      "\titers: 200, epoch: 13 | loss: 0.0063878\n",
      "\tspeed: 0.0442s/iter; left time: 132.1518s\n",
      "\titers: 300, epoch: 13 | loss: 0.0104977\n",
      "\tspeed: 0.0458s/iter; left time: 132.4084s\n",
      "Epoch: 13 cost time: 18.070176601409912\n",
      "Epoch: 13, Steps: 399 | Train Loss: 0.0085703 Vali Loss: 0.0105751 Test Loss: 0.0110642\n",
      "Validation loss decreased (0.010632 --> 0.010575).  Saving model ...\n",
      "Updating learning rate to 2.44140625e-08\n",
      "\titers: 100, epoch: 14 | loss: 0.0079384\n",
      "\tspeed: 0.1539s/iter; left time: 414.5116s\n",
      "\titers: 200, epoch: 14 | loss: 0.0085441\n",
      "\tspeed: 0.0467s/iter; left time: 121.2336s\n",
      "\titers: 300, epoch: 14 | loss: 0.0112537\n",
      "\tspeed: 0.0468s/iter; left time: 116.6539s\n",
      "Epoch: 14 cost time: 18.496868133544922\n",
      "Epoch: 14, Steps: 399 | Train Loss: 0.0085090 Vali Loss: 0.0106159 Test Loss: 0.0110741\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "\titers: 100, epoch: 15 | loss: 0.0071791\n",
      "\tspeed: 0.1534s/iter; left time: 351.9790s\n",
      "\titers: 200, epoch: 15 | loss: 0.0094281\n",
      "\tspeed: 0.0456s/iter; left time: 100.1030s\n",
      "\titers: 300, epoch: 15 | loss: 0.0077105\n",
      "\tspeed: 0.0451s/iter; left time: 94.5647s\n",
      "Epoch: 15 cost time: 18.327353715896606\n",
      "Epoch: 15, Steps: 399 | Train Loss: 0.0085832 Vali Loss: 0.0106250 Test Loss: 0.0110860\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.103515625e-09\n",
      "\titers: 100, epoch: 16 | loss: 0.0077916\n",
      "\tspeed: 0.1482s/iter; left time: 280.9449s\n",
      "\titers: 200, epoch: 16 | loss: 0.0086909\n",
      "\tspeed: 0.0474s/iter; left time: 85.0969s\n",
      "\titers: 300, epoch: 16 | loss: 0.0066137\n",
      "\tspeed: 0.0468s/iter; left time: 79.2973s\n",
      "Epoch: 16 cost time: 18.526134729385376\n",
      "Epoch: 16, Steps: 399 | Train Loss: 0.0085773 Vali Loss: 0.0105803 Test Loss: 0.0110771\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.011064196936786175, mae:0.08277041465044022\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'data': 'SYNTH_additive', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 48, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_ftS_sl168_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.0351502\n",
      "\tspeed: 0.0449s/iter; left time: 352.8723s\n",
      "\titers: 200, epoch: 1 | loss: 0.0263294\n",
      "\tspeed: 0.0463s/iter; left time: 359.1347s\n",
      "\titers: 300, epoch: 1 | loss: 0.0208937\n",
      "\tspeed: 0.0484s/iter; left time: 371.0278s\n",
      "Epoch: 1 cost time: 18.588325262069702\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0599663 Vali Loss: 0.0212033 Test Loss: 0.0205651\n",
      "Validation loss decreased (inf --> 0.021203).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0145786\n",
      "\tspeed: 0.1529s/iter; left time: 1141.1943s\n",
      "\titers: 200, epoch: 2 | loss: 0.0141747\n",
      "\tspeed: 0.0470s/iter; left time: 346.2333s\n",
      "\titers: 300, epoch: 2 | loss: 0.0147972\n",
      "\tspeed: 0.0471s/iter; left time: 342.1043s\n",
      "Epoch: 2 cost time: 18.69439196586609\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0151463 Vali Loss: 0.0148490 Test Loss: 0.0160076\n",
      "Validation loss decreased (0.021203 --> 0.014849).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0092939\n",
      "\tspeed: 0.1566s/iter; left time: 1106.4711s\n",
      "\titers: 200, epoch: 3 | loss: 0.0095254\n",
      "\tspeed: 0.0482s/iter; left time: 335.5433s\n",
      "\titers: 300, epoch: 3 | loss: 0.0085382\n",
      "\tspeed: 0.0475s/iter; left time: 325.7536s\n",
      "Epoch: 3 cost time: 19.117703914642334\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0110132 Vali Loss: 0.0145965 Test Loss: 0.0148705\n",
      "Validation loss decreased (0.014849 --> 0.014597).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0098578\n",
      "\tspeed: 0.1577s/iter; left time: 1051.2042s\n",
      "\titers: 200, epoch: 4 | loss: 0.0113374\n",
      "\tspeed: 0.0520s/iter; left time: 341.2251s\n",
      "\titers: 300, epoch: 4 | loss: 0.0107035\n",
      "\tspeed: 0.0495s/iter; left time: 319.8076s\n",
      "Epoch: 4 cost time: 19.296597957611084\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0096616 Vali Loss: 0.0140344 Test Loss: 0.0137532\n",
      "Validation loss decreased (0.014597 --> 0.014034).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0074460\n",
      "\tspeed: 0.1548s/iter; left time: 970.1391s\n",
      "\titers: 200, epoch: 5 | loss: 0.0088411\n",
      "\tspeed: 0.0502s/iter; left time: 309.5864s\n",
      "\titers: 300, epoch: 5 | loss: 0.0065079\n",
      "\tspeed: 0.0499s/iter; left time: 302.7507s\n",
      "Epoch: 5 cost time: 19.499338626861572\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0086433 Vali Loss: 0.0146239 Test Loss: 0.0144870\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0104467\n",
      "\tspeed: 0.1615s/iter; left time: 948.3565s\n",
      "\titers: 200, epoch: 6 | loss: 0.0091305\n",
      "\tspeed: 0.0493s/iter; left time: 284.7730s\n",
      "\titers: 300, epoch: 6 | loss: 0.0063372\n",
      "\tspeed: 0.0473s/iter; left time: 268.1803s\n",
      "Epoch: 6 cost time: 19.225979804992676\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0081112 Vali Loss: 0.0150618 Test Loss: 0.0150281\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0074789\n",
      "\tspeed: 0.1579s/iter; left time: 864.1568s\n",
      "\titers: 200, epoch: 7 | loss: 0.0067170\n",
      "\tspeed: 0.0494s/iter; left time: 265.3145s\n",
      "\titers: 300, epoch: 7 | loss: 0.0093956\n",
      "\tspeed: 0.0496s/iter; left time: 261.6130s\n",
      "Epoch: 7 cost time: 19.55199146270752\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0081276 Vali Loss: 0.0154431 Test Loss: 0.0153089\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.013753172010183334, mae:0.09154915809631348\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'data': 'SYNTH_additive', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 168, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_ftS_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.0597598\n",
      "\tspeed: 0.0641s/iter; left time: 499.1008s\n",
      "\titers: 200, epoch: 1 | loss: 0.0395661\n",
      "\tspeed: 0.0593s/iter; left time: 455.6137s\n",
      "\titers: 300, epoch: 1 | loss: 0.0311890\n",
      "\tspeed: 0.0595s/iter; left time: 450.7877s\n",
      "Epoch: 1 cost time: 23.925986528396606\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.0635147 Vali Loss: 0.0450013 Test Loss: 0.0461274\n",
      "Validation loss decreased (inf --> 0.045001).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0316423\n",
      "\tspeed: 0.1867s/iter; left time: 1378.9512s\n",
      "\titers: 200, epoch: 2 | loss: 0.0342299\n",
      "\tspeed: 0.0586s/iter; left time: 427.0239s\n",
      "\titers: 300, epoch: 2 | loss: 0.0310646\n",
      "\tspeed: 0.0602s/iter; left time: 432.6661s\n",
      "Epoch: 2 cost time: 23.146241188049316\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0322244 Vali Loss: 0.0335969 Test Loss: 0.0370159\n",
      "Validation loss decreased (0.045001 --> 0.033597).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0265497\n",
      "\tspeed: 0.1912s/iter; left time: 1336.7268s\n",
      "\titers: 200, epoch: 3 | loss: 0.0321208\n",
      "\tspeed: 0.0592s/iter; left time: 408.0412s\n",
      "\titers: 300, epoch: 3 | loss: 0.0279600\n",
      "\tspeed: 0.0592s/iter; left time: 402.1333s\n",
      "Epoch: 3 cost time: 23.145594120025635\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0279383 Vali Loss: 0.0318519 Test Loss: 0.0348915\n",
      "Validation loss decreased (0.033597 --> 0.031852).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0276059\n",
      "\tspeed: 0.1842s/iter; left time: 1215.5347s\n",
      "\titers: 200, epoch: 4 | loss: 0.0247920\n",
      "\tspeed: 0.0574s/iter; left time: 373.0197s\n",
      "\titers: 300, epoch: 4 | loss: 0.0287924\n",
      "\tspeed: 0.0576s/iter; left time: 368.6859s\n",
      "Epoch: 4 cost time: 22.826592922210693\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0263069 Vali Loss: 0.0315720 Test Loss: 0.0358724\n",
      "Validation loss decreased (0.031852 --> 0.031572).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0270622\n",
      "\tspeed: 0.1894s/iter; left time: 1175.1293s\n",
      "\titers: 200, epoch: 5 | loss: 0.0263543\n",
      "\tspeed: 0.0593s/iter; left time: 361.9329s\n",
      "\titers: 300, epoch: 5 | loss: 0.0297352\n",
      "\tspeed: 0.0596s/iter; left time: 357.9372s\n",
      "Epoch: 5 cost time: 23.380223274230957\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0251271 Vali Loss: 0.0312008 Test Loss: 0.0354324\n",
      "Validation loss decreased (0.031572 --> 0.031201).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0245272\n",
      "\tspeed: 0.1886s/iter; left time: 1095.8016s\n",
      "\titers: 200, epoch: 6 | loss: 0.0243507\n",
      "\tspeed: 0.0594s/iter; left time: 339.3822s\n",
      "\titers: 300, epoch: 6 | loss: 0.0295953\n",
      "\tspeed: 0.0623s/iter; left time: 349.3476s\n",
      "Epoch: 6 cost time: 23.74433922767639\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0245794 Vali Loss: 0.0316263 Test Loss: 0.0357806\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0266191\n",
      "\tspeed: 0.1869s/iter; left time: 1012.2498s\n",
      "\titers: 200, epoch: 7 | loss: 0.0250885\n",
      "\tspeed: 0.0579s/iter; left time: 307.7333s\n",
      "\titers: 300, epoch: 7 | loss: 0.0217825\n",
      "\tspeed: 0.0600s/iter; left time: 312.8189s\n",
      "Epoch: 7 cost time: 23.146536588668823\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0242202 Vali Loss: 0.0317134 Test Loss: 0.0360563\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0286416\n",
      "\tspeed: 0.1911s/iter; left time: 959.7989s\n",
      "\titers: 200, epoch: 8 | loss: 0.0262323\n",
      "\tspeed: 0.0625s/iter; left time: 307.6107s\n",
      "\titers: 300, epoch: 8 | loss: 0.0255851\n",
      "\tspeed: 0.0609s/iter; left time: 293.7282s\n",
      "Epoch: 8 cost time: 23.806204319000244\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0241089 Vali Loss: 0.0318638 Test Loss: 0.0362353\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.0354323573410511, mae:0.15160292387008667\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'data': 'SYNTH_additive', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 336, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_ftS_sl168_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.0751105\n",
      "\tspeed: 0.0867s/iter; left time: 665.7145s\n",
      "\titers: 200, epoch: 1 | loss: 0.0494246\n",
      "\tspeed: 0.0869s/iter; left time: 658.5242s\n",
      "\titers: 300, epoch: 1 | loss: 0.0483052\n",
      "\tspeed: 0.0872s/iter; left time: 652.6560s\n",
      "Epoch: 1 cost time: 33.82415962219238\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.0725165 Vali Loss: 0.0601906 Test Loss: 0.0644923\n",
      "Validation loss decreased (inf --> 0.060191).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0435048\n",
      "\tspeed: 0.2833s/iter; left time: 2065.7384s\n",
      "\titers: 200, epoch: 2 | loss: 0.0460629\n",
      "\tspeed: 0.0829s/iter; left time: 595.8810s\n",
      "\titers: 300, epoch: 2 | loss: 0.0407885\n",
      "\tspeed: 0.0816s/iter; left time: 578.9914s\n",
      "Epoch: 2 cost time: 32.50018358230591\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0433196 Vali Loss: 0.0502442 Test Loss: 0.0545797\n",
      "Validation loss decreased (0.060191 --> 0.050244).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0386718\n",
      "\tspeed: 0.2873s/iter; left time: 1983.3787s\n",
      "\titers: 200, epoch: 3 | loss: 0.0322480\n",
      "\tspeed: 0.0872s/iter; left time: 593.0213s\n",
      "\titers: 300, epoch: 3 | loss: 0.0345391\n",
      "\tspeed: 0.0822s/iter; left time: 551.0967s\n",
      "Epoch: 3 cost time: 32.71329355239868\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0378901 Vali Loss: 0.0545962 Test Loss: 0.0605667\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0386595\n",
      "\tspeed: 0.2836s/iter; left time: 1847.3059s\n",
      "\titers: 200, epoch: 4 | loss: 0.0378027\n",
      "\tspeed: 0.0859s/iter; left time: 551.0157s\n",
      "\titers: 300, epoch: 4 | loss: 0.0335528\n",
      "\tspeed: 0.0834s/iter; left time: 526.5407s\n",
      "Epoch: 4 cost time: 33.51522350311279\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0358151 Vali Loss: 0.0513944 Test Loss: 0.0570791\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0337524\n",
      "\tspeed: 0.2902s/iter; left time: 1777.7482s\n",
      "\titers: 200, epoch: 5 | loss: 0.0342789\n",
      "\tspeed: 0.0877s/iter; left time: 528.1839s\n",
      "\titers: 300, epoch: 5 | loss: 0.0355986\n",
      "\tspeed: 0.0876s/iter; left time: 519.2965s\n",
      "Epoch: 5 cost time: 33.75879240036011\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0351384 Vali Loss: 0.0512822 Test Loss: 0.0569523\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.054579708725214005, mae:0.1936657875776291\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'data': 'SYNTH_additive', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 720, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_ftS_sl168_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.0616740\n",
      "\tspeed: 0.1299s/iter; left time: 966.4166s\n",
      "\titers: 200, epoch: 1 | loss: 0.0479767\n",
      "\tspeed: 0.1260s/iter; left time: 924.7759s\n",
      "\titers: 300, epoch: 1 | loss: 0.0381171\n",
      "\tspeed: 0.1295s/iter; left time: 937.8262s\n",
      "Epoch: 1 cost time: 48.619120597839355\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.0622135 Vali Loss: 0.0546709 Test Loss: 0.0609158\n",
      "Validation loss decreased (inf --> 0.054671).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0392157\n",
      "\tspeed: 0.3743s/iter; left time: 2643.8036s\n",
      "\titers: 200, epoch: 2 | loss: 0.0355212\n",
      "\tspeed: 0.1258s/iter; left time: 876.0527s\n",
      "\titers: 300, epoch: 2 | loss: 0.0325078\n",
      "\tspeed: 0.1280s/iter; left time: 878.8350s\n",
      "Epoch: 2 cost time: 48.79007935523987\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0358335 Vali Loss: 0.0530499 Test Loss: 0.0618201\n",
      "Validation loss decreased (0.054671 --> 0.053050).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0329773\n",
      "\tspeed: 0.3876s/iter; left time: 2591.7254s\n",
      "\titers: 200, epoch: 3 | loss: 0.0360804\n",
      "\tspeed: 0.1313s/iter; left time: 865.0956s\n",
      "\titers: 300, epoch: 3 | loss: 0.0367062\n",
      "\tspeed: 0.1269s/iter; left time: 823.3755s\n",
      "Epoch: 3 cost time: 49.40454912185669\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0324179 Vali Loss: 0.0457657 Test Loss: 0.0535678\n",
      "Validation loss decreased (0.053050 --> 0.045766).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0295257\n",
      "\tspeed: 0.3854s/iter; left time: 2431.8663s\n",
      "\titers: 200, epoch: 4 | loss: 0.0304890\n",
      "\tspeed: 0.1344s/iter; left time: 834.8609s\n",
      "\titers: 300, epoch: 4 | loss: 0.0308180\n",
      "\tspeed: 0.1340s/iter; left time: 819.0161s\n",
      "Epoch: 4 cost time: 50.312604665756226\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0312062 Vali Loss: 0.0473343 Test Loss: 0.0561181\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0310643\n",
      "\tspeed: 0.3622s/iter; left time: 2148.7235s\n",
      "\titers: 200, epoch: 5 | loss: 0.0328672\n",
      "\tspeed: 0.1257s/iter; left time: 732.9453s\n",
      "\titers: 300, epoch: 5 | loss: 0.0299601\n",
      "\tspeed: 0.1275s/iter; left time: 731.2432s\n",
      "Epoch: 5 cost time: 47.93116784095764\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0310319 Vali Loss: 0.0456368 Test Loss: 0.0535591\n",
      "Validation loss decreased (0.045766 --> 0.045637).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0285421\n",
      "\tspeed: 0.3843s/iter; left time: 2135.1328s\n",
      "\titers: 200, epoch: 6 | loss: 0.0341514\n",
      "\tspeed: 0.1372s/iter; left time: 748.7243s\n",
      "\titers: 300, epoch: 6 | loss: 0.0286537\n",
      "\tspeed: 0.1339s/iter; left time: 717.2841s\n",
      "Epoch: 6 cost time: 50.97359085083008\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0307829 Vali Loss: 0.0449454 Test Loss: 0.0529418\n",
      "Validation loss decreased (0.045637 --> 0.044945).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0314750\n",
      "\tspeed: 0.3827s/iter; left time: 1982.2221s\n",
      "\titers: 200, epoch: 7 | loss: 0.0266714\n",
      "\tspeed: 0.1334s/iter; left time: 677.3326s\n",
      "\titers: 300, epoch: 7 | loss: 0.0284021\n",
      "\tspeed: 0.1336s/iter; left time: 665.2009s\n",
      "Epoch: 7 cost time: 48.972819566726685\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0307654 Vali Loss: 0.0447341 Test Loss: 0.0527421\n",
      "Validation loss decreased (0.044945 --> 0.044734).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0309725\n",
      "\tspeed: 0.3658s/iter; left time: 1756.5383s\n",
      "\titers: 200, epoch: 8 | loss: 0.0330706\n",
      "\tspeed: 0.1323s/iter; left time: 622.2237s\n",
      "\titers: 300, epoch: 8 | loss: 0.0298837\n",
      "\tspeed: 0.1271s/iter; left time: 584.9934s\n",
      "Epoch: 8 cost time: 49.301313638687134\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.0305522 Vali Loss: 0.0445900 Test Loss: 0.0524509\n",
      "Validation loss decreased (0.044734 --> 0.044590).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0361614\n",
      "\tspeed: 0.3772s/iter; left time: 1668.9423s\n",
      "\titers: 200, epoch: 9 | loss: 0.0322863\n",
      "\tspeed: 0.1354s/iter; left time: 585.6328s\n",
      "\titers: 300, epoch: 9 | loss: 0.0390197\n",
      "\tspeed: 0.1347s/iter; left time: 568.9597s\n",
      "Epoch: 9 cost time: 50.28256940841675\n",
      "Epoch: 9, Steps: 377 | Train Loss: 0.0306580 Vali Loss: 0.0446997 Test Loss: 0.0526514\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0295334\n",
      "\tspeed: 0.3767s/iter; left time: 1524.9289s\n",
      "\titers: 200, epoch: 10 | loss: 0.0286212\n",
      "\tspeed: 0.1313s/iter; left time: 518.3038s\n",
      "\titers: 300, epoch: 10 | loss: 0.0328553\n",
      "\tspeed: 0.1342s/iter; left time: 516.3573s\n",
      "Epoch: 10 cost time: 49.08869242668152\n",
      "Epoch: 10, Steps: 377 | Train Loss: 0.0305858 Vali Loss: 0.0448208 Test Loss: 0.0528027\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0273124\n",
      "\tspeed: 0.3646s/iter; left time: 1338.5383s\n",
      "\titers: 200, epoch: 11 | loss: 0.0269390\n",
      "\tspeed: 0.1331s/iter; left time: 475.2465s\n",
      "\titers: 300, epoch: 11 | loss: 0.0290085\n",
      "\tspeed: 0.1276s/iter; left time: 442.7840s\n",
      "Epoch: 11 cost time: 49.16062116622925\n",
      "Epoch: 11, Steps: 377 | Train Loss: 0.0307217 Vali Loss: 0.0447773 Test Loss: 0.0528032\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.05245085433125496, mae:0.18530263006687164\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'data': 'SYNTH_additive_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_reversal_ftS_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.0489957\n",
      "\tspeed: 0.0431s/iter; left time: 339.2950s\n",
      "\titers: 200, epoch: 1 | loss: 0.0915252\n",
      "\tspeed: 0.0447s/iter; left time: 348.1741s\n",
      "\titers: 300, epoch: 1 | loss: 0.0818511\n",
      "\tspeed: 0.0451s/iter; left time: 346.0457s\n",
      "Epoch: 1 cost time: 17.750816822052002\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.1262940 Vali Loss: 0.0678498 Test Loss: 0.0708692\n",
      "Validation loss decreased (inf --> 0.067850).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0417193\n",
      "\tspeed: 0.1497s/iter; left time: 1120.1876s\n",
      "\titers: 200, epoch: 2 | loss: 0.0322749\n",
      "\tspeed: 0.0456s/iter; left time: 336.7258s\n",
      "\titers: 300, epoch: 2 | loss: 0.0228053\n",
      "\tspeed: 0.0447s/iter; left time: 325.5863s\n",
      "Epoch: 2 cost time: 17.93130922317505\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0363842 Vali Loss: 0.0438991 Test Loss: 0.0444558\n",
      "Validation loss decreased (0.067850 --> 0.043899).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0213397\n",
      "\tspeed: 0.1558s/iter; left time: 1103.3565s\n",
      "\titers: 200, epoch: 3 | loss: 0.0207407\n",
      "\tspeed: 0.0449s/iter; left time: 313.5439s\n",
      "\titers: 300, epoch: 3 | loss: 0.0217047\n",
      "\tspeed: 0.0447s/iter; left time: 307.4442s\n",
      "Epoch: 3 cost time: 18.434921264648438\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0213330 Vali Loss: 0.0314857 Test Loss: 0.0348566\n",
      "Validation loss decreased (0.043899 --> 0.031486).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0208929\n",
      "\tspeed: 0.1596s/iter; left time: 1066.7300s\n",
      "\titers: 200, epoch: 4 | loss: 0.0186977\n",
      "\tspeed: 0.0468s/iter; left time: 308.0147s\n",
      "\titers: 300, epoch: 4 | loss: 0.0153353\n",
      "\tspeed: 0.0480s/iter; left time: 310.9138s\n",
      "Epoch: 4 cost time: 18.86354899406433\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0174740 Vali Loss: 0.0283664 Test Loss: 0.0307899\n",
      "Validation loss decreased (0.031486 --> 0.028366).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0206723\n",
      "\tspeed: 0.1570s/iter; left time: 986.8231s\n",
      "\titers: 200, epoch: 5 | loss: 0.0177513\n",
      "\tspeed: 0.0463s/iter; left time: 286.4911s\n",
      "\titers: 300, epoch: 5 | loss: 0.0155638\n",
      "\tspeed: 0.0454s/iter; left time: 276.3683s\n",
      "Epoch: 5 cost time: 18.29183840751648\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0160885 Vali Loss: 0.0282101 Test Loss: 0.0305555\n",
      "Validation loss decreased (0.028366 --> 0.028210).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0128551\n",
      "\tspeed: 0.1461s/iter; left time: 860.1764s\n",
      "\titers: 200, epoch: 6 | loss: 0.0151808\n",
      "\tspeed: 0.0449s/iter; left time: 259.5927s\n",
      "\titers: 300, epoch: 6 | loss: 0.0120647\n",
      "\tspeed: 0.0475s/iter; left time: 269.8416s\n",
      "Epoch: 6 cost time: 18.231939792633057\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0151731 Vali Loss: 0.0291796 Test Loss: 0.0302572\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0158034\n",
      "\tspeed: 0.1506s/iter; left time: 826.4128s\n",
      "\titers: 200, epoch: 7 | loss: 0.0192675\n",
      "\tspeed: 0.0453s/iter; left time: 244.1831s\n",
      "\titers: 300, epoch: 7 | loss: 0.0162257\n",
      "\tspeed: 0.0462s/iter; left time: 244.0042s\n",
      "Epoch: 7 cost time: 18.12523317337036\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0148149 Vali Loss: 0.0287764 Test Loss: 0.0300972\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0166862\n",
      "\tspeed: 0.1526s/iter; left time: 776.3355s\n",
      "\titers: 200, epoch: 8 | loss: 0.0132980\n",
      "\tspeed: 0.0446s/iter; left time: 222.5210s\n",
      "\titers: 300, epoch: 8 | loss: 0.0137437\n",
      "\tspeed: 0.0441s/iter; left time: 215.3701s\n",
      "Epoch: 8 cost time: 17.680171728134155\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0148415 Vali Loss: 0.0289522 Test Loss: 0.0308636\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.030555512756109238, mae:0.137058287858963\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'data': 'SYNTH_additive_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 48, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_reversal_ftS_sl168_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.0978297\n",
      "\tspeed: 0.0463s/iter; left time: 363.6583s\n",
      "\titers: 200, epoch: 1 | loss: 0.0870930\n",
      "\tspeed: 0.0472s/iter; left time: 366.1537s\n",
      "\titers: 300, epoch: 1 | loss: 0.0655422\n",
      "\tspeed: 0.0461s/iter; left time: 352.8821s\n",
      "Epoch: 1 cost time: 18.480798482894897\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.1070394 Vali Loss: 0.0680729 Test Loss: 0.0739122\n",
      "Validation loss decreased (inf --> 0.068073).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0514472\n",
      "\tspeed: 0.1515s/iter; left time: 1130.6790s\n",
      "\titers: 200, epoch: 2 | loss: 0.0281261\n",
      "\tspeed: 0.0457s/iter; left time: 336.2780s\n",
      "\titers: 300, epoch: 2 | loss: 0.0398876\n",
      "\tspeed: 0.0457s/iter; left time: 332.0522s\n",
      "Epoch: 2 cost time: 18.43596386909485\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0370379 Vali Loss: 0.0445310 Test Loss: 0.0463486\n",
      "Validation loss decreased (0.068073 --> 0.044531).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0253945\n",
      "\tspeed: 0.1598s/iter; left time: 1129.3175s\n",
      "\titers: 200, epoch: 3 | loss: 0.0307488\n",
      "\tspeed: 0.0458s/iter; left time: 319.0671s\n",
      "\titers: 300, epoch: 3 | loss: 0.0273119\n",
      "\tspeed: 0.0496s/iter; left time: 340.7480s\n",
      "Epoch: 3 cost time: 19.310486316680908\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0275728 Vali Loss: 0.0413382 Test Loss: 0.0445243\n",
      "Validation loss decreased (0.044531 --> 0.041338).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0251007\n",
      "\tspeed: 0.1635s/iter; left time: 1089.8054s\n",
      "\titers: 200, epoch: 4 | loss: 0.0253557\n",
      "\tspeed: 0.0486s/iter; left time: 319.1212s\n",
      "\titers: 300, epoch: 4 | loss: 0.0265528\n",
      "\tspeed: 0.0485s/iter; left time: 313.3445s\n",
      "Epoch: 4 cost time: 19.35852813720703\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0235496 Vali Loss: 0.0398208 Test Loss: 0.0430320\n",
      "Validation loss decreased (0.041338 --> 0.039821).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0171138\n",
      "\tspeed: 0.1602s/iter; left time: 1004.0752s\n",
      "\titers: 200, epoch: 5 | loss: 0.0177215\n",
      "\tspeed: 0.0465s/iter; left time: 287.0487s\n",
      "\titers: 300, epoch: 5 | loss: 0.0164425\n",
      "\tspeed: 0.0456s/iter; left time: 276.8600s\n",
      "Epoch: 5 cost time: 18.115406036376953\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0210565 Vali Loss: 0.0388232 Test Loss: 0.0407218\n",
      "Validation loss decreased (0.039821 --> 0.038823).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0187074\n",
      "\tspeed: 0.1471s/iter; left time: 863.3838s\n",
      "\titers: 200, epoch: 6 | loss: 0.0234274\n",
      "\tspeed: 0.0458s/iter; left time: 264.5907s\n",
      "\titers: 300, epoch: 6 | loss: 0.0205772\n",
      "\tspeed: 0.0460s/iter; left time: 260.8414s\n",
      "Epoch: 6 cost time: 18.557401657104492\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0203414 Vali Loss: 0.0368719 Test Loss: 0.0401252\n",
      "Validation loss decreased (0.038823 --> 0.036872).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0181020\n",
      "\tspeed: 0.1599s/iter; left time: 874.8619s\n",
      "\titers: 200, epoch: 7 | loss: 0.0201837\n",
      "\tspeed: 0.0470s/iter; left time: 252.5179s\n",
      "\titers: 300, epoch: 7 | loss: 0.0181286\n",
      "\tspeed: 0.0482s/iter; left time: 254.4211s\n",
      "Epoch: 7 cost time: 19.048405170440674\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0194464 Vali Loss: 0.0415506 Test Loss: 0.0446792\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0179576\n",
      "\tspeed: 0.1571s/iter; left time: 797.3062s\n",
      "\titers: 200, epoch: 8 | loss: 0.0194858\n",
      "\tspeed: 0.0481s/iter; left time: 239.1619s\n",
      "\titers: 300, epoch: 8 | loss: 0.0184395\n",
      "\tspeed: 0.0480s/iter; left time: 234.1014s\n",
      "Epoch: 8 cost time: 19.100508451461792\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0191198 Vali Loss: 0.0401838 Test Loss: 0.0442341\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0187316\n",
      "\tspeed: 0.1606s/iter; left time: 751.1708s\n",
      "\titers: 200, epoch: 9 | loss: 0.0193886\n",
      "\tspeed: 0.0462s/iter; left time: 211.6851s\n",
      "\titers: 300, epoch: 9 | loss: 0.0157698\n",
      "\tspeed: 0.0461s/iter; left time: 206.3060s\n",
      "Epoch: 9 cost time: 18.5489182472229\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0192697 Vali Loss: 0.0411040 Test Loss: 0.0444896\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.04012524336576462, mae:0.15267501771450043\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'data': 'SYNTH_additive_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 168, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_reversal_ftS_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.1771931\n",
      "\tspeed: 0.0586s/iter; left time: 455.6199s\n",
      "\titers: 200, epoch: 1 | loss: 0.1565294\n",
      "\tspeed: 0.0593s/iter; left time: 455.3917s\n",
      "\titers: 300, epoch: 1 | loss: 0.1329616\n",
      "\tspeed: 0.0609s/iter; left time: 461.8379s\n",
      "Epoch: 1 cost time: 23.70665216445923\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.1645831 Vali Loss: 0.1785083 Test Loss: 0.2179745\n",
      "Validation loss decreased (inf --> 0.178508).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0879291\n",
      "\tspeed: 0.1931s/iter; left time: 1426.0661s\n",
      "\titers: 200, epoch: 2 | loss: 0.0924924\n",
      "\tspeed: 0.0583s/iter; left time: 424.5296s\n",
      "\titers: 300, epoch: 2 | loss: 0.1025033\n",
      "\tspeed: 0.0575s/iter; left time: 413.6056s\n",
      "Epoch: 2 cost time: 22.69951295852661\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.1013688 Vali Loss: 0.1551001 Test Loss: 0.1468192\n",
      "Validation loss decreased (0.178508 --> 0.155100).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0874611\n",
      "\tspeed: 0.1909s/iter; left time: 1334.9141s\n",
      "\titers: 200, epoch: 3 | loss: 0.0630309\n",
      "\tspeed: 0.0640s/iter; left time: 441.1992s\n",
      "\titers: 300, epoch: 3 | loss: 0.1081255\n",
      "\tspeed: 0.0630s/iter; left time: 427.8838s\n",
      "Epoch: 3 cost time: 24.176265239715576\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0900570 Vali Loss: 0.1388134 Test Loss: 0.1363431\n",
      "Validation loss decreased (0.155100 --> 0.138813).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0826368\n",
      "\tspeed: 0.1929s/iter; left time: 1272.8931s\n",
      "\titers: 200, epoch: 4 | loss: 0.1011170\n",
      "\tspeed: 0.0617s/iter; left time: 400.7049s\n",
      "\titers: 300, epoch: 4 | loss: 0.0975038\n",
      "\tspeed: 0.0609s/iter; left time: 389.5849s\n",
      "Epoch: 4 cost time: 23.952023029327393\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0847710 Vali Loss: 0.1391679 Test Loss: 0.1415630\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0740938\n",
      "\tspeed: 0.1808s/iter; left time: 1122.0763s\n",
      "\titers: 200, epoch: 5 | loss: 0.0716475\n",
      "\tspeed: 0.0614s/iter; left time: 375.0528s\n",
      "\titers: 300, epoch: 5 | loss: 0.0875504\n",
      "\tspeed: 0.0595s/iter; left time: 357.5567s\n",
      "Epoch: 5 cost time: 23.769425630569458\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0816851 Vali Loss: 0.1486481 Test Loss: 0.1431058\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0835834\n",
      "\tspeed: 0.1756s/iter; left time: 1020.5425s\n",
      "\titers: 200, epoch: 6 | loss: 0.1125921\n",
      "\tspeed: 0.0635s/iter; left time: 362.6746s\n",
      "\titers: 300, epoch: 6 | loss: 0.0763122\n",
      "\tspeed: 0.0576s/iter; left time: 323.1570s\n",
      "Epoch: 6 cost time: 23.8841335773468\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0795908 Vali Loss: 0.1455588 Test Loss: 0.1400544\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.1363430768251419, mae:0.29264694452285767\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'data': 'SYNTH_additive_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 336, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_reversal_ftS_sl168_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.2209477\n",
      "\tspeed: 0.0873s/iter; left time: 670.8018s\n",
      "\titers: 200, epoch: 1 | loss: 0.2101532\n",
      "\tspeed: 0.0850s/iter; left time: 644.4257s\n",
      "\titers: 300, epoch: 1 | loss: 0.1881227\n",
      "\tspeed: 0.0827s/iter; left time: 618.9899s\n",
      "Epoch: 1 cost time: 32.98898458480835\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.2276291 Vali Loss: 0.3190134 Test Loss: 0.2920031\n",
      "Validation loss decreased (inf --> 0.319013).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1783742\n",
      "\tspeed: 0.2887s/iter; left time: 2105.1541s\n",
      "\titers: 200, epoch: 2 | loss: 0.1844728\n",
      "\tspeed: 0.0886s/iter; left time: 637.3857s\n",
      "\titers: 300, epoch: 2 | loss: 0.1662727\n",
      "\tspeed: 0.0875s/iter; left time: 620.8518s\n",
      "Epoch: 2 cost time: 33.51235556602478\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.1668617 Vali Loss: 0.2899578 Test Loss: 0.2875070\n",
      "Validation loss decreased (0.319013 --> 0.289958).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1404930\n",
      "\tspeed: 0.2716s/iter; left time: 1875.1712s\n",
      "\titers: 200, epoch: 3 | loss: 0.1388626\n",
      "\tspeed: 0.0843s/iter; left time: 573.6236s\n",
      "\titers: 300, epoch: 3 | loss: 0.1461964\n",
      "\tspeed: 0.0820s/iter; left time: 549.7528s\n",
      "Epoch: 3 cost time: 32.518383502960205\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.1402755 Vali Loss: 0.2953455 Test Loss: 0.2726845\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1097627\n",
      "\tspeed: 0.2686s/iter; left time: 1749.6913s\n",
      "\titers: 200, epoch: 4 | loss: 0.1376510\n",
      "\tspeed: 0.0851s/iter; left time: 545.8569s\n",
      "\titers: 300, epoch: 4 | loss: 0.1193879\n",
      "\tspeed: 0.0824s/iter; left time: 520.4688s\n",
      "Epoch: 4 cost time: 33.08233332633972\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.1323859 Vali Loss: 0.2917631 Test Loss: 0.2887057\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1346490\n",
      "\tspeed: 0.2912s/iter; left time: 1783.7216s\n",
      "\titers: 200, epoch: 5 | loss: 0.1539253\n",
      "\tspeed: 0.0894s/iter; left time: 538.4499s\n",
      "\titers: 300, epoch: 5 | loss: 0.1003996\n",
      "\tspeed: 0.0831s/iter; left time: 492.1342s\n",
      "Epoch: 5 cost time: 33.29521727561951\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.1284722 Vali Loss: 0.3135206 Test Loss: 0.2722483\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.28750696778297424, mae:0.421739786863327\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_additive_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'data': 'SYNTH_additive_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 720, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_additive_reversal_ftS_sl168_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.2624522\n",
      "\tspeed: 0.1379s/iter; left time: 1026.0747s\n",
      "\titers: 200, epoch: 1 | loss: 0.2536667\n",
      "\tspeed: 0.1362s/iter; left time: 1000.1966s\n",
      "\titers: 300, epoch: 1 | loss: 0.2457719\n",
      "\tspeed: 0.1339s/iter; left time: 969.7862s\n",
      "Epoch: 1 cost time: 50.72823166847229\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.2770139 Vali Loss: 0.6948174 Test Loss: 0.4627288\n",
      "Validation loss decreased (inf --> 0.694817).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1888694\n",
      "\tspeed: 0.3778s/iter; left time: 2668.6986s\n",
      "\titers: 200, epoch: 2 | loss: 0.2362717\n",
      "\tspeed: 0.1303s/iter; left time: 907.6208s\n",
      "\titers: 300, epoch: 2 | loss: 0.2179256\n",
      "\tspeed: 0.1290s/iter; left time: 885.5697s\n",
      "Epoch: 2 cost time: 48.74476480484009\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.2414047 Vali Loss: 0.6914209 Test Loss: 0.4346135\n",
      "Validation loss decreased (0.694817 --> 0.691421).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2559272\n",
      "\tspeed: 0.3585s/iter; left time: 2397.5956s\n",
      "\titers: 200, epoch: 3 | loss: 0.1961967\n",
      "\tspeed: 0.1336s/iter; left time: 880.0124s\n",
      "\titers: 300, epoch: 3 | loss: 0.2489941\n",
      "\tspeed: 0.1310s/iter; left time: 849.4798s\n",
      "Epoch: 3 cost time: 49.682759523391724\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.2320254 Vali Loss: 0.7041132 Test Loss: 0.4415968\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2152065\n",
      "\tspeed: 0.3853s/iter; left time: 2431.1595s\n",
      "\titers: 200, epoch: 4 | loss: 0.2655168\n",
      "\tspeed: 0.1360s/iter; left time: 844.2530s\n",
      "\titers: 300, epoch: 4 | loss: 0.1680807\n",
      "\tspeed: 0.1347s/iter; left time: 823.1798s\n",
      "Epoch: 4 cost time: 50.604652643203735\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.2270181 Vali Loss: 0.6660019 Test Loss: 0.4612713\n",
      "Validation loss decreased (0.691421 --> 0.666002).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2279389\n",
      "\tspeed: 0.3766s/iter; left time: 2234.4195s\n",
      "\titers: 200, epoch: 5 | loss: 0.1957909\n",
      "\tspeed: 0.1313s/iter; left time: 765.8810s\n",
      "\titers: 300, epoch: 5 | loss: 0.2209346\n",
      "\tspeed: 0.1306s/iter; left time: 748.5822s\n",
      "Epoch: 5 cost time: 49.71223211288452\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.2256260 Vali Loss: 0.6804048 Test Loss: 0.4496968\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2181283\n",
      "\tspeed: 0.3751s/iter; left time: 2083.9714s\n",
      "\titers: 200, epoch: 6 | loss: 0.2501311\n",
      "\tspeed: 0.1344s/iter; left time: 733.2296s\n",
      "\titers: 300, epoch: 6 | loss: 0.2302448\n",
      "\tspeed: 0.1281s/iter; left time: 686.1949s\n",
      "Epoch: 6 cost time: 49.366960763931274\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.2242841 Vali Loss: 0.6790493 Test Loss: 0.4554223\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2235481\n",
      "\tspeed: 0.3778s/iter; left time: 1956.6056s\n",
      "\titers: 200, epoch: 7 | loss: 0.2159320\n",
      "\tspeed: 0.1306s/iter; left time: 663.2089s\n",
      "\titers: 300, epoch: 7 | loss: 0.2516025\n",
      "\tspeed: 0.1323s/iter; left time: 658.7135s\n",
      "Epoch: 7 cost time: 49.53090977668762\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.2238086 Vali Loss: 0.6774448 Test Loss: 0.4529329\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.4612713158130646, mae:0.5526147484779358\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'data': 'SYNTH_multiplicative', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_ftS_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.0741512\n",
      "\tspeed: 0.0493s/iter; left time: 388.9039s\n",
      "\titers: 200, epoch: 1 | loss: 0.0624823\n",
      "\tspeed: 0.0464s/iter; left time: 361.4126s\n",
      "\titers: 300, epoch: 1 | loss: 0.0626036\n",
      "\tspeed: 0.0474s/iter; left time: 364.0311s\n",
      "Epoch: 1 cost time: 18.885600805282593\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.0901491 Vali Loss: 0.1120993 Test Loss: 0.1826288\n",
      "Validation loss decreased (inf --> 0.112099).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0439145\n",
      "\tspeed: 0.1568s/iter; left time: 1172.8137s\n",
      "\titers: 200, epoch: 2 | loss: 0.0444663\n",
      "\tspeed: 0.0447s/iter; left time: 329.6368s\n",
      "\titers: 300, epoch: 2 | loss: 0.0344573\n",
      "\tspeed: 0.0444s/iter; left time: 323.1938s\n",
      "Epoch: 2 cost time: 17.833931922912598\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0335274 Vali Loss: 0.0744303 Test Loss: 0.1306515\n",
      "Validation loss decreased (0.112099 --> 0.074430).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0172933\n",
      "\tspeed: 0.1419s/iter; left time: 1004.8997s\n",
      "\titers: 200, epoch: 3 | loss: 0.0234268\n",
      "\tspeed: 0.0475s/iter; left time: 331.5834s\n",
      "\titers: 300, epoch: 3 | loss: 0.0180743\n",
      "\tspeed: 0.0460s/iter; left time: 316.5705s\n",
      "Epoch: 3 cost time: 18.584203004837036\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0224535 Vali Loss: 0.0665491 Test Loss: 0.1240920\n",
      "Validation loss decreased (0.074430 --> 0.066549).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0120770\n",
      "\tspeed: 0.1610s/iter; left time: 1076.3011s\n",
      "\titers: 200, epoch: 4 | loss: 0.0241770\n",
      "\tspeed: 0.0476s/iter; left time: 313.2633s\n",
      "\titers: 300, epoch: 4 | loss: 0.0187446\n",
      "\tspeed: 0.0469s/iter; left time: 304.2245s\n",
      "Epoch: 4 cost time: 18.709775924682617\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0189786 Vali Loss: 0.0688197 Test Loss: 0.1221454\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0194958\n",
      "\tspeed: 0.1381s/iter; left time: 867.9310s\n",
      "\titers: 200, epoch: 5 | loss: 0.0201705\n",
      "\tspeed: 0.0431s/iter; left time: 266.8669s\n",
      "\titers: 300, epoch: 5 | loss: 0.0162394\n",
      "\tspeed: 0.0425s/iter; left time: 258.8458s\n",
      "Epoch: 5 cost time: 17.241039514541626\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0175292 Vali Loss: 0.0600912 Test Loss: 0.1125200\n",
      "Validation loss decreased (0.066549 --> 0.060091).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0182009\n",
      "\tspeed: 0.1492s/iter; left time: 878.1921s\n",
      "\titers: 200, epoch: 6 | loss: 0.0143837\n",
      "\tspeed: 0.0467s/iter; left time: 270.1487s\n",
      "\titers: 300, epoch: 6 | loss: 0.0136383\n",
      "\tspeed: 0.0465s/iter; left time: 264.3321s\n",
      "Epoch: 6 cost time: 18.4460186958313\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0165829 Vali Loss: 0.0619915 Test Loss: 0.1143851\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0201821\n",
      "\tspeed: 0.1590s/iter; left time: 872.5989s\n",
      "\titers: 200, epoch: 7 | loss: 0.0178274\n",
      "\tspeed: 0.0450s/iter; left time: 242.3439s\n",
      "\titers: 300, epoch: 7 | loss: 0.0182770\n",
      "\tspeed: 0.0445s/iter; left time: 235.2131s\n",
      "Epoch: 7 cost time: 17.719043731689453\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0160122 Vali Loss: 0.0618673 Test Loss: 0.1142717\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0111325\n",
      "\tspeed: 0.1474s/iter; left time: 750.0648s\n",
      "\titers: 200, epoch: 8 | loss: 0.0137690\n",
      "\tspeed: 0.0430s/iter; left time: 214.6948s\n",
      "\titers: 300, epoch: 8 | loss: 0.0145820\n",
      "\tspeed: 0.0438s/iter; left time: 213.9402s\n",
      "Epoch: 8 cost time: 17.541751861572266\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0157993 Vali Loss: 0.0609423 Test Loss: 0.1124179\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.11251995712518692, mae:0.27325430512428284\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'data': 'SYNTH_multiplicative', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 48, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_ftS_sl168_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.0702301\n",
      "\tspeed: 0.0467s/iter; left time: 367.1244s\n",
      "\titers: 200, epoch: 1 | loss: 0.0502240\n",
      "\tspeed: 0.0479s/iter; left time: 371.7646s\n",
      "\titers: 300, epoch: 1 | loss: 0.0457329\n",
      "\tspeed: 0.0478s/iter; left time: 366.0152s\n",
      "Epoch: 1 cost time: 19.040446043014526\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0809257 Vali Loss: 0.1045849 Test Loss: 0.1786743\n",
      "Validation loss decreased (inf --> 0.104585).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0360124\n",
      "\tspeed: 0.1579s/iter; left time: 1178.4507s\n",
      "\titers: 200, epoch: 2 | loss: 0.0200727\n",
      "\tspeed: 0.0476s/iter; left time: 350.3519s\n",
      "\titers: 300, epoch: 2 | loss: 0.0190611\n",
      "\tspeed: 0.0469s/iter; left time: 340.8995s\n",
      "Epoch: 2 cost time: 18.785019397735596\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0265125 Vali Loss: 0.0952553 Test Loss: 0.1598437\n",
      "Validation loss decreased (0.104585 --> 0.095255).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0156130\n",
      "\tspeed: 0.1642s/iter; left time: 1159.9356s\n",
      "\titers: 200, epoch: 3 | loss: 0.0213216\n",
      "\tspeed: 0.0499s/iter; left time: 347.4743s\n",
      "\titers: 300, epoch: 3 | loss: 0.0161389\n",
      "\tspeed: 0.0491s/iter; left time: 336.9205s\n",
      "Epoch: 3 cost time: 20.004951238632202\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0194299 Vali Loss: 0.0802773 Test Loss: 0.1373168\n",
      "Validation loss decreased (0.095255 --> 0.080277).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0145455\n",
      "\tspeed: 0.1645s/iter; left time: 1096.8499s\n",
      "\titers: 200, epoch: 4 | loss: 0.0144385\n",
      "\tspeed: 0.0494s/iter; left time: 324.7377s\n",
      "\titers: 300, epoch: 4 | loss: 0.0219245\n",
      "\tspeed: 0.0499s/iter; left time: 322.4462s\n",
      "Epoch: 4 cost time: 19.589086055755615\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0159893 Vali Loss: 0.0647886 Test Loss: 0.1192847\n",
      "Validation loss decreased (0.080277 --> 0.064789).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0105901\n",
      "\tspeed: 0.1543s/iter; left time: 967.6103s\n",
      "\titers: 200, epoch: 5 | loss: 0.0125631\n",
      "\tspeed: 0.0456s/iter; left time: 281.1898s\n",
      "\titers: 300, epoch: 5 | loss: 0.0176860\n",
      "\tspeed: 0.0457s/iter; left time: 277.2151s\n",
      "Epoch: 5 cost time: 18.229021549224854\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0146449 Vali Loss: 0.0642764 Test Loss: 0.1181009\n",
      "Validation loss decreased (0.064789 --> 0.064276).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0262036\n",
      "\tspeed: 0.1571s/iter; left time: 922.3919s\n",
      "\titers: 200, epoch: 6 | loss: 0.0127497\n",
      "\tspeed: 0.0474s/iter; left time: 273.7133s\n",
      "\titers: 300, epoch: 6 | loss: 0.0166210\n",
      "\tspeed: 0.0484s/iter; left time: 274.7204s\n",
      "Epoch: 6 cost time: 18.98950505256653\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0140705 Vali Loss: 0.0624247 Test Loss: 0.1160133\n",
      "Validation loss decreased (0.064276 --> 0.062425).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0144381\n",
      "\tspeed: 0.1528s/iter; left time: 836.2442s\n",
      "\titers: 200, epoch: 7 | loss: 0.0127520\n",
      "\tspeed: 0.0463s/iter; left time: 248.7651s\n",
      "\titers: 300, epoch: 7 | loss: 0.0143201\n",
      "\tspeed: 0.0475s/iter; left time: 250.5782s\n",
      "Epoch: 7 cost time: 18.54778528213501\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0133810 Vali Loss: 0.0644759 Test Loss: 0.1201809\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0118739\n",
      "\tspeed: 0.1561s/iter; left time: 792.2766s\n",
      "\titers: 200, epoch: 8 | loss: 0.0115992\n",
      "\tspeed: 0.0471s/iter; left time: 234.5045s\n",
      "\titers: 300, epoch: 8 | loss: 0.0115549\n",
      "\tspeed: 0.0466s/iter; left time: 227.3831s\n",
      "Epoch: 8 cost time: 18.57915449142456\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0133482 Vali Loss: 0.0644215 Test Loss: 0.1203414\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0138911\n",
      "\tspeed: 0.1533s/iter; left time: 717.1646s\n",
      "\titers: 200, epoch: 9 | loss: 0.0130453\n",
      "\tspeed: 0.0464s/iter; left time: 212.5787s\n",
      "\titers: 300, epoch: 9 | loss: 0.0088070\n",
      "\tspeed: 0.0468s/iter; left time: 209.4317s\n",
      "Epoch: 9 cost time: 18.523549795150757\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0133415 Vali Loss: 0.0628068 Test Loss: 0.1176175\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.11601333320140839, mae:0.26953092217445374\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'data': 'SYNTH_multiplicative', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 168, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_ftS_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.0984645\n",
      "\tspeed: 0.0609s/iter; left time: 473.4863s\n",
      "\titers: 200, epoch: 1 | loss: 0.0741848\n",
      "\tspeed: 0.0581s/iter; left time: 445.9056s\n",
      "\titers: 300, epoch: 1 | loss: 0.0511436\n",
      "\tspeed: 0.0609s/iter; left time: 461.6070s\n",
      "Epoch: 1 cost time: 24.08078122138977\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.0981217 Vali Loss: 0.1911211 Test Loss: 0.3019166\n",
      "Validation loss decreased (inf --> 0.191121).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0607691\n",
      "\tspeed: 0.2073s/iter; left time: 1531.3509s\n",
      "\titers: 200, epoch: 2 | loss: 0.0666611\n",
      "\tspeed: 0.0605s/iter; left time: 440.9114s\n",
      "\titers: 300, epoch: 2 | loss: 0.0596437\n",
      "\tspeed: 0.0592s/iter; left time: 425.4156s\n",
      "Epoch: 2 cost time: 23.97174906730652\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0544428 Vali Loss: 0.1696457 Test Loss: 0.2669599\n",
      "Validation loss decreased (0.191121 --> 0.169646).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0416294\n",
      "\tspeed: 0.1899s/iter; left time: 1327.7762s\n",
      "\titers: 200, epoch: 3 | loss: 0.0499032\n",
      "\tspeed: 0.0572s/iter; left time: 394.1447s\n",
      "\titers: 300, epoch: 3 | loss: 0.0419345\n",
      "\tspeed: 0.0584s/iter; left time: 396.9828s\n",
      "Epoch: 3 cost time: 23.103967905044556\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0475838 Vali Loss: 0.1667616 Test Loss: 0.2651906\n",
      "Validation loss decreased (0.169646 --> 0.166762).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0383358\n",
      "\tspeed: 0.1958s/iter; left time: 1291.8054s\n",
      "\titers: 200, epoch: 4 | loss: 0.0542562\n",
      "\tspeed: 0.0608s/iter; left time: 395.0268s\n",
      "\titers: 300, epoch: 4 | loss: 0.0488477\n",
      "\tspeed: 0.0617s/iter; left time: 394.9699s\n",
      "Epoch: 4 cost time: 24.270941019058228\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0443179 Vali Loss: 0.1854617 Test Loss: 0.2899226\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0466862\n",
      "\tspeed: 0.1950s/iter; left time: 1210.0058s\n",
      "\titers: 200, epoch: 5 | loss: 0.0363319\n",
      "\tspeed: 0.0569s/iter; left time: 347.1656s\n",
      "\titers: 300, epoch: 5 | loss: 0.0395032\n",
      "\tspeed: 0.0590s/iter; left time: 354.2454s\n",
      "Epoch: 5 cost time: 23.476757287979126\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0418624 Vali Loss: 0.2477342 Test Loss: 0.3766555\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0440916\n",
      "\tspeed: 0.1994s/iter; left time: 1158.9666s\n",
      "\titers: 200, epoch: 6 | loss: 0.0363461\n",
      "\tspeed: 0.0646s/iter; left time: 368.7635s\n",
      "\titers: 300, epoch: 6 | loss: 0.0391509\n",
      "\tspeed: 0.0622s/iter; left time: 348.7814s\n",
      "Epoch: 6 cost time: 24.619689464569092\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0408887 Vali Loss: 0.2711851 Test Loss: 0.4210870\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.26519057154655457, mae:0.4222194254398346\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'data': 'SYNTH_multiplicative', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 336, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_ftS_sl168_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.1087251\n",
      "\tspeed: 0.0836s/iter; left time: 642.3800s\n",
      "\titers: 200, epoch: 1 | loss: 0.0751775\n",
      "\tspeed: 0.0811s/iter; left time: 614.4407s\n",
      "\titers: 300, epoch: 1 | loss: 0.0762006\n",
      "\tspeed: 0.0818s/iter; left time: 611.6983s\n",
      "Epoch: 1 cost time: 32.190972328186035\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1158817 Vali Loss: 0.3501975 Test Loss: 0.4983619\n",
      "Validation loss decreased (inf --> 0.350197).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0749111\n",
      "\tspeed: 0.2745s/iter; left time: 2001.8304s\n",
      "\titers: 200, epoch: 2 | loss: 0.0893814\n",
      "\tspeed: 0.0825s/iter; left time: 593.2937s\n",
      "\titers: 300, epoch: 2 | loss: 0.0822540\n",
      "\tspeed: 0.0838s/iter; left time: 594.1145s\n",
      "Epoch: 2 cost time: 32.169689655303955\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0705848 Vali Loss: 0.3401681 Test Loss: 0.5041975\n",
      "Validation loss decreased (0.350197 --> 0.340168).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0687988\n",
      "\tspeed: 0.2805s/iter; left time: 1935.9946s\n",
      "\titers: 200, epoch: 3 | loss: 0.0764388\n",
      "\tspeed: 0.0878s/iter; left time: 597.6315s\n",
      "\titers: 300, epoch: 3 | loss: 0.0490174\n",
      "\tspeed: 0.0875s/iter; left time: 586.7585s\n",
      "Epoch: 3 cost time: 34.03120946884155\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0615597 Vali Loss: 0.4545955 Test Loss: 0.6596261\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0468091\n",
      "\tspeed: 0.2763s/iter; left time: 1799.6851s\n",
      "\titers: 200, epoch: 4 | loss: 0.0670640\n",
      "\tspeed: 0.0867s/iter; left time: 556.3748s\n",
      "\titers: 300, epoch: 4 | loss: 0.0556166\n",
      "\tspeed: 0.0858s/iter; left time: 541.6379s\n",
      "Epoch: 4 cost time: 33.127010345458984\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0559803 Vali Loss: 0.5535675 Test Loss: 0.8373256\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0453451\n",
      "\tspeed: 0.2779s/iter; left time: 1702.1909s\n",
      "\titers: 200, epoch: 5 | loss: 0.0453871\n",
      "\tspeed: 0.0861s/iter; left time: 519.0171s\n",
      "\titers: 300, epoch: 5 | loss: 0.0403954\n",
      "\tspeed: 0.0792s/iter; left time: 469.2766s\n",
      "Epoch: 5 cost time: 32.74449920654297\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0507659 Vali Loss: 1.0987434 Test Loss: 1.5982790\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.5041974782943726, mae:0.5790762901306152\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'data': 'SYNTH_multiplicative', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 720, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_ftS_sl168_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.0956715\n",
      "\tspeed: 0.1258s/iter; left time: 935.8670s\n",
      "\titers: 200, epoch: 1 | loss: 0.0785887\n",
      "\tspeed: 0.1268s/iter; left time: 930.6775s\n",
      "\titers: 300, epoch: 1 | loss: 0.0569393\n",
      "\tspeed: 0.1271s/iter; left time: 920.0052s\n",
      "Epoch: 1 cost time: 48.37246775627136\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.0968211 Vali Loss: 0.2440327 Test Loss: 0.3866280\n",
      "Validation loss decreased (inf --> 0.244033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0555815\n",
      "\tspeed: 0.3783s/iter; left time: 2672.3069s\n",
      "\titers: 200, epoch: 2 | loss: 0.0527477\n",
      "\tspeed: 0.1270s/iter; left time: 884.6825s\n",
      "\titers: 300, epoch: 2 | loss: 0.0589594\n",
      "\tspeed: 0.1301s/iter; left time: 893.3411s\n",
      "Epoch: 2 cost time: 48.24889659881592\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0631949 Vali Loss: 0.2323397 Test Loss: 0.3925026\n",
      "Validation loss decreased (0.244033 --> 0.232340).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0493882\n",
      "\tspeed: 0.3940s/iter; left time: 2634.6227s\n",
      "\titers: 200, epoch: 3 | loss: 0.0471104\n",
      "\tspeed: 0.1347s/iter; left time: 887.4212s\n",
      "\titers: 300, epoch: 3 | loss: 0.0565727\n",
      "\tspeed: 0.1283s/iter; left time: 832.3154s\n",
      "Epoch: 3 cost time: 50.5577335357666\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0581579 Vali Loss: 0.2376643 Test Loss: 0.3850798\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0445436\n",
      "\tspeed: 0.3890s/iter; left time: 2454.3374s\n",
      "\titers: 200, epoch: 4 | loss: 0.0662931\n",
      "\tspeed: 0.1312s/iter; left time: 814.4523s\n",
      "\titers: 300, epoch: 4 | loss: 0.0557901\n",
      "\tspeed: 0.1210s/iter; left time: 739.4832s\n",
      "Epoch: 4 cost time: 49.05441975593567\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0550174 Vali Loss: 0.2390472 Test Loss: 0.3697545\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0436083\n",
      "\tspeed: 0.3880s/iter; left time: 2302.2528s\n",
      "\titers: 200, epoch: 5 | loss: 0.0573383\n",
      "\tspeed: 0.1331s/iter; left time: 776.5483s\n",
      "\titers: 300, epoch: 5 | loss: 0.0517081\n",
      "\tspeed: 0.1236s/iter; left time: 708.6014s\n",
      "Epoch: 5 cost time: 48.97093963623047\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0529670 Vali Loss: 0.2864779 Test Loss: 0.4397054\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.3925026059150696, mae:0.5097677111625671\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'data': 'SYNTH_multiplicative_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.0853506\n",
      "\tspeed: 0.0476s/iter; left time: 375.1687s\n",
      "\titers: 200, epoch: 1 | loss: 0.0733196\n",
      "\tspeed: 0.0472s/iter; left time: 367.6259s\n",
      "\titers: 300, epoch: 1 | loss: 0.0641990\n",
      "\tspeed: 0.0469s/iter; left time: 360.6052s\n",
      "Epoch: 1 cost time: 18.50152015686035\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.1058120 Vali Loss: 0.3022885 Test Loss: 0.5035188\n",
      "Validation loss decreased (inf --> 0.302288).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0251882\n",
      "\tspeed: 0.1390s/iter; left time: 1040.2284s\n",
      "\titers: 200, epoch: 2 | loss: 0.0319603\n",
      "\tspeed: 0.0415s/iter; left time: 306.3711s\n",
      "\titers: 300, epoch: 2 | loss: 0.0282405\n",
      "\tspeed: 0.0421s/iter; left time: 306.2806s\n",
      "Epoch: 2 cost time: 17.07301092147827\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0300733 Vali Loss: 0.2607008 Test Loss: 0.4832944\n",
      "Validation loss decreased (0.302288 --> 0.260701).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0145252\n",
      "\tspeed: 0.1561s/iter; left time: 1105.8602s\n",
      "\titers: 200, epoch: 3 | loss: 0.0153570\n",
      "\tspeed: 0.0467s/iter; left time: 326.3913s\n",
      "\titers: 300, epoch: 3 | loss: 0.0193962\n",
      "\tspeed: 0.0459s/iter; left time: 315.6478s\n",
      "Epoch: 3 cost time: 18.664551258087158\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0231749 Vali Loss: 0.2553830 Test Loss: 0.4676984\n",
      "Validation loss decreased (0.260701 --> 0.255383).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0144165\n",
      "\tspeed: 0.1570s/iter; left time: 1049.5178s\n",
      "\titers: 200, epoch: 4 | loss: 0.0114108\n",
      "\tspeed: 0.0458s/iter; left time: 301.7415s\n",
      "\titers: 300, epoch: 4 | loss: 0.0208459\n",
      "\tspeed: 0.0419s/iter; left time: 271.7109s\n",
      "Epoch: 4 cost time: 17.613361120224\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0211238 Vali Loss: 0.2406454 Test Loss: 0.4520710\n",
      "Validation loss decreased (0.255383 --> 0.240645).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0243052\n",
      "\tspeed: 0.1463s/iter; left time: 919.4251s\n",
      "\titers: 200, epoch: 5 | loss: 0.0170034\n",
      "\tspeed: 0.0462s/iter; left time: 285.8963s\n",
      "\titers: 300, epoch: 5 | loss: 0.0172769\n",
      "\tspeed: 0.0460s/iter; left time: 280.1253s\n",
      "Epoch: 5 cost time: 18.28261923789978\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0193479 Vali Loss: 0.2380140 Test Loss: 0.4532616\n",
      "Validation loss decreased (0.240645 --> 0.238014).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0222519\n",
      "\tspeed: 0.1545s/iter; left time: 909.5637s\n",
      "\titers: 200, epoch: 6 | loss: 0.0087242\n",
      "\tspeed: 0.0472s/iter; left time: 273.3750s\n",
      "\titers: 300, epoch: 6 | loss: 0.0129325\n",
      "\tspeed: 0.0467s/iter; left time: 265.4641s\n",
      "Epoch: 6 cost time: 18.667935609817505\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0183547 Vali Loss: 0.2394024 Test Loss: 0.4461909\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0175294\n",
      "\tspeed: 0.1482s/iter; left time: 812.9584s\n",
      "\titers: 200, epoch: 7 | loss: 0.0167699\n",
      "\tspeed: 0.0413s/iter; left time: 222.6755s\n",
      "\titers: 300, epoch: 7 | loss: 0.0212492\n",
      "\tspeed: 0.0422s/iter; left time: 223.2743s\n",
      "Epoch: 7 cost time: 16.970451831817627\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0178154 Vali Loss: 0.2363384 Test Loss: 0.4448737\n",
      "Validation loss decreased (0.238014 --> 0.236338).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0183668\n",
      "\tspeed: 0.1516s/iter; left time: 771.2227s\n",
      "\titers: 200, epoch: 8 | loss: 0.0147301\n",
      "\tspeed: 0.0486s/iter; left time: 242.5400s\n",
      "\titers: 300, epoch: 8 | loss: 0.0196219\n",
      "\tspeed: 0.0486s/iter; left time: 237.4233s\n",
      "Epoch: 8 cost time: 19.177927255630493\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0174489 Vali Loss: 0.2347191 Test Loss: 0.4428016\n",
      "Validation loss decreased (0.236338 --> 0.234719).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0163944\n",
      "\tspeed: 0.1539s/iter; left time: 721.7811s\n",
      "\titers: 200, epoch: 9 | loss: 0.0140513\n",
      "\tspeed: 0.0468s/iter; left time: 214.8403s\n",
      "\titers: 300, epoch: 9 | loss: 0.0325552\n",
      "\tspeed: 0.0454s/iter; left time: 203.6284s\n",
      "Epoch: 9 cost time: 18.52893590927124\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0172183 Vali Loss: 0.2338544 Test Loss: 0.4412359\n",
      "Validation loss decreased (0.234719 --> 0.233854).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0203106\n",
      "\tspeed: 0.1571s/iter; left time: 673.9121s\n",
      "\titers: 200, epoch: 10 | loss: 0.0236026\n",
      "\tspeed: 0.0454s/iter; left time: 190.0685s\n",
      "\titers: 300, epoch: 10 | loss: 0.0105482\n",
      "\tspeed: 0.0461s/iter; left time: 188.6389s\n",
      "Epoch: 10 cost time: 18.592997789382935\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0170964 Vali Loss: 0.2355807 Test Loss: 0.4430431\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0186701\n",
      "\tspeed: 0.1542s/iter; left time: 599.8030s\n",
      "\titers: 200, epoch: 11 | loss: 0.0243754\n",
      "\tspeed: 0.0483s/iter; left time: 182.9858s\n",
      "\titers: 300, epoch: 11 | loss: 0.0130795\n",
      "\tspeed: 0.0482s/iter; left time: 177.9195s\n",
      "Epoch: 11 cost time: 19.02476406097412\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0169937 Vali Loss: 0.2343667 Test Loss: 0.4422545\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0204569\n",
      "\tspeed: 0.1630s/iter; left time: 569.1740s\n",
      "\titers: 200, epoch: 12 | loss: 0.0181456\n",
      "\tspeed: 0.0479s/iter; left time: 162.4339s\n",
      "\titers: 300, epoch: 12 | loss: 0.0124001\n",
      "\tspeed: 0.0467s/iter; left time: 153.8925s\n",
      "Epoch: 12 cost time: 19.099521160125732\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0170833 Vali Loss: 0.2345356 Test Loss: 0.4430206\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.4412359297275543, mae:0.4615080952644348\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'data': 'SYNTH_multiplicative_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 48, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.0727793\n",
      "\tspeed: 0.0469s/iter; left time: 368.9834s\n",
      "\titers: 200, epoch: 1 | loss: 0.0804901\n",
      "\tspeed: 0.0502s/iter; left time: 389.2838s\n",
      "\titers: 300, epoch: 1 | loss: 0.0397305\n",
      "\tspeed: 0.0497s/iter; left time: 380.7392s\n",
      "Epoch: 1 cost time: 19.562257528305054\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0840129 Vali Loss: 0.3741884 Test Loss: 0.6092449\n",
      "Validation loss decreased (inf --> 0.374188).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0268116\n",
      "\tspeed: 0.1644s/iter; left time: 1226.8898s\n",
      "\titers: 200, epoch: 2 | loss: 0.0226885\n",
      "\tspeed: 0.0482s/iter; left time: 354.6137s\n",
      "\titers: 300, epoch: 2 | loss: 0.0217987\n",
      "\tspeed: 0.0478s/iter; left time: 347.1455s\n",
      "Epoch: 2 cost time: 19.09266948699951\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0280058 Vali Loss: 0.3545829 Test Loss: 0.6055917\n",
      "Validation loss decreased (0.374188 --> 0.354583).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0207924\n",
      "\tspeed: 0.1564s/iter; left time: 1105.1327s\n",
      "\titers: 200, epoch: 3 | loss: 0.0228084\n",
      "\tspeed: 0.0487s/iter; left time: 339.0771s\n",
      "\titers: 300, epoch: 3 | loss: 0.0171530\n",
      "\tspeed: 0.0487s/iter; left time: 334.2708s\n",
      "Epoch: 3 cost time: 19.112979412078857\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0223240 Vali Loss: 0.3293166 Test Loss: 0.5716394\n",
      "Validation loss decreased (0.354583 --> 0.329317).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0168272\n",
      "\tspeed: 0.1579s/iter; left time: 1052.4131s\n",
      "\titers: 200, epoch: 4 | loss: 0.0127248\n",
      "\tspeed: 0.0467s/iter; left time: 306.5060s\n",
      "\titers: 300, epoch: 4 | loss: 0.0188582\n",
      "\tspeed: 0.0459s/iter; left time: 296.9326s\n",
      "Epoch: 4 cost time: 18.502681493759155\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0200338 Vali Loss: 0.3153682 Test Loss: 0.5531100\n",
      "Validation loss decreased (0.329317 --> 0.315368).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0235524\n",
      "\tspeed: 0.1573s/iter; left time: 986.1361s\n",
      "\titers: 200, epoch: 5 | loss: 0.0305943\n",
      "\tspeed: 0.0441s/iter; left time: 271.8994s\n",
      "\titers: 300, epoch: 5 | loss: 0.0140420\n",
      "\tspeed: 0.0474s/iter; left time: 287.5354s\n",
      "Epoch: 5 cost time: 18.496396780014038\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0190800 Vali Loss: 0.3137066 Test Loss: 0.5489970\n",
      "Validation loss decreased (0.315368 --> 0.313707).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0152850\n",
      "\tspeed: 0.1555s/iter; left time: 912.9600s\n",
      "\titers: 200, epoch: 6 | loss: 0.0137889\n",
      "\tspeed: 0.0493s/iter; left time: 284.4826s\n",
      "\titers: 300, epoch: 6 | loss: 0.0252569\n",
      "\tspeed: 0.0506s/iter; left time: 286.9156s\n",
      "Epoch: 6 cost time: 19.73051953315735\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0181978 Vali Loss: 0.3130617 Test Loss: 0.5444563\n",
      "Validation loss decreased (0.313707 --> 0.313062).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0150771\n",
      "\tspeed: 0.1645s/iter; left time: 900.1693s\n",
      "\titers: 200, epoch: 7 | loss: 0.0143589\n",
      "\tspeed: 0.0489s/iter; left time: 262.7515s\n",
      "\titers: 300, epoch: 7 | loss: 0.0151071\n",
      "\tspeed: 0.0494s/iter; left time: 260.6906s\n",
      "Epoch: 7 cost time: 19.645185708999634\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0176982 Vali Loss: 0.3106766 Test Loss: 0.5436448\n",
      "Validation loss decreased (0.313062 --> 0.310677).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0177075\n",
      "\tspeed: 0.1596s/iter; left time: 810.1047s\n",
      "\titers: 200, epoch: 8 | loss: 0.0110151\n",
      "\tspeed: 0.0488s/iter; left time: 242.8400s\n",
      "\titers: 300, epoch: 8 | loss: 0.0191545\n",
      "\tspeed: 0.0494s/iter; left time: 240.8958s\n",
      "Epoch: 8 cost time: 19.349931716918945\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0173033 Vali Loss: 0.3121367 Test Loss: 0.5437858\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0317953\n",
      "\tspeed: 0.1558s/iter; left time: 728.5208s\n",
      "\titers: 200, epoch: 9 | loss: 0.0187441\n",
      "\tspeed: 0.0475s/iter; left time: 217.3173s\n",
      "\titers: 300, epoch: 9 | loss: 0.0202432\n",
      "\tspeed: 0.0458s/iter; left time: 205.1988s\n",
      "Epoch: 9 cost time: 18.432547569274902\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0171959 Vali Loss: 0.3120642 Test Loss: 0.5451418\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0159963\n",
      "\tspeed: 0.1542s/iter; left time: 660.0020s\n",
      "\titers: 200, epoch: 10 | loss: 0.0182884\n",
      "\tspeed: 0.0459s/iter; left time: 191.9212s\n",
      "\titers: 300, epoch: 10 | loss: 0.0168281\n",
      "\tspeed: 0.0452s/iter; left time: 184.2805s\n",
      "Epoch: 10 cost time: 18.153181552886963\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.0171469 Vali Loss: 0.3135233 Test Loss: 0.5458924\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.5436447858810425, mae:0.5465571880340576\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'data': 'SYNTH_multiplicative_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 168, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.1212454\n",
      "\tspeed: 0.0578s/iter; left time: 449.5371s\n",
      "\titers: 200, epoch: 1 | loss: 0.0985804\n",
      "\tspeed: 0.0607s/iter; left time: 466.1508s\n",
      "\titers: 300, epoch: 1 | loss: 0.0751453\n",
      "\tspeed: 0.0607s/iter; left time: 459.9984s\n",
      "Epoch: 1 cost time: 23.656389713287354\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.1223861 Vali Loss: 0.5552529 Test Loss: 0.8723179\n",
      "Validation loss decreased (inf --> 0.555253).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1019429\n",
      "\tspeed: 0.1873s/iter; left time: 1383.7067s\n",
      "\titers: 200, epoch: 2 | loss: 0.0793062\n",
      "\tspeed: 0.0569s/iter; left time: 414.2833s\n",
      "\titers: 300, epoch: 2 | loss: 0.0728310\n",
      "\tspeed: 0.0559s/iter; left time: 401.7011s\n",
      "Epoch: 2 cost time: 22.297691822052002\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0719473 Vali Loss: 0.5272435 Test Loss: 0.8566338\n",
      "Validation loss decreased (0.555253 --> 0.527243).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0533480\n",
      "\tspeed: 0.1745s/iter; left time: 1220.0900s\n",
      "\titers: 200, epoch: 3 | loss: 0.0829031\n",
      "\tspeed: 0.0567s/iter; left time: 391.0285s\n",
      "\titers: 300, epoch: 3 | loss: 0.0604422\n",
      "\tspeed: 0.0568s/iter; left time: 386.0197s\n",
      "Epoch: 3 cost time: 22.74174404144287\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0642768 Vali Loss: 0.5673940 Test Loss: 1.0524610\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0948143\n",
      "\tspeed: 0.1786s/iter; left time: 1178.6059s\n",
      "\titers: 200, epoch: 4 | loss: 0.0573375\n",
      "\tspeed: 0.0609s/iter; left time: 395.6400s\n",
      "\titers: 300, epoch: 4 | loss: 0.0576567\n",
      "\tspeed: 0.0610s/iter; left time: 390.4761s\n",
      "Epoch: 4 cost time: 23.88644576072693\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0604876 Vali Loss: 0.6935437 Test Loss: 1.1252840\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0466857\n",
      "\tspeed: 0.1846s/iter; left time: 1145.4746s\n",
      "\titers: 200, epoch: 5 | loss: 0.0636202\n",
      "\tspeed: 0.0570s/iter; left time: 348.2530s\n",
      "\titers: 300, epoch: 5 | loss: 0.0671474\n",
      "\tspeed: 0.0587s/iter; left time: 352.4220s\n",
      "Epoch: 5 cost time: 22.970561027526855\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0580635 Vali Loss: 0.6823589 Test Loss: 1.1269265\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.8566336631774902, mae:0.6818663477897644\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'data': 'SYNTH_multiplicative_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 336, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.1233315\n",
      "\tspeed: 0.0866s/iter; left time: 664.9418s\n",
      "\titers: 200, epoch: 1 | loss: 0.1004254\n",
      "\tspeed: 0.0853s/iter; left time: 646.4143s\n",
      "\titers: 300, epoch: 1 | loss: 0.0981352\n",
      "\tspeed: 0.0839s/iter; left time: 627.7901s\n",
      "Epoch: 1 cost time: 33.0909960269928\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1294310 Vali Loss: 0.8007831 Test Loss: 1.2902825\n",
      "Validation loss decreased (inf --> 0.800783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1063711\n",
      "\tspeed: 0.2505s/iter; left time: 1826.9187s\n",
      "\titers: 200, epoch: 2 | loss: 0.0981034\n",
      "\tspeed: 0.0900s/iter; left time: 647.5053s\n",
      "\titers: 300, epoch: 2 | loss: 0.0858048\n",
      "\tspeed: 0.0866s/iter; left time: 614.4577s\n",
      "Epoch: 2 cost time: 34.04532337188721\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0957606 Vali Loss: 0.7763919 Test Loss: 1.2720077\n",
      "Validation loss decreased (0.800783 --> 0.776392).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0876140\n",
      "\tspeed: 0.2765s/iter; left time: 1908.8020s\n",
      "\titers: 200, epoch: 3 | loss: 0.0910802\n",
      "\tspeed: 0.0838s/iter; left time: 570.3088s\n",
      "\titers: 300, epoch: 3 | loss: 0.0707150\n",
      "\tspeed: 0.0869s/iter; left time: 582.5092s\n",
      "Epoch: 3 cost time: 33.187506437301636\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0873218 Vali Loss: 0.7751520 Test Loss: 1.2583783\n",
      "Validation loss decreased (0.776392 --> 0.775152).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0703236\n",
      "\tspeed: 0.2890s/iter; left time: 1882.8156s\n",
      "\titers: 200, epoch: 4 | loss: 0.0744318\n",
      "\tspeed: 0.0868s/iter; left time: 556.8584s\n",
      "\titers: 300, epoch: 4 | loss: 0.1027741\n",
      "\tspeed: 0.0784s/iter; left time: 494.9052s\n",
      "Epoch: 4 cost time: 32.80587840080261\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0824949 Vali Loss: 0.7984123 Test Loss: 1.2874820\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0808479\n",
      "\tspeed: 0.2685s/iter; left time: 1644.2669s\n",
      "\titers: 200, epoch: 5 | loss: 0.0997431\n",
      "\tspeed: 0.0822s/iter; left time: 495.4433s\n",
      "\titers: 300, epoch: 5 | loss: 0.0720160\n",
      "\tspeed: 0.0814s/iter; left time: 482.3522s\n",
      "Epoch: 5 cost time: 31.756720781326294\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0804826 Vali Loss: 0.7937391 Test Loss: 1.2860457\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1063714\n",
      "\tspeed: 0.2717s/iter; left time: 1558.5572s\n",
      "\titers: 200, epoch: 6 | loss: 0.0995228\n",
      "\tspeed: 0.0862s/iter; left time: 485.7149s\n",
      "\titers: 300, epoch: 6 | loss: 0.0834020\n",
      "\tspeed: 0.0882s/iter; left time: 488.0267s\n",
      "Epoch: 6 cost time: 33.95673704147339\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0791155 Vali Loss: 0.7966217 Test Loss: 1.2955817\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:1.2583783864974976, mae:0.8584901094436646\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training AutoformerTS on SYNTH_multiplicative_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Autoformer', 'target': 'TARGET', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 0, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'data': 'SYNTH_multiplicative_reversal', 'features': 'S', 'seq_len': 168, 'label_len': 48, 'pred_len': 720, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'itr': 3, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 20, 'lradj': 'type1', 'model_id': 'Autoformer_Synth1_24', 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Autoformer_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.1729018\n",
      "\tspeed: 0.1311s/iter; left time: 975.1702s\n",
      "\titers: 200, epoch: 1 | loss: 0.1237248\n",
      "\tspeed: 0.1273s/iter; left time: 934.6717s\n",
      "\titers: 300, epoch: 1 | loss: 0.0959343\n",
      "\tspeed: 0.1286s/iter; left time: 931.0945s\n",
      "Epoch: 1 cost time: 49.19697976112366\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.1347467 Vali Loss: 1.4215770 Test Loss: 2.3196545\n",
      "Validation loss decreased (inf --> 1.421577).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1258034\n",
      "\tspeed: 0.3872s/iter; left time: 2735.0297s\n",
      "\titers: 200, epoch: 2 | loss: 0.0982173\n",
      "\tspeed: 0.1283s/iter; left time: 893.3810s\n",
      "\titers: 300, epoch: 2 | loss: 0.0710933\n",
      "\tspeed: 0.1258s/iter; left time: 863.2286s\n",
      "Epoch: 2 cost time: 48.310028314590454\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.1004845 Vali Loss: 1.4934440 Test Loss: 2.4174261\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0734363\n",
      "\tspeed: 0.3645s/iter; left time: 2437.5086s\n",
      "\titers: 200, epoch: 3 | loss: 0.0842078\n",
      "\tspeed: 0.1345s/iter; left time: 885.8720s\n",
      "\titers: 300, epoch: 3 | loss: 0.0892569\n",
      "\tspeed: 0.1309s/iter; left time: 848.8363s\n",
      "Epoch: 3 cost time: 49.844396114349365\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0919077 Vali Loss: 1.5422962 Test Loss: 2.5031917\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0730869\n",
      "\tspeed: 0.3885s/iter; left time: 2451.6111s\n",
      "\titers: 200, epoch: 4 | loss: 0.0852750\n",
      "\tspeed: 0.1297s/iter; left time: 805.5765s\n",
      "\titers: 300, epoch: 4 | loss: 0.0710763\n",
      "\tspeed: 0.1307s/iter; left time: 798.4185s\n",
      "Epoch: 4 cost time: 49.65636110305786\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0857172 Vali Loss: 1.5642948 Test Loss: 2.5269098\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:2.3196542263031006, mae:1.2740752696990967\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "CPU times: user 1d 1h 34min 10s, sys: 2h 31min 58s, total: 1d 4h 6min 9s\n",
      "Wall time: 5h 12min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Simple loop\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "    for iter in range(1,model.args.itr):\n",
    "        for dataset_name, dataset_params in datasets.items():\n",
    "            for pred_len in pred_lens:\n",
    "                print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "                    # High amount of epochs to accomodate all models\n",
    "                    # Early stopping should kick in anyways\n",
    "                model.fit(\n",
    "                    iter = iter + 1,\n",
    "                    data=dataset_name,\n",
    "                    data_root_path=dataset_params[0],\n",
    "                    batch_size=32,\n",
    "                    epochs=20, # very high\n",
    "                    pred_len=pred_len,\n",
    "                    features = dataset_params[1],\n",
    "                    target = dataset_params[2],\n",
    "                    seq_len = dataset_params[3],\n",
    "                    enc_in = dataset_params[4],\n",
    "                    dec_in = dataset_params[5],\n",
    "                    c_out = dataset_params[6]\n",
    "                )\n",
    "\n",
    "                predictions = model.predict()\n",
    "\n",
    "                print(f'\\nMoving to next...\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets = {\n",
    "    'ETTh1': ['./ETTDataset/' , 'M' , 'OT' , 96 , 7 , 7 , 7] ,\n",
    "    'DEWINDh_small': ['./WINDataset/' , 'S' , 'TARGET' , 96, 1 , 1 , 1] ,\n",
    "    'SYNTHh1': ['./SYNTHDataset/', 'S' , 'TARGET' , 96, 1 , 1 , 1] ,\n",
    "    'SYNTH_additive' : ['./SYNTHDataset/', 'S' , 'TARGET' , 96, 1 , 1 , 1] ,\n",
    "    'SYNTH_additive_reversal' : ['./SYNTHDataset/', 'S' , 'TARGET' , 96, 1 , 1 , 1] ,\n",
    "    'SYNTH_multiplicative' : ['./SYNTHDataset/', 'S' , 'TARGET' , 96, 1 , 1 , 1] ,\n",
    "    'SYNTH_multiplicative_reversal' : ['./SYNTHDataset/', 'S' , 'TARGET' , 96, 1 , 1 , 1]\n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "\n",
    "models = [FedformerTS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: FedformerTS\n",
      "Training FedformerTS on ETTh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'checkpoints': './checkpoints/', 'features': 'M', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "Epoch: 1 cost time: 38.87531757354736\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.3546676 Vali Loss: 0.5704523 Test Loss: 0.3471192\n",
      "Validation loss decreased (inf --> 0.570452).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 39.86790132522583\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.3082622 Vali Loss: 0.5421322 Test Loss: 0.3220158\n",
      "Validation loss decreased (0.570452 --> 0.542132).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 40.87931823730469\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.2923464 Vali Loss: 0.5456946 Test Loss: 0.3209929\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 39.33022713661194\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.2855563 Vali Loss: 0.5436274 Test Loss: 0.3197227\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 38.678308725357056\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.2815106 Vali Loss: 0.5377334 Test Loss: 0.3150476\n",
      "Validation loss decreased (0.542132 --> 0.537733).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 40.9122428894043\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.2794642 Vali Loss: 0.5419190 Test Loss: 0.3169852\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 38.60162115097046\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.2785844 Vali Loss: 0.5387025 Test Loss: 0.3147192\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 39.17294526100159\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.2779846 Vali Loss: 0.5372060 Test Loss: 0.3144137\n",
      "Validation loss decreased (0.537733 --> 0.537206).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 41.063103675842285\n",
      "Epoch: 9, Steps: 266 | Train Loss: 0.2773371 Vali Loss: 0.5391022 Test Loss: 0.3150410\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 40.18669843673706\n",
      "Epoch: 10, Steps: 266 | Train Loss: 0.2774007 Vali Loss: 0.5369796 Test Loss: 0.3144516\n",
      "Validation loss decreased (0.537206 --> 0.536980).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 39.56333518028259\n",
      "Epoch: 11, Steps: 266 | Train Loss: 0.2773554 Vali Loss: 0.5381390 Test Loss: 0.3143746\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 39.34297180175781\n",
      "Epoch: 12, Steps: 266 | Train Loss: 0.2771083 Vali Loss: 0.5376571 Test Loss: 0.3143114\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 40.61108088493347\n",
      "Epoch: 13, Steps: 266 | Train Loss: 0.2771913 Vali Loss: 0.5372985 Test Loss: 0.3143480\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "mse:0.3144516944885254, mae:0.3802911043167114\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on ETTh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'checkpoints': './checkpoints/', 'features': 'M', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_ETTh1_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "Epoch: 1 cost time: 45.0875563621521\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.3848579 Vali Loss: 0.6495603 Test Loss: 0.3494930\n",
      "Validation loss decreased (inf --> 0.649560).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 44.50517749786377\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.3353950 Vali Loss: 0.6375594 Test Loss: 0.3451103\n",
      "Validation loss decreased (0.649560 --> 0.637559).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 46.145474672317505\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.3219157 Vali Loss: 0.6322899 Test Loss: 0.3390561\n",
      "Validation loss decreased (0.637559 --> 0.632290).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 44.179327726364136\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.3157025 Vali Loss: 0.6275306 Test Loss: 0.3393722\n",
      "Validation loss decreased (0.632290 --> 0.627531).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 47.79756498336792\n",
      "Epoch: 5, Steps: 265 | Train Loss: 0.3125152 Vali Loss: 0.6280199 Test Loss: 0.3388376\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 47.027113914489746\n",
      "Epoch: 6, Steps: 265 | Train Loss: 0.3108918 Vali Loss: 0.6275216 Test Loss: 0.3365225\n",
      "Validation loss decreased (0.627531 --> 0.627522).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 46.23801898956299\n",
      "Epoch: 7, Steps: 265 | Train Loss: 0.3100848 Vali Loss: 0.6243787 Test Loss: 0.3358493\n",
      "Validation loss decreased (0.627522 --> 0.624379).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 46.33748173713684\n",
      "Epoch: 8, Steps: 265 | Train Loss: 0.3096640 Vali Loss: 0.6268923 Test Loss: 0.3354422\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 46.09128737449646\n",
      "Epoch: 9, Steps: 265 | Train Loss: 0.3094656 Vali Loss: 0.6267653 Test Loss: 0.3361059\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 43.978862285614014\n",
      "Epoch: 10, Steps: 265 | Train Loss: 0.3093214 Vali Loss: 0.6269985 Test Loss: 0.3358702\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 7) (88, 32, 48, 7)\n",
      "test shape: (2816, 48, 7) (2816, 48, 7)\n",
      "mse:0.33584922552108765, mae:0.39113274216651917\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on ETTh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'checkpoints': './checkpoints/', 'features': 'M', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 5, 6, 8, 10, 11, 12, 13, 14, 16, 17, 19, 21, 23, 24, 25, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 45, 48, 49, 52, 55, 56, 58, 60, 62, 63, 64, 65, 66, 68, 69, 74, 80, 83, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 105, 106, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[2, 4, 6, 7, 8, 9, 10, 11, 14, 16, 17, 23, 25, 26, 27, 29, 31, 32, 33, 36, 37, 40, 41, 43, 46, 48, 50, 51, 52, 54, 55, 58, 59, 62, 63, 64, 65, 68, 70, 73, 74, 75, 76, 77, 79, 82, 84, 85, 86, 88, 89, 90, 92, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_ETTh1_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "Epoch: 1 cost time: 67.19021582603455\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.4668398 Vali Loss: 1.0091040 Test Loss: 0.4240157\n",
      "Validation loss decreased (inf --> 1.009104).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 66.23469805717468\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.4192423 Vali Loss: 1.0061097 Test Loss: 0.4157835\n",
      "Validation loss decreased (1.009104 --> 1.006110).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 66.0031316280365\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.4069239 Vali Loss: 0.9913337 Test Loss: 0.4075572\n",
      "Validation loss decreased (1.006110 --> 0.991334).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 65.28243279457092\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.4008107 Vali Loss: 0.9887508 Test Loss: 0.4088992\n",
      "Validation loss decreased (0.991334 --> 0.988751).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 66.53749799728394\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.3980299 Vali Loss: 0.9903563 Test Loss: 0.4093503\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 64.92759537696838\n",
      "Epoch: 6, Steps: 261 | Train Loss: 0.3966281 Vali Loss: 0.9881018 Test Loss: 0.4071042\n",
      "Validation loss decreased (0.988751 --> 0.988102).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 68.18708539009094\n",
      "Epoch: 7, Steps: 261 | Train Loss: 0.3959158 Vali Loss: 0.9893166 Test Loss: 0.4096519\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 66.39869809150696\n",
      "Epoch: 8, Steps: 261 | Train Loss: 0.3959486 Vali Loss: 0.9869510 Test Loss: 0.4080735\n",
      "Validation loss decreased (0.988102 --> 0.986951).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 63.986735582351685\n",
      "Epoch: 9, Steps: 261 | Train Loss: 0.3955842 Vali Loss: 0.9872282 Test Loss: 0.4089850\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 66.97317504882812\n",
      "Epoch: 10, Steps: 261 | Train Loss: 0.3955481 Vali Loss: 0.9872884 Test Loss: 0.4087791\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 67.68754315376282\n",
      "Epoch: 11, Steps: 261 | Train Loss: 0.3954550 Vali Loss: 0.9883178 Test Loss: 0.4089414\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 7) (84, 32, 168, 7)\n",
      "test shape: (2688, 168, 7) (2688, 168, 7)\n",
      "mse:0.4080735146999359, mae:0.4339016377925873\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on ETTh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'checkpoints': './checkpoints/', 'features': 'M', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 4, 7, 10, 11, 20, 21, 22, 25, 27, 30, 32, 36, 38, 41, 43, 44, 45, 48, 53, 55, 58, 62, 65, 69, 71, 77, 78, 79, 80, 82, 83, 89, 91, 92, 94, 99, 104, 110, 118, 125, 127, 128, 130, 131, 144, 146, 150, 151, 154, 162, 164, 165, 169, 172, 175, 177, 182, 183, 184, 186, 187, 191]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[2, 4, 10, 14, 18, 23, 27, 29, 30, 34, 36, 37, 38, 39, 40, 41, 45, 48, 49, 50, 51, 54, 57, 58, 64, 66, 68, 70, 71, 82, 88, 93, 94, 102, 105, 107, 111, 112, 113, 118, 120, 124, 125, 128, 129, 132, 136, 138, 142, 143, 144, 151, 153, 154, 157, 161, 165, 169, 173, 175, 176, 177, 185, 186]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_ETTh1_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 79.19471073150635\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.5233870 Vali Loss: 1.3236581 Test Loss: 0.4621147\n",
      "Validation loss decreased (inf --> 1.323658).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 79.1165201663971\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.4819805 Vali Loss: 1.3217778 Test Loss: 0.4546271\n",
      "Validation loss decreased (1.323658 --> 1.321778).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 76.24671387672424\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.4710798 Vali Loss: 1.3017173 Test Loss: 0.4506920\n",
      "Validation loss decreased (1.321778 --> 1.301717).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 73.44457793235779\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.4650939 Vali Loss: 1.3026003 Test Loss: 0.4485756\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 81.04035019874573\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.4628401 Vali Loss: 1.3069835 Test Loss: 0.4461470\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 80.31781911849976\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.4617598 Vali Loss: 1.3052976 Test Loss: 0.4454111\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 7) (79, 32, 336, 7)\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "mse:0.4506917893886566, mae:0.4620455801486969\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on ETTh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'checkpoints': './checkpoints/', 'features': 'M', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 5, 8, 10, 12, 17, 24, 29, 30, 35, 54, 62, 66, 77, 94, 102, 103, 110, 117, 127, 130, 152, 154, 159, 173, 180, 187, 189, 192, 193, 201, 205, 215, 224, 226, 228, 241, 248, 252, 262, 271, 277, 281, 285, 294, 303, 312, 317, 325, 326, 331, 333, 340, 342, 347, 349, 352, 353, 356, 364, 367, 373, 379, 383]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[10, 19, 24, 36, 39, 49, 58, 62, 66, 72, 75, 76, 83, 98, 99, 104, 113, 115, 119, 122, 124, 133, 145, 146, 147, 148, 150, 152, 155, 168, 169, 183, 194, 195, 196, 212, 218, 220, 225, 226, 227, 239, 241, 247, 253, 260, 264, 270, 275, 278, 283, 295, 305, 309, 320, 331, 332, 338, 344, 352, 361, 369, 375, 378]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_ETTh1_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 98.57748818397522\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.6314598 Vali Loss: 1.5778683 Test Loss: 0.4782569\n",
      "Validation loss decreased (inf --> 1.577868).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 98.66949677467346\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.5851454 Vali Loss: 1.5668286 Test Loss: 0.4883707\n",
      "Validation loss decreased (1.577868 --> 1.566829).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 103.01046133041382\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.5726929 Vali Loss: 1.5623363 Test Loss: 0.4931071\n",
      "Validation loss decreased (1.566829 --> 1.562336).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 101.43505668640137\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.5662678 Vali Loss: 1.5765572 Test Loss: 0.4935587\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 101.19586682319641\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.5638529 Vali Loss: 1.5746857 Test Loss: 0.4981390\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 100.79992198944092\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.5623748 Vali Loss: 1.5743043 Test Loss: 0.4984783\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 7) (67, 32, 720, 7)\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "mse:0.4931066930294037, mae:0.5020555257797241\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 60.18210768699646\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.2057153 Vali Loss: 0.1609508 Test Loss: 0.1263719\n",
      "Validation loss decreased (inf --> 0.160951).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 59.64935326576233\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.1410012 Vali Loss: 0.1305510 Test Loss: 0.1126148\n",
      "Validation loss decreased (0.160951 --> 0.130551).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 59.71894860267639\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.1299569 Vali Loss: 0.1269556 Test Loss: 0.1101326\n",
      "Validation loss decreased (0.130551 --> 0.126956).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 58.64652347564697\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.1253058 Vali Loss: 0.1226439 Test Loss: 0.1084264\n",
      "Validation loss decreased (0.126956 --> 0.122644).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 59.59471774101257\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.1228073 Vali Loss: 0.1198580 Test Loss: 0.1067619\n",
      "Validation loss decreased (0.122644 --> 0.119858).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 57.24584674835205\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.1217889 Vali Loss: 0.1184148 Test Loss: 0.1058149\n",
      "Validation loss decreased (0.119858 --> 0.118415).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 58.37265586853027\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.1210087 Vali Loss: 0.1183378 Test Loss: 0.1054104\n",
      "Validation loss decreased (0.118415 --> 0.118338).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 63.45735454559326\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.1206422 Vali Loss: 0.1187106 Test Loss: 0.1052842\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 60.64141511917114\n",
      "Epoch: 9, Steps: 401 | Train Loss: 0.1206261 Vali Loss: 0.1180682 Test Loss: 0.1050354\n",
      "Validation loss decreased (0.118338 --> 0.118068).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 60.000662326812744\n",
      "Epoch: 10, Steps: 401 | Train Loss: 0.1206272 Vali Loss: 0.1181797 Test Loss: 0.1051389\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 61.27904224395752\n",
      "Epoch: 11, Steps: 401 | Train Loss: 0.1205055 Vali Loss: 0.1183097 Test Loss: 0.1050059\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 60.424495458602905\n",
      "Epoch: 12, Steps: 401 | Train Loss: 0.1203320 Vali Loss: 0.1181332 Test Loss: 0.1050188\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.10503536462783813, mae:0.19266660511493683\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 71.63831543922424\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.2181850 Vali Loss: 0.1792701 Test Loss: 0.1616071\n",
      "Validation loss decreased (inf --> 0.179270).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 70.35047507286072\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.1571223 Vali Loss: 0.1596837 Test Loss: 0.1369100\n",
      "Validation loss decreased (0.179270 --> 0.159684).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 69.04194164276123\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.1469938 Vali Loss: 0.1557192 Test Loss: 0.1289356\n",
      "Validation loss decreased (0.159684 --> 0.155719).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 70.29545783996582\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.1432165 Vali Loss: 0.1596442 Test Loss: 0.1257710\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 67.48125171661377\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.1415271 Vali Loss: 0.1526772 Test Loss: 0.1244508\n",
      "Validation loss decreased (0.155719 --> 0.152677).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 71.25172543525696\n",
      "Epoch: 6, Steps: 400 | Train Loss: 0.1403044 Vali Loss: 0.1524612 Test Loss: 0.1231592\n",
      "Validation loss decreased (0.152677 --> 0.152461).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 70.28855228424072\n",
      "Epoch: 7, Steps: 400 | Train Loss: 0.1397896 Vali Loss: 0.1516918 Test Loss: 0.1237642\n",
      "Validation loss decreased (0.152461 --> 0.151692).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 68.04004144668579\n",
      "Epoch: 8, Steps: 400 | Train Loss: 0.1395849 Vali Loss: 0.1519892 Test Loss: 0.1231307\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 69.98377084732056\n",
      "Epoch: 9, Steps: 400 | Train Loss: 0.1394709 Vali Loss: 0.1514992 Test Loss: 0.1234816\n",
      "Validation loss decreased (0.151692 --> 0.151499).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 69.9442708492279\n",
      "Epoch: 10, Steps: 400 | Train Loss: 0.1393560 Vali Loss: 0.1514056 Test Loss: 0.1235021\n",
      "Validation loss decreased (0.151499 --> 0.151406).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 69.08520293235779\n",
      "Epoch: 11, Steps: 400 | Train Loss: 0.1393211 Vali Loss: 0.1513627 Test Loss: 0.1233620\n",
      "Validation loss decreased (0.151406 --> 0.151363).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 69.33553147315979\n",
      "Epoch: 12, Steps: 400 | Train Loss: 0.1394700 Vali Loss: 0.1513165 Test Loss: 0.1233746\n",
      "Validation loss decreased (0.151363 --> 0.151317).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 68.6834876537323\n",
      "Epoch: 13, Steps: 400 | Train Loss: 0.1394106 Vali Loss: 0.1513915 Test Loss: 0.1233395\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 68.28977870941162\n",
      "Epoch: 14, Steps: 400 | Train Loss: 0.1392390 Vali Loss: 0.1512607 Test Loss: 0.1233288\n",
      "Validation loss decreased (0.151317 --> 0.151261).  Saving model ...\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 66.67130088806152\n",
      "Epoch: 15, Steps: 400 | Train Loss: 0.1392795 Vali Loss: 0.1513968 Test Loss: 0.1233224\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 70.62838673591614\n",
      "Epoch: 16, Steps: 400 | Train Loss: 0.1392985 Vali Loss: 0.1514143 Test Loss: 0.1233204\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.0517578125e-09\n",
      "Epoch: 17 cost time: 73.68536567687988\n",
      "Epoch: 17, Steps: 400 | Train Loss: 0.1392665 Vali Loss: 0.1512313 Test Loss: 0.1233187\n",
      "Validation loss decreased (0.151261 --> 0.151231).  Saving model ...\n",
      "Updating learning rate to 1.52587890625e-09\n",
      "Epoch: 18 cost time: 71.42034721374512\n",
      "Epoch: 18, Steps: 400 | Train Loss: 0.1392623 Vali Loss: 0.1513636 Test Loss: 0.1233191\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.62939453125e-10\n",
      "Epoch: 19 cost time: 68.71473407745361\n",
      "Epoch: 19, Steps: 400 | Train Loss: 0.1392842 Vali Loss: 0.1514162 Test Loss: 0.1233188\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.814697265625e-10\n",
      "Epoch: 20 cost time: 64.50067162513733\n",
      "Epoch: 20, Steps: 400 | Train Loss: 0.1392456 Vali Loss: 0.1514073 Test Loss: 0.1233188\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.12331867963075638, mae:0.20470045506954193\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 4, 5, 6, 8, 9, 11, 13, 16, 17, 18, 21, 23, 25, 27, 28, 29, 35, 36, 37, 39, 42, 43, 45, 47, 48, 49, 52, 55, 56, 58, 59, 60, 62, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 81, 83, 85, 86, 87, 88, 90, 94, 95, 97, 99, 100, 102, 103, 106, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[3, 4, 7, 8, 10, 12, 13, 17, 19, 20, 22, 23, 28, 29, 30, 31, 34, 35, 38, 41, 42, 44, 46, 48, 49, 53, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 79, 82, 83, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 97, 98, 99, 101, 106, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 92.38951182365417\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.2422375 Vali Loss: 0.2206435 Test Loss: 0.1962069\n",
      "Validation loss decreased (inf --> 0.220643).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 92.60062503814697\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.1790936 Vali Loss: 0.2180638 Test Loss: 0.1603428\n",
      "Validation loss decreased (0.220643 --> 0.218064).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 93.43432545661926\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.1689637 Vali Loss: 0.1939451 Test Loss: 0.1650088\n",
      "Validation loss decreased (0.218064 --> 0.193945).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 90.09431910514832\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.1649308 Vali Loss: 0.1917303 Test Loss: 0.1602382\n",
      "Validation loss decreased (0.193945 --> 0.191730).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 94.92135310173035\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.1631912 Vali Loss: 0.1909433 Test Loss: 0.1603530\n",
      "Validation loss decreased (0.191730 --> 0.190943).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 92.38623929023743\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.1623553 Vali Loss: 0.1895536 Test Loss: 0.1581237\n",
      "Validation loss decreased (0.190943 --> 0.189554).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 93.69812941551208\n",
      "Epoch: 7, Steps: 396 | Train Loss: 0.1617959 Vali Loss: 0.1901944 Test Loss: 0.1595593\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 92.57913446426392\n",
      "Epoch: 8, Steps: 396 | Train Loss: 0.1614692 Vali Loss: 0.1900961 Test Loss: 0.1602385\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 96.39537572860718\n",
      "Epoch: 9, Steps: 396 | Train Loss: 0.1613547 Vali Loss: 0.1902082 Test Loss: 0.1602750\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.15812373161315918, mae:0.23397067189216614\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 6, 9, 10, 12, 14, 20, 24, 25, 27, 33, 35, 36, 39, 45, 46, 49, 52, 54, 56, 61, 62, 68, 72, 75, 76, 78, 80, 86, 87, 88, 89, 91, 92, 94, 99, 100, 102, 104, 125, 129, 130, 131, 135, 139, 146, 148, 153, 157, 158, 160, 166, 168, 169, 171, 172, 174, 179, 183, 190, 191]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[5, 7, 13, 18, 20, 22, 23, 27, 30, 34, 36, 37, 39, 40, 46, 48, 51, 53, 55, 60, 61, 64, 66, 67, 69, 76, 78, 81, 82, 85, 90, 101, 104, 105, 107, 111, 112, 115, 116, 117, 118, 120, 123, 124, 125, 128, 139, 141, 143, 144, 147, 148, 151, 152, 154, 158, 159, 162, 165, 167, 173, 174, 182, 185]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 113.10158205032349\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.2386886 Vali Loss: 0.2474388 Test Loss: 0.2434087\n",
      "Validation loss decreased (inf --> 0.247439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 113.53865504264832\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.1844638 Vali Loss: 0.2191827 Test Loss: 0.1794720\n",
      "Validation loss decreased (0.247439 --> 0.219183).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 113.95733737945557\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.1750455 Vali Loss: 0.2136951 Test Loss: 0.1890377\n",
      "Validation loss decreased (0.219183 --> 0.213695).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 114.20542097091675\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.1721338 Vali Loss: 0.2082815 Test Loss: 0.1806149\n",
      "Validation loss decreased (0.213695 --> 0.208281).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 113.52020931243896\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.1703350 Vali Loss: 0.2093336 Test Loss: 0.1886848\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 113.62194323539734\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.1692973 Vali Loss: 0.2068151 Test Loss: 0.1841666\n",
      "Validation loss decreased (0.208281 --> 0.206815).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 115.15467047691345\n",
      "Epoch: 7, Steps: 391 | Train Loss: 0.1688572 Vali Loss: 0.2089463 Test Loss: 0.1878860\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 112.75279927253723\n",
      "Epoch: 8, Steps: 391 | Train Loss: 0.1685771 Vali Loss: 0.2078161 Test Loss: 0.1866412\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 115.44252681732178\n",
      "Epoch: 9, Steps: 391 | Train Loss: 0.1683991 Vali Loss: 0.2066533 Test Loss: 0.1837800\n",
      "Validation loss decreased (0.206815 --> 0.206653).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 114.95610046386719\n",
      "Epoch: 10, Steps: 391 | Train Loss: 0.1682898 Vali Loss: 0.2074294 Test Loss: 0.1858107\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 115.83724331855774\n",
      "Epoch: 11, Steps: 391 | Train Loss: 0.1683050 Vali Loss: 0.2074389 Test Loss: 0.1857771\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 113.2006824016571\n",
      "Epoch: 12, Steps: 391 | Train Loss: 0.1682412 Vali Loss: 0.2073286 Test Loss: 0.1857898\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.18378008902072906, mae:0.25751471519470215\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 3, 8, 12, 13, 22, 23, 34, 47, 48, 49, 54, 55, 60, 81, 82, 87, 88, 89, 91, 96, 100, 112, 117, 123, 128, 129, 137, 138, 159, 163, 178, 182, 200, 211, 217, 218, 220, 229, 236, 237, 238, 239, 247, 254, 256, 257, 260, 276, 286, 288, 300, 302, 316, 321, 328, 342, 348, 352, 360, 367, 371, 375]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[2, 12, 15, 25, 33, 37, 38, 39, 51, 54, 59, 62, 64, 70, 75, 101, 108, 114, 120, 124, 132, 142, 147, 148, 156, 174, 175, 176, 184, 189, 193, 196, 204, 205, 214, 219, 234, 241, 246, 251, 252, 253, 257, 258, 259, 260, 266, 294, 296, 300, 302, 305, 308, 313, 317, 318, 331, 334, 342, 358, 359, 372, 373, 380]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 152.30423593521118\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.2654704 Vali Loss: 0.2613783 Test Loss: 0.3349632\n",
      "Validation loss decreased (inf --> 0.261378).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 151.53039693832397\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.2049139 Vali Loss: 0.2353620 Test Loss: 0.2880968\n",
      "Validation loss decreased (0.261378 --> 0.235362).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 149.66381359100342\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.1923360 Vali Loss: 0.2194582 Test Loss: 0.2358497\n",
      "Validation loss decreased (0.235362 --> 0.219458).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 152.65774273872375\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.1890877 Vali Loss: 0.2186037 Test Loss: 0.2329927\n",
      "Validation loss decreased (0.219458 --> 0.218604).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 151.32447361946106\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.1874777 Vali Loss: 0.2186759 Test Loss: 0.2422246\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 150.55812191963196\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.1866640 Vali Loss: 0.2176472 Test Loss: 0.2327879\n",
      "Validation loss decreased (0.218604 --> 0.217647).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 151.29495787620544\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.1861895 Vali Loss: 0.2176559 Test Loss: 0.2350636\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 151.19810390472412\n",
      "Epoch: 8, Steps: 379 | Train Loss: 0.1859797 Vali Loss: 0.2179829 Test Loss: 0.2374401\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 151.9761483669281\n",
      "Epoch: 9, Steps: 379 | Train Loss: 0.1857717 Vali Loss: 0.2176917 Test Loss: 0.2363697\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.23278798162937164, mae:0.31447556614875793\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 58.98245310783386\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.2014733 Vali Loss: 0.0834621 Test Loss: 0.0987196\n",
      "Validation loss decreased (inf --> 0.083462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 57.72672986984253\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.0892496 Vali Loss: 0.0581577 Test Loss: 0.0704660\n",
      "Validation loss decreased (0.083462 --> 0.058158).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 60.471617221832275\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.0690844 Vali Loss: 0.0447688 Test Loss: 0.0531307\n",
      "Validation loss decreased (0.058158 --> 0.044769).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 58.97959113121033\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.0538780 Vali Loss: 0.0406564 Test Loss: 0.0452756\n",
      "Validation loss decreased (0.044769 --> 0.040656).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 58.648396730422974\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.0458930 Vali Loss: 0.0378389 Test Loss: 0.0407955\n",
      "Validation loss decreased (0.040656 --> 0.037839).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 59.47415208816528\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.0425094 Vali Loss: 0.0338917 Test Loss: 0.0376770\n",
      "Validation loss decreased (0.037839 --> 0.033892).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 59.48070025444031\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.0410163 Vali Loss: 0.0332238 Test Loss: 0.0363850\n",
      "Validation loss decreased (0.033892 --> 0.033224).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 59.84150743484497\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.0403196 Vali Loss: 0.0334294 Test Loss: 0.0366431\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 59.35283279418945\n",
      "Epoch: 9, Steps: 401 | Train Loss: 0.0398414 Vali Loss: 0.0328490 Test Loss: 0.0361264\n",
      "Validation loss decreased (0.033224 --> 0.032849).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 58.477070331573486\n",
      "Epoch: 10, Steps: 401 | Train Loss: 0.0398933 Vali Loss: 0.0327718 Test Loss: 0.0361237\n",
      "Validation loss decreased (0.032849 --> 0.032772).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 59.84573984146118\n",
      "Epoch: 11, Steps: 401 | Train Loss: 0.0398510 Vali Loss: 0.0326979 Test Loss: 0.0361238\n",
      "Validation loss decreased (0.032772 --> 0.032698).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 57.71270155906677\n",
      "Epoch: 12, Steps: 401 | Train Loss: 0.0394285 Vali Loss: 0.0326422 Test Loss: 0.0361011\n",
      "Validation loss decreased (0.032698 --> 0.032642).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 60.22635865211487\n",
      "Epoch: 13, Steps: 401 | Train Loss: 0.0397967 Vali Loss: 0.0328642 Test Loss: 0.0360839\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 60.56472682952881\n",
      "Epoch: 14, Steps: 401 | Train Loss: 0.0396152 Vali Loss: 0.0327668 Test Loss: 0.0360645\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 59.35080814361572\n",
      "Epoch: 15, Steps: 401 | Train Loss: 0.0396576 Vali Loss: 0.0328839 Test Loss: 0.0360623\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.03610114008188248, mae:0.15188154578208923\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 67.83306574821472\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.2302986 Vali Loss: 0.0967287 Test Loss: 0.1177445\n",
      "Validation loss decreased (inf --> 0.096729).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 68.14561104774475\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.1051461 Vali Loss: 0.0783400 Test Loss: 0.1005214\n",
      "Validation loss decreased (0.096729 --> 0.078340).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 69.68476033210754\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.0595580 Vali Loss: 0.0938686 Test Loss: 0.1460239\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 68.88254618644714\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.0473459 Vali Loss: 0.0916846 Test Loss: 0.1409653\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 68.89871335029602\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.0451963 Vali Loss: 0.0884767 Test Loss: 0.1363880\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.10052144527435303, mae:0.263336181640625\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 4, 7, 10, 11, 15, 19, 21, 26, 27, 29, 30, 31, 32, 33, 34, 38, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 54, 57, 58, 60, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 86, 87, 88, 92, 94, 95, 97, 98, 100, 102, 103, 105]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[3, 5, 6, 7, 8, 10, 11, 12, 14, 16, 17, 18, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 49, 51, 52, 55, 57, 58, 59, 62, 63, 65, 66, 67, 69, 70, 71, 74, 75, 79, 80, 81, 83, 86, 88, 90, 95, 96, 97, 102, 104, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 94.53016567230225\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.3194715 Vali Loss: 0.2891754 Test Loss: 0.4055609\n",
      "Validation loss decreased (inf --> 0.289175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 93.35473036766052\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.1761318 Vali Loss: 0.2457186 Test Loss: 0.4194306\n",
      "Validation loss decreased (0.289175 --> 0.245719).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 94.82075548171997\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.1107007 Vali Loss: 0.2616015 Test Loss: 0.4395580\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 92.52742004394531\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.1054962 Vali Loss: 0.2689426 Test Loss: 0.4465958\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 94.94643425941467\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.1034454 Vali Loss: 0.2668097 Test Loss: 0.4434127\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.4194306433200836, mae:0.5518016815185547\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 5, 6, 7, 9, 16, 17, 23, 25, 26, 33, 37, 40, 45, 46, 51, 55, 56, 57, 58, 59, 63, 68, 69, 70, 71, 72, 73, 78, 80, 81, 86, 88, 89, 91, 97, 98, 99, 102, 105, 106, 109, 115, 116, 121, 122, 127, 128, 129, 137, 139, 140, 147, 150, 157, 169, 170, 171, 172, 173, 179, 182, 183, 185]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 6, 7, 10, 13, 16, 17, 22, 23, 25, 30, 34, 36, 37, 39, 41, 43, 46, 48, 50, 51, 53, 57, 60, 67, 68, 70, 72, 74, 76, 78, 89, 99, 100, 104, 105, 109, 110, 113, 116, 117, 122, 124, 137, 143, 144, 148, 150, 153, 155, 157, 163, 167, 170, 171, 173, 178, 182, 183, 184, 186, 188, 190, 191]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 116.02088069915771\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.5781016 Vali Loss: 0.5576701 Test Loss: 0.8363286\n",
      "Validation loss decreased (inf --> 0.557670).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 112.28401160240173\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.3082736 Vali Loss: 0.6280749 Test Loss: 0.8866830\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 115.88228631019592\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.2841276 Vali Loss: 0.6280255 Test Loss: 0.9064316\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 117.95266461372375\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.2770705 Vali Loss: 0.5599458 Test Loss: 0.8215513\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.8363285064697266, mae:0.7482426762580872\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[11, 14, 17, 34, 36, 39, 43, 51, 55, 72, 75, 84, 85, 89, 90, 95, 97, 109, 112, 113, 126, 132, 136, 138, 147, 148, 149, 151, 153, 170, 174, 180, 181, 185, 198, 199, 202, 207, 211, 222, 240, 244, 251, 256, 267, 281, 282, 290, 291, 299, 305, 309, 313, 318, 321, 327, 328, 338, 351, 363, 367, 369, 379, 380]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[8, 9, 19, 29, 36, 50, 55, 61, 70, 73, 78, 94, 97, 117, 120, 124, 135, 141, 146, 156, 159, 161, 178, 179, 184, 189, 214, 215, 222, 227, 230, 231, 244, 254, 255, 256, 259, 260, 266, 267, 274, 275, 279, 280, 283, 298, 301, 302, 303, 305, 307, 308, 309, 311, 323, 324, 329, 331, 339, 345, 347, 350, 380, 382]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 147.4128770828247\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.7908243 Vali Loss: 0.7918193 Test Loss: 0.8983113\n",
      "Validation loss decreased (inf --> 0.791819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 147.0712206363678\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.5747401 Vali Loss: 0.7451208 Test Loss: 0.8670657\n",
      "Validation loss decreased (0.791819 --> 0.745121).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 158.6460452079773\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.5452885 Vali Loss: 0.7301303 Test Loss: 0.8462722\n",
      "Validation loss decreased (0.745121 --> 0.730130).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 155.51173758506775\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.5311926 Vali Loss: 0.7221412 Test Loss: 0.8410932\n",
      "Validation loss decreased (0.730130 --> 0.722141).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 146.20303559303284\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.5238516 Vali Loss: 0.7182199 Test Loss: 0.8360907\n",
      "Validation loss decreased (0.722141 --> 0.718220).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 151.98948740959167\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.5207088 Vali Loss: 0.7150733 Test Loss: 0.8345420\n",
      "Validation loss decreased (0.718220 --> 0.715073).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 149.92659950256348\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.5193383 Vali Loss: 0.7133070 Test Loss: 0.8328858\n",
      "Validation loss decreased (0.715073 --> 0.713307).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 153.17452812194824\n",
      "Epoch: 8, Steps: 379 | Train Loss: 0.5176539 Vali Loss: 0.7127601 Test Loss: 0.8317580\n",
      "Validation loss decreased (0.713307 --> 0.712760).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 150.98148584365845\n",
      "Epoch: 9, Steps: 379 | Train Loss: 0.5175139 Vali Loss: 0.7126378 Test Loss: 0.8317470\n",
      "Validation loss decreased (0.712760 --> 0.712638).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 153.57650423049927\n",
      "Epoch: 10, Steps: 379 | Train Loss: 0.5168960 Vali Loss: 0.7120919 Test Loss: 0.8315364\n",
      "Validation loss decreased (0.712638 --> 0.712092).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 150.9727807044983\n",
      "Epoch: 11, Steps: 379 | Train Loss: 0.5169670 Vali Loss: 0.7124178 Test Loss: 0.8314735\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 150.7301344871521\n",
      "Epoch: 12, Steps: 379 | Train Loss: 0.5167725 Vali Loss: 0.7123100 Test Loss: 0.8314685\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 153.53088116645813\n",
      "Epoch: 13, Steps: 379 | Train Loss: 0.5169338 Vali Loss: 0.7125003 Test Loss: 0.8314292\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.8315364122390747, mae:0.7378129959106445\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 60.01345157623291\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.0209384 Vali Loss: 0.0048774 Test Loss: 0.0054698\n",
      "Validation loss decreased (inf --> 0.004877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 60.60295581817627\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.0052063 Vali Loss: 0.0042701 Test Loss: 0.0056616\n",
      "Validation loss decreased (0.004877 --> 0.004270).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 60.54190635681152\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.0028248 Vali Loss: 0.0038736 Test Loss: 0.0052655\n",
      "Validation loss decreased (0.004270 --> 0.003874).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 60.587698221206665\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.0025048 Vali Loss: 0.0039560 Test Loss: 0.0054859\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 59.18573045730591\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.0023607 Vali Loss: 0.0037130 Test Loss: 0.0051784\n",
      "Validation loss decreased (0.003874 --> 0.003713).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 61.941429138183594\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.0022858 Vali Loss: 0.0037482 Test Loss: 0.0052805\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 60.372153997421265\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.0022462 Vali Loss: 0.0038677 Test Loss: 0.0054197\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 60.92287230491638\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.0022385 Vali Loss: 0.0037935 Test Loss: 0.0053192\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.005178380291908979, mae:0.06217702105641365\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 70.21907758712769\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.0253742 Vali Loss: 0.0069338 Test Loss: 0.0076513\n",
      "Validation loss decreased (inf --> 0.006934).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 68.1661536693573\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.0044149 Vali Loss: 0.0061742 Test Loss: 0.0085661\n",
      "Validation loss decreased (0.006934 --> 0.006174).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 70.77472567558289\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.0030473 Vali Loss: 0.0051692 Test Loss: 0.0076230\n",
      "Validation loss decreased (0.006174 --> 0.005169).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 69.01703548431396\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.0027663 Vali Loss: 0.0049565 Test Loss: 0.0072980\n",
      "Validation loss decreased (0.005169 --> 0.004957).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 70.48936986923218\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.0026507 Vali Loss: 0.0049068 Test Loss: 0.0072377\n",
      "Validation loss decreased (0.004957 --> 0.004907).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 67.55632996559143\n",
      "Epoch: 6, Steps: 400 | Train Loss: 0.0026132 Vali Loss: 0.0049068 Test Loss: 0.0072704\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 71.00981330871582\n",
      "Epoch: 7, Steps: 400 | Train Loss: 0.0025692 Vali Loss: 0.0048293 Test Loss: 0.0071864\n",
      "Validation loss decreased (0.004907 --> 0.004829).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 69.99074459075928\n",
      "Epoch: 8, Steps: 400 | Train Loss: 0.0025494 Vali Loss: 0.0048935 Test Loss: 0.0072624\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 69.55289793014526\n",
      "Epoch: 9, Steps: 400 | Train Loss: 0.0025526 Vali Loss: 0.0048660 Test Loss: 0.0072352\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 70.57131314277649\n",
      "Epoch: 10, Steps: 400 | Train Loss: 0.0025377 Vali Loss: 0.0048485 Test Loss: 0.0072133\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.007186408620327711, mae:0.07349315285682678\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 4, 6, 7, 8, 9, 11, 12, 14, 15, 16, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 34, 36, 37, 38, 40, 41, 42, 43, 46, 50, 51, 55, 57, 58, 60, 61, 65, 66, 67, 68, 69, 70, 72, 75, 76, 78, 79, 80, 83, 84, 86, 87, 88, 89, 93, 94, 95, 100, 101, 106, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 3, 4, 5, 6, 7, 8, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 29, 34, 38, 39, 40, 41, 43, 44, 45, 46, 50, 51, 52, 55, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 79, 80, 81, 82, 83, 84, 86, 89, 90, 92, 93, 94, 97, 98, 103, 105, 106, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 94.37233018875122\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.0304094 Vali Loss: 0.0167397 Test Loss: 0.0206226\n",
      "Validation loss decreased (inf --> 0.016740).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 93.24624991416931\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.0109920 Vali Loss: 0.0153057 Test Loss: 0.0192411\n",
      "Validation loss decreased (0.016740 --> 0.015306).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 94.52992415428162\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.0102722 Vali Loss: 0.0153702 Test Loss: 0.0195137\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 93.21392178535461\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.0100557 Vali Loss: 0.0140595 Test Loss: 0.0178477\n",
      "Validation loss decreased (0.015306 --> 0.014060).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 94.54548835754395\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.0099340 Vali Loss: 0.0140867 Test Loss: 0.0178608\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 91.91387438774109\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.0098702 Vali Loss: 0.0142809 Test Loss: 0.0181146\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 94.26009154319763\n",
      "Epoch: 7, Steps: 396 | Train Loss: 0.0098500 Vali Loss: 0.0151055 Test Loss: 0.0191603\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.01784774474799633, mae:0.10882145166397095\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 3, 5, 7, 8, 12, 14, 15, 17, 19, 20, 21, 24, 26, 27, 33, 38, 39, 40, 42, 47, 53, 54, 57, 62, 64, 70, 76, 87, 89, 90, 93, 94, 95, 96, 99, 110, 111, 118, 126, 129, 130, 131, 132, 134, 140, 142, 143, 152, 153, 154, 156, 160, 163, 164, 170, 171, 173, 176, 178, 184, 185, 186, 190]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 5, 12, 13, 14, 24, 25, 28, 29, 31, 35, 37, 38, 41, 42, 43, 46, 56, 58, 60, 61, 77, 83, 90, 93, 94, 98, 100, 101, 102, 104, 108, 112, 113, 117, 118, 121, 122, 125, 130, 131, 135, 138, 142, 143, 146, 147, 151, 153, 156, 164, 165, 168, 169, 170, 175, 176, 177, 178, 179, 187, 188, 190, 191]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 115.71883773803711\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.0388099 Vali Loss: 0.0257332 Test Loss: 0.0379966\n",
      "Validation loss decreased (inf --> 0.025733).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 113.4830904006958\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.0137661 Vali Loss: 0.0270898 Test Loss: 0.0401559\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 113.49974918365479\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.0125082 Vali Loss: 0.0282435 Test Loss: 0.0418917\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 115.91375350952148\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.0109059 Vali Loss: 0.0280661 Test Loss: 0.0421791\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.03799663856625557, mae:0.15760093927383423\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 23, 28, 29, 31, 35, 40, 47, 48, 52, 53, 58, 61, 63, 67, 68, 75, 79, 103, 118, 119, 120, 124, 126, 131, 137, 139, 140, 144, 160, 183, 185, 186, 187, 190, 192, 199, 204, 206, 211, 216, 218, 220, 225, 242, 243, 255, 270, 277, 287, 293, 313, 321, 323, 329, 331, 347, 353, 357, 361, 367, 371, 372, 383]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 4, 5, 10, 11, 16, 19, 25, 26, 28, 35, 47, 60, 76, 83, 91, 94, 97, 106, 107, 114, 119, 138, 139, 143, 154, 158, 166, 175, 176, 185, 189, 193, 195, 200, 215, 222, 225, 236, 253, 254, 261, 262, 268, 284, 287, 290, 292, 300, 309, 316, 321, 323, 329, 330, 342, 356, 362, 363, 366, 370, 374, 381, 383]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 152.56025457382202\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.0524581 Vali Loss: 0.0355718 Test Loss: 0.0425204\n",
      "Validation loss decreased (inf --> 0.035572).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 153.8959834575653\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.0231039 Vali Loss: 0.0326141 Test Loss: 0.0407600\n",
      "Validation loss decreased (0.035572 --> 0.032614).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 151.73199152946472\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.0217083 Vali Loss: 0.0324284 Test Loss: 0.0387523\n",
      "Validation loss decreased (0.032614 --> 0.032428).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 151.58317399024963\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.0210368 Vali Loss: 0.0313711 Test Loss: 0.0386019\n",
      "Validation loss decreased (0.032428 --> 0.031371).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 152.3573079109192\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.0205338 Vali Loss: 0.0311619 Test Loss: 0.0381791\n",
      "Validation loss decreased (0.031371 --> 0.031162).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 152.23938083648682\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.0202137 Vali Loss: 0.0312600 Test Loss: 0.0379266\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 152.03044414520264\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.0200261 Vali Loss: 0.0309804 Test Loss: 0.0374808\n",
      "Validation loss decreased (0.031162 --> 0.030980).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 150.98111081123352\n",
      "Epoch: 8, Steps: 379 | Train Loss: 0.0199213 Vali Loss: 0.0310815 Test Loss: 0.0376763\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 150.89610815048218\n",
      "Epoch: 9, Steps: 379 | Train Loss: 0.0198818 Vali Loss: 0.0310315 Test Loss: 0.0376886\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 153.95677590370178\n",
      "Epoch: 10, Steps: 379 | Train Loss: 0.0198625 Vali Loss: 0.0310223 Test Loss: 0.0377415\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.03748079016804695, mae:0.1542816311120987\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_reversal_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 60.647260904312134\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.0485467 Vali Loss: 0.0211393 Test Loss: 0.0216604\n",
      "Validation loss decreased (inf --> 0.021139).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 60.83491063117981\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.0157249 Vali Loss: 0.0206584 Test Loss: 0.0201290\n",
      "Validation loss decreased (0.021139 --> 0.020658).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 60.79740881919861\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.0136332 Vali Loss: 0.0199993 Test Loss: 0.0196077\n",
      "Validation loss decreased (0.020658 --> 0.019999).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 59.245418071746826\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.0128183 Vali Loss: 0.0181311 Test Loss: 0.0184658\n",
      "Validation loss decreased (0.019999 --> 0.018131).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 62.66299796104431\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.0124611 Vali Loss: 0.0190522 Test Loss: 0.0185619\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 59.622228145599365\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.0122701 Vali Loss: 0.0194639 Test Loss: 0.0188781\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 60.32753252983093\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.0121274 Vali Loss: 0.0187538 Test Loss: 0.0183290\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.01846582256257534, mae:0.109492726624012\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_reversal_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 68.37972044944763\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.0514171 Vali Loss: 0.0266060 Test Loss: 0.0280481\n",
      "Validation loss decreased (inf --> 0.026606).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 70.566823720932\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.0194698 Vali Loss: 0.0341625 Test Loss: 0.0336331\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 69.60228610038757\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.0178209 Vali Loss: 0.0277657 Test Loss: 0.0280877\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 70.53261661529541\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.0170223 Vali Loss: 0.0268682 Test Loss: 0.0269462\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.02804814651608467, mae:0.13616028428077698\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 2, 3, 4, 6, 7, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 41, 42, 45, 46, 48, 58, 59, 64, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 85, 86, 87, 90, 91, 92, 93, 94, 95, 97, 98, 106, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 23, 24, 25, 26, 29, 31, 33, 34, 35, 39, 41, 42, 44, 46, 52, 53, 55, 56, 58, 59, 60, 61, 63, 65, 67, 69, 70, 73, 74, 75, 76, 78, 79, 80, 81, 84, 87, 88, 89, 90, 91, 94, 95, 97, 98, 101, 102, 106]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_reversal_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 92.35158324241638\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.0750050 Vali Loss: 0.1015574 Test Loss: 0.1043309\n",
      "Validation loss decreased (inf --> 0.101557).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 95.55241847038269\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.0323465 Vali Loss: 0.0976610 Test Loss: 0.1087016\n",
      "Validation loss decreased (0.101557 --> 0.097661).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 93.4400577545166\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.0283949 Vali Loss: 0.1006957 Test Loss: 0.1208976\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 92.38323903083801\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.0274070 Vali Loss: 0.0995101 Test Loss: 0.1164421\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 95.83010578155518\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.0268791 Vali Loss: 0.0940095 Test Loss: 0.1145412\n",
      "Validation loss decreased (0.097661 --> 0.094009).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 94.77147388458252\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.0266353 Vali Loss: 0.0979537 Test Loss: 0.1157652\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 94.13488388061523\n",
      "Epoch: 7, Steps: 396 | Train Loss: 0.0264641 Vali Loss: 0.0976721 Test Loss: 0.1155368\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 94.10699152946472\n",
      "Epoch: 8, Steps: 396 | Train Loss: 0.0263656 Vali Loss: 0.0976898 Test Loss: 0.1159229\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.11454115808010101, mae:0.259062796831131\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 4, 6, 9, 11, 12, 16, 21, 22, 25, 31, 33, 37, 39, 46, 49, 57, 58, 59, 60, 61, 64, 67, 68, 69, 71, 73, 78, 80, 83, 86, 87, 90, 91, 94, 95, 99, 100, 103, 110, 111, 112, 113, 117, 119, 120, 122, 126, 128, 131, 137, 141, 142, 147, 149, 154, 158, 166, 168, 171, 176, 178, 179, 185]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 4, 5, 13, 14, 15, 17, 18, 22, 27, 28, 33, 35, 39, 40, 42, 43, 48, 50, 53, 55, 56, 57, 61, 63, 64, 66, 68, 69, 72, 77, 81, 82, 85, 87, 90, 91, 92, 95, 104, 109, 112, 116, 120, 121, 132, 136, 139, 149, 150, 154, 155, 160, 162, 167, 170, 171, 174, 175, 179, 184, 185, 186, 187]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_reversal_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 113.9651346206665\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.1219081 Vali Loss: 0.2331103 Test Loss: 0.2368332\n",
      "Validation loss decreased (inf --> 0.233110).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 116.02891850471497\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.0773023 Vali Loss: 0.2300756 Test Loss: 0.2332946\n",
      "Validation loss decreased (0.233110 --> 0.230076).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 112.7029218673706\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.0747129 Vali Loss: 0.2290654 Test Loss: 0.2285571\n",
      "Validation loss decreased (0.230076 --> 0.229065).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 113.93131637573242\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.0739355 Vali Loss: 0.2346487 Test Loss: 0.2353959\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 115.44507718086243\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.0735311 Vali Loss: 0.2296997 Test Loss: 0.2317039\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 113.5545380115509\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.0732303 Vali Loss: 0.2346377 Test Loss: 0.2358761\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.22855708003044128, mae:0.3531331717967987\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[16, 25, 26, 28, 40, 42, 47, 52, 63, 66, 69, 70, 79, 81, 83, 95, 105, 106, 116, 128, 134, 135, 137, 143, 144, 146, 165, 176, 185, 186, 190, 191, 199, 206, 212, 213, 219, 220, 224, 227, 235, 239, 241, 249, 260, 273, 275, 282, 284, 297, 299, 307, 316, 317, 326, 328, 332, 336, 342, 343, 356, 359, 363, 369]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[8, 9, 11, 19, 22, 23, 26, 28, 60, 61, 62, 64, 70, 73, 74, 86, 87, 88, 99, 107, 120, 121, 124, 125, 129, 130, 137, 140, 148, 149, 153, 154, 172, 180, 187, 189, 194, 203, 204, 210, 219, 229, 238, 239, 244, 246, 247, 250, 252, 253, 270, 271, 274, 301, 315, 316, 323, 327, 328, 329, 338, 345, 369, 370]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_reversal_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 150.83080887794495\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.3039177 Vali Loss: 0.5719351 Test Loss: 0.4345807\n",
      "Validation loss decreased (inf --> 0.571935).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 151.27735781669617\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.2188470 Vali Loss: 0.5360391 Test Loss: 0.4174485\n",
      "Validation loss decreased (0.571935 --> 0.536039).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 150.46197819709778\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.2073605 Vali Loss: 0.5730216 Test Loss: 0.3761778\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 150.24923038482666\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.2028325 Vali Loss: 0.5529457 Test Loss: 0.3953261\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 152.515389919281\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.2009261 Vali Loss: 0.5419801 Test Loss: 0.4012458\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.4174485206604004, mae:0.5305169224739075\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 59.72833800315857\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.0346916 Vali Loss: 0.0685388 Test Loss: 0.1311339\n",
      "Validation loss decreased (inf --> 0.068539).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 59.60770559310913\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.0108913 Vali Loss: 0.0215224 Test Loss: 0.0465747\n",
      "Validation loss decreased (0.068539 --> 0.021522).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 59.7245032787323\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.0063855 Vali Loss: 0.0163483 Test Loss: 0.0361515\n",
      "Validation loss decreased (0.021522 --> 0.016348).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 59.64251661300659\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.0057526 Vali Loss: 0.0165459 Test Loss: 0.0359469\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 59.49539518356323\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.0053908 Vali Loss: 0.0159931 Test Loss: 0.0347808\n",
      "Validation loss decreased (0.016348 --> 0.015993).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 59.86403846740723\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.0052288 Vali Loss: 0.0144230 Test Loss: 0.0315399\n",
      "Validation loss decreased (0.015993 --> 0.014423).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 58.84497904777527\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.0051632 Vali Loss: 0.0144756 Test Loss: 0.0314659\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 59.36567568778992\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.0050954 Vali Loss: 0.0141910 Test Loss: 0.0309823\n",
      "Validation loss decreased (0.014423 --> 0.014191).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 58.562381744384766\n",
      "Epoch: 9, Steps: 401 | Train Loss: 0.0050748 Vali Loss: 0.0139561 Test Loss: 0.0304831\n",
      "Validation loss decreased (0.014191 --> 0.013956).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 57.17268514633179\n",
      "Epoch: 10, Steps: 401 | Train Loss: 0.0050702 Vali Loss: 0.0140083 Test Loss: 0.0305961\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 61.03413772583008\n",
      "Epoch: 11, Steps: 401 | Train Loss: 0.0050513 Vali Loss: 0.0140055 Test Loss: 0.0305204\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 60.592379093170166\n",
      "Epoch: 12, Steps: 401 | Train Loss: 0.0050630 Vali Loss: 0.0139848 Test Loss: 0.0304716\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.030483121052384377, mae:0.13933828473091125\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 69.74017333984375\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.0394080 Vali Loss: 0.0718668 Test Loss: 0.1397295\n",
      "Validation loss decreased (inf --> 0.071867).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 68.17572689056396\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.0128922 Vali Loss: 0.0247268 Test Loss: 0.0522360\n",
      "Validation loss decreased (0.071867 --> 0.024727).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 68.61594343185425\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.0069455 Vali Loss: 0.0181868 Test Loss: 0.0399301\n",
      "Validation loss decreased (0.024727 --> 0.018187).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 69.4875340461731\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.0054772 Vali Loss: 0.0166206 Test Loss: 0.0366091\n",
      "Validation loss decreased (0.018187 --> 0.016621).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 69.32447528839111\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.0049291 Vali Loss: 0.0155348 Test Loss: 0.0348355\n",
      "Validation loss decreased (0.016621 --> 0.015535).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 68.15985822677612\n",
      "Epoch: 6, Steps: 400 | Train Loss: 0.0046884 Vali Loss: 0.0161535 Test Loss: 0.0361809\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 69.09184694290161\n",
      "Epoch: 7, Steps: 400 | Train Loss: 0.0045718 Vali Loss: 0.0159459 Test Loss: 0.0359156\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 67.5468270778656\n",
      "Epoch: 8, Steps: 400 | Train Loss: 0.0044976 Vali Loss: 0.0157238 Test Loss: 0.0351663\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.03483551740646362, mae:0.1497315615415573\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 3, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 23, 24, 25, 26, 27, 30, 31, 33, 37, 39, 40, 41, 42, 43, 44, 48, 49, 50, 52, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 72, 74, 75, 76, 77, 78, 83, 86, 87, 88, 91, 94, 95, 96, 97, 101, 103, 106]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 3, 4, 8, 9, 10, 12, 14, 15, 17, 19, 20, 21, 23, 24, 26, 27, 34, 35, 36, 38, 42, 43, 47, 48, 49, 50, 51, 52, 57, 58, 60, 62, 63, 65, 66, 69, 72, 73, 74, 76, 77, 80, 81, 83, 84, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 105, 106, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 93.19481658935547\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.0502869 Vali Loss: 0.1021506 Test Loss: 0.1751750\n",
      "Validation loss decreased (inf --> 0.102151).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 91.2597336769104\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.0251036 Vali Loss: 0.0910751 Test Loss: 0.1558491\n",
      "Validation loss decreased (0.102151 --> 0.091075).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 95.16014170646667\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.0226057 Vali Loss: 0.0890623 Test Loss: 0.1507062\n",
      "Validation loss decreased (0.091075 --> 0.089062).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 94.33355212211609\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.0215413 Vali Loss: 0.0848250 Test Loss: 0.1445262\n",
      "Validation loss decreased (0.089062 --> 0.084825).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 93.90412950515747\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.0210235 Vali Loss: 0.0841290 Test Loss: 0.1429176\n",
      "Validation loss decreased (0.084825 --> 0.084129).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 92.97585225105286\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.0207047 Vali Loss: 0.0838996 Test Loss: 0.1418610\n",
      "Validation loss decreased (0.084129 --> 0.083900).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 92.06728076934814\n",
      "Epoch: 7, Steps: 396 | Train Loss: 0.0206188 Vali Loss: 0.0840486 Test Loss: 0.1421911\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 90.967782497406\n",
      "Epoch: 8, Steps: 396 | Train Loss: 0.0205370 Vali Loss: 0.0843613 Test Loss: 0.1428309\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 93.91552686691284\n",
      "Epoch: 9, Steps: 396 | Train Loss: 0.0205130 Vali Loss: 0.0840310 Test Loss: 0.1422498\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.14186102151870728, mae:0.3075639605522156\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 2, 5, 7, 14, 15, 18, 27, 28, 32, 43, 44, 45, 50, 55, 62, 67, 73, 76, 77, 83, 84, 85, 86, 88, 91, 92, 97, 99, 100, 101, 105, 115, 116, 117, 119, 120, 122, 124, 125, 128, 129, 131, 137, 138, 139, 143, 144, 149, 151, 152, 154, 159, 161, 162, 167, 172, 173, 176, 177, 187, 188, 189, 191]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 6, 7, 8, 11, 13, 20, 22, 28, 37, 38, 40, 41, 42, 44, 45, 48, 52, 53, 54, 55, 62, 63, 64, 67, 70, 71, 72, 73, 76, 77, 79, 81, 82, 94, 101, 104, 106, 107, 114, 115, 118, 119, 120, 123, 132, 137, 138, 147, 156, 158, 159, 160, 163, 171, 173, 174, 176, 177, 179, 182, 184, 187]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 114.0143051147461\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.0539841 Vali Loss: 0.1287367 Test Loss: 0.2377240\n",
      "Validation loss decreased (inf --> 0.128737).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 113.23256134986877\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.0283393 Vali Loss: 0.1402884 Test Loss: 0.2587996\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 115.0208911895752\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.0255662 Vali Loss: 0.1273800 Test Loss: 0.2428766\n",
      "Validation loss decreased (0.128737 --> 0.127380).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 110.90881967544556\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.0235821 Vali Loss: 0.1240049 Test Loss: 0.2388631\n",
      "Validation loss decreased (0.127380 --> 0.124005).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 115.77521252632141\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.0220632 Vali Loss: 0.1194808 Test Loss: 0.2345023\n",
      "Validation loss decreased (0.124005 --> 0.119481).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 112.58568096160889\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.0212694 Vali Loss: 0.1211291 Test Loss: 0.2370723\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 113.99198460578918\n",
      "Epoch: 7, Steps: 391 | Train Loss: 0.0208619 Vali Loss: 0.1179576 Test Loss: 0.2330825\n",
      "Validation loss decreased (0.119481 --> 0.117958).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 114.1085205078125\n",
      "Epoch: 8, Steps: 391 | Train Loss: 0.0206609 Vali Loss: 0.1196173 Test Loss: 0.2355395\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 112.8701229095459\n",
      "Epoch: 9, Steps: 391 | Train Loss: 0.0205814 Vali Loss: 0.1199483 Test Loss: 0.2361860\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 115.03463840484619\n",
      "Epoch: 10, Steps: 391 | Train Loss: 0.0205309 Vali Loss: 0.1193561 Test Loss: 0.2354320\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.233082577586174, mae:0.396233469247818\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[12, 14, 15, 16, 19, 20, 25, 29, 35, 40, 41, 45, 46, 76, 77, 86, 89, 91, 98, 101, 105, 107, 109, 119, 126, 143, 173, 179, 181, 182, 185, 187, 188, 191, 193, 197, 201, 207, 208, 216, 237, 246, 249, 257, 259, 265, 276, 280, 301, 304, 316, 317, 325, 326, 329, 340, 348, 355, 363, 369, 376, 377, 378, 379]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[8, 12, 28, 30, 36, 51, 55, 56, 69, 72, 73, 74, 79, 101, 103, 110, 112, 113, 134, 137, 139, 171, 174, 179, 182, 183, 185, 189, 190, 194, 196, 204, 212, 225, 233, 237, 242, 246, 258, 264, 267, 275, 278, 280, 281, 284, 287, 293, 294, 295, 299, 308, 309, 318, 320, 321, 322, 337, 345, 357, 364, 369, 376, 377]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 152.37193727493286\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.0855636 Vali Loss: 0.1707658 Test Loss: 0.2636439\n",
      "Validation loss decreased (inf --> 0.170766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 151.04610085487366\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.0453562 Vali Loss: 0.1568872 Test Loss: 0.2493232\n",
      "Validation loss decreased (0.170766 --> 0.156887).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 151.25760769844055\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.0407951 Vali Loss: 0.1504613 Test Loss: 0.2345203\n",
      "Validation loss decreased (0.156887 --> 0.150461).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 150.8864541053772\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.0395742 Vali Loss: 0.1493004 Test Loss: 0.2359465\n",
      "Validation loss decreased (0.150461 --> 0.149300).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 152.19359064102173\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.0389209 Vali Loss: 0.1469833 Test Loss: 0.2311966\n",
      "Validation loss decreased (0.149300 --> 0.146983).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 151.55610156059265\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.0386410 Vali Loss: 0.1452716 Test Loss: 0.2275952\n",
      "Validation loss decreased (0.146983 --> 0.145272).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 151.3568148612976\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.0384765 Vali Loss: 0.1449529 Test Loss: 0.2276573\n",
      "Validation loss decreased (0.145272 --> 0.144953).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 152.33427357673645\n",
      "Epoch: 8, Steps: 379 | Train Loss: 0.0383737 Vali Loss: 0.1453247 Test Loss: 0.2285212\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 152.50800895690918\n",
      "Epoch: 9, Steps: 379 | Train Loss: 0.0383761 Vali Loss: 0.1451298 Test Loss: 0.2280376\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 154.02163934707642\n",
      "Epoch: 10, Steps: 379 | Train Loss: 0.0383485 Vali Loss: 0.1450957 Test Loss: 0.2277979\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.2276572585105896, mae:0.38995274901390076\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_reversal_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 61.63006567955017\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.0384371 Vali Loss: 0.1730080 Test Loss: 0.3410659\n",
      "Validation loss decreased (inf --> 0.173008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 59.48732376098633\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.0121103 Vali Loss: 0.1446635 Test Loss: 0.3020226\n",
      "Validation loss decreased (0.173008 --> 0.144664).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 61.51800465583801\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.0091505 Vali Loss: 0.1324521 Test Loss: 0.2831129\n",
      "Validation loss decreased (0.144664 --> 0.132452).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 60.78149342536926\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.0081837 Vali Loss: 0.1316591 Test Loss: 0.2789604\n",
      "Validation loss decreased (0.132452 --> 0.131659).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 61.80347728729248\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.0079961 Vali Loss: 0.1324825 Test Loss: 0.2791721\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 60.86036658287048\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.0077295 Vali Loss: 0.1303523 Test Loss: 0.2794895\n",
      "Validation loss decreased (0.131659 --> 0.130352).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 62.25968670845032\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.0075800 Vali Loss: 0.1317261 Test Loss: 0.2773947\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 59.6430127620697\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.0075282 Vali Loss: 0.1312628 Test Loss: 0.2781720\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 62.499332904815674\n",
      "Epoch: 9, Steps: 401 | Train Loss: 0.0075306 Vali Loss: 0.1312364 Test Loss: 0.2779109\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.27948957681655884, mae:0.2924863398075104\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_reversal_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 70.26758599281311\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.0482935 Vali Loss: 0.2146144 Test Loss: 0.4111435\n",
      "Validation loss decreased (inf --> 0.214614).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 67.66874194145203\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.0140441 Vali Loss: 0.1713410 Test Loss: 0.3625821\n",
      "Validation loss decreased (0.214614 --> 0.171341).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 67.42820644378662\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.0100486 Vali Loss: 0.1680719 Test Loss: 0.3508684\n",
      "Validation loss decreased (0.171341 --> 0.168072).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 69.21937727928162\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.0087118 Vali Loss: 0.1669144 Test Loss: 0.3476095\n",
      "Validation loss decreased (0.168072 --> 0.166914).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 69.79255056381226\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.0081525 Vali Loss: 0.1677683 Test Loss: 0.3491202\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 70.948233127594\n",
      "Epoch: 6, Steps: 400 | Train Loss: 0.0079285 Vali Loss: 0.1667918 Test Loss: 0.3486687\n",
      "Validation loss decreased (0.166914 --> 0.166792).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 67.58414125442505\n",
      "Epoch: 7, Steps: 400 | Train Loss: 0.0077645 Vali Loss: 0.1663973 Test Loss: 0.3469245\n",
      "Validation loss decreased (0.166792 --> 0.166397).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 67.92915868759155\n",
      "Epoch: 8, Steps: 400 | Train Loss: 0.0076999 Vali Loss: 0.1666422 Test Loss: 0.3478306\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 71.24834942817688\n",
      "Epoch: 9, Steps: 400 | Train Loss: 0.0076776 Vali Loss: 0.1668033 Test Loss: 0.3477983\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 68.57515239715576\n",
      "Epoch: 10, Steps: 400 | Train Loss: 0.0076689 Vali Loss: 0.1666197 Test Loss: 0.3476075\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.3469245731830597, mae:0.3362710475921631\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 4, 6, 8, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 30, 32, 36, 37, 38, 39, 40, 42, 44, 45, 50, 51, 52, 53, 56, 57, 61, 62, 64, 65, 67, 69, 72, 73, 74, 75, 76, 78, 79, 80, 81, 83, 84, 85, 90, 92, 93, 95, 97, 100, 102, 103, 104, 105, 106, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 31, 37, 39, 40, 46, 47, 51, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 85, 86, 90, 92, 94, 95, 97, 101, 102, 103, 105, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_reversal_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 92.67970490455627\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.0708558 Vali Loss: 0.4167214 Test Loss: 0.7002963\n",
      "Validation loss decreased (inf --> 0.416721).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 92.8022072315216\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.0358555 Vali Loss: 0.4052675 Test Loss: 0.6903707\n",
      "Validation loss decreased (0.416721 --> 0.405268).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 94.26202201843262\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.0315305 Vali Loss: 0.3906738 Test Loss: 0.6706370\n",
      "Validation loss decreased (0.405268 --> 0.390674).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 93.5692355632782\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.0299590 Vali Loss: 0.3855158 Test Loss: 0.6654446\n",
      "Validation loss decreased (0.390674 --> 0.385516).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 96.35421538352966\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.0292287 Vali Loss: 0.3817026 Test Loss: 0.6586768\n",
      "Validation loss decreased (0.385516 --> 0.381703).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 94.11655831336975\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.0288469 Vali Loss: 0.3819579 Test Loss: 0.6578563\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 91.47300934791565\n",
      "Epoch: 7, Steps: 396 | Train Loss: 0.0285475 Vali Loss: 0.3810432 Test Loss: 0.6566708\n",
      "Validation loss decreased (0.381703 --> 0.381043).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 93.88086652755737\n",
      "Epoch: 8, Steps: 396 | Train Loss: 0.0285889 Vali Loss: 0.3796439 Test Loss: 0.6557037\n",
      "Validation loss decreased (0.381043 --> 0.379644).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 93.81723523139954\n",
      "Epoch: 9, Steps: 396 | Train Loss: 0.0285097 Vali Loss: 0.3799803 Test Loss: 0.6554606\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 92.5205991268158\n",
      "Epoch: 10, Steps: 396 | Train Loss: 0.0284903 Vali Loss: 0.3812751 Test Loss: 0.6553301\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 92.1592161655426\n",
      "Epoch: 11, Steps: 396 | Train Loss: 0.0284211 Vali Loss: 0.3812173 Test Loss: 0.6553196\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.6557036638259888, mae:0.5339525938034058\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 3, 7, 10, 12, 15, 16, 19, 20, 23, 27, 28, 29, 30, 32, 36, 38, 40, 46, 47, 48, 49, 50, 57, 59, 60, 61, 64, 65, 83, 85, 86, 88, 90, 93, 94, 97, 100, 104, 108, 112, 117, 121, 122, 123, 126, 127, 148, 150, 152, 155, 161, 165, 169, 170, 171, 173, 174, 175, 176, 179, 181, 188, 191]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 2, 3, 5, 9, 14, 16, 19, 20, 23, 29, 30, 32, 33, 34, 35, 39, 40, 41, 44, 51, 53, 54, 58, 61, 63, 71, 73, 82, 85, 87, 88, 94, 95, 102, 104, 106, 107, 109, 110, 119, 120, 121, 125, 128, 129, 131, 132, 135, 136, 137, 140, 141, 147, 148, 149, 153, 155, 161, 162, 164, 168, 174, 179]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_reversal_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 112.88726091384888\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.0764402 Vali Loss: 0.6423928 Test Loss: 1.1065644\n",
      "Validation loss decreased (inf --> 0.642393).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 114.97385787963867\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.0438189 Vali Loss: 0.6368480 Test Loss: 1.1070455\n",
      "Validation loss decreased (0.642393 --> 0.636848).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 111.91963219642639\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.0410944 Vali Loss: 0.6375264 Test Loss: 1.1087278\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 114.82058835029602\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.0397690 Vali Loss: 0.6301678 Test Loss: 1.1034178\n",
      "Validation loss decreased (0.636848 --> 0.630168).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 114.24879050254822\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.0391744 Vali Loss: 0.6274056 Test Loss: 1.0992978\n",
      "Validation loss decreased (0.630168 --> 0.627406).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 116.02988529205322\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.0387370 Vali Loss: 0.6251032 Test Loss: 1.0991933\n",
      "Validation loss decreased (0.627406 --> 0.625103).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 113.30346035957336\n",
      "Epoch: 7, Steps: 391 | Train Loss: 0.0384560 Vali Loss: 0.6258027 Test Loss: 1.1001160\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 114.16897821426392\n",
      "Epoch: 8, Steps: 391 | Train Loss: 0.0383823 Vali Loss: 0.6256388 Test Loss: 1.0995523\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 114.3311357498169\n",
      "Epoch: 9, Steps: 391 | Train Loss: 0.0382956 Vali Loss: 0.6254143 Test Loss: 1.0998954\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:1.0991933345794678, mae:0.7600651383399963\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 5, 18, 34, 40, 41, 46, 51, 53, 64, 67, 69, 73, 79, 85, 97, 98, 106, 111, 121, 122, 123, 132, 136, 137, 139, 140, 151, 157, 162, 168, 169, 170, 171, 173, 179, 182, 191, 192, 193, 195, 197, 202, 210, 216, 230, 249, 250, 260, 268, 274, 289, 293, 305, 313, 318, 346, 355, 356, 366, 373, 376, 380, 381]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[2, 3, 18, 21, 30, 38, 44, 46, 47, 48, 50, 54, 64, 66, 68, 92, 94, 103, 115, 116, 118, 119, 132, 143, 159, 172, 180, 187, 192, 196, 206, 211, 216, 228, 231, 232, 240, 244, 249, 256, 267, 272, 275, 276, 279, 290, 291, 309, 313, 317, 319, 322, 324, 327, 331, 334, 340, 341, 357, 360, 361, 363, 366, 369]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_reversal_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 150.17946791648865\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.1099465 Vali Loss: 1.2617509 Test Loss: 2.1961606\n",
      "Validation loss decreased (inf --> 1.261751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 152.33059358596802\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.0708923 Vali Loss: 1.2456849 Test Loss: 2.1978884\n",
      "Validation loss decreased (1.261751 --> 1.245685).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 150.80031609535217\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.0672923 Vali Loss: 1.2550417 Test Loss: 2.2405510\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 150.98870062828064\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.0658842 Vali Loss: 1.2464848 Test Loss: 2.2276254\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 150.7677137851715\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.0653155 Vali Loss: 1.2472507 Test Loss: 2.2321286\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:2.1978886127471924, mae:1.2426397800445557\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on ETTh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'checkpoints': './checkpoints/', 'features': 'M', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "Epoch: 1 cost time: 40.354398250579834\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.3547676 Vali Loss: 0.5667475 Test Loss: 0.3413119\n",
      "Validation loss decreased (inf --> 0.566747).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 40.29376006126404\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.3080354 Vali Loss: 0.5574415 Test Loss: 0.3283693\n",
      "Validation loss decreased (0.566747 --> 0.557441).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 40.14724063873291\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.2921279 Vali Loss: 0.5487423 Test Loss: 0.3206333\n",
      "Validation loss decreased (0.557441 --> 0.548742).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 39.60086989402771\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.2846879 Vali Loss: 0.5427594 Test Loss: 0.3157062\n",
      "Validation loss decreased (0.548742 --> 0.542759).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 39.51895332336426\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.2809594 Vali Loss: 0.5402600 Test Loss: 0.3164662\n",
      "Validation loss decreased (0.542759 --> 0.540260).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 39.92855787277222\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.2789397 Vali Loss: 0.5408678 Test Loss: 0.3149052\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 39.42803716659546\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.2778924 Vali Loss: 0.5385687 Test Loss: 0.3138030\n",
      "Validation loss decreased (0.540260 --> 0.538569).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 39.91635179519653\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.2773291 Vali Loss: 0.5388881 Test Loss: 0.3137806\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 38.41700625419617\n",
      "Epoch: 9, Steps: 266 | Train Loss: 0.2770763 Vali Loss: 0.5392795 Test Loss: 0.3136173\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 38.29322814941406\n",
      "Epoch: 10, Steps: 266 | Train Loss: 0.2767820 Vali Loss: 0.5390457 Test Loss: 0.3138958\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "mse:0.31380292773246765, mae:0.38087016344070435\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on ETTh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'checkpoints': './checkpoints/', 'features': 'M', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_ETTh1_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "Epoch: 1 cost time: 46.85428500175476\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.3791072 Vali Loss: 0.6485992 Test Loss: 0.3548473\n",
      "Validation loss decreased (inf --> 0.648599).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 46.9959180355072\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.3351017 Vali Loss: 0.6437092 Test Loss: 0.3467089\n",
      "Validation loss decreased (0.648599 --> 0.643709).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 45.097060680389404\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.3215242 Vali Loss: 0.6320509 Test Loss: 0.3384984\n",
      "Validation loss decreased (0.643709 --> 0.632051).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 45.353394746780396\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.3153181 Vali Loss: 0.6363560 Test Loss: 0.3414051\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 45.88928699493408\n",
      "Epoch: 5, Steps: 265 | Train Loss: 0.3119586 Vali Loss: 0.6324491 Test Loss: 0.3373532\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 45.19245719909668\n",
      "Epoch: 6, Steps: 265 | Train Loss: 0.3106815 Vali Loss: 0.6294050 Test Loss: 0.3368940\n",
      "Validation loss decreased (0.632051 --> 0.629405).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 45.33347797393799\n",
      "Epoch: 7, Steps: 265 | Train Loss: 0.3096200 Vali Loss: 0.6278040 Test Loss: 0.3359227\n",
      "Validation loss decreased (0.629405 --> 0.627804).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 45.54415011405945\n",
      "Epoch: 8, Steps: 265 | Train Loss: 0.3092891 Vali Loss: 0.6287706 Test Loss: 0.3362239\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 45.53574585914612\n",
      "Epoch: 9, Steps: 265 | Train Loss: 0.3088678 Vali Loss: 0.6262332 Test Loss: 0.3361263\n",
      "Validation loss decreased (0.627804 --> 0.626233).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 45.511542320251465\n",
      "Epoch: 10, Steps: 265 | Train Loss: 0.3088430 Vali Loss: 0.6275211 Test Loss: 0.3356560\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 45.3637535572052\n",
      "Epoch: 11, Steps: 265 | Train Loss: 0.3084759 Vali Loss: 0.6267906 Test Loss: 0.3357377\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 45.222227573394775\n",
      "Epoch: 12, Steps: 265 | Train Loss: 0.3085062 Vali Loss: 0.6270862 Test Loss: 0.3357497\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 7) (88, 32, 48, 7)\n",
      "test shape: (2816, 48, 7) (2816, 48, 7)\n",
      "mse:0.3361263573169708, mae:0.39111483097076416\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on ETTh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'checkpoints': './checkpoints/', 'features': 'M', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 2, 5, 6, 7, 11, 12, 13, 14, 18, 20, 23, 25, 26, 27, 28, 29, 31, 35, 36, 37, 38, 39, 43, 44, 45, 47, 49, 50, 53, 56, 57, 59, 60, 62, 63, 64, 66, 67, 68, 70, 72, 73, 74, 78, 79, 80, 81, 82, 84, 87, 89, 92, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[2, 3, 4, 6, 7, 13, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 30, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 53, 54, 55, 58, 59, 62, 63, 64, 66, 68, 69, 73, 74, 76, 78, 79, 80, 83, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 99, 100, 101, 103, 104, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_ETTh1_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "Epoch: 1 cost time: 67.85286903381348\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.4595626 Vali Loss: 1.0063337 Test Loss: 0.4149725\n",
      "Validation loss decreased (inf --> 1.006334).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 63.64136505126953\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.4167981 Vali Loss: 0.9976314 Test Loss: 0.4121369\n",
      "Validation loss decreased (1.006334 --> 0.997631).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 65.40639472007751\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.4066132 Vali Loss: 0.9983236 Test Loss: 0.4145674\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 64.71331906318665\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.4023317 Vali Loss: 0.9881207 Test Loss: 0.4063976\n",
      "Validation loss decreased (0.997631 --> 0.988121).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 65.0372941493988\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.3996576 Vali Loss: 0.9911683 Test Loss: 0.4059829\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 67.38847017288208\n",
      "Epoch: 6, Steps: 261 | Train Loss: 0.3983285 Vali Loss: 0.9868723 Test Loss: 0.4062511\n",
      "Validation loss decreased (0.988121 --> 0.986872).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 65.76967310905457\n",
      "Epoch: 7, Steps: 261 | Train Loss: 0.3974982 Vali Loss: 0.9871619 Test Loss: 0.4048836\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 64.4282374382019\n",
      "Epoch: 8, Steps: 261 | Train Loss: 0.3970250 Vali Loss: 0.9892823 Test Loss: 0.4056073\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 64.63427925109863\n",
      "Epoch: 9, Steps: 261 | Train Loss: 0.3971711 Vali Loss: 0.9883423 Test Loss: 0.4055017\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 7) (84, 32, 168, 7)\n",
      "test shape: (2688, 168, 7) (2688, 168, 7)\n",
      "mse:0.4062512516975403, mae:0.43467748165130615\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on ETTh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'checkpoints': './checkpoints/', 'features': 'M', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 4, 7, 8, 9, 11, 18, 19, 21, 22, 23, 25, 27, 29, 33, 41, 42, 45, 49, 50, 52, 55, 58, 59, 61, 62, 65, 66, 67, 72, 75, 86, 93, 96, 97, 102, 105, 106, 110, 115, 116, 117, 119, 125, 126, 128, 135, 139, 140, 141, 148, 150, 154, 157, 160, 164, 165, 166, 170, 173, 178, 180, 188, 191]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[3, 4, 7, 8, 10, 14, 16, 18, 23, 26, 28, 30, 32, 34, 36, 38, 40, 43, 47, 48, 50, 58, 64, 67, 69, 71, 76, 78, 84, 85, 91, 94, 96, 98, 104, 107, 109, 111, 118, 120, 121, 124, 128, 130, 131, 132, 134, 135, 137, 138, 141, 145, 155, 156, 160, 167, 170, 172, 173, 175, 181, 182, 184, 186]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_ETTh1_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 74.90640163421631\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.5312896 Vali Loss: 1.3271554 Test Loss: 0.4702417\n",
      "Validation loss decreased (inf --> 1.327155).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 78.87285280227661\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.4865520 Vali Loss: 1.3164440 Test Loss: 0.4543734\n",
      "Validation loss decreased (1.327155 --> 1.316444).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 77.03700876235962\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.4758136 Vali Loss: 1.3152031 Test Loss: 0.4498186\n",
      "Validation loss decreased (1.316444 --> 1.315203).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 78.94314575195312\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.4708815 Vali Loss: 1.3156215 Test Loss: 0.4473310\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 79.27601075172424\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.4679364 Vali Loss: 1.3106773 Test Loss: 0.4473425\n",
      "Validation loss decreased (1.315203 --> 1.310677).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 76.29879021644592\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.4667432 Vali Loss: 1.3123024 Test Loss: 0.4460039\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 75.8613452911377\n",
      "Epoch: 7, Steps: 256 | Train Loss: 0.4660979 Vali Loss: 1.3120013 Test Loss: 0.4472001\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 78.2560248374939\n",
      "Epoch: 8, Steps: 256 | Train Loss: 0.4656697 Vali Loss: 1.3124371 Test Loss: 0.4460172\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 7) (79, 32, 336, 7)\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "mse:0.447342187166214, mae:0.45934081077575684\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on ETTh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'checkpoints': './checkpoints/', 'features': 'M', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 5, 14, 15, 17, 19, 25, 26, 28, 41, 48, 51, 59, 64, 67, 73, 74, 78, 85, 97, 104, 105, 114, 118, 131, 136, 143, 146, 151, 158, 184, 190, 191, 221, 223, 224, 225, 232, 238, 245, 250, 257, 260, 265, 272, 277, 286, 301, 304, 308, 313, 316, 319, 337, 340, 342, 346, 350, 355, 361, 367, 373, 375, 383]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[9, 10, 11, 12, 13, 14, 16, 20, 26, 30, 32, 40, 58, 59, 73, 82, 88, 90, 94, 100, 107, 114, 116, 145, 146, 153, 159, 164, 167, 170, 171, 172, 173, 192, 193, 201, 217, 225, 229, 241, 247, 259, 264, 265, 274, 276, 279, 283, 284, 288, 290, 294, 303, 314, 338, 344, 345, 357, 358, 362, 366, 371, 378, 382]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_ETTh1_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 101.24715113639832\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.6367551 Vali Loss: 1.5729579 Test Loss: 0.4878041\n",
      "Validation loss decreased (inf --> 1.572958).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 98.51539087295532\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.5906034 Vali Loss: 1.5694159 Test Loss: 0.4806972\n",
      "Validation loss decreased (1.572958 --> 1.569416).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 99.84184265136719\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.5733282 Vali Loss: 1.5646377 Test Loss: 0.4869906\n",
      "Validation loss decreased (1.569416 --> 1.564638).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 100.64149713516235\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.5670669 Vali Loss: 1.5663128 Test Loss: 0.4790223\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 98.86827993392944\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.5640362 Vali Loss: 1.5723960 Test Loss: 0.4767770\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 99.3767192363739\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.5621091 Vali Loss: 1.5686775 Test Loss: 0.4775060\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 7) (67, 32, 720, 7)\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "mse:0.48699042201042175, mae:0.5026131272315979\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 59.44682574272156\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.1987707 Vali Loss: 0.1529904 Test Loss: 0.1311541\n",
      "Validation loss decreased (inf --> 0.152990).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 57.80388522148132\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.1418418 Vali Loss: 0.1384751 Test Loss: 0.1147639\n",
      "Validation loss decreased (0.152990 --> 0.138475).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 60.5586633682251\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.1282357 Vali Loss: 0.1264990 Test Loss: 0.1091097\n",
      "Validation loss decreased (0.138475 --> 0.126499).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 59.5587317943573\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.1241484 Vali Loss: 0.1202716 Test Loss: 0.1069188\n",
      "Validation loss decreased (0.126499 --> 0.120272).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 61.157426595687866\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.1223410 Vali Loss: 0.1187763 Test Loss: 0.1064698\n",
      "Validation loss decreased (0.120272 --> 0.118776).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 58.642672061920166\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.1209157 Vali Loss: 0.1172369 Test Loss: 0.1057374\n",
      "Validation loss decreased (0.118776 --> 0.117237).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 60.710952281951904\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.1202025 Vali Loss: 0.1183713 Test Loss: 0.1054025\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 57.89907717704773\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.1200016 Vali Loss: 0.1183123 Test Loss: 0.1051835\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 59.63353109359741\n",
      "Epoch: 9, Steps: 401 | Train Loss: 0.1197625 Vali Loss: 0.1175143 Test Loss: 0.1051936\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.10573741048574448, mae:0.19346113502979279\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 69.10120296478271\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.2110086 Vali Loss: 0.1729396 Test Loss: 0.1495688\n",
      "Validation loss decreased (inf --> 0.172940).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 68.00060939788818\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.1577042 Vali Loss: 0.1664874 Test Loss: 0.1340120\n",
      "Validation loss decreased (0.172940 --> 0.166487).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 68.34809446334839\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.1468234 Vali Loss: 0.1585644 Test Loss: 0.1284362\n",
      "Validation loss decreased (0.166487 --> 0.158564).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 68.671391248703\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.1435376 Vali Loss: 0.1538096 Test Loss: 0.1255010\n",
      "Validation loss decreased (0.158564 --> 0.153810).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 68.04718971252441\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.1415012 Vali Loss: 0.1518487 Test Loss: 0.1244460\n",
      "Validation loss decreased (0.153810 --> 0.151849).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 67.05621767044067\n",
      "Epoch: 6, Steps: 400 | Train Loss: 0.1402992 Vali Loss: 0.1515416 Test Loss: 0.1235832\n",
      "Validation loss decreased (0.151849 --> 0.151542).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 66.76327323913574\n",
      "Epoch: 7, Steps: 400 | Train Loss: 0.1397730 Vali Loss: 0.1510477 Test Loss: 0.1235366\n",
      "Validation loss decreased (0.151542 --> 0.151048).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 69.09465265274048\n",
      "Epoch: 8, Steps: 400 | Train Loss: 0.1396742 Vali Loss: 0.1509032 Test Loss: 0.1241275\n",
      "Validation loss decreased (0.151048 --> 0.150903).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 68.90346169471741\n",
      "Epoch: 9, Steps: 400 | Train Loss: 0.1393394 Vali Loss: 0.1508232 Test Loss: 0.1236984\n",
      "Validation loss decreased (0.150903 --> 0.150823).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 68.51344704627991\n",
      "Epoch: 10, Steps: 400 | Train Loss: 0.1393318 Vali Loss: 0.1506597 Test Loss: 0.1236928\n",
      "Validation loss decreased (0.150823 --> 0.150660).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 66.43047571182251\n",
      "Epoch: 11, Steps: 400 | Train Loss: 0.1392022 Vali Loss: 0.1507034 Test Loss: 0.1236404\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 67.42133784294128\n",
      "Epoch: 12, Steps: 400 | Train Loss: 0.1393399 Vali Loss: 0.1507117 Test Loss: 0.1236559\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 66.43635988235474\n",
      "Epoch: 13, Steps: 400 | Train Loss: 0.1392960 Vali Loss: 0.1507491 Test Loss: 0.1236422\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.12369284778833389, mae:0.20493613183498383\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 17, 20, 22, 26, 28, 29, 30, 31, 33, 34, 36, 38, 39, 41, 42, 43, 44, 45, 47, 48, 51, 53, 57, 58, 60, 66, 69, 70, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 91, 93, 95, 97, 98, 101, 103, 104, 105, 106, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[3, 4, 5, 7, 12, 15, 16, 17, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 32, 33, 35, 36, 38, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 56, 58, 59, 61, 62, 63, 64, 65, 69, 70, 72, 73, 74, 75, 77, 79, 80, 85, 86, 88, 92, 93, 95, 96, 97, 99, 102, 104, 106]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 93.36119842529297\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.2372275 Vali Loss: 0.2246109 Test Loss: 0.2136859\n",
      "Validation loss decreased (inf --> 0.224611).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 91.7676568031311\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.1796970 Vali Loss: 0.1975957 Test Loss: 0.1638055\n",
      "Validation loss decreased (0.224611 --> 0.197596).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 92.41746687889099\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.1683904 Vali Loss: 0.1977332 Test Loss: 0.1696886\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 92.72800350189209\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.1653937 Vali Loss: 0.1943672 Test Loss: 0.1641614\n",
      "Validation loss decreased (0.197596 --> 0.194367).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 90.9319920539856\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.1634906 Vali Loss: 0.1916175 Test Loss: 0.1612386\n",
      "Validation loss decreased (0.194367 --> 0.191618).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 93.39889574050903\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.1624687 Vali Loss: 0.1904878 Test Loss: 0.1609138\n",
      "Validation loss decreased (0.191618 --> 0.190488).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 92.17834377288818\n",
      "Epoch: 7, Steps: 396 | Train Loss: 0.1618764 Vali Loss: 0.1907893 Test Loss: 0.1615348\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 91.47998976707458\n",
      "Epoch: 8, Steps: 396 | Train Loss: 0.1617379 Vali Loss: 0.1891079 Test Loss: 0.1579821\n",
      "Validation loss decreased (0.190488 --> 0.189108).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 92.72005581855774\n",
      "Epoch: 9, Steps: 396 | Train Loss: 0.1615401 Vali Loss: 0.1902852 Test Loss: 0.1608869\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 92.82962203025818\n",
      "Epoch: 10, Steps: 396 | Train Loss: 0.1614596 Vali Loss: 0.1900073 Test Loss: 0.1602928\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 91.5515866279602\n",
      "Epoch: 11, Steps: 396 | Train Loss: 0.1614060 Vali Loss: 0.1899900 Test Loss: 0.1600480\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.15798208117485046, mae:0.23269711434841156\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 5, 7, 9, 13, 14, 16, 20, 23, 26, 30, 32, 34, 39, 46, 50, 51, 52, 53, 59, 62, 65, 69, 70, 72, 73, 76, 80, 85, 88, 89, 92, 95, 96, 97, 100, 105, 106, 113, 114, 123, 124, 127, 129, 131, 135, 143, 145, 149, 156, 157, 160, 161, 164, 171, 174, 176, 178, 179, 180, 181, 183, 187, 190]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 3, 6, 10, 13, 15, 17, 18, 19, 20, 27, 28, 29, 33, 35, 37, 41, 49, 55, 56, 57, 58, 63, 64, 65, 66, 68, 73, 78, 79, 80, 81, 90, 93, 97, 100, 104, 109, 114, 115, 117, 123, 125, 126, 130, 131, 134, 136, 138, 139, 142, 146, 150, 151, 157, 159, 162, 163, 169, 172, 173, 186, 191]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 114.37873339653015\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.2488596 Vali Loss: 0.2525232 Test Loss: 0.2098475\n",
      "Validation loss decreased (inf --> 0.252523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 111.01910161972046\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.1892412 Vali Loss: 0.2171561 Test Loss: 0.1991579\n",
      "Validation loss decreased (0.252523 --> 0.217156).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 114.54446148872375\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.1775574 Vali Loss: 0.2170919 Test Loss: 0.2017702\n",
      "Validation loss decreased (0.217156 --> 0.217092).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 112.58011984825134\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.1735381 Vali Loss: 0.2088509 Test Loss: 0.1845132\n",
      "Validation loss decreased (0.217092 --> 0.208851).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 111.62920308113098\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.1720237 Vali Loss: 0.2089380 Test Loss: 0.1869360\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 114.41329264640808\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.1709964 Vali Loss: 0.2079418 Test Loss: 0.1868493\n",
      "Validation loss decreased (0.208851 --> 0.207942).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 113.2433910369873\n",
      "Epoch: 7, Steps: 391 | Train Loss: 0.1705936 Vali Loss: 0.2081662 Test Loss: 0.1883146\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 114.27958083152771\n",
      "Epoch: 8, Steps: 391 | Train Loss: 0.1702676 Vali Loss: 0.2089226 Test Loss: 0.1890950\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 115.21334838867188\n",
      "Epoch: 9, Steps: 391 | Train Loss: 0.1701092 Vali Loss: 0.2088655 Test Loss: 0.1895599\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.18684929609298706, mae:0.25890523195266724\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[4, 5, 14, 21, 22, 26, 29, 32, 44, 51, 54, 55, 56, 62, 65, 66, 82, 96, 99, 105, 109, 118, 120, 126, 140, 148, 155, 157, 168, 169, 174, 179, 180, 185, 190, 199, 203, 205, 211, 218, 223, 229, 235, 247, 258, 272, 279, 283, 295, 299, 301, 309, 321, 323, 326, 329, 341, 348, 349, 351, 354, 359, 370, 382]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 15, 16, 19, 25, 26, 28, 34, 43, 47, 53, 55, 56, 57, 63, 75, 86, 98, 105, 118, 124, 125, 135, 136, 139, 142, 147, 148, 153, 171, 174, 197, 199, 200, 204, 222, 226, 233, 234, 235, 239, 240, 243, 244, 246, 247, 250, 255, 260, 267, 276, 293, 295, 311, 319, 329, 336, 342, 346, 348, 351, 371, 372, 380]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 150.60063099861145\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.2691191 Vali Loss: 0.2539694 Test Loss: 0.2827206\n",
      "Validation loss decreased (inf --> 0.253969).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 150.5049033164978\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.2069146 Vali Loss: 0.2221089 Test Loss: 0.2354000\n",
      "Validation loss decreased (0.253969 --> 0.222109).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 150.74315071105957\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.1946290 Vali Loss: 0.2170856 Test Loss: 0.2273795\n",
      "Validation loss decreased (0.222109 --> 0.217086).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 151.83943510055542\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.1914161 Vali Loss: 0.2165337 Test Loss: 0.2261066\n",
      "Validation loss decreased (0.217086 --> 0.216534).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 153.3432068824768\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.1895839 Vali Loss: 0.2189696 Test Loss: 0.2364443\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 149.55594062805176\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.1886643 Vali Loss: 0.2149731 Test Loss: 0.2233962\n",
      "Validation loss decreased (0.216534 --> 0.214973).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 151.32650709152222\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.1880223 Vali Loss: 0.2145115 Test Loss: 0.2200793\n",
      "Validation loss decreased (0.214973 --> 0.214512).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 151.21100068092346\n",
      "Epoch: 8, Steps: 379 | Train Loss: 0.1877570 Vali Loss: 0.2147123 Test Loss: 0.2231766\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 151.0873920917511\n",
      "Epoch: 9, Steps: 379 | Train Loss: 0.1876113 Vali Loss: 0.2145520 Test Loss: 0.2213596\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 152.80415225028992\n",
      "Epoch: 10, Steps: 379 | Train Loss: 0.1875717 Vali Loss: 0.2150785 Test Loss: 0.2251893\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.22007936239242554, mae:0.3044557571411133\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 58.43137264251709\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.2068261 Vali Loss: 0.0686425 Test Loss: 0.0794751\n",
      "Validation loss decreased (inf --> 0.068642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 59.0591926574707\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.0809509 Vali Loss: 0.0566163 Test Loss: 0.0682201\n",
      "Validation loss decreased (0.068642 --> 0.056616).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 60.093022108078\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.0677552 Vali Loss: 0.0521582 Test Loss: 0.0597096\n",
      "Validation loss decreased (0.056616 --> 0.052158).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 61.61879563331604\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.0592457 Vali Loss: 0.0452178 Test Loss: 0.0504030\n",
      "Validation loss decreased (0.052158 --> 0.045218).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 59.38260507583618\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.0538472 Vali Loss: 0.0427302 Test Loss: 0.0486541\n",
      "Validation loss decreased (0.045218 --> 0.042730).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 57.802814960479736\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.0506675 Vali Loss: 0.0411265 Test Loss: 0.0460191\n",
      "Validation loss decreased (0.042730 --> 0.041126).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 59.75121212005615\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.0492103 Vali Loss: 0.0413594 Test Loss: 0.0468450\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 60.043391942977905\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.0485499 Vali Loss: 0.0408320 Test Loss: 0.0454283\n",
      "Validation loss decreased (0.041126 --> 0.040832).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 60.504108905792236\n",
      "Epoch: 9, Steps: 401 | Train Loss: 0.0481666 Vali Loss: 0.0402791 Test Loss: 0.0450413\n",
      "Validation loss decreased (0.040832 --> 0.040279).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 59.51370668411255\n",
      "Epoch: 10, Steps: 401 | Train Loss: 0.0479408 Vali Loss: 0.0401852 Test Loss: 0.0447848\n",
      "Validation loss decreased (0.040279 --> 0.040185).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 57.97480249404907\n",
      "Epoch: 11, Steps: 401 | Train Loss: 0.0477353 Vali Loss: 0.0401049 Test Loss: 0.0446849\n",
      "Validation loss decreased (0.040185 --> 0.040105).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 59.09093523025513\n",
      "Epoch: 12, Steps: 401 | Train Loss: 0.0480183 Vali Loss: 0.0400493 Test Loss: 0.0446500\n",
      "Validation loss decreased (0.040105 --> 0.040049).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 60.79144024848938\n",
      "Epoch: 13, Steps: 401 | Train Loss: 0.0475434 Vali Loss: 0.0400036 Test Loss: 0.0446229\n",
      "Validation loss decreased (0.040049 --> 0.040004).  Saving model ...\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 58.95346117019653\n",
      "Epoch: 14, Steps: 401 | Train Loss: 0.0476706 Vali Loss: 0.0400804 Test Loss: 0.0446172\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 59.741769552230835\n",
      "Epoch: 15, Steps: 401 | Train Loss: 0.0477440 Vali Loss: 0.0400167 Test Loss: 0.0446118\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 57.6005175113678\n",
      "Epoch: 16, Steps: 401 | Train Loss: 0.0476810 Vali Loss: 0.0400752 Test Loss: 0.0446102\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.044622935354709625, mae:0.1710953563451767\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 69.63879656791687\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.2566578 Vali Loss: 0.0838393 Test Loss: 0.1105219\n",
      "Validation loss decreased (inf --> 0.083839).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 69.49869012832642\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.1055860 Vali Loss: 0.0733991 Test Loss: 0.0893039\n",
      "Validation loss decreased (0.083839 --> 0.073399).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 68.38466119766235\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.0930528 Vali Loss: 0.0717473 Test Loss: 0.0883107\n",
      "Validation loss decreased (0.073399 --> 0.071747).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 68.34941959381104\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.0816866 Vali Loss: 0.0597361 Test Loss: 0.0750319\n",
      "Validation loss decreased (0.071747 --> 0.059736).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 68.66883826255798\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.0745677 Vali Loss: 0.0642743 Test Loss: 0.0761067\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 69.95762753486633\n",
      "Epoch: 6, Steps: 400 | Train Loss: 0.0708210 Vali Loss: 0.0608502 Test Loss: 0.0728661\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 69.85972833633423\n",
      "Epoch: 7, Steps: 400 | Train Loss: 0.0687116 Vali Loss: 0.0594798 Test Loss: 0.0718989\n",
      "Validation loss decreased (0.059736 --> 0.059480).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 67.40525698661804\n",
      "Epoch: 8, Steps: 400 | Train Loss: 0.0679528 Vali Loss: 0.0585373 Test Loss: 0.0703961\n",
      "Validation loss decreased (0.059480 --> 0.058537).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 67.01394367218018\n",
      "Epoch: 9, Steps: 400 | Train Loss: 0.0676790 Vali Loss: 0.0590107 Test Loss: 0.0709021\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 68.07035708427429\n",
      "Epoch: 10, Steps: 400 | Train Loss: 0.0673517 Vali Loss: 0.0585022 Test Loss: 0.0703803\n",
      "Validation loss decreased (0.058537 --> 0.058502).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 68.99058198928833\n",
      "Epoch: 11, Steps: 400 | Train Loss: 0.0672984 Vali Loss: 0.0584148 Test Loss: 0.0702923\n",
      "Validation loss decreased (0.058502 --> 0.058415).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 68.46066093444824\n",
      "Epoch: 12, Steps: 400 | Train Loss: 0.0672467 Vali Loss: 0.0583761 Test Loss: 0.0702400\n",
      "Validation loss decreased (0.058415 --> 0.058376).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 69.92988729476929\n",
      "Epoch: 13, Steps: 400 | Train Loss: 0.0673380 Vali Loss: 0.0583869 Test Loss: 0.0702405\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 68.1170425415039\n",
      "Epoch: 14, Steps: 400 | Train Loss: 0.0676000 Vali Loss: 0.0583668 Test Loss: 0.0702338\n",
      "Validation loss decreased (0.058376 --> 0.058367).  Saving model ...\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 69.8102753162384\n",
      "Epoch: 15, Steps: 400 | Train Loss: 0.0672681 Vali Loss: 0.0583545 Test Loss: 0.0702296\n",
      "Validation loss decreased (0.058367 --> 0.058355).  Saving model ...\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 68.29684162139893\n",
      "Epoch: 16, Steps: 400 | Train Loss: 0.0672733 Vali Loss: 0.0583548 Test Loss: 0.0702229\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.0517578125e-09\n",
      "Epoch: 17 cost time: 67.80844783782959\n",
      "Epoch: 17, Steps: 400 | Train Loss: 0.0673730 Vali Loss: 0.0583282 Test Loss: 0.0702223\n",
      "Validation loss decreased (0.058355 --> 0.058328).  Saving model ...\n",
      "Updating learning rate to 1.52587890625e-09\n",
      "Epoch: 18 cost time: 68.04567217826843\n",
      "Epoch: 18, Steps: 400 | Train Loss: 0.0671238 Vali Loss: 0.0583387 Test Loss: 0.0702219\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.62939453125e-10\n",
      "Epoch: 19 cost time: 67.98461318016052\n",
      "Epoch: 19, Steps: 400 | Train Loss: 0.0671905 Vali Loss: 0.0583406 Test Loss: 0.0702215\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.814697265625e-10\n",
      "Epoch: 20 cost time: 68.83929538726807\n",
      "Epoch: 20, Steps: 400 | Train Loss: 0.0673517 Vali Loss: 0.0583449 Test Loss: 0.0702215\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.07022228837013245, mae:0.21534501016139984\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 19, 20, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 38, 39, 40, 43, 45, 47, 50, 51, 53, 54, 55, 61, 62, 65, 66, 67, 69, 71, 74, 76, 79, 81, 83, 84, 87, 88, 91, 92, 95, 96, 97, 99, 102, 104, 105, 106, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 3, 4, 7, 8, 10, 13, 14, 19, 20, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 35, 36, 37, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 60, 61, 64, 65, 66, 68, 73, 74, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 91, 92, 94, 96, 98, 99, 100, 101, 102, 103]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 94.25541400909424\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.4023966 Vali Loss: 0.4028020 Test Loss: 0.5197109\n",
      "Validation loss decreased (inf --> 0.402802).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 90.76573944091797\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.2415968 Vali Loss: 0.3924464 Test Loss: 0.5143986\n",
      "Validation loss decreased (0.402802 --> 0.392446).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 93.56431198120117\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.2286818 Vali Loss: 0.3739435 Test Loss: 0.5007620\n",
      "Validation loss decreased (0.392446 --> 0.373944).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 92.79277205467224\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.2230959 Vali Loss: 0.3714590 Test Loss: 0.4955775\n",
      "Validation loss decreased (0.373944 --> 0.371459).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 95.93512630462646\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.2192159 Vali Loss: 0.3555765 Test Loss: 0.4707592\n",
      "Validation loss decreased (0.371459 --> 0.355576).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 91.41406011581421\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.2171656 Vali Loss: 0.3577234 Test Loss: 0.4750243\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 94.01993989944458\n",
      "Epoch: 7, Steps: 396 | Train Loss: 0.2163941 Vali Loss: 0.3615301 Test Loss: 0.4792105\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 94.75152707099915\n",
      "Epoch: 8, Steps: 396 | Train Loss: 0.2155281 Vali Loss: 0.3609864 Test Loss: 0.4785947\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.47075918316841125, mae:0.5589473247528076\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 7, 14, 15, 20, 25, 27, 28, 29, 30, 32, 35, 38, 39, 41, 43, 46, 49, 52, 58, 61, 62, 63, 65, 70, 72, 73, 74, 76, 77, 82, 83, 95, 96, 100, 103, 108, 109, 110, 113, 114, 116, 120, 126, 132, 134, 135, 140, 141, 146, 154, 159, 163, 165, 169, 170, 176, 179, 181, 182, 186, 187, 188]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 3, 7, 8, 13, 21, 25, 27, 28, 31, 38, 46, 49, 54, 62, 63, 64, 65, 67, 68, 70, 76, 78, 80, 82, 83, 85, 89, 99, 100, 104, 109, 110, 111, 114, 115, 122, 128, 130, 134, 135, 138, 139, 142, 146, 148, 156, 158, 160, 163, 167, 168, 169, 172, 175, 176, 178, 179, 183, 184, 186, 187, 189]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 113.3888258934021\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.4876117 Vali Loss: 0.5883736 Test Loss: 0.9046170\n",
      "Validation loss decreased (inf --> 0.588374).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 115.64352607727051\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.2468372 Vali Loss: 0.6216320 Test Loss: 0.9281439\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 114.00950503349304\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.2055863 Vali Loss: 0.5755582 Test Loss: 0.8703616\n",
      "Validation loss decreased (0.588374 --> 0.575558).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 113.64299607276917\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.1829799 Vali Loss: 0.5592883 Test Loss: 0.8636393\n",
      "Validation loss decreased (0.575558 --> 0.559288).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 114.94961738586426\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.1781895 Vali Loss: 0.5801232 Test Loss: 0.8816132\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 113.04990792274475\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.1762289 Vali Loss: 0.5727633 Test Loss: 0.8689538\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 113.05541515350342\n",
      "Epoch: 7, Steps: 391 | Train Loss: 0.1751259 Vali Loss: 0.5686989 Test Loss: 0.8687397\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.8636395335197449, mae:0.787218451499939\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[3, 7, 26, 30, 34, 42, 45, 55, 58, 61, 64, 107, 108, 110, 113, 124, 137, 140, 153, 155, 157, 158, 162, 164, 174, 175, 176, 184, 192, 195, 196, 198, 204, 207, 208, 211, 212, 227, 230, 243, 246, 247, 256, 265, 277, 287, 290, 307, 318, 320, 323, 325, 328, 345, 346, 347, 350, 352, 354, 358, 365, 372, 379, 383]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[7, 9, 15, 17, 20, 26, 27, 30, 32, 36, 43, 62, 71, 81, 96, 97, 102, 105, 112, 124, 129, 130, 134, 135, 145, 147, 162, 164, 180, 184, 191, 197, 201, 204, 206, 214, 215, 218, 231, 238, 239, 255, 256, 260, 270, 276, 279, 291, 296, 298, 304, 305, 306, 317, 323, 326, 328, 330, 335, 338, 345, 360, 363, 379]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 153.7495892047882\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.6867788 Vali Loss: 0.7589868 Test Loss: 0.8695918\n",
      "Validation loss decreased (inf --> 0.758987).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 151.71660947799683\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.5241085 Vali Loss: 0.7371955 Test Loss: 0.8574588\n",
      "Validation loss decreased (0.758987 --> 0.737195).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 150.12484288215637\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.5135679 Vali Loss: 0.7264537 Test Loss: 0.8468779\n",
      "Validation loss decreased (0.737195 --> 0.726454).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 153.01103019714355\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.5084675 Vali Loss: 0.7293689 Test Loss: 0.8498868\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 151.10443258285522\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.5041704 Vali Loss: 0.7255717 Test Loss: 0.8501531\n",
      "Validation loss decreased (0.726454 --> 0.725572).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 152.226909160614\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.5018545 Vali Loss: 0.7238262 Test Loss: 0.8467904\n",
      "Validation loss decreased (0.725572 --> 0.723826).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 152.26867699623108\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.5005407 Vali Loss: 0.7235832 Test Loss: 0.8466174\n",
      "Validation loss decreased (0.723826 --> 0.723583).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 151.70818877220154\n",
      "Epoch: 8, Steps: 379 | Train Loss: 0.4997195 Vali Loss: 0.7229574 Test Loss: 0.8461223\n",
      "Validation loss decreased (0.723583 --> 0.722957).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 153.06881880760193\n",
      "Epoch: 9, Steps: 379 | Train Loss: 0.4993857 Vali Loss: 0.7226989 Test Loss: 0.8457575\n",
      "Validation loss decreased (0.722957 --> 0.722699).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 150.0866973400116\n",
      "Epoch: 10, Steps: 379 | Train Loss: 0.4993571 Vali Loss: 0.7226591 Test Loss: 0.8456959\n",
      "Validation loss decreased (0.722699 --> 0.722659).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 151.0908763408661\n",
      "Epoch: 11, Steps: 379 | Train Loss: 0.4990647 Vali Loss: 0.7226876 Test Loss: 0.8456461\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 152.30340909957886\n",
      "Epoch: 12, Steps: 379 | Train Loss: 0.4990398 Vali Loss: 0.7225677 Test Loss: 0.8456403\n",
      "Validation loss decreased (0.722659 --> 0.722568).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 150.63439345359802\n",
      "Epoch: 13, Steps: 379 | Train Loss: 0.4990905 Vali Loss: 0.7225208 Test Loss: 0.8456250\n",
      "Validation loss decreased (0.722568 --> 0.722521).  Saving model ...\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 152.88920640945435\n",
      "Epoch: 14, Steps: 379 | Train Loss: 0.4990369 Vali Loss: 0.7226302 Test Loss: 0.8456233\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 174.15884017944336\n",
      "Epoch: 15, Steps: 379 | Train Loss: 0.4990583 Vali Loss: 0.7223616 Test Loss: 0.8456216\n",
      "Validation loss decreased (0.722521 --> 0.722362).  Saving model ...\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 151.60770750045776\n",
      "Epoch: 16, Steps: 379 | Train Loss: 0.4992102 Vali Loss: 0.7225592 Test Loss: 0.8456144\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.0517578125e-09\n",
      "Epoch: 17 cost time: 153.19684863090515\n",
      "Epoch: 17, Steps: 379 | Train Loss: 0.4991878 Vali Loss: 0.7226588 Test Loss: 0.8456132\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.52587890625e-09\n",
      "Epoch: 18 cost time: 149.02688884735107\n",
      "Epoch: 18, Steps: 379 | Train Loss: 0.4989219 Vali Loss: 0.7228532 Test Loss: 0.8456142\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.8456218242645264, mae:0.7587440609931946\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 61.88624811172485\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.0228145 Vali Loss: 0.0037023 Test Loss: 0.0038884\n",
      "Validation loss decreased (inf --> 0.003702).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 63.51071000099182\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.0042333 Vali Loss: 0.0035908 Test Loss: 0.0049277\n",
      "Validation loss decreased (0.003702 --> 0.003591).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 63.43566083908081\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.0025761 Vali Loss: 0.0035054 Test Loss: 0.0049411\n",
      "Validation loss decreased (0.003591 --> 0.003505).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 61.572436809539795\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.0023397 Vali Loss: 0.0036853 Test Loss: 0.0052487\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 61.63496422767639\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.0022464 Vali Loss: 0.0033844 Test Loss: 0.0048576\n",
      "Validation loss decreased (0.003505 --> 0.003384).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 58.96178364753723\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.0021863 Vali Loss: 0.0034300 Test Loss: 0.0049179\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 58.69012475013733\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.0021493 Vali Loss: 0.0033909 Test Loss: 0.0048723\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 60.466662883758545\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.0021366 Vali Loss: 0.0033761 Test Loss: 0.0048645\n",
      "Validation loss decreased (0.003384 --> 0.003376).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 58.47988724708557\n",
      "Epoch: 9, Steps: 401 | Train Loss: 0.0021368 Vali Loss: 0.0034611 Test Loss: 0.0049540\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 58.71887755393982\n",
      "Epoch: 10, Steps: 401 | Train Loss: 0.0021189 Vali Loss: 0.0034794 Test Loss: 0.0049852\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 58.2710325717926\n",
      "Epoch: 11, Steps: 401 | Train Loss: 0.0021241 Vali Loss: 0.0034621 Test Loss: 0.0049606\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.0048644812777638435, mae:0.0595906563103199\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 69.56833481788635\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.0298419 Vali Loss: 0.0046586 Test Loss: 0.0051158\n",
      "Validation loss decreased (inf --> 0.004659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 71.0808641910553\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.0061691 Vali Loss: 0.0039473 Test Loss: 0.0047675\n",
      "Validation loss decreased (0.004659 --> 0.003947).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 67.22265148162842\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.0054480 Vali Loss: 0.0039407 Test Loss: 0.0045333\n",
      "Validation loss decreased (0.003947 --> 0.003941).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 67.5294725894928\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.0051496 Vali Loss: 0.0045045 Test Loss: 0.0052150\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 68.12941217422485\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.0050043 Vali Loss: 0.0046477 Test Loss: 0.0053197\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 71.03295159339905\n",
      "Epoch: 6, Steps: 400 | Train Loss: 0.0049390 Vali Loss: 0.0039759 Test Loss: 0.0045723\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.004533267579972744, mae:0.05557721108198166\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 3, 7, 8, 10, 11, 14, 16, 18, 19, 22, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 64, 68, 71, 72, 73, 74, 75, 77, 82, 84, 86, 87, 88, 90, 91, 92, 93, 95, 96, 98, 100, 105, 106, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 5, 6, 9, 11, 13, 14, 16, 17, 19, 22, 27, 29, 31, 32, 33, 36, 38, 39, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 62, 64, 65, 66, 70, 71, 72, 73, 77, 78, 79, 81, 82, 83, 84, 86, 88, 89, 90, 92, 94, 95, 96, 97, 99, 100, 103, 105, 106]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 94.60595488548279\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.0292320 Vali Loss: 0.0141476 Test Loss: 0.0176393\n",
      "Validation loss decreased (inf --> 0.014148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 93.04640340805054\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.0110622 Vali Loss: 0.0156980 Test Loss: 0.0198690\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 92.6189284324646\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.0103238 Vali Loss: 0.0164215 Test Loss: 0.0207732\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 93.040212392807\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.0100401 Vali Loss: 0.0144218 Test Loss: 0.0181793\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.01763930544257164, mae:0.10766196995973587\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[3, 4, 6, 9, 14, 16, 24, 26, 28, 29, 30, 31, 33, 41, 42, 44, 48, 49, 51, 55, 56, 59, 62, 73, 74, 77, 78, 83, 84, 88, 92, 96, 101, 102, 104, 105, 106, 109, 114, 116, 117, 120, 122, 125, 127, 128, 129, 132, 133, 136, 137, 138, 143, 148, 152, 153, 161, 162, 167, 169, 173, 176, 183, 187]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 3, 10, 13, 19, 20, 24, 27, 28, 30, 31, 34, 37, 41, 43, 44, 46, 51, 52, 53, 57, 58, 61, 63, 64, 69, 71, 72, 73, 89, 92, 96, 97, 98, 101, 103, 110, 112, 113, 115, 118, 119, 122, 124, 129, 130, 131, 135, 140, 142, 144, 148, 151, 153, 155, 164, 173, 175, 178, 182, 184, 187, 189]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 114.51337480545044\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.0409428 Vali Loss: 0.0387923 Test Loss: 0.0510403\n",
      "Validation loss decreased (inf --> 0.038792).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 113.68643450737\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.0168499 Vali Loss: 0.0376128 Test Loss: 0.0504045\n",
      "Validation loss decreased (0.038792 --> 0.037613).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 111.67349553108215\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.0156813 Vali Loss: 0.0341347 Test Loss: 0.0459410\n",
      "Validation loss decreased (0.037613 --> 0.034135).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 115.56565141677856\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.0151176 Vali Loss: 0.0352001 Test Loss: 0.0473894\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 111.53718996047974\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.0148763 Vali Loss: 0.0360890 Test Loss: 0.0486857\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 112.70967817306519\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.0147502 Vali Loss: 0.0350804 Test Loss: 0.0471576\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.045940954238176346, mae:0.1666465550661087\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[6, 7, 15, 20, 28, 32, 44, 46, 49, 58, 60, 80, 86, 92, 96, 98, 112, 119, 123, 131, 135, 141, 143, 145, 148, 149, 153, 160, 161, 167, 170, 172, 175, 179, 181, 184, 187, 199, 201, 202, 212, 215, 224, 242, 244, 256, 267, 268, 275, 277, 282, 290, 291, 302, 308, 309, 312, 329, 330, 331, 339, 346, 350, 351]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[2, 12, 13, 14, 20, 22, 24, 29, 32, 36, 39, 44, 50, 64, 67, 71, 72, 82, 83, 85, 88, 99, 116, 119, 140, 143, 144, 167, 174, 187, 188, 198, 199, 202, 210, 218, 219, 225, 230, 248, 252, 259, 265, 268, 271, 278, 281, 288, 291, 293, 294, 312, 316, 317, 334, 337, 344, 346, 355, 358, 360, 363, 369, 380]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 153.34744811058044\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.0506303 Vali Loss: 0.0356146 Test Loss: 0.0403203\n",
      "Validation loss decreased (inf --> 0.035615).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 152.40332412719727\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.0256134 Vali Loss: 0.0329018 Test Loss: 0.0379457\n",
      "Validation loss decreased (0.035615 --> 0.032902).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 150.13234972953796\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.0230650 Vali Loss: 0.0318994 Test Loss: 0.0358962\n",
      "Validation loss decreased (0.032902 --> 0.031899).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 151.42698216438293\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.0226613 Vali Loss: 0.0314974 Test Loss: 0.0356911\n",
      "Validation loss decreased (0.031899 --> 0.031497).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 152.42769956588745\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.0224813 Vali Loss: 0.0317388 Test Loss: 0.0358076\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 150.95989441871643\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.0224119 Vali Loss: 0.0315356 Test Loss: 0.0356539\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 150.84988927841187\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.0223503 Vali Loss: 0.0315107 Test Loss: 0.0356661\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.035691093653440475, mae:0.1538427472114563\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_reversal_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 59.920674085617065\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.0401705 Vali Loss: 0.0221337 Test Loss: 0.0230657\n",
      "Validation loss decreased (inf --> 0.022134).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 59.14320111274719\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.0158036 Vali Loss: 0.0203539 Test Loss: 0.0194284\n",
      "Validation loss decreased (0.022134 --> 0.020354).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 59.69447207450867\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.0134282 Vali Loss: 0.0198904 Test Loss: 0.0194111\n",
      "Validation loss decreased (0.020354 --> 0.019890).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 61.16299748420715\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.0125691 Vali Loss: 0.0185979 Test Loss: 0.0181155\n",
      "Validation loss decreased (0.019890 --> 0.018598).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 58.00836992263794\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.0121441 Vali Loss: 0.0178304 Test Loss: 0.0179958\n",
      "Validation loss decreased (0.018598 --> 0.017830).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 58.445072412490845\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.0118733 Vali Loss: 0.0182978 Test Loss: 0.0179405\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 59.675262451171875\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.0117609 Vali Loss: 0.0181668 Test Loss: 0.0179839\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 58.02113676071167\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.0117047 Vali Loss: 0.0177857 Test Loss: 0.0176079\n",
      "Validation loss decreased (0.017830 --> 0.017786).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 60.69711971282959\n",
      "Epoch: 9, Steps: 401 | Train Loss: 0.0116568 Vali Loss: 0.0178588 Test Loss: 0.0177377\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 58.50407552719116\n",
      "Epoch: 10, Steps: 401 | Train Loss: 0.0116019 Vali Loss: 0.0177990 Test Loss: 0.0176840\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 60.52176308631897\n",
      "Epoch: 11, Steps: 401 | Train Loss: 0.0116386 Vali Loss: 0.0179087 Test Loss: 0.0176844\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.017607880756258965, mae:0.1064135804772377\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_reversal_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 71.17656993865967\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.0670135 Vali Loss: 0.0304825 Test Loss: 0.0312033\n",
      "Validation loss decreased (inf --> 0.030483).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 66.31762433052063\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.0195557 Vali Loss: 0.0279248 Test Loss: 0.0292463\n",
      "Validation loss decreased (0.030483 --> 0.027925).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 68.02662658691406\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.0149163 Vali Loss: 0.0314370 Test Loss: 0.0381871\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 69.27662062644958\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.0111691 Vali Loss: 0.0297868 Test Loss: 0.0364136\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 70.0732045173645\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.0107539 Vali Loss: 0.0304149 Test Loss: 0.0367457\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.029246272519230843, mae:0.13727417588233948\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 4, 6, 7, 8, 11, 12, 13, 14, 16, 18, 19, 20, 21, 22, 24, 28, 29, 31, 32, 33, 34, 35, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 53, 54, 55, 56, 57, 58, 60, 64, 67, 70, 72, 75, 76, 78, 79, 80, 84, 85, 86, 88, 89, 92, 93, 94, 95, 99, 101, 103, 106, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 4, 5, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 29, 31, 32, 33, 36, 37, 38, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 56, 60, 62, 63, 64, 67, 68, 74, 75, 76, 77, 78, 83, 84, 85, 86, 87, 88, 89, 90, 93, 95, 96, 98, 99, 102, 105]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_reversal_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 91.68695497512817\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.0749089 Vali Loss: 0.0989607 Test Loss: 0.1025710\n",
      "Validation loss decreased (inf --> 0.098961).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 94.57424139976501\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.0450773 Vali Loss: 0.1070214 Test Loss: 0.1092079\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 95.81341004371643\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.0429984 Vali Loss: 0.0971309 Test Loss: 0.1054819\n",
      "Validation loss decreased (0.098961 --> 0.097131).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 91.84808444976807\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.0421608 Vali Loss: 0.0977441 Test Loss: 0.1034074\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 93.47177267074585\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.0415963 Vali Loss: 0.0969303 Test Loss: 0.1028195\n",
      "Validation loss decreased (0.097131 --> 0.096930).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 93.59106850624084\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.0413856 Vali Loss: 0.0992407 Test Loss: 0.1033325\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 94.26598048210144\n",
      "Epoch: 7, Steps: 396 | Train Loss: 0.0412464 Vali Loss: 0.0975854 Test Loss: 0.1024000\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 93.22821307182312\n",
      "Epoch: 8, Steps: 396 | Train Loss: 0.0411260 Vali Loss: 0.0975694 Test Loss: 0.1028161\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.10281952470541, mae:0.2442311942577362\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 5, 12, 22, 23, 25, 29, 35, 39, 44, 45, 47, 48, 51, 57, 59, 62, 65, 72, 73, 74, 78, 82, 83, 88, 89, 90, 93, 94, 98, 100, 101, 104, 106, 110, 113, 117, 119, 121, 124, 125, 126, 130, 131, 132, 133, 134, 135, 138, 154, 158, 165, 169, 171, 172, 176, 178, 179, 180, 183, 184, 187, 188, 189]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[6, 9, 10, 13, 15, 17, 19, 20, 21, 23, 28, 31, 32, 39, 42, 46, 48, 50, 52, 53, 55, 56, 57, 61, 65, 73, 80, 84, 85, 86, 97, 100, 101, 105, 108, 113, 117, 120, 124, 125, 130, 132, 135, 137, 139, 140, 141, 142, 144, 149, 150, 151, 153, 159, 162, 163, 166, 167, 168, 173, 174, 176, 188, 189]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_reversal_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 114.0364637374878\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.1430279 Vali Loss: 0.2402590 Test Loss: 0.2396583\n",
      "Validation loss decreased (inf --> 0.240259).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 112.29693818092346\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.0821642 Vali Loss: 0.2350863 Test Loss: 0.2375984\n",
      "Validation loss decreased (0.240259 --> 0.235086).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 117.17693758010864\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.0751863 Vali Loss: 0.2176989 Test Loss: 0.2331344\n",
      "Validation loss decreased (0.235086 --> 0.217699).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 114.9445571899414\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.0721758 Vali Loss: 0.2281244 Test Loss: 0.2307718\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 112.11173176765442\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.0704625 Vali Loss: 0.2247543 Test Loss: 0.2298360\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 115.19386005401611\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.0695703 Vali Loss: 0.2262498 Test Loss: 0.2290466\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.2331344038248062, mae:0.3500434458255768\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[12, 21, 22, 28, 30, 33, 34, 36, 41, 59, 66, 68, 71, 76, 82, 86, 87, 95, 97, 103, 106, 107, 115, 121, 122, 132, 146, 152, 154, 158, 159, 169, 181, 183, 186, 191, 192, 216, 223, 226, 234, 236, 238, 249, 261, 262, 263, 272, 275, 285, 295, 298, 300, 301, 304, 315, 319, 326, 329, 330, 341, 347, 351, 363]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[10, 19, 23, 28, 32, 52, 54, 58, 67, 78, 79, 81, 88, 91, 92, 95, 101, 105, 110, 116, 117, 118, 128, 131, 141, 158, 164, 165, 168, 169, 170, 174, 179, 195, 202, 204, 208, 218, 220, 224, 225, 226, 231, 233, 250, 251, 259, 262, 266, 274, 279, 280, 284, 285, 301, 302, 312, 333, 349, 353, 362, 372, 373, 383]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_reversal_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 151.05350923538208\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.2807189 Vali Loss: 0.5876417 Test Loss: 0.4070529\n",
      "Validation loss decreased (inf --> 0.587642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 150.16270780563354\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.2139382 Vali Loss: 0.5561690 Test Loss: 0.3931277\n",
      "Validation loss decreased (0.587642 --> 0.556169).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 152.72035694122314\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.2031691 Vali Loss: 0.5260001 Test Loss: 0.4243935\n",
      "Validation loss decreased (0.556169 --> 0.526000).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 152.32572150230408\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.1976861 Vali Loss: 0.5248364 Test Loss: 0.4065206\n",
      "Validation loss decreased (0.526000 --> 0.524836).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 150.30677032470703\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.1914989 Vali Loss: 0.5209653 Test Loss: 0.3978195\n",
      "Validation loss decreased (0.524836 --> 0.520965).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 152.94141268730164\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.1850717 Vali Loss: 0.5140472 Test Loss: 0.3949850\n",
      "Validation loss decreased (0.520965 --> 0.514047).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 151.7281687259674\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.1811179 Vali Loss: 0.5160337 Test Loss: 0.3889326\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 150.1020200252533\n",
      "Epoch: 8, Steps: 379 | Train Loss: 0.1789377 Vali Loss: 0.5120655 Test Loss: 0.3902896\n",
      "Validation loss decreased (0.514047 --> 0.512066).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 151.41701912879944\n",
      "Epoch: 9, Steps: 379 | Train Loss: 0.1778901 Vali Loss: 0.5101411 Test Loss: 0.3910918\n",
      "Validation loss decreased (0.512066 --> 0.510141).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 150.85005640983582\n",
      "Epoch: 10, Steps: 379 | Train Loss: 0.1774580 Vali Loss: 0.5116476 Test Loss: 0.3891372\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 154.05554366111755\n",
      "Epoch: 11, Steps: 379 | Train Loss: 0.1771665 Vali Loss: 0.5112108 Test Loss: 0.3890328\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 150.2941164970398\n",
      "Epoch: 12, Steps: 379 | Train Loss: 0.1771325 Vali Loss: 0.5112457 Test Loss: 0.3891570\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.39109182357788086, mae:0.4988265335559845\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 60.53071975708008\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.0353735 Vali Loss: 0.0383236 Test Loss: 0.0785312\n",
      "Validation loss decreased (inf --> 0.038324).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 60.73611235618591\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.0078902 Vali Loss: 0.0171091 Test Loss: 0.0391359\n",
      "Validation loss decreased (0.038324 --> 0.017109).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 60.764567375183105\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.0055388 Vali Loss: 0.0154556 Test Loss: 0.0354159\n",
      "Validation loss decreased (0.017109 --> 0.015456).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 58.71666598320007\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.0046918 Vali Loss: 0.0132524 Test Loss: 0.0301507\n",
      "Validation loss decreased (0.015456 --> 0.013252).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 59.20347833633423\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.0042673 Vali Loss: 0.0131903 Test Loss: 0.0303198\n",
      "Validation loss decreased (0.013252 --> 0.013190).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 58.654380083084106\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.0040751 Vali Loss: 0.0124710 Test Loss: 0.0286761\n",
      "Validation loss decreased (0.013190 --> 0.012471).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 61.1691575050354\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.0039683 Vali Loss: 0.0120903 Test Loss: 0.0275002\n",
      "Validation loss decreased (0.012471 --> 0.012090).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 59.34902739524841\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.0039224 Vali Loss: 0.0119392 Test Loss: 0.0271534\n",
      "Validation loss decreased (0.012090 --> 0.011939).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 61.142847776412964\n",
      "Epoch: 9, Steps: 401 | Train Loss: 0.0038944 Vali Loss: 0.0120162 Test Loss: 0.0273187\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 59.645217180252075\n",
      "Epoch: 10, Steps: 401 | Train Loss: 0.0038958 Vali Loss: 0.0119608 Test Loss: 0.0272016\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 60.224586963653564\n",
      "Epoch: 11, Steps: 401 | Train Loss: 0.0038800 Vali Loss: 0.0119966 Test Loss: 0.0272905\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.02715339884161949, mae:0.13172799348831177\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 70.30477595329285\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.0423188 Vali Loss: 0.0737666 Test Loss: 0.1454510\n",
      "Validation loss decreased (inf --> 0.073767).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 67.90506649017334\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.0147961 Vali Loss: 0.0367488 Test Loss: 0.0730776\n",
      "Validation loss decreased (0.073767 --> 0.036749).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 68.91181540489197\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.0086943 Vali Loss: 0.0230949 Test Loss: 0.0478707\n",
      "Validation loss decreased (0.036749 --> 0.023095).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 68.53817629814148\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.0061196 Vali Loss: 0.0187787 Test Loss: 0.0413781\n",
      "Validation loss decreased (0.023095 --> 0.018779).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 68.0054862499237\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.0051680 Vali Loss: 0.0181471 Test Loss: 0.0401604\n",
      "Validation loss decreased (0.018779 --> 0.018147).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 66.84814262390137\n",
      "Epoch: 6, Steps: 400 | Train Loss: 0.0048546 Vali Loss: 0.0179040 Test Loss: 0.0395276\n",
      "Validation loss decreased (0.018147 --> 0.017904).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 69.42548489570618\n",
      "Epoch: 7, Steps: 400 | Train Loss: 0.0047103 Vali Loss: 0.0176909 Test Loss: 0.0393153\n",
      "Validation loss decreased (0.017904 --> 0.017691).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 69.16405391693115\n",
      "Epoch: 8, Steps: 400 | Train Loss: 0.0046297 Vali Loss: 0.0171093 Test Loss: 0.0381421\n",
      "Validation loss decreased (0.017691 --> 0.017109).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 68.11550617218018\n",
      "Epoch: 9, Steps: 400 | Train Loss: 0.0045839 Vali Loss: 0.0172055 Test Loss: 0.0382657\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 69.12120580673218\n",
      "Epoch: 10, Steps: 400 | Train Loss: 0.0045878 Vali Loss: 0.0172504 Test Loss: 0.0383880\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 70.27533078193665\n",
      "Epoch: 11, Steps: 400 | Train Loss: 0.0045728 Vali Loss: 0.0173128 Test Loss: 0.0384870\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.038142137229442596, mae:0.1568286269903183\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 12, 13, 14, 15, 17, 19, 20, 21, 22, 24, 30, 31, 32, 33, 34, 35, 36, 39, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 57, 58, 60, 61, 63, 64, 66, 67, 68, 69, 70, 71, 72, 76, 77, 79, 80, 81, 84, 86, 88, 89, 90, 92, 93, 96, 97, 98, 100, 102, 104, 105]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[3, 5, 10, 11, 12, 14, 16, 17, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 51, 55, 57, 58, 59, 61, 64, 66, 68, 69, 70, 71, 72, 73, 75, 77, 78, 79, 81, 83, 84, 85, 86, 87, 88, 89, 90, 96, 97, 100, 102, 106, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 91.30093955993652\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.0444001 Vali Loss: 0.0853811 Test Loss: 0.1546485\n",
      "Validation loss decreased (inf --> 0.085381).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 92.87196850776672\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.0208929 Vali Loss: 0.0767754 Test Loss: 0.1451552\n",
      "Validation loss decreased (0.085381 --> 0.076775).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 91.87318396568298\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.0135601 Vali Loss: 0.0632839 Test Loss: 0.1259105\n",
      "Validation loss decreased (0.076775 --> 0.063284).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 94.92492890357971\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.0117631 Vali Loss: 0.0605722 Test Loss: 0.1215959\n",
      "Validation loss decreased (0.063284 --> 0.060572).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 94.50122904777527\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.0109999 Vali Loss: 0.0557414 Test Loss: 0.1148267\n",
      "Validation loss decreased (0.060572 --> 0.055741).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 91.29504823684692\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.0106453 Vali Loss: 0.0558947 Test Loss: 0.1154508\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 92.0756733417511\n",
      "Epoch: 7, Steps: 396 | Train Loss: 0.0104778 Vali Loss: 0.0555764 Test Loss: 0.1145410\n",
      "Validation loss decreased (0.055741 --> 0.055576).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 92.6834728717804\n",
      "Epoch: 8, Steps: 396 | Train Loss: 0.0104064 Vali Loss: 0.0552832 Test Loss: 0.1143982\n",
      "Validation loss decreased (0.055576 --> 0.055283).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 94.85633778572083\n",
      "Epoch: 9, Steps: 396 | Train Loss: 0.0103177 Vali Loss: 0.0549907 Test Loss: 0.1140243\n",
      "Validation loss decreased (0.055283 --> 0.054991).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 91.7248375415802\n",
      "Epoch: 10, Steps: 396 | Train Loss: 0.0103106 Vali Loss: 0.0546820 Test Loss: 0.1136889\n",
      "Validation loss decreased (0.054991 --> 0.054682).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 90.89395713806152\n",
      "Epoch: 11, Steps: 396 | Train Loss: 0.0103088 Vali Loss: 0.0547020 Test Loss: 0.1136264\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 91.64695906639099\n",
      "Epoch: 12, Steps: 396 | Train Loss: 0.0102840 Vali Loss: 0.0545867 Test Loss: 0.1136151\n",
      "Validation loss decreased (0.054682 --> 0.054587).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 93.86218619346619\n",
      "Epoch: 13, Steps: 396 | Train Loss: 0.0102963 Vali Loss: 0.0546998 Test Loss: 0.1135865\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 93.67630171775818\n",
      "Epoch: 14, Steps: 396 | Train Loss: 0.0102891 Vali Loss: 0.0547147 Test Loss: 0.1135798\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 93.29539752006531\n",
      "Epoch: 15, Steps: 396 | Train Loss: 0.0103020 Vali Loss: 0.0546686 Test Loss: 0.1135363\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.11361516267061234, mae:0.2791794240474701\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 2, 4, 5, 7, 10, 12, 15, 16, 17, 18, 21, 23, 28, 40, 43, 47, 51, 52, 54, 59, 63, 64, 65, 67, 68, 69, 70, 76, 77, 80, 82, 83, 84, 90, 92, 95, 96, 101, 104, 107, 109, 110, 112, 116, 118, 121, 122, 123, 127, 136, 138, 147, 149, 155, 156, 174, 177, 178, 179, 181, 183, 185, 191]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[6, 8, 9, 22, 25, 26, 27, 31, 32, 34, 35, 38, 39, 43, 44, 46, 47, 55, 56, 58, 59, 63, 67, 68, 69, 75, 80, 81, 82, 84, 89, 92, 97, 98, 99, 103, 106, 107, 108, 110, 112, 113, 114, 116, 120, 121, 122, 130, 132, 138, 141, 143, 144, 145, 151, 166, 167, 170, 174, 176, 178, 183, 184, 190]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 114.37500214576721\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.0565684 Vali Loss: 0.1352639 Test Loss: 0.2518068\n",
      "Validation loss decreased (inf --> 0.135264).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 114.86253046989441\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.0285757 Vali Loss: 0.1211143 Test Loss: 0.2330834\n",
      "Validation loss decreased (0.135264 --> 0.121114).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 114.72996020317078\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.0258190 Vali Loss: 0.1287211 Test Loss: 0.2429210\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 111.7325644493103\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.0227375 Vali Loss: 0.1139370 Test Loss: 0.2282876\n",
      "Validation loss decreased (0.121114 --> 0.113937).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 113.40638756752014\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.0205711 Vali Loss: 0.1122436 Test Loss: 0.2267202\n",
      "Validation loss decreased (0.113937 --> 0.112244).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 114.22377181053162\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.0196819 Vali Loss: 0.1113634 Test Loss: 0.2271568\n",
      "Validation loss decreased (0.112244 --> 0.111363).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 113.9233090877533\n",
      "Epoch: 7, Steps: 391 | Train Loss: 0.0192845 Vali Loss: 0.1110254 Test Loss: 0.2270298\n",
      "Validation loss decreased (0.111363 --> 0.111025).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 116.94934344291687\n",
      "Epoch: 8, Steps: 391 | Train Loss: 0.0190689 Vali Loss: 0.1108986 Test Loss: 0.2265614\n",
      "Validation loss decreased (0.111025 --> 0.110899).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 110.02935934066772\n",
      "Epoch: 9, Steps: 391 | Train Loss: 0.0189774 Vali Loss: 0.1106386 Test Loss: 0.2265792\n",
      "Validation loss decreased (0.110899 --> 0.110639).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 112.8883547782898\n",
      "Epoch: 10, Steps: 391 | Train Loss: 0.0189179 Vali Loss: 0.1103625 Test Loss: 0.2263881\n",
      "Validation loss decreased (0.110639 --> 0.110363).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 115.9039466381073\n",
      "Epoch: 11, Steps: 391 | Train Loss: 0.0189214 Vali Loss: 0.1103763 Test Loss: 0.2264442\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 114.18314361572266\n",
      "Epoch: 12, Steps: 391 | Train Loss: 0.0189060 Vali Loss: 0.1104050 Test Loss: 0.2263892\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 114.47247743606567\n",
      "Epoch: 13, Steps: 391 | Train Loss: 0.0188785 Vali Loss: 0.1103266 Test Loss: 0.2263961\n",
      "Validation loss decreased (0.110363 --> 0.110327).  Saving model ...\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 113.41781210899353\n",
      "Epoch: 14, Steps: 391 | Train Loss: 0.0188795 Vali Loss: 0.1103409 Test Loss: 0.2263540\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 115.65186977386475\n",
      "Epoch: 15, Steps: 391 | Train Loss: 0.0188803 Vali Loss: 0.1103863 Test Loss: 0.2263581\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 112.60853171348572\n",
      "Epoch: 16, Steps: 391 | Train Loss: 0.0188860 Vali Loss: 0.1102362 Test Loss: 0.2263536\n",
      "Validation loss decreased (0.110327 --> 0.110236).  Saving model ...\n",
      "Updating learning rate to 3.0517578125e-09\n",
      "Epoch: 17 cost time: 116.77280783653259\n",
      "Epoch: 17, Steps: 391 | Train Loss: 0.0188814 Vali Loss: 0.1103993 Test Loss: 0.2263605\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.52587890625e-09\n",
      "Epoch: 18 cost time: 111.59157276153564\n",
      "Epoch: 18, Steps: 391 | Train Loss: 0.0188625 Vali Loss: 0.1103777 Test Loss: 0.2263613\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.62939453125e-10\n",
      "Epoch: 19 cost time: 113.94652605056763\n",
      "Epoch: 19, Steps: 391 | Train Loss: 0.0188759 Vali Loss: 0.1103864 Test Loss: 0.2263620\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.22635361552238464, mae:0.3907318115234375\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 3, 5, 12, 13, 20, 23, 35, 56, 60, 70, 71, 75, 82, 96, 103, 112, 115, 124, 139, 144, 148, 150, 151, 157, 173, 187, 189, 192, 193, 195, 198, 216, 223, 225, 226, 229, 232, 234, 237, 238, 244, 255, 264, 274, 283, 287, 298, 300, 305, 306, 308, 311, 321, 322, 325, 339, 345, 355, 367, 371, 378, 380]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 10, 15, 23, 31, 32, 34, 38, 43, 47, 55, 60, 62, 63, 68, 71, 74, 80, 98, 106, 109, 112, 113, 115, 124, 134, 145, 151, 170, 171, 180, 182, 184, 185, 186, 189, 190, 199, 202, 216, 218, 219, 220, 240, 244, 249, 253, 269, 279, 302, 305, 308, 315, 322, 324, 326, 332, 338, 345, 352, 358, 360, 365, 383]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 152.41388463974\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.0532124 Vali Loss: 0.1253151 Test Loss: 0.2469149\n",
      "Validation loss decreased (inf --> 0.125315).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 152.79368352890015\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.0189638 Vali Loss: 0.1211251 Test Loss: 0.2400998\n",
      "Validation loss decreased (0.125315 --> 0.121125).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 149.5133728981018\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.0177342 Vali Loss: 0.1215703 Test Loss: 0.2411307\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 150.50377821922302\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.0172359 Vali Loss: 0.1105204 Test Loss: 0.2260745\n",
      "Validation loss decreased (0.121125 --> 0.110520).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 151.35050225257874\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.0169211 Vali Loss: 0.1133449 Test Loss: 0.2282993\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 151.683913230896\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.0167301 Vali Loss: 0.1141733 Test Loss: 0.2285312\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 150.8034999370575\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.0166188 Vali Loss: 0.1133903 Test Loss: 0.2274438\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.2260744422674179, mae:0.38856372237205505\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_reversal_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 60.61620283126831\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.0405549 Vali Loss: 0.2057856 Test Loss: 0.3751359\n",
      "Validation loss decreased (inf --> 0.205786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 59.74930715560913\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.0155731 Vali Loss: 0.1419080 Test Loss: 0.2881297\n",
      "Validation loss decreased (0.205786 --> 0.141908).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 60.27839970588684\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.0081457 Vali Loss: 0.1362832 Test Loss: 0.2823275\n",
      "Validation loss decreased (0.141908 --> 0.136283).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 60.03082776069641\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.0068830 Vali Loss: 0.1359508 Test Loss: 0.2817340\n",
      "Validation loss decreased (0.136283 --> 0.135951).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 59.4575138092041\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.0064993 Vali Loss: 0.1320523 Test Loss: 0.2785085\n",
      "Validation loss decreased (0.135951 --> 0.132052).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 61.00469636917114\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.0063527 Vali Loss: 0.1324688 Test Loss: 0.2775018\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 59.21776461601257\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.0062530 Vali Loss: 0.1338008 Test Loss: 0.2768524\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 59.229297399520874\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.0062110 Vali Loss: 0.1327767 Test Loss: 0.2774501\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.2785085439682007, mae:0.2941352128982544\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_reversal_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 70.01117753982544\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.0506473 Vali Loss: 0.2265587 Test Loss: 0.4326788\n",
      "Validation loss decreased (inf --> 0.226559).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 69.09825038909912\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.0153333 Vali Loss: 0.1743646 Test Loss: 0.3602331\n",
      "Validation loss decreased (0.226559 --> 0.174365).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 69.82922172546387\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.0104398 Vali Loss: 0.1689037 Test Loss: 0.3542697\n",
      "Validation loss decreased (0.174365 --> 0.168904).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 69.26936626434326\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.0088111 Vali Loss: 0.1655127 Test Loss: 0.3477826\n",
      "Validation loss decreased (0.168904 --> 0.165513).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 69.33525681495667\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.0081708 Vali Loss: 0.1685346 Test Loss: 0.3501271\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 71.62722134590149\n",
      "Epoch: 6, Steps: 400 | Train Loss: 0.0078545 Vali Loss: 0.1663846 Test Loss: 0.3486870\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 71.57784748077393\n",
      "Epoch: 7, Steps: 400 | Train Loss: 0.0077164 Vali Loss: 0.1661708 Test Loss: 0.3478517\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.34778252243995667, mae:0.3370762765407562\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 3, 7, 8, 12, 14, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 31, 33, 35, 36, 37, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 57, 60, 61, 63, 64, 65, 68, 69, 71, 72, 73, 74, 75, 81, 83, 84, 85, 89, 90, 91, 93, 94, 95, 97, 98, 101, 103, 104, 105, 106]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 19, 21, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 37, 40, 41, 43, 48, 51, 52, 54, 56, 57, 59, 62, 63, 64, 66, 67, 68, 71, 75, 76, 77, 78, 81, 84, 87, 90, 91, 92, 93, 94, 96, 98, 99, 100, 102, 103, 104, 106, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_reversal_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 92.93467259407043\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.0679234 Vali Loss: 0.4011059 Test Loss: 0.6934277\n",
      "Validation loss decreased (inf --> 0.401106).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 90.8153429031372\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.0304937 Vali Loss: 0.4102021 Test Loss: 0.7046237\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 90.43287348747253\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.0245225 Vali Loss: 0.4006408 Test Loss: 0.6946273\n",
      "Validation loss decreased (0.401106 --> 0.400641).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 92.96437048912048\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.0226451 Vali Loss: 0.3983459 Test Loss: 0.7000499\n",
      "Validation loss decreased (0.400641 --> 0.398346).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 92.34062385559082\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.0216334 Vali Loss: 0.4008483 Test Loss: 0.7040514\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 91.24964118003845\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.0211967 Vali Loss: 0.4003155 Test Loss: 0.7010239\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 92.48243546485901\n",
      "Epoch: 7, Steps: 396 | Train Loss: 0.0209648 Vali Loss: 0.3988019 Test Loss: 0.7023948\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.7000499963760376, mae:0.5358109474182129\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 3, 5, 6, 7, 8, 10, 12, 13, 17, 18, 23, 26, 27, 31, 38, 40, 46, 49, 59, 60, 61, 62, 66, 67, 70, 75, 77, 79, 82, 85, 86, 87, 89, 94, 97, 99, 100, 103, 106, 107, 109, 111, 112, 114, 121, 122, 125, 128, 129, 138, 140, 142, 152, 153, 156, 158, 166, 170, 174, 181, 186, 187, 191]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 4, 6, 8, 10, 14, 16, 19, 21, 22, 23, 25, 29, 34, 37, 40, 50, 55, 57, 59, 61, 64, 67, 73, 79, 80, 83, 86, 88, 94, 96, 100, 111, 119, 122, 125, 126, 131, 133, 136, 137, 142, 143, 144, 145, 148, 149, 153, 154, 156, 157, 159, 161, 162, 168, 170, 175, 176, 179, 183, 184, 185]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_reversal_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 114.03545451164246\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.0792052 Vali Loss: 0.6518425 Test Loss: 1.1241977\n",
      "Validation loss decreased (inf --> 0.651842).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 110.36332488059998\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.0436794 Vali Loss: 0.6237646 Test Loss: 1.0947427\n",
      "Validation loss decreased (0.651842 --> 0.623765).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 113.9103741645813\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.0410187 Vali Loss: 0.6245063 Test Loss: 1.0930215\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 115.8397946357727\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.0392750 Vali Loss: 0.6237597 Test Loss: 1.0970979\n",
      "Validation loss decreased (0.623765 --> 0.623760).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 109.78019094467163\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.0383437 Vali Loss: 0.6241511 Test Loss: 1.0930823\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 114.25630784034729\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.0376615 Vali Loss: 0.6218606 Test Loss: 1.0976443\n",
      "Validation loss decreased (0.623760 --> 0.621861).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 118.29690718650818\n",
      "Epoch: 7, Steps: 391 | Train Loss: 0.0372964 Vali Loss: 0.6247255 Test Loss: 1.0978506\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 112.65424990653992\n",
      "Epoch: 8, Steps: 391 | Train Loss: 0.0370936 Vali Loss: 0.6255807 Test Loss: 1.0990151\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 112.07039070129395\n",
      "Epoch: 9, Steps: 391 | Train Loss: 0.0369846 Vali Loss: 0.6250312 Test Loss: 1.0993005\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:1.097644567489624, mae:0.757301926612854\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 5, 6, 10, 11, 12, 18, 19, 21, 34, 37, 46, 55, 56, 57, 58, 59, 73, 75, 81, 84, 95, 100, 101, 105, 109, 116, 136, 144, 148, 149, 151, 155, 157, 160, 164, 165, 167, 184, 185, 188, 196, 237, 241, 250, 258, 261, 270, 273, 276, 278, 290, 299, 300, 322, 343, 345, 346, 358, 369, 371, 372, 379]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[4, 5, 18, 19, 24, 29, 31, 36, 37, 39, 43, 45, 47, 48, 51, 54, 56, 69, 79, 84, 86, 108, 115, 116, 122, 124, 134, 137, 147, 173, 174, 177, 185, 192, 199, 202, 220, 229, 235, 247, 258, 261, 272, 273, 282, 294, 300, 303, 319, 320, 325, 336, 340, 343, 344, 347, 363, 364, 368, 372, 375, 379, 382, 383]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_reversal_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 145.77199840545654\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.0739664 Vali Loss: 1.2338747 Test Loss: 2.1779213\n",
      "Validation loss decreased (inf --> 1.233875).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 150.48611426353455\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.0479071 Vali Loss: 1.2292317 Test Loss: 2.1857502\n",
      "Validation loss decreased (1.233875 --> 1.229232).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 153.1161711215973\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.0456761 Vali Loss: 1.2269183 Test Loss: 2.1997340\n",
      "Validation loss decreased (1.229232 --> 1.226918).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 153.7033851146698\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.0437757 Vali Loss: 1.2476000 Test Loss: 2.2649009\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 150.90673542022705\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.0426561 Vali Loss: 1.2533790 Test Loss: 2.2838154\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 147.46567749977112\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.0423430 Vali Loss: 1.2527252 Test Loss: 2.2801552\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:2.1997337341308594, mae:1.237791895866394\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on ETTh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'checkpoints': './checkpoints/', 'features': 'M', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "Epoch: 1 cost time: 39.4292471408844\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.3560937 Vali Loss: 0.5693879 Test Loss: 0.3421759\n",
      "Validation loss decreased (inf --> 0.569388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 38.109734773635864\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.3079579 Vali Loss: 0.5634654 Test Loss: 0.3359944\n",
      "Validation loss decreased (0.569388 --> 0.563465).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 38.15110158920288\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.2925668 Vali Loss: 0.5403578 Test Loss: 0.3182344\n",
      "Validation loss decreased (0.563465 --> 0.540358).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 41.025821924209595\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.2854273 Vali Loss: 0.5400949 Test Loss: 0.3167158\n",
      "Validation loss decreased (0.540358 --> 0.540095).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 40.4438898563385\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.2814595 Vali Loss: 0.5396610 Test Loss: 0.3146743\n",
      "Validation loss decreased (0.540095 --> 0.539661).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 38.570671796798706\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.2794973 Vali Loss: 0.5357214 Test Loss: 0.3139231\n",
      "Validation loss decreased (0.539661 --> 0.535721).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 39.461986780166626\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.2783551 Vali Loss: 0.5397990 Test Loss: 0.3149660\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 39.55534791946411\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.2780562 Vali Loss: 0.5378606 Test Loss: 0.3141928\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 40.09894609451294\n",
      "Epoch: 9, Steps: 266 | Train Loss: 0.2776142 Vali Loss: 0.5380682 Test Loss: 0.3144516\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "mse:0.31392303109169006, mae:0.38027849793434143\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on ETTh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'checkpoints': './checkpoints/', 'features': 'M', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_ETTh1_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "Epoch: 1 cost time: 45.63693833351135\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.3820184 Vali Loss: 0.6472998 Test Loss: 0.3544668\n",
      "Validation loss decreased (inf --> 0.647300).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 44.80087423324585\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.3356099 Vali Loss: 0.6379506 Test Loss: 0.3443408\n",
      "Validation loss decreased (0.647300 --> 0.637951).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 45.823063373565674\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.3226318 Vali Loss: 0.6352159 Test Loss: 0.3406995\n",
      "Validation loss decreased (0.637951 --> 0.635216).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 45.290295362472534\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.3161707 Vali Loss: 0.6251249 Test Loss: 0.3354794\n",
      "Validation loss decreased (0.635216 --> 0.625125).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 45.29592680931091\n",
      "Epoch: 5, Steps: 265 | Train Loss: 0.3129404 Vali Loss: 0.6290459 Test Loss: 0.3374685\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 45.73460865020752\n",
      "Epoch: 6, Steps: 265 | Train Loss: 0.3113267 Vali Loss: 0.6249933 Test Loss: 0.3361160\n",
      "Validation loss decreased (0.625125 --> 0.624993).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 46.47059726715088\n",
      "Epoch: 7, Steps: 265 | Train Loss: 0.3102333 Vali Loss: 0.6274818 Test Loss: 0.3360601\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 45.82109618186951\n",
      "Epoch: 8, Steps: 265 | Train Loss: 0.3098101 Vali Loss: 0.6277946 Test Loss: 0.3369080\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 43.67456293106079\n",
      "Epoch: 9, Steps: 265 | Train Loss: 0.3097281 Vali Loss: 0.6249367 Test Loss: 0.3363561\n",
      "Validation loss decreased (0.624993 --> 0.624937).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 45.95915770530701\n",
      "Epoch: 10, Steps: 265 | Train Loss: 0.3097267 Vali Loss: 0.6257203 Test Loss: 0.3363674\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 45.2721312046051\n",
      "Epoch: 11, Steps: 265 | Train Loss: 0.3095745 Vali Loss: 0.6281756 Test Loss: 0.3364649\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 45.23294258117676\n",
      "Epoch: 12, Steps: 265 | Train Loss: 0.3095619 Vali Loss: 0.6268631 Test Loss: 0.3363706\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 7) (88, 32, 48, 7)\n",
      "test shape: (2816, 48, 7) (2816, 48, 7)\n",
      "mse:0.3363560736179352, mae:0.3904569745063782\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on ETTh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'checkpoints': './checkpoints/', 'features': 'M', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 2, 3, 5, 8, 9, 10, 11, 14, 15, 16, 17, 19, 23, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 53, 54, 56, 57, 58, 62, 63, 64, 65, 66, 68, 73, 74, 75, 76, 77, 78, 80, 83, 84, 86, 87, 88, 96, 97, 98, 99, 100, 103, 105, 106, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 27, 28, 29, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 48, 49, 50, 51, 52, 56, 57, 60, 61, 64, 65, 66, 72, 76, 77, 80, 81, 82, 85, 87, 88, 92, 93, 96, 97, 100, 101, 102, 104, 106]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_ETTh1_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "Epoch: 1 cost time: 66.39172077178955\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.4663427 Vali Loss: 1.0103109 Test Loss: 0.4203082\n",
      "Validation loss decreased (inf --> 1.010311).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 65.11141180992126\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.4188976 Vali Loss: 0.9935778 Test Loss: 0.4034222\n",
      "Validation loss decreased (1.010311 --> 0.993578).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 63.84464240074158\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.4070355 Vali Loss: 0.9956070 Test Loss: 0.4074542\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 65.43893909454346\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.4015149 Vali Loss: 0.9896457 Test Loss: 0.4043758\n",
      "Validation loss decreased (0.993578 --> 0.989646).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 65.90268468856812\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.3987419 Vali Loss: 0.9922255 Test Loss: 0.4048817\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 68.1942527294159\n",
      "Epoch: 6, Steps: 261 | Train Loss: 0.3974657 Vali Loss: 0.9878474 Test Loss: 0.4054518\n",
      "Validation loss decreased (0.989646 --> 0.987847).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 64.71474766731262\n",
      "Epoch: 7, Steps: 261 | Train Loss: 0.3962649 Vali Loss: 0.9892825 Test Loss: 0.4042021\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 63.35525584220886\n",
      "Epoch: 8, Steps: 261 | Train Loss: 0.3961198 Vali Loss: 0.9887212 Test Loss: 0.4043977\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 64.44470047950745\n",
      "Epoch: 9, Steps: 261 | Train Loss: 0.3959970 Vali Loss: 0.9871507 Test Loss: 0.4039853\n",
      "Validation loss decreased (0.987847 --> 0.987151).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 64.81478762626648\n",
      "Epoch: 10, Steps: 261 | Train Loss: 0.3960051 Vali Loss: 0.9876971 Test Loss: 0.4044451\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 67.25840210914612\n",
      "Epoch: 11, Steps: 261 | Train Loss: 0.3956038 Vali Loss: 0.9878493 Test Loss: 0.4043566\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 63.427778244018555\n",
      "Epoch: 12, Steps: 261 | Train Loss: 0.3956736 Vali Loss: 0.9902205 Test Loss: 0.4043725\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 7) (84, 32, 168, 7)\n",
      "test shape: (2688, 168, 7) (2688, 168, 7)\n",
      "mse:0.40398523211479187, mae:0.43057164549827576\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on ETTh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'checkpoints': './checkpoints/', 'features': 'M', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 4, 8, 20, 27, 30, 31, 32, 33, 38, 39, 41, 42, 43, 46, 53, 54, 55, 57, 61, 65, 68, 69, 71, 72, 73, 74, 75, 77, 78, 79, 82, 86, 92, 95, 100, 103, 107, 108, 116, 119, 122, 127, 129, 133, 135, 140, 142, 144, 146, 150, 152, 159, 165, 166, 167, 168, 172, 175, 181, 186, 187, 188]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[3, 4, 5, 7, 8, 11, 20, 23, 30, 33, 38, 40, 47, 51, 53, 54, 61, 66, 75, 76, 77, 79, 85, 86, 92, 93, 94, 96, 100, 104, 108, 109, 111, 113, 114, 116, 117, 118, 120, 127, 130, 132, 133, 134, 135, 137, 139, 141, 142, 144, 147, 151, 155, 160, 161, 162, 163, 171, 173, 177, 180, 185, 186, 190]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_ETTh1_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 78.92772221565247\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.5332626 Vali Loss: 1.3265139 Test Loss: 0.4669275\n",
      "Validation loss decreased (inf --> 1.326514).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 77.21411490440369\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.4874257 Vali Loss: 1.3245035 Test Loss: 0.4561735\n",
      "Validation loss decreased (1.326514 --> 1.324504).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 79.83611369132996\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.4755731 Vali Loss: 1.3168979 Test Loss: 0.4528944\n",
      "Validation loss decreased (1.324504 --> 1.316898).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 75.26332521438599\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.4703583 Vali Loss: 1.3103958 Test Loss: 0.4538519\n",
      "Validation loss decreased (1.316898 --> 1.310396).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 76.93144059181213\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.4679912 Vali Loss: 1.3084521 Test Loss: 0.4522762\n",
      "Validation loss decreased (1.310396 --> 1.308452).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 78.06313157081604\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.4666742 Vali Loss: 1.3094897 Test Loss: 0.4498580\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 76.56650137901306\n",
      "Epoch: 7, Steps: 256 | Train Loss: 0.4660950 Vali Loss: 1.3070533 Test Loss: 0.4491669\n",
      "Validation loss decreased (1.308452 --> 1.307053).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 75.60925436019897\n",
      "Epoch: 8, Steps: 256 | Train Loss: 0.4658519 Vali Loss: 1.3080100 Test Loss: 0.4486023\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 78.61885452270508\n",
      "Epoch: 9, Steps: 256 | Train Loss: 0.4656362 Vali Loss: 1.3063020 Test Loss: 0.4483161\n",
      "Validation loss decreased (1.307053 --> 1.306302).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 77.33524584770203\n",
      "Epoch: 10, Steps: 256 | Train Loss: 0.4657095 Vali Loss: 1.3084410 Test Loss: 0.4484350\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 77.4699034690857\n",
      "Epoch: 11, Steps: 256 | Train Loss: 0.4659461 Vali Loss: 1.3079903 Test Loss: 0.4485042\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 78.73912143707275\n",
      "Epoch: 12, Steps: 256 | Train Loss: 0.4655855 Vali Loss: 1.3078882 Test Loss: 0.4484065\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 7) (79, 32, 336, 7)\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "mse:0.4483164846897125, mae:0.4611133933067322\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on ETTh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'checkpoints': './checkpoints/', 'features': 'M', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 7, 8, 15, 19, 20, 22, 25, 43, 47, 53, 71, 85, 95, 101, 110, 112, 131, 138, 139, 145, 147, 160, 161, 168, 169, 174, 175, 178, 181, 185, 187, 189, 191, 213, 217, 220, 228, 232, 248, 251, 253, 254, 255, 262, 274, 286, 290, 293, 305, 306, 312, 313, 317, 326, 333, 344, 347, 350, 352, 354, 357, 362, 373]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[9, 15, 17, 28, 37, 38, 40, 49, 55, 58, 67, 70, 77, 78, 92, 93, 95, 99, 102, 112, 114, 117, 119, 144, 147, 154, 155, 162, 169, 179, 185, 195, 205, 209, 211, 219, 226, 233, 239, 241, 247, 259, 262, 264, 273, 299, 301, 302, 303, 309, 317, 321, 323, 331, 333, 334, 341, 353, 354, 355, 360, 362, 366, 375]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_ETTh1_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 101.56728076934814\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.6390642 Vali Loss: 1.5724411 Test Loss: 0.4847057\n",
      "Validation loss decreased (inf --> 1.572441).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 96.59360098838806\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.5922822 Vali Loss: 1.5693941 Test Loss: 0.4917519\n",
      "Validation loss decreased (1.572441 --> 1.569394).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 101.9324061870575\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.5800638 Vali Loss: 1.5694731 Test Loss: 0.4751557\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 100.08907580375671\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.5757338 Vali Loss: 1.5661328 Test Loss: 0.4780923\n",
      "Validation loss decreased (1.569394 --> 1.566133).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 101.17670321464539\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.5731343 Vali Loss: 1.5687866 Test Loss: 0.4709525\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 98.83686900138855\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.5716922 Vali Loss: 1.5670183 Test Loss: 0.4696585\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 99.6847026348114\n",
      "Epoch: 7, Steps: 244 | Train Loss: 0.5707024 Vali Loss: 1.5727470 Test Loss: 0.4693733\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 7) (67, 32, 720, 7)\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "mse:0.4780922830104828, mae:0.497843474149704\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 57.64874315261841\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.2028650 Vali Loss: 0.1554452 Test Loss: 0.1368140\n",
      "Validation loss decreased (inf --> 0.155445).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 60.71033072471619\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.1423015 Vali Loss: 0.1347606 Test Loss: 0.1160570\n",
      "Validation loss decreased (0.155445 --> 0.134761).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 59.06700420379639\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.1289442 Vali Loss: 0.1221814 Test Loss: 0.1092894\n",
      "Validation loss decreased (0.134761 --> 0.122181).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 59.70687413215637\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.1248034 Vali Loss: 0.1277960 Test Loss: 0.1119031\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 60.1347451210022\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.1223444 Vali Loss: 0.1208890 Test Loss: 0.1072133\n",
      "Validation loss decreased (0.122181 --> 0.120889).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 61.0398530960083\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.1213081 Vali Loss: 0.1216538 Test Loss: 0.1064463\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 62.960747718811035\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.1209689 Vali Loss: 0.1187497 Test Loss: 0.1057242\n",
      "Validation loss decreased (0.120889 --> 0.118750).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 61.22847819328308\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.1201504 Vali Loss: 0.1187833 Test Loss: 0.1060190\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 57.81444978713989\n",
      "Epoch: 9, Steps: 401 | Train Loss: 0.1200158 Vali Loss: 0.1180892 Test Loss: 0.1058948\n",
      "Validation loss decreased (0.118750 --> 0.118089).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 57.69891381263733\n",
      "Epoch: 10, Steps: 401 | Train Loss: 0.1200639 Vali Loss: 0.1182988 Test Loss: 0.1058205\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 60.18586015701294\n",
      "Epoch: 11, Steps: 401 | Train Loss: 0.1200949 Vali Loss: 0.1187031 Test Loss: 0.1057469\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 59.77372407913208\n",
      "Epoch: 12, Steps: 401 | Train Loss: 0.1199835 Vali Loss: 0.1188160 Test Loss: 0.1057487\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.1058947741985321, mae:0.19335882365703583\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 70.82803845405579\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.2148154 Vali Loss: 0.1786389 Test Loss: 0.1469961\n",
      "Validation loss decreased (inf --> 0.178639).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 71.59412336349487\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.1578257 Vali Loss: 0.1619865 Test Loss: 0.1354518\n",
      "Validation loss decreased (0.178639 --> 0.161987).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 72.63675165176392\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.1472524 Vali Loss: 0.1572798 Test Loss: 0.1284123\n",
      "Validation loss decreased (0.161987 --> 0.157280).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 66.67839503288269\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.1441359 Vali Loss: 0.1542530 Test Loss: 0.1263210\n",
      "Validation loss decreased (0.157280 --> 0.154253).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 63.72207593917847\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.1422819 Vali Loss: 0.1547104 Test Loss: 0.1269396\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 66.58849382400513\n",
      "Epoch: 6, Steps: 400 | Train Loss: 0.1412137 Vali Loss: 0.1546915 Test Loss: 0.1266595\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 68.09507155418396\n",
      "Epoch: 7, Steps: 400 | Train Loss: 0.1409155 Vali Loss: 0.1526827 Test Loss: 0.1244747\n",
      "Validation loss decreased (0.154253 --> 0.152683).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 69.87933874130249\n",
      "Epoch: 8, Steps: 400 | Train Loss: 0.1404935 Vali Loss: 0.1528004 Test Loss: 0.1241959\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 68.92680168151855\n",
      "Epoch: 9, Steps: 400 | Train Loss: 0.1405111 Vali Loss: 0.1524713 Test Loss: 0.1245602\n",
      "Validation loss decreased (0.152683 --> 0.152471).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 70.02378749847412\n",
      "Epoch: 10, Steps: 400 | Train Loss: 0.1403387 Vali Loss: 0.1525676 Test Loss: 0.1246193\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 69.27418041229248\n",
      "Epoch: 11, Steps: 400 | Train Loss: 0.1403551 Vali Loss: 0.1525255 Test Loss: 0.1243775\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 69.21089220046997\n",
      "Epoch: 12, Steps: 400 | Train Loss: 0.1402115 Vali Loss: 0.1525250 Test Loss: 0.1244095\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.12456019222736359, mae:0.20593641698360443\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 3, 4, 5, 9, 10, 13, 17, 18, 19, 20, 27, 28, 29, 31, 33, 35, 36, 37, 40, 41, 42, 43, 47, 48, 49, 52, 53, 54, 55, 56, 58, 60, 61, 63, 66, 68, 69, 70, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 88, 90, 91, 92, 93, 95, 96, 98, 99, 100, 102, 104, 105]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 2, 5, 6, 7, 10, 11, 12, 13, 15, 17, 20, 22, 24, 25, 26, 27, 29, 31, 32, 33, 35, 37, 38, 41, 44, 46, 48, 49, 51, 52, 53, 54, 57, 59, 60, 61, 64, 66, 67, 68, 69, 70, 71, 73, 74, 75, 82, 84, 86, 87, 89, 90, 91, 93, 96, 97, 98, 100, 102, 103, 104, 105, 106]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 93.06547784805298\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.2381201 Vali Loss: 0.2166409 Test Loss: 0.1805608\n",
      "Validation loss decreased (inf --> 0.216641).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 92.02286505699158\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.1796644 Vali Loss: 0.1956821 Test Loss: 0.1689198\n",
      "Validation loss decreased (0.216641 --> 0.195682).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 96.4088921546936\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.1690852 Vali Loss: 0.1935101 Test Loss: 0.1595697\n",
      "Validation loss decreased (0.195682 --> 0.193510).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 94.03348636627197\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.1648671 Vali Loss: 0.1925153 Test Loss: 0.1604464\n",
      "Validation loss decreased (0.193510 --> 0.192515).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 94.61446905136108\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.1632318 Vali Loss: 0.1941234 Test Loss: 0.1636032\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 94.22230744361877\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.1622921 Vali Loss: 0.1906290 Test Loss: 0.1601325\n",
      "Validation loss decreased (0.192515 --> 0.190629).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 92.03839612007141\n",
      "Epoch: 7, Steps: 396 | Train Loss: 0.1618852 Vali Loss: 0.1916138 Test Loss: 0.1615802\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 96.3674385547638\n",
      "Epoch: 8, Steps: 396 | Train Loss: 0.1615785 Vali Loss: 0.1896512 Test Loss: 0.1582652\n",
      "Validation loss decreased (0.190629 --> 0.189651).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 97.50193166732788\n",
      "Epoch: 9, Steps: 396 | Train Loss: 0.1613948 Vali Loss: 0.1901625 Test Loss: 0.1599813\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 94.88268637657166\n",
      "Epoch: 10, Steps: 396 | Train Loss: 0.1613316 Vali Loss: 0.1900460 Test Loss: 0.1591242\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 90.45511412620544\n",
      "Epoch: 11, Steps: 396 | Train Loss: 0.1613264 Vali Loss: 0.1900183 Test Loss: 0.1593278\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.15826517343521118, mae:0.23380997776985168\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 2, 6, 14, 20, 21, 26, 27, 35, 36, 37, 38, 41, 46, 47, 54, 55, 59, 60, 61, 62, 63, 69, 70, 71, 73, 75, 78, 81, 82, 83, 84, 93, 95, 97, 101, 103, 106, 107, 109, 111, 114, 121, 122, 124, 125, 127, 130, 135, 136, 141, 147, 153, 158, 164, 167, 168, 173, 174, 176, 183, 186, 187, 188]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[2, 5, 6, 9, 11, 16, 18, 19, 29, 30, 34, 35, 40, 43, 45, 46, 47, 50, 55, 58, 60, 61, 62, 63, 64, 66, 68, 69, 72, 74, 75, 76, 87, 88, 89, 92, 96, 97, 100, 114, 117, 119, 123, 124, 125, 128, 130, 133, 134, 135, 143, 145, 146, 149, 150, 152, 154, 159, 160, 161, 164, 173, 179, 186]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 112.83611822128296\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.2476708 Vali Loss: 0.2416239 Test Loss: 0.2251905\n",
      "Validation loss decreased (inf --> 0.241624).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 114.55141401290894\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.1891081 Vali Loss: 0.2174883 Test Loss: 0.2043164\n",
      "Validation loss decreased (0.241624 --> 0.217488).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 111.84080410003662\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.1785199 Vali Loss: 0.2161808 Test Loss: 0.1966305\n",
      "Validation loss decreased (0.217488 --> 0.216181).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 112.87453365325928\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.1747192 Vali Loss: 0.2116852 Test Loss: 0.1934171\n",
      "Validation loss decreased (0.216181 --> 0.211685).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 113.17101788520813\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.1732683 Vali Loss: 0.2102191 Test Loss: 0.1882488\n",
      "Validation loss decreased (0.211685 --> 0.210219).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 113.89237260818481\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.1722333 Vali Loss: 0.2107868 Test Loss: 0.1888346\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 112.89122724533081\n",
      "Epoch: 7, Steps: 391 | Train Loss: 0.1717878 Vali Loss: 0.2115265 Test Loss: 0.1909584\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 113.45197343826294\n",
      "Epoch: 8, Steps: 391 | Train Loss: 0.1713792 Vali Loss: 0.2105070 Test Loss: 0.1883930\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.18824884295463562, mae:0.25947657227516174\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 2, 4, 14, 20, 23, 24, 40, 50, 54, 59, 69, 70, 73, 92, 93, 107, 121, 126, 137, 138, 142, 147, 163, 174, 183, 187, 188, 190, 194, 202, 208, 214, 230, 237, 238, 244, 246, 253, 255, 256, 265, 278, 280, 289, 292, 293, 294, 297, 304, 323, 325, 328, 334, 339, 351, 355, 358, 360, 362, 364, 368, 377, 382]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[2, 3, 8, 27, 36, 41, 45, 49, 53, 65, 66, 69, 70, 76, 79, 88, 98, 104, 105, 114, 119, 122, 132, 133, 142, 150, 151, 153, 165, 173, 177, 191, 192, 197, 201, 211, 212, 213, 215, 220, 222, 225, 235, 260, 265, 273, 288, 289, 308, 309, 318, 334, 339, 347, 357, 358, 362, 363, 367, 369, 370, 373, 374, 382]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 152.10245656967163\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.2486988 Vali Loss: 0.2525077 Test Loss: 0.2442859\n",
      "Validation loss decreased (inf --> 0.252508).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 150.0137758255005\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.1872527 Vali Loss: 0.2188831 Test Loss: 0.2025017\n",
      "Validation loss decreased (0.252508 --> 0.218883).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 150.6865315437317\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.1757146 Vali Loss: 0.2114640 Test Loss: 0.1915999\n",
      "Validation loss decreased (0.218883 --> 0.211464).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 149.35034275054932\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.1723784 Vali Loss: 0.2094813 Test Loss: 0.1887556\n",
      "Validation loss decreased (0.211464 --> 0.209481).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 151.80474615097046\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.1707160 Vali Loss: 0.2081821 Test Loss: 0.1886780\n",
      "Validation loss decreased (0.209481 --> 0.208182).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 150.84036874771118\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.1699517 Vali Loss: 0.2118916 Test Loss: 0.1850240\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 150.0798156261444\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.1694582 Vali Loss: 0.2095001 Test Loss: 0.1856755\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 151.00831866264343\n",
      "Epoch: 8, Steps: 379 | Train Loss: 0.1692599 Vali Loss: 0.2086291 Test Loss: 0.1864005\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.18867796659469604, mae:0.2582058310508728\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 61.77440023422241\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.2144586 Vali Loss: 0.0882131 Test Loss: 0.1032715\n",
      "Validation loss decreased (inf --> 0.088213).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 61.726282835006714\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.0892195 Vali Loss: 0.0693036 Test Loss: 0.0794847\n",
      "Validation loss decreased (0.088213 --> 0.069304).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 60.592284202575684\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.0708550 Vali Loss: 0.0580646 Test Loss: 0.0682695\n",
      "Validation loss decreased (0.069304 --> 0.058065).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 52.98763632774353\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.0606013 Vali Loss: 0.0463081 Test Loss: 0.0536825\n",
      "Validation loss decreased (0.058065 --> 0.046308).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 56.648327350616455\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.0547489 Vali Loss: 0.0443581 Test Loss: 0.0505465\n",
      "Validation loss decreased (0.046308 --> 0.044358).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 59.8602397441864\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.0520522 Vali Loss: 0.0413445 Test Loss: 0.0466286\n",
      "Validation loss decreased (0.044358 --> 0.041345).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 61.581151485443115\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.0506016 Vali Loss: 0.0409534 Test Loss: 0.0459407\n",
      "Validation loss decreased (0.041345 --> 0.040953).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 61.864787101745605\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.0498100 Vali Loss: 0.0409695 Test Loss: 0.0460944\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 60.97818326950073\n",
      "Epoch: 9, Steps: 401 | Train Loss: 0.0494785 Vali Loss: 0.0408788 Test Loss: 0.0458351\n",
      "Validation loss decreased (0.040953 --> 0.040879).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 55.05456185340881\n",
      "Epoch: 10, Steps: 401 | Train Loss: 0.0494295 Vali Loss: 0.0407287 Test Loss: 0.0456529\n",
      "Validation loss decreased (0.040879 --> 0.040729).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 55.17363524436951\n",
      "Epoch: 11, Steps: 401 | Train Loss: 0.0491366 Vali Loss: 0.0405479 Test Loss: 0.0456674\n",
      "Validation loss decreased (0.040729 --> 0.040548).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 59.1258385181427\n",
      "Epoch: 12, Steps: 401 | Train Loss: 0.0491435 Vali Loss: 0.0406277 Test Loss: 0.0456098\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 57.93526315689087\n",
      "Epoch: 13, Steps: 401 | Train Loss: 0.0491022 Vali Loss: 0.0405916 Test Loss: 0.0455899\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 59.36620759963989\n",
      "Epoch: 14, Steps: 401 | Train Loss: 0.0492532 Vali Loss: 0.0403309 Test Loss: 0.0455773\n",
      "Validation loss decreased (0.040548 --> 0.040331).  Saving model ...\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 59.73277759552002\n",
      "Epoch: 15, Steps: 401 | Train Loss: 0.0489704 Vali Loss: 0.0404363 Test Loss: 0.0455722\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 60.7141547203064\n",
      "Epoch: 16, Steps: 401 | Train Loss: 0.0490195 Vali Loss: 0.0404740 Test Loss: 0.0455700\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.0517578125e-09\n",
      "Epoch: 17 cost time: 58.878535985946655\n",
      "Epoch: 17, Steps: 401 | Train Loss: 0.0489319 Vali Loss: 0.0405405 Test Loss: 0.0455680\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.04557725787162781, mae:0.1733807474374771\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 67.91076493263245\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.2302533 Vali Loss: 0.0831349 Test Loss: 0.1075261\n",
      "Validation loss decreased (inf --> 0.083135).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 68.5435082912445\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.1039199 Vali Loss: 0.0829259 Test Loss: 0.0943742\n",
      "Validation loss decreased (0.083135 --> 0.082926).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 66.97291326522827\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.0868907 Vali Loss: 0.0614244 Test Loss: 0.0760378\n",
      "Validation loss decreased (0.082926 --> 0.061424).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 67.67995643615723\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.0739648 Vali Loss: 0.0613674 Test Loss: 0.0732469\n",
      "Validation loss decreased (0.061424 --> 0.061367).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 68.15194034576416\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.0665039 Vali Loss: 0.0554158 Test Loss: 0.0676013\n",
      "Validation loss decreased (0.061367 --> 0.055416).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 66.13401865959167\n",
      "Epoch: 6, Steps: 400 | Train Loss: 0.0631379 Vali Loss: 0.0531112 Test Loss: 0.0642078\n",
      "Validation loss decreased (0.055416 --> 0.053111).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 68.07691502571106\n",
      "Epoch: 7, Steps: 400 | Train Loss: 0.0615085 Vali Loss: 0.0529554 Test Loss: 0.0632035\n",
      "Validation loss decreased (0.053111 --> 0.052955).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 67.70956611633301\n",
      "Epoch: 8, Steps: 400 | Train Loss: 0.0612089 Vali Loss: 0.0522763 Test Loss: 0.0625871\n",
      "Validation loss decreased (0.052955 --> 0.052276).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 67.14874148368835\n",
      "Epoch: 9, Steps: 400 | Train Loss: 0.0607201 Vali Loss: 0.0522083 Test Loss: 0.0623658\n",
      "Validation loss decreased (0.052276 --> 0.052208).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 67.59241080284119\n",
      "Epoch: 10, Steps: 400 | Train Loss: 0.0606229 Vali Loss: 0.0522412 Test Loss: 0.0623639\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 66.9525499343872\n",
      "Epoch: 11, Steps: 400 | Train Loss: 0.0604660 Vali Loss: 0.0521002 Test Loss: 0.0622976\n",
      "Validation loss decreased (0.052208 --> 0.052100).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 68.5889081954956\n",
      "Epoch: 12, Steps: 400 | Train Loss: 0.0607042 Vali Loss: 0.0521002 Test Loss: 0.0622447\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 68.24186372756958\n",
      "Epoch: 13, Steps: 400 | Train Loss: 0.0603176 Vali Loss: 0.0521136 Test Loss: 0.0622518\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 69.75973987579346\n",
      "Epoch: 14, Steps: 400 | Train Loss: 0.0602959 Vali Loss: 0.0521018 Test Loss: 0.0622442\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.06229761987924576, mae:0.20033995807170868\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 5, 8, 10, 11, 13, 14, 15, 18, 20, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 53, 55, 57, 59, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 76, 77, 78, 80, 84, 85, 86, 87, 91, 94, 97, 99, 100, 101, 102, 104, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 3, 4, 9, 11, 12, 13, 14, 15, 21, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 37, 38, 39, 42, 43, 45, 46, 47, 48, 50, 51, 52, 53, 56, 57, 59, 60, 62, 67, 69, 70, 71, 73, 75, 76, 79, 81, 82, 84, 85, 87, 88, 91, 92, 94, 95, 96, 98, 99, 102, 103, 104, 105, 106]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 90.8220465183258\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.3305759 Vali Loss: 0.2719252 Test Loss: 0.3873199\n",
      "Validation loss decreased (inf --> 0.271925).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 89.1974720954895\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.1449595 Vali Loss: 0.2864251 Test Loss: 0.4848824\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 91.55435752868652\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.1006238 Vali Loss: 0.2927105 Test Loss: 0.4926664\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 91.1150209903717\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.0978779 Vali Loss: 0.2701624 Test Loss: 0.4658799\n",
      "Validation loss decreased (0.271925 --> 0.270162).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 92.51652669906616\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.0966533 Vali Loss: 0.2892831 Test Loss: 0.4906828\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 91.54053783416748\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.0960236 Vali Loss: 0.2815675 Test Loss: 0.4774726\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 95.32264852523804\n",
      "Epoch: 7, Steps: 396 | Train Loss: 0.0954864 Vali Loss: 0.2812835 Test Loss: 0.4753265\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.46587997674942017, mae:0.5801746249198914\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[3, 4, 12, 15, 19, 24, 29, 32, 33, 35, 36, 39, 40, 41, 42, 44, 49, 50, 52, 58, 59, 61, 64, 66, 71, 74, 75, 76, 78, 79, 83, 92, 97, 101, 108, 111, 115, 116, 119, 121, 124, 125, 126, 129, 131, 134, 138, 143, 145, 149, 152, 155, 158, 162, 163, 170, 173, 174, 176, 179, 180, 182, 184, 187]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[2, 14, 16, 17, 20, 27, 28, 29, 44, 46, 47, 49, 60, 61, 62, 63, 65, 67, 70, 71, 76, 78, 79, 83, 86, 89, 93, 96, 102, 104, 107, 115, 117, 118, 122, 123, 124, 126, 128, 129, 130, 132, 135, 139, 140, 143, 144, 147, 151, 152, 153, 154, 155, 160, 167, 169, 173, 174, 175, 179, 181, 187, 188, 189]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 112.28041577339172\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.5795221 Vali Loss: 0.7909821 Test Loss: 1.0447564\n",
      "Validation loss decreased (inf --> 0.790982).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 109.7675096988678\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.3603801 Vali Loss: 0.8141116 Test Loss: 1.0914081\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 112.7893271446228\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.3459210 Vali Loss: 0.7880391 Test Loss: 1.0586231\n",
      "Validation loss decreased (0.790982 --> 0.788039).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 114.35683536529541\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.3309527 Vali Loss: 0.7778084 Test Loss: 1.0785657\n",
      "Validation loss decreased (0.788039 --> 0.777808).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 112.89367961883545\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.3153705 Vali Loss: 0.7562907 Test Loss: 1.0652260\n",
      "Validation loss decreased (0.777808 --> 0.756291).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 111.05491495132446\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.3056508 Vali Loss: 0.7439106 Test Loss: 1.0527073\n",
      "Validation loss decreased (0.756291 --> 0.743911).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 114.05532312393188\n",
      "Epoch: 7, Steps: 391 | Train Loss: 0.3017224 Vali Loss: 0.7356894 Test Loss: 1.0465723\n",
      "Validation loss decreased (0.743911 --> 0.735689).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 113.97036170959473\n",
      "Epoch: 8, Steps: 391 | Train Loss: 0.2986094 Vali Loss: 0.7362725 Test Loss: 1.0502740\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 111.00677418708801\n",
      "Epoch: 9, Steps: 391 | Train Loss: 0.2980626 Vali Loss: 0.7383066 Test Loss: 1.0543379\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 114.79521679878235\n",
      "Epoch: 10, Steps: 391 | Train Loss: 0.2978796 Vali Loss: 0.7362310 Test Loss: 1.0520726\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:1.0465726852416992, mae:0.81715327501297\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 8, 9, 13, 17, 23, 26, 27, 29, 34, 37, 48, 58, 73, 91, 92, 103, 107, 112, 117, 118, 121, 126, 140, 148, 149, 150, 151, 183, 185, 186, 196, 200, 208, 209, 213, 232, 241, 244, 247, 256, 264, 276, 285, 288, 291, 295, 298, 310, 331, 337, 339, 347, 348, 349, 353, 355, 362, 364, 366, 370, 371, 381, 383]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[4, 9, 11, 18, 19, 39, 56, 62, 68, 72, 73, 76, 89, 90, 94, 117, 128, 129, 138, 147, 149, 170, 171, 172, 177, 184, 188, 190, 196, 198, 201, 205, 213, 217, 227, 229, 231, 235, 247, 251, 256, 259, 262, 263, 265, 268, 270, 276, 285, 286, 304, 316, 321, 323, 343, 346, 350, 353, 356, 358, 363, 364, 373, 374]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 154.25474500656128\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.3890654 Vali Loss: 0.5652149 Test Loss: 0.8131747\n",
      "Validation loss decreased (inf --> 0.565215).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 147.48589158058167\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.1450261 Vali Loss: 0.5424733 Test Loss: 0.7636646\n",
      "Validation loss decreased (0.565215 --> 0.542473).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 152.49836206436157\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.1412507 Vali Loss: 0.5129174 Test Loss: 0.7374701\n",
      "Validation loss decreased (0.542473 --> 0.512917).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 148.73332118988037\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.1397857 Vali Loss: 0.5323688 Test Loss: 0.7602255\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 149.50840973854065\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.1390182 Vali Loss: 0.5237237 Test Loss: 0.7488002\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 154.00810384750366\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.1387904 Vali Loss: 0.5318374 Test Loss: 0.7579790\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.7374702095985413, mae:0.6945299506187439\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 57.64921045303345\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.0278311 Vali Loss: 0.0046833 Test Loss: 0.0050458\n",
      "Validation loss decreased (inf --> 0.004683).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 60.123042583465576\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.0052158 Vali Loss: 0.0027474 Test Loss: 0.0034931\n",
      "Validation loss decreased (0.004683 --> 0.002747).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 57.293835163116455\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.0030542 Vali Loss: 0.0035031 Test Loss: 0.0050207\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 60.1719126701355\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.0026119 Vali Loss: 0.0035080 Test Loss: 0.0051216\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 56.56537365913391\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.0024595 Vali Loss: 0.0032792 Test Loss: 0.0048110\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.0034930820111185312, mae:0.047092895954847336\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 69.37794542312622\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.0277002 Vali Loss: 0.0041920 Test Loss: 0.0046738\n",
      "Validation loss decreased (inf --> 0.004192).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 65.83928775787354\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.0062060 Vali Loss: 0.0049992 Test Loss: 0.0058182\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 68.65796613693237\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.0036586 Vali Loss: 0.0057713 Test Loss: 0.0080778\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 68.44533205032349\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.0029655 Vali Loss: 0.0054307 Test Loss: 0.0078043\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.004673834890127182, mae:0.05549824237823486\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 11, 12, 14, 15, 16, 17, 23, 24, 25, 26, 28, 29, 30, 36, 37, 38, 39, 41, 44, 46, 48, 49, 50, 57, 59, 60, 61, 62, 64, 65, 66, 72, 73, 74, 75, 77, 78, 79, 80, 81, 84, 85, 87, 88, 89, 92, 93, 95, 96, 97, 98, 99, 101, 102, 104, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 5, 7, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 29, 30, 31, 32, 33, 35, 38, 39, 40, 42, 47, 48, 50, 51, 54, 57, 58, 59, 60, 62, 63, 64, 67, 68, 69, 71, 72, 73, 76, 77, 78, 79, 80, 82, 83, 84, 85, 90, 91, 93, 94, 98, 100, 101, 102, 103, 104, 105, 106]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 94.11888194084167\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.0300804 Vali Loss: 0.0147296 Test Loss: 0.0190662\n",
      "Validation loss decreased (inf --> 0.014730).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 87.28435325622559\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.0069269 Vali Loss: 0.0135911 Test Loss: 0.0218291\n",
      "Validation loss decreased (0.014730 --> 0.013591).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 91.76303339004517\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.0052103 Vali Loss: 0.0131746 Test Loss: 0.0204752\n",
      "Validation loss decreased (0.013591 --> 0.013175).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 92.8325366973877\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.0049898 Vali Loss: 0.0125329 Test Loss: 0.0199277\n",
      "Validation loss decreased (0.013175 --> 0.012533).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 90.81347966194153\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.0048888 Vali Loss: 0.0130577 Test Loss: 0.0205784\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 93.54133796691895\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.0048384 Vali Loss: 0.0125863 Test Loss: 0.0200115\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 93.86338925361633\n",
      "Epoch: 7, Steps: 396 | Train Loss: 0.0048004 Vali Loss: 0.0126151 Test Loss: 0.0199958\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.01992766000330448, mae:0.12064705044031143\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 6, 8, 14, 15, 16, 17, 20, 27, 33, 39, 44, 47, 49, 50, 51, 52, 59, 64, 66, 70, 74, 75, 78, 79, 87, 91, 95, 96, 99, 100, 103, 105, 109, 112, 113, 115, 116, 120, 121, 127, 130, 131, 134, 135, 137, 139, 140, 141, 144, 157, 158, 162, 169, 173, 175, 178, 181, 184, 185, 187, 189, 191]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[9, 12, 15, 17, 18, 22, 23, 26, 27, 29, 31, 36, 40, 41, 42, 44, 48, 51, 52, 55, 56, 58, 59, 60, 68, 69, 72, 73, 75, 80, 83, 84, 88, 95, 96, 103, 104, 109, 110, 112, 117, 120, 125, 130, 133, 135, 137, 139, 140, 142, 144, 148, 151, 154, 162, 167, 171, 172, 173, 174, 176, 180, 182, 188]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 111.66469931602478\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.0321885 Vali Loss: 0.0335296 Test Loss: 0.0448528\n",
      "Validation loss decreased (inf --> 0.033530).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 112.99430727958679\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.0127611 Vali Loss: 0.0315710 Test Loss: 0.0433712\n",
      "Validation loss decreased (0.033530 --> 0.031571).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 114.38979768753052\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.0118119 Vali Loss: 0.0301193 Test Loss: 0.0422476\n",
      "Validation loss decreased (0.031571 --> 0.030119).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 112.115553855896\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.0113974 Vali Loss: 0.0311607 Test Loss: 0.0431062\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 115.06254863739014\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.0112217 Vali Loss: 0.0308264 Test Loss: 0.0429155\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 115.74842119216919\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.0111557 Vali Loss: 0.0297232 Test Loss: 0.0413989\n",
      "Validation loss decreased (0.030119 --> 0.029723).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 111.34582567214966\n",
      "Epoch: 7, Steps: 391 | Train Loss: 0.0111271 Vali Loss: 0.0298821 Test Loss: 0.0416181\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 113.36294555664062\n",
      "Epoch: 8, Steps: 391 | Train Loss: 0.0111049 Vali Loss: 0.0299146 Test Loss: 0.0416269\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 113.18115592002869\n",
      "Epoch: 9, Steps: 391 | Train Loss: 0.0110888 Vali Loss: 0.0300116 Test Loss: 0.0417601\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.04139893874526024, mae:0.16124869883060455\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 9, 11, 14, 28, 33, 39, 58, 67, 69, 77, 78, 89, 92, 99, 106, 108, 132, 133, 136, 141, 147, 172, 178, 180, 182, 183, 193, 205, 207, 215, 217, 220, 224, 239, 242, 245, 246, 253, 257, 263, 266, 267, 275, 281, 285, 288, 294, 298, 300, 308, 309, 312, 314, 315, 328, 334, 336, 346, 347, 354, 369, 377, 382]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[8, 9, 22, 25, 45, 49, 50, 53, 56, 68, 72, 81, 83, 90, 99, 102, 106, 123, 125, 131, 132, 143, 145, 147, 163, 167, 172, 176, 177, 179, 181, 185, 186, 187, 189, 193, 195, 197, 198, 201, 203, 219, 220, 222, 225, 235, 242, 252, 257, 259, 279, 281, 286, 298, 319, 333, 340, 342, 343, 344, 347, 356, 368, 373]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 152.43959784507751\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.0490952 Vali Loss: 0.0358812 Test Loss: 0.0420087\n",
      "Validation loss decreased (inf --> 0.035881).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 151.1631214618683\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.0251443 Vali Loss: 0.0334109 Test Loss: 0.0381286\n",
      "Validation loss decreased (0.035881 --> 0.033411).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 151.15839648246765\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.0223196 Vali Loss: 0.0328022 Test Loss: 0.0379668\n",
      "Validation loss decreased (0.033411 --> 0.032802).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 149.99158644676208\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.0213741 Vali Loss: 0.0320309 Test Loss: 0.0370238\n",
      "Validation loss decreased (0.032802 --> 0.032031).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 150.50745844841003\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.0209205 Vali Loss: 0.0319518 Test Loss: 0.0369339\n",
      "Validation loss decreased (0.032031 --> 0.031952).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 150.9856252670288\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.0206486 Vali Loss: 0.0314142 Test Loss: 0.0362596\n",
      "Validation loss decreased (0.031952 --> 0.031414).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 151.7410488128662\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.0204761 Vali Loss: 0.0312723 Test Loss: 0.0361639\n",
      "Validation loss decreased (0.031414 --> 0.031272).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 151.92860102653503\n",
      "Epoch: 8, Steps: 379 | Train Loss: 0.0203622 Vali Loss: 0.0312730 Test Loss: 0.0361705\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 149.9771671295166\n",
      "Epoch: 9, Steps: 379 | Train Loss: 0.0203137 Vali Loss: 0.0312250 Test Loss: 0.0361075\n",
      "Validation loss decreased (0.031272 --> 0.031225).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 150.93191027641296\n",
      "Epoch: 10, Steps: 379 | Train Loss: 0.0202865 Vali Loss: 0.0312371 Test Loss: 0.0361415\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 150.76183032989502\n",
      "Epoch: 11, Steps: 379 | Train Loss: 0.0202624 Vali Loss: 0.0312285 Test Loss: 0.0361295\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 147.80488467216492\n",
      "Epoch: 12, Steps: 379 | Train Loss: 0.0202616 Vali Loss: 0.0312311 Test Loss: 0.0361313\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.036107517778873444, mae:0.15525880455970764\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_reversal_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 60.54825758934021\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.0450899 Vali Loss: 0.0214596 Test Loss: 0.0221017\n",
      "Validation loss decreased (inf --> 0.021460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 61.3884654045105\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.0160086 Vali Loss: 0.0194349 Test Loss: 0.0212070\n",
      "Validation loss decreased (0.021460 --> 0.019435).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 60.111090898513794\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.0134644 Vali Loss: 0.0191630 Test Loss: 0.0192332\n",
      "Validation loss decreased (0.019435 --> 0.019163).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 58.72136449813843\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.0125718 Vali Loss: 0.0181599 Test Loss: 0.0182185\n",
      "Validation loss decreased (0.019163 --> 0.018160).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 57.070011615753174\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.0121352 Vali Loss: 0.0187610 Test Loss: 0.0183073\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 60.41943907737732\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.0118874 Vali Loss: 0.0179232 Test Loss: 0.0176779\n",
      "Validation loss decreased (0.018160 --> 0.017923).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 59.61530017852783\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.0117641 Vali Loss: 0.0175485 Test Loss: 0.0173617\n",
      "Validation loss decreased (0.017923 --> 0.017548).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 57.61549639701843\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.0117138 Vali Loss: 0.0174652 Test Loss: 0.0172997\n",
      "Validation loss decreased (0.017548 --> 0.017465).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 59.3901002407074\n",
      "Epoch: 9, Steps: 401 | Train Loss: 0.0116553 Vali Loss: 0.0178000 Test Loss: 0.0175086\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 59.949538469314575\n",
      "Epoch: 10, Steps: 401 | Train Loss: 0.0116387 Vali Loss: 0.0177016 Test Loss: 0.0174530\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 58.739232540130615\n",
      "Epoch: 11, Steps: 401 | Train Loss: 0.0116131 Vali Loss: 0.0177631 Test Loss: 0.0174515\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.0172997135668993, mae:0.10555349290370941\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_reversal_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 68.34883975982666\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.0534481 Vali Loss: 0.0312133 Test Loss: 0.0307239\n",
      "Validation loss decreased (inf --> 0.031213).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 68.22215008735657\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.0194977 Vali Loss: 0.0296971 Test Loss: 0.0302911\n",
      "Validation loss decreased (0.031213 --> 0.029697).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 66.22622871398926\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.0179631 Vali Loss: 0.0294917 Test Loss: 0.0295711\n",
      "Validation loss decreased (0.029697 --> 0.029492).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 69.48470973968506\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.0170810 Vali Loss: 0.0281580 Test Loss: 0.0285501\n",
      "Validation loss decreased (0.029492 --> 0.028158).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 66.95558381080627\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.0165359 Vali Loss: 0.0270549 Test Loss: 0.0275428\n",
      "Validation loss decreased (0.028158 --> 0.027055).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 65.99477958679199\n",
      "Epoch: 6, Steps: 400 | Train Loss: 0.0162754 Vali Loss: 0.0271592 Test Loss: 0.0276758\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 70.09021759033203\n",
      "Epoch: 7, Steps: 400 | Train Loss: 0.0161877 Vali Loss: 0.0262976 Test Loss: 0.0268383\n",
      "Validation loss decreased (0.027055 --> 0.026298).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 70.62527894973755\n",
      "Epoch: 8, Steps: 400 | Train Loss: 0.0160336 Vali Loss: 0.0264029 Test Loss: 0.0269138\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 70.8919906616211\n",
      "Epoch: 9, Steps: 400 | Train Loss: 0.0160106 Vali Loss: 0.0263054 Test Loss: 0.0267453\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 64.98041915893555\n",
      "Epoch: 10, Steps: 400 | Train Loss: 0.0159942 Vali Loss: 0.0262594 Test Loss: 0.0266599\n",
      "Validation loss decreased (0.026298 --> 0.026259).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 64.11943507194519\n",
      "Epoch: 11, Steps: 400 | Train Loss: 0.0159667 Vali Loss: 0.0262923 Test Loss: 0.0266918\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 70.22079944610596\n",
      "Epoch: 12, Steps: 400 | Train Loss: 0.0159538 Vali Loss: 0.0262806 Test Loss: 0.0266885\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 67.53122115135193\n",
      "Epoch: 13, Steps: 400 | Train Loss: 0.0159669 Vali Loss: 0.0262675 Test Loss: 0.0266773\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.02665993571281433, mae:0.1291130930185318\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 25, 28, 31, 32, 33, 36, 37, 38, 45, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 77, 78, 82, 84, 85, 87, 88, 90, 91, 93, 94, 95, 96, 98, 104, 106]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 4, 6, 8, 11, 12, 14, 15, 16, 17, 22, 23, 25, 26, 27, 28, 30, 32, 33, 35, 37, 38, 39, 40, 41, 42, 45, 47, 49, 50, 51, 52, 55, 57, 58, 59, 61, 65, 66, 67, 68, 69, 71, 73, 74, 75, 77, 78, 81, 82, 83, 84, 85, 87, 88, 91, 94, 97, 101, 102, 106]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_reversal_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 89.23695158958435\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.1016840 Vali Loss: 0.1036841 Test Loss: 0.1107144\n",
      "Validation loss decreased (inf --> 0.103684).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 94.74194979667664\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.0373916 Vali Loss: 0.1008307 Test Loss: 0.1174113\n",
      "Validation loss decreased (0.103684 --> 0.100831).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 92.00326466560364\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.0305674 Vali Loss: 0.0979512 Test Loss: 0.1153572\n",
      "Validation loss decreased (0.100831 --> 0.097951).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 91.7340395450592\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.0293958 Vali Loss: 0.0989886 Test Loss: 0.1186851\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 90.50686287879944\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.0288576 Vali Loss: 0.0982202 Test Loss: 0.1150951\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 92.29197096824646\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.0285554 Vali Loss: 0.0982205 Test Loss: 0.1148945\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.1153571829199791, mae:0.25728827714920044\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 5, 9, 11, 12, 13, 20, 21, 24, 28, 32, 41, 45, 49, 51, 52, 53, 54, 57, 60, 65, 67, 71, 73, 75, 78, 83, 84, 85, 86, 87, 90, 91, 94, 95, 96, 99, 106, 111, 112, 117, 119, 124, 125, 126, 129, 131, 139, 141, 146, 149, 155, 157, 158, 159, 161, 163, 164, 174, 175, 176, 177, 187, 191]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[4, 11, 13, 15, 18, 19, 24, 27, 28, 30, 33, 38, 39, 43, 45, 46, 48, 57, 62, 68, 71, 72, 74, 75, 76, 77, 80, 81, 82, 84, 86, 90, 95, 98, 99, 104, 105, 106, 109, 111, 119, 120, 121, 129, 136, 139, 141, 143, 144, 145, 147, 151, 153, 156, 160, 161, 166, 169, 172, 174, 175, 181, 187, 191]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_reversal_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 113.79455995559692\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.1326739 Vali Loss: 0.2577760 Test Loss: 0.2487369\n",
      "Validation loss decreased (inf --> 0.257776).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 113.93947744369507\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.0808558 Vali Loss: 0.2406103 Test Loss: 0.2408287\n",
      "Validation loss decreased (0.257776 --> 0.240610).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 112.01351356506348\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.0763678 Vali Loss: 0.2380989 Test Loss: 0.2365355\n",
      "Validation loss decreased (0.240610 --> 0.238099).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 113.5777702331543\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.0745602 Vali Loss: 0.2309251 Test Loss: 0.2347137\n",
      "Validation loss decreased (0.238099 --> 0.230925).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 113.90338087081909\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.0735128 Vali Loss: 0.2244767 Test Loss: 0.2292860\n",
      "Validation loss decreased (0.230925 --> 0.224477).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 112.43725752830505\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.0728946 Vali Loss: 0.2327782 Test Loss: 0.2299176\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 112.51198196411133\n",
      "Epoch: 7, Steps: 391 | Train Loss: 0.0726350 Vali Loss: 0.2319693 Test Loss: 0.2314667\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 113.9047577381134\n",
      "Epoch: 8, Steps: 391 | Train Loss: 0.0724211 Vali Loss: 0.2315784 Test Loss: 0.2310107\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.22928595542907715, mae:0.342141717672348\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[4, 16, 19, 21, 29, 36, 43, 54, 63, 66, 71, 72, 77, 87, 94, 110, 111, 113, 114, 115, 119, 121, 125, 132, 135, 138, 144, 151, 158, 166, 167, 177, 189, 192, 198, 200, 209, 211, 218, 225, 228, 235, 242, 248, 262, 263, 269, 273, 282, 298, 299, 303, 323, 325, 331, 339, 341, 343, 344, 355, 359, 370, 372, 375]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[5, 6, 7, 8, 10, 13, 15, 19, 26, 40, 51, 68, 69, 70, 73, 74, 85, 89, 95, 96, 102, 111, 114, 119, 124, 129, 132, 143, 148, 162, 165, 179, 181, 184, 186, 195, 206, 211, 221, 223, 225, 226, 239, 253, 269, 278, 284, 287, 290, 294, 296, 299, 304, 305, 313, 320, 326, 328, 329, 347, 350, 355, 371, 383]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_reversal_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 151.44992876052856\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.2443862 Vali Loss: 0.5742699 Test Loss: 0.4086014\n",
      "Validation loss decreased (inf --> 0.574270).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 149.4806091785431\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.2087703 Vali Loss: 0.5763826 Test Loss: 0.3889495\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 150.81007957458496\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.2042711 Vali Loss: 0.5554314 Test Loss: 0.4073909\n",
      "Validation loss decreased (0.574270 --> 0.555431).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 152.34178471565247\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.2017649 Vali Loss: 0.5566671 Test Loss: 0.4080868\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 148.4822735786438\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.2005230 Vali Loss: 0.5654250 Test Loss: 0.3978240\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 150.74489283561707\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.2000027 Vali Loss: 0.5499653 Test Loss: 0.4135398\n",
      "Validation loss decreased (0.555431 --> 0.549965).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 152.38886070251465\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.1997203 Vali Loss: 0.5549336 Test Loss: 0.4087619\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 149.49140453338623\n",
      "Epoch: 8, Steps: 379 | Train Loss: 0.1996352 Vali Loss: 0.5533090 Test Loss: 0.4105301\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 152.64114356040955\n",
      "Epoch: 9, Steps: 379 | Train Loss: 0.1994935 Vali Loss: 0.5534270 Test Loss: 0.4107832\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.4135397672653198, mae:0.5294992327690125\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 60.40204834938049\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.0333237 Vali Loss: 0.0600987 Test Loss: 0.1188942\n",
      "Validation loss decreased (inf --> 0.060099).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 56.851722240448\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.0134370 Vali Loss: 0.0251345 Test Loss: 0.0527168\n",
      "Validation loss decreased (0.060099 --> 0.025134).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 58.472365379333496\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.0071731 Vali Loss: 0.0197292 Test Loss: 0.0413809\n",
      "Validation loss decreased (0.025134 --> 0.019729).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 57.82252049446106\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.0060869 Vali Loss: 0.0172333 Test Loss: 0.0366448\n",
      "Validation loss decreased (0.019729 --> 0.017233).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 59.528045415878296\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.0057041 Vali Loss: 0.0161052 Test Loss: 0.0342052\n",
      "Validation loss decreased (0.017233 --> 0.016105).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 59.6087212562561\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.0054925 Vali Loss: 0.0160569 Test Loss: 0.0340844\n",
      "Validation loss decreased (0.016105 --> 0.016057).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 59.82052993774414\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.0053974 Vali Loss: 0.0153963 Test Loss: 0.0325138\n",
      "Validation loss decreased (0.016057 --> 0.015396).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 58.97012972831726\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.0053548 Vali Loss: 0.0153718 Test Loss: 0.0326775\n",
      "Validation loss decreased (0.015396 --> 0.015372).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 58.22850036621094\n",
      "Epoch: 9, Steps: 401 | Train Loss: 0.0052929 Vali Loss: 0.0151668 Test Loss: 0.0321763\n",
      "Validation loss decreased (0.015372 --> 0.015167).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 59.293705463409424\n",
      "Epoch: 10, Steps: 401 | Train Loss: 0.0052877 Vali Loss: 0.0152000 Test Loss: 0.0322396\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 60.43933439254761\n",
      "Epoch: 11, Steps: 401 | Train Loss: 0.0052912 Vali Loss: 0.0152856 Test Loss: 0.0324571\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 57.684043884277344\n",
      "Epoch: 12, Steps: 401 | Train Loss: 0.0052685 Vali Loss: 0.0152124 Test Loss: 0.0323371\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.03217631205916405, mae:0.1427481770515442\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 68.5355806350708\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.0421334 Vali Loss: 0.0455089 Test Loss: 0.0968749\n",
      "Validation loss decreased (inf --> 0.045509).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 69.89366054534912\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.0093830 Vali Loss: 0.0194497 Test Loss: 0.0453962\n",
      "Validation loss decreased (0.045509 --> 0.019450).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 67.96797251701355\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.0058783 Vali Loss: 0.0173994 Test Loss: 0.0410205\n",
      "Validation loss decreased (0.019450 --> 0.017399).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 65.06634497642517\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.0047918 Vali Loss: 0.0156108 Test Loss: 0.0369781\n",
      "Validation loss decreased (0.017399 --> 0.015611).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 67.76180100440979\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.0044129 Vali Loss: 0.0155537 Test Loss: 0.0369018\n",
      "Validation loss decreased (0.015611 --> 0.015554).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 67.98161149024963\n",
      "Epoch: 6, Steps: 400 | Train Loss: 0.0042565 Vali Loss: 0.0151121 Test Loss: 0.0358658\n",
      "Validation loss decreased (0.015554 --> 0.015112).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 69.45483660697937\n",
      "Epoch: 7, Steps: 400 | Train Loss: 0.0041495 Vali Loss: 0.0149318 Test Loss: 0.0353925\n",
      "Validation loss decreased (0.015112 --> 0.014932).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 66.97317600250244\n",
      "Epoch: 8, Steps: 400 | Train Loss: 0.0041159 Vali Loss: 0.0148865 Test Loss: 0.0352681\n",
      "Validation loss decreased (0.014932 --> 0.014887).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 68.37807941436768\n",
      "Epoch: 9, Steps: 400 | Train Loss: 0.0040849 Vali Loss: 0.0150229 Test Loss: 0.0354650\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 64.60303974151611\n",
      "Epoch: 10, Steps: 400 | Train Loss: 0.0040650 Vali Loss: 0.0148896 Test Loss: 0.0351543\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 66.24226260185242\n",
      "Epoch: 11, Steps: 400 | Train Loss: 0.0040694 Vali Loss: 0.0148794 Test Loss: 0.0351608\n",
      "Validation loss decreased (0.014887 --> 0.014879).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 68.57432270050049\n",
      "Epoch: 12, Steps: 400 | Train Loss: 0.0040622 Vali Loss: 0.0148865 Test Loss: 0.0351406\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 70.74853563308716\n",
      "Epoch: 13, Steps: 400 | Train Loss: 0.0040625 Vali Loss: 0.0148883 Test Loss: 0.0351334\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 69.5378749370575\n",
      "Epoch: 14, Steps: 400 | Train Loss: 0.0040474 Vali Loss: 0.0148887 Test Loss: 0.0351271\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.035160768777132034, mae:0.15026941895484924\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 3, 4, 6, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 26, 28, 31, 33, 34, 35, 37, 38, 40, 41, 43, 44, 45, 46, 48, 49, 50, 54, 55, 58, 59, 62, 63, 65, 66, 67, 69, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 90, 91, 92, 96, 99, 102, 106]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 3, 4, 5, 6, 7, 9, 10, 13, 14, 15, 18, 19, 20, 21, 22, 23, 27, 29, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 50, 51, 53, 55, 56, 59, 65, 68, 69, 72, 73, 75, 79, 80, 81, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 97, 98, 100, 101, 103, 104, 105, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 91.39283227920532\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.0529228 Vali Loss: 0.0811002 Test Loss: 0.1501494\n",
      "Validation loss decreased (inf --> 0.081100).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 89.12640190124512\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.0180887 Vali Loss: 0.0625557 Test Loss: 0.1279549\n",
      "Validation loss decreased (0.081100 --> 0.062556).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 91.32222890853882\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.0129792 Vali Loss: 0.0636699 Test Loss: 0.1268337\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 91.55963611602783\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.0115620 Vali Loss: 0.0555793 Test Loss: 0.1153969\n",
      "Validation loss decreased (0.062556 --> 0.055579).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 93.07579469680786\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.0107753 Vali Loss: 0.0565067 Test Loss: 0.1165636\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 91.20813226699829\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.0103702 Vali Loss: 0.0559746 Test Loss: 0.1159234\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 90.96168160438538\n",
      "Epoch: 7, Steps: 396 | Train Loss: 0.0102192 Vali Loss: 0.0539206 Test Loss: 0.1132464\n",
      "Validation loss decreased (0.055579 --> 0.053921).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 92.25184869766235\n",
      "Epoch: 8, Steps: 396 | Train Loss: 0.0101104 Vali Loss: 0.0535788 Test Loss: 0.1129039\n",
      "Validation loss decreased (0.053921 --> 0.053579).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 90.15117835998535\n",
      "Epoch: 9, Steps: 396 | Train Loss: 0.0100841 Vali Loss: 0.0538858 Test Loss: 0.1133331\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 92.57884812355042\n",
      "Epoch: 10, Steps: 396 | Train Loss: 0.0100472 Vali Loss: 0.0539169 Test Loss: 0.1134249\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 90.73865032196045\n",
      "Epoch: 11, Steps: 396 | Train Loss: 0.0100169 Vali Loss: 0.0538021 Test Loss: 0.1134162\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.11290385574102402, mae:0.27709609270095825\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 5, 7, 9, 11, 13, 15, 16, 21, 23, 25, 37, 50, 53, 59, 61, 67, 70, 76, 79, 81, 82, 85, 86, 87, 93, 94, 99, 100, 102, 103, 107, 112, 113, 119, 122, 125, 126, 128, 130, 136, 138, 140, 141, 144, 148, 151, 155, 159, 165, 167, 168, 169, 172, 175, 178, 180, 181, 182, 185, 187, 189]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[5, 8, 10, 15, 19, 23, 25, 26, 29, 30, 32, 34, 36, 37, 38, 48, 49, 51, 52, 53, 54, 58, 59, 60, 65, 68, 73, 75, 77, 78, 79, 81, 85, 92, 95, 97, 100, 109, 111, 112, 122, 123, 124, 125, 127, 128, 138, 144, 145, 146, 154, 156, 159, 162, 167, 168, 169, 171, 174, 179, 180, 182, 188, 191]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 112.5726044178009\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.0495407 Vali Loss: 0.1261062 Test Loss: 0.2406582\n",
      "Validation loss decreased (inf --> 0.126106).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 114.59628796577454\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.0244725 Vali Loss: 0.1273883 Test Loss: 0.2442191\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 110.82453179359436\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.0228899 Vali Loss: 0.1189984 Test Loss: 0.2336315\n",
      "Validation loss decreased (0.126106 --> 0.118998).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 116.559250831604\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.0220416 Vali Loss: 0.1236764 Test Loss: 0.2395664\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 109.78699254989624\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.0216090 Vali Loss: 0.1238652 Test Loss: 0.2392461\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 110.8843321800232\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.0213754 Vali Loss: 0.1232267 Test Loss: 0.2381067\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.23363149166107178, mae:0.3997879922389984\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 4, 5, 20, 27, 30, 41, 45, 50, 55, 68, 73, 75, 84, 87, 88, 92, 93, 103, 105, 134, 142, 150, 161, 163, 164, 166, 171, 175, 180, 183, 189, 195, 196, 209, 214, 216, 234, 241, 245, 248, 251, 253, 256, 266, 274, 278, 285, 287, 296, 300, 305, 308, 310, 311, 330, 332, 349, 360, 364, 369, 371, 380]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[9, 12, 24, 28, 37, 49, 58, 61, 66, 71, 76, 80, 82, 85, 87, 90, 92, 100, 103, 105, 106, 116, 124, 125, 136, 139, 141, 142, 154, 155, 158, 167, 172, 186, 195, 201, 210, 211, 217, 218, 230, 239, 240, 241, 242, 248, 249, 251, 260, 279, 281, 292, 294, 306, 322, 334, 350, 352, 357, 364, 365, 367, 374, 381]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 151.81598019599915\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.0563133 Vali Loss: 0.1177574 Test Loss: 0.2346031\n",
      "Validation loss decreased (inf --> 0.117757).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 154.6128363609314\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.0204035 Vali Loss: 0.1200664 Test Loss: 0.2370338\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 157.74975085258484\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.0172516 Vali Loss: 0.1130795 Test Loss: 0.2276197\n",
      "Validation loss decreased (0.117757 --> 0.113080).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 142.57910466194153\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.0164896 Vali Loss: 0.1104702 Test Loss: 0.2242773\n",
      "Validation loss decreased (0.113080 --> 0.110470).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 150.6406273841858\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.0162502 Vali Loss: 0.1121376 Test Loss: 0.2257445\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 149.8668155670166\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.0161111 Vali Loss: 0.1092069 Test Loss: 0.2215534\n",
      "Validation loss decreased (0.110470 --> 0.109207).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 149.92216062545776\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.0160621 Vali Loss: 0.1108298 Test Loss: 0.2237869\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 150.3479688167572\n",
      "Epoch: 8, Steps: 379 | Train Loss: 0.0160248 Vali Loss: 0.1107277 Test Loss: 0.2236476\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 149.86246275901794\n",
      "Epoch: 9, Steps: 379 | Train Loss: 0.0160005 Vali Loss: 0.1109374 Test Loss: 0.2240827\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.22155332565307617, mae:0.3852747082710266\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_reversal_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12841\n",
      "val 2137\n",
      "test 2137\n",
      "Epoch: 1 cost time: 60.77790188789368\n",
      "Epoch: 1, Steps: 401 | Train Loss: 0.0380478 Vali Loss: 0.1634406 Test Loss: 0.3202288\n",
      "Validation loss decreased (inf --> 0.163441).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 60.453272581100464\n",
      "Epoch: 2, Steps: 401 | Train Loss: 0.0108202 Vali Loss: 0.1422508 Test Loss: 0.3010687\n",
      "Validation loss decreased (0.163441 --> 0.142251).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 59.311705112457275\n",
      "Epoch: 3, Steps: 401 | Train Loss: 0.0081076 Vali Loss: 0.1350647 Test Loss: 0.2958822\n",
      "Validation loss decreased (0.142251 --> 0.135065).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 59.08242392539978\n",
      "Epoch: 4, Steps: 401 | Train Loss: 0.0069939 Vali Loss: 0.1334884 Test Loss: 0.2926076\n",
      "Validation loss decreased (0.135065 --> 0.133488).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 59.07762098312378\n",
      "Epoch: 5, Steps: 401 | Train Loss: 0.0065087 Vali Loss: 0.1323246 Test Loss: 0.2904402\n",
      "Validation loss decreased (0.133488 --> 0.132325).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 57.763678789138794\n",
      "Epoch: 6, Steps: 401 | Train Loss: 0.0063316 Vali Loss: 0.1317594 Test Loss: 0.2895851\n",
      "Validation loss decreased (0.132325 --> 0.131759).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 58.122849225997925\n",
      "Epoch: 7, Steps: 401 | Train Loss: 0.0061829 Vali Loss: 0.1317046 Test Loss: 0.2879759\n",
      "Validation loss decreased (0.131759 --> 0.131705).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 62.192789793014526\n",
      "Epoch: 8, Steps: 401 | Train Loss: 0.0061448 Vali Loss: 0.1318772 Test Loss: 0.2883483\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 59.366026401519775\n",
      "Epoch: 9, Steps: 401 | Train Loss: 0.0061226 Vali Loss: 0.1318389 Test Loss: 0.2889868\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 58.75920104980469\n",
      "Epoch: 10, Steps: 401 | Train Loss: 0.0060943 Vali Loss: 0.1318911 Test Loss: 0.2885985\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.28797590732574463, mae:0.2896229028701782\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_reversal_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12817\n",
      "val 2113\n",
      "test 2113\n",
      "Epoch: 1 cost time: 69.34287166595459\n",
      "Epoch: 1, Steps: 400 | Train Loss: 0.0515972 Vali Loss: 0.2166534 Test Loss: 0.4203115\n",
      "Validation loss decreased (inf --> 0.216653).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 64.63821172714233\n",
      "Epoch: 2, Steps: 400 | Train Loss: 0.0151016 Vali Loss: 0.1728075 Test Loss: 0.3550427\n",
      "Validation loss decreased (0.216653 --> 0.172807).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 68.17164826393127\n",
      "Epoch: 3, Steps: 400 | Train Loss: 0.0109236 Vali Loss: 0.1691343 Test Loss: 0.3503296\n",
      "Validation loss decreased (0.172807 --> 0.169134).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 67.51090216636658\n",
      "Epoch: 4, Steps: 400 | Train Loss: 0.0092733 Vali Loss: 0.1645442 Test Loss: 0.3453105\n",
      "Validation loss decreased (0.169134 --> 0.164544).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 68.2899386882782\n",
      "Epoch: 5, Steps: 400 | Train Loss: 0.0085637 Vali Loss: 0.1656669 Test Loss: 0.3463454\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 67.37639021873474\n",
      "Epoch: 6, Steps: 400 | Train Loss: 0.0082167 Vali Loss: 0.1652340 Test Loss: 0.3438381\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 67.65887975692749\n",
      "Epoch: 7, Steps: 400 | Train Loss: 0.0080223 Vali Loss: 0.1654840 Test Loss: 0.3440033\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.3453104794025421, mae:0.3350580632686615\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 6, 7, 9, 11, 12, 14, 16, 17, 18, 20, 22, 23, 25, 26, 27, 29, 30, 31, 33, 36, 41, 42, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 59, 60, 61, 62, 63, 65, 73, 74, 75, 76, 77, 79, 80, 81, 82, 85, 86, 88, 89, 90, 93, 94, 96, 97, 98, 100, 101, 105, 106]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 4, 6, 8, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 26, 27, 29, 30, 33, 34, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 50, 53, 54, 55, 56, 57, 59, 60, 61, 63, 65, 66, 67, 69, 70, 71, 72, 74, 75, 77, 78, 79, 83, 86, 88, 89, 97, 99, 100, 102, 105]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_reversal_ftS_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12697\n",
      "val 1993\n",
      "test 1993\n",
      "Epoch: 1 cost time: 91.63733458518982\n",
      "Epoch: 1, Steps: 396 | Train Loss: 0.0528754 Vali Loss: 0.3919947 Test Loss: 0.6988737\n",
      "Validation loss decreased (inf --> 0.391995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 91.03598403930664\n",
      "Epoch: 2, Steps: 396 | Train Loss: 0.0286323 Vali Loss: 0.3936759 Test Loss: 0.6932378\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 90.26776671409607\n",
      "Epoch: 3, Steps: 396 | Train Loss: 0.0231195 Vali Loss: 0.3848537 Test Loss: 0.6853633\n",
      "Validation loss decreased (0.391995 --> 0.384854).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 92.25890040397644\n",
      "Epoch: 4, Steps: 396 | Train Loss: 0.0202459 Vali Loss: 0.3836461 Test Loss: 0.6852593\n",
      "Validation loss decreased (0.384854 --> 0.383646).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 93.9937858581543\n",
      "Epoch: 5, Steps: 396 | Train Loss: 0.0190751 Vali Loss: 0.3764817 Test Loss: 0.6813509\n",
      "Validation loss decreased (0.383646 --> 0.376482).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 92.57333946228027\n",
      "Epoch: 6, Steps: 396 | Train Loss: 0.0184708 Vali Loss: 0.3796396 Test Loss: 0.6861902\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 90.05207109451294\n",
      "Epoch: 7, Steps: 396 | Train Loss: 0.0180568 Vali Loss: 0.3797131 Test Loss: 0.6864185\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 91.34951496124268\n",
      "Epoch: 8, Steps: 396 | Train Loss: 0.0179377 Vali Loss: 0.3788717 Test Loss: 0.6865495\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.6813511252403259, mae:0.5538075566291809\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 2, 5, 8, 10, 11, 14, 16, 20, 22, 23, 24, 28, 29, 32, 37, 38, 39, 41, 45, 48, 50, 52, 59, 60, 61, 69, 74, 76, 79, 81, 88, 89, 92, 94, 97, 98, 99, 101, 106, 109, 110, 111, 117, 119, 125, 126, 127, 131, 134, 138, 139, 145, 152, 156, 160, 161, 163, 168, 169, 180, 181, 182, 189]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 3, 4, 7, 8, 9, 13, 15, 19, 20, 21, 23, 24, 25, 32, 34, 36, 37, 42, 47, 54, 56, 69, 71, 75, 82, 84, 90, 91, 94, 96, 99, 101, 102, 103, 105, 109, 117, 121, 122, 123, 126, 127, 131, 137, 138, 139, 147, 150, 151, 153, 156, 157, 163, 165, 166, 167, 168, 173, 175, 177, 182, 183, 189]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_reversal_ftS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12529\n",
      "val 1825\n",
      "test 1825\n",
      "Epoch: 1 cost time: 114.36378479003906\n",
      "Epoch: 1, Steps: 391 | Train Loss: 0.0735379 Vali Loss: 0.6375748 Test Loss: 1.1071730\n",
      "Validation loss decreased (inf --> 0.637575).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 112.6307737827301\n",
      "Epoch: 2, Steps: 391 | Train Loss: 0.0435125 Vali Loss: 0.6471726 Test Loss: 1.1188107\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 113.3493447303772\n",
      "Epoch: 3, Steps: 391 | Train Loss: 0.0402752 Vali Loss: 0.6275038 Test Loss: 1.0957088\n",
      "Validation loss decreased (0.637575 --> 0.627504).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 111.10525059700012\n",
      "Epoch: 4, Steps: 391 | Train Loss: 0.0380739 Vali Loss: 0.6274892 Test Loss: 1.0953701\n",
      "Validation loss decreased (0.627504 --> 0.627489).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 116.30642771720886\n",
      "Epoch: 5, Steps: 391 | Train Loss: 0.0366713 Vali Loss: 0.6280867 Test Loss: 1.1047364\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 113.3902370929718\n",
      "Epoch: 6, Steps: 391 | Train Loss: 0.0357955 Vali Loss: 0.6304570 Test Loss: 1.1091919\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 110.54698204994202\n",
      "Epoch: 7, Steps: 391 | Train Loss: 0.0353803 Vali Loss: 0.6313823 Test Loss: 1.1095546\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:1.0953696966171265, mae:0.759247899055481\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'model_id': 'Fedformer_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True, 'iter': 3}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[10, 18, 19, 31, 36, 38, 42, 44, 52, 69, 70, 71, 73, 80, 81, 84, 96, 106, 107, 114, 115, 121, 124, 126, 129, 132, 137, 138, 146, 148, 151, 156, 160, 174, 175, 177, 184, 186, 191, 194, 195, 201, 208, 212, 218, 219, 222, 225, 250, 260, 284, 292, 294, 301, 309, 315, 319, 322, 338, 356, 357, 359, 372, 381]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 19, 20, 23, 29, 37, 41, 46, 47, 54, 82, 87, 94, 99, 100, 104, 109, 111, 124, 129, 133, 134, 138, 139, 148, 158, 161, 170, 171, 188, 191, 198, 210, 219, 220, 222, 228, 233, 238, 239, 245, 259, 263, 271, 282, 285, 296, 303, 304, 311, 319, 322, 324, 326, 327, 328, 331, 333, 334, 341, 355, 360, 369, 370]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_reversal_ftS_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 1441\n",
      "test 1441\n",
      "Epoch: 1 cost time: 153.24749660491943\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.1268907 Vali Loss: 1.3111011 Test Loss: 2.2924731\n",
      "Validation loss decreased (inf --> 1.311101).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 149.68443250656128\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.0758919 Vali Loss: 1.2997314 Test Loss: 2.3222983\n",
      "Validation loss decreased (1.311101 --> 1.299731).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 151.0427188873291\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.0561636 Vali Loss: 1.2701770 Test Loss: 2.3130884\n",
      "Validation loss decreased (1.299731 --> 1.270177).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 149.63130640983582\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.0493984 Vali Loss: 1.2468650 Test Loss: 2.2697675\n",
      "Validation loss decreased (1.270177 --> 1.246865).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 152.14243483543396\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.0472684 Vali Loss: 1.2468700 Test Loss: 2.2708561\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 149.89415407180786\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.0463778 Vali Loss: 1.2416893 Test Loss: 2.2615523\n",
      "Validation loss decreased (1.246865 --> 1.241689).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 148.84529781341553\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.0458424 Vali Loss: 1.2412152 Test Loss: 2.2629523\n",
      "Validation loss decreased (1.241689 --> 1.241215).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 151.69232535362244\n",
      "Epoch: 8, Steps: 379 | Train Loss: 0.0455668 Vali Loss: 1.2407405 Test Loss: 2.2620039\n",
      "Validation loss decreased (1.241215 --> 1.240741).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 152.03760719299316\n",
      "Epoch: 9, Steps: 379 | Train Loss: 0.0455235 Vali Loss: 1.2409129 Test Loss: 2.2641275\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 148.67260479927063\n",
      "Epoch: 10, Steps: 379 | Train Loss: 0.0454655 Vali Loss: 1.2401228 Test Loss: 2.2630162\n",
      "Validation loss decreased (1.240741 --> 1.240123).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 151.13515257835388\n",
      "Epoch: 11, Steps: 379 | Train Loss: 0.0454306 Vali Loss: 1.2400870 Test Loss: 2.2634993\n",
      "Validation loss decreased (1.240123 --> 1.240087).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 150.28639197349548\n",
      "Epoch: 12, Steps: 379 | Train Loss: 0.0454582 Vali Loss: 1.2407049 Test Loss: 2.2634232\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 153.3083996772766\n",
      "Epoch: 13, Steps: 379 | Train Loss: 0.0454852 Vali Loss: 1.2406204 Test Loss: 2.2633145\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 149.42802834510803\n",
      "Epoch: 14, Steps: 379 | Train Loss: 0.0454330 Vali Loss: 1.2394934 Test Loss: 2.2634358\n",
      "Validation loss decreased (1.240087 --> 1.239493).  Saving model ...\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 151.77836728096008\n",
      "Epoch: 15, Steps: 379 | Train Loss: 0.0453133 Vali Loss: 1.2391323 Test Loss: 2.2633724\n",
      "Validation loss decreased (1.239493 --> 1.239132).  Saving model ...\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 150.746258020401\n",
      "Epoch: 16, Steps: 379 | Train Loss: 0.0453597 Vali Loss: 1.2406240 Test Loss: 2.2633593\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.0517578125e-09\n",
      "Epoch: 17 cost time: 150.81388545036316\n",
      "Epoch: 17, Steps: 379 | Train Loss: 0.0453947 Vali Loss: 1.2391802 Test Loss: 2.2633655\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.52587890625e-09\n",
      "Epoch: 18 cost time: 151.89844346046448\n",
      "Epoch: 18, Steps: 379 | Train Loss: 0.0453031 Vali Loss: 1.2392309 Test Loss: 2.2633629\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:2.2633726596832275, mae:1.2311124801635742\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "CPU times: user 1d 15h 40min 33s, sys: 4h 57min 36s, total: 1d 20h 38min 10s\n",
      "Wall time: 1d 2h 28min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Simple loop\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "    for iter in range(model.args.itr):\n",
    "        for dataset_name, dataset_params in datasets.items():\n",
    "            for pred_len in pred_lens:\n",
    "                print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "                    # High amount of epochs to accomodate all models\n",
    "                    # Early stopping should kick in anyways\n",
    "                model.fit(\n",
    "                    iter = iter + 1,\n",
    "                    data=dataset_name,\n",
    "                    data_root_path=dataset_params[0],\n",
    "                    batch_size=32,\n",
    "                    epochs=20, # very high\n",
    "                    pred_len=pred_len,\n",
    "                    features = dataset_params[1],\n",
    "                    target = dataset_params[2],\n",
    "                    seq_len = dataset_params[3],\n",
    "                    enc_in = dataset_params[4],\n",
    "                    dec_in = dataset_params[5],\n",
    "                    c_out = dataset_params[6]\n",
    "                )\n",
    "\n",
    "                predictions = model.predict()\n",
    "\n",
    "                print(f'\\nMoving to next...\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {    \n",
    "'SYNTH_multiplicative_reversal' : ['./SYNTHDataset/', 'S' , 'TARGET' , 768, 1 , 1 , 1]\n",
    "}\n",
    "pred_lens = [720]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: LogsparseTS\n",
      "Training LogsparseTS on SYNTH_multiplicative_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 44.35 GiB of which 5.62 MiB is free. Process 384 has 1.29 GiB memory in use. Process 19020 has 9.40 GiB memory in use. Process 5885 has 33.63 GiB memory in use. Of the allocated memory 9.00 GiB is allocated by PyTorch, and 57.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/Schreibtisch/Github/TransformersEnergyTS/LogSparseAPI.py:2224\u001b[0m, in \u001b[0;36mLogsparseTS.fit\u001b[0;34m(self, data, data_root_path, batch_size, epochs, pred_len, seq_len, features, target, enc_in, dec_in, c_out, iter)\u001b[0m\n\u001b[1;32m   2220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetting \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_ft\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_sl\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_ll\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_pl\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_dm\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_nh\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_dl\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_df\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_fc\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_eb\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_dt\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_des\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_iter\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mfeatures, \n\u001b[1;32m   2221\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mseq_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mlabel_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpred_len,\n\u001b[1;32m   2222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39md_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39md_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39md_ff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mfactor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdistil, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39miter)\n\u001b[1;32m   2223\u001b[0m \u001b[38;5;66;03m# Initialize Model Class\u001b[39;00m\n\u001b[0;32m-> 2224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_model \u001b[38;5;241m=\u001b[39m \u001b[43mExperiment_Model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m   2226\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>start training : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetting))\n",
      "File \u001b[0;32m~/Schreibtisch/Github/TransformersEnergyTS/LogSparseAPI.py:1650\u001b[0m, in \u001b[0;36mExp_Logsparse.__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, args):\n\u001b[0;32m-> 1650\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mExp_Logsparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Schreibtisch/Github/TransformersEnergyTS/LogSparseAPI.py:1053\u001b[0m, in \u001b[0;36mExp_Basic.__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquire_device()\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:857\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, buf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 857\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers[key] \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 44.35 GiB of which 5.62 MiB is free. Process 384 has 1.29 GiB memory in use. Process 19020 has 9.40 GiB memory in use. Process 5885 has 33.63 GiB memory in use. Of the allocated memory 9.00 GiB is allocated by PyTorch, and 57.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Simple loop\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "    for iter in range(1 ,2):\n",
    "        for dataset_name, dataset_params in datasets.items():\n",
    "            for pred_len in pred_lens:\n",
    "                print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "                        # High amount of epochs to accomodate all models\n",
    "                        # Early stopping should kick in anyways\n",
    "                model.fit(\n",
    "                    iter = iter + 1,\n",
    "                    data=dataset_name,\n",
    "                    data_root_path=dataset_params[0],\n",
    "                    batch_size=32,\n",
    "                    epochs=20, # very high\n",
    "                    pred_len=pred_len,\n",
    "                    features = dataset_params[1],\n",
    "                    target = dataset_params[2],\n",
    "                    seq_len = dataset_params[3],\n",
    "                    enc_in = dataset_params[4],\n",
    "                    dec_in = dataset_params[5],\n",
    "                    c_out = dataset_params[6]\n",
    "                )\n",
    "\n",
    "                predictions = model.predict()\n",
    "\n",
    "                print(f'\\nMoving to next...\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'ETTh1': ['./ETTDataset/' , 'M' , 'OT' , 768 , 7 , 7 , 7] ,\n",
    "    'DEWINDh_small': ['./WINDataset/' , 'S' , 'TARGET' , 768, 1 , 1 , 1] ,\n",
    "    'SYNTHh1': ['./SYNTHDataset/', 'S' , 'TARGET' , 768, 1 , 1 , 1] ,\n",
    "    'SYNTH_additive' : ['./SYNTHDataset/', 'S' , 'TARGET' , 768, 1 , 1 , 1] ,\n",
    "    'SYNTH_additive_reversal' : ['./SYNTHDataset/', 'S' , 'TARGET' ,768, 1 , 1 , 1] ,\n",
    "    'SYNTH_multiplicative' : ['./SYNTHDataset/', 'S' , 'TARGET' , 768, 1 , 1 , 1] ,\n",
    "    'SYNTH_multiplicative_reversal' : ['./SYNTHDataset/', 'S' , 'TARGET' , 768, 1 , 1 , 1]\n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "\n",
    "models = [LogsparseTS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: LogsparseTS\n",
      "Training LogsparseTS on ETTh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'M', 'seq_len': 768, 'label_len': 48, 'pred_len': 24, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_ETTh1_ftM_sl768_ll48_pl24_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7849\n",
      "val 2857\n",
      "test 2857\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/245, epoch: 1 | loss: 0.4136209\n",
      "\titers: 200/245, epoch: 1 | loss: 0.3359213\n",
      "Epoch: 1 cost time: 60.758885622024536\n",
      "Epoch: 1, Steps: 245 | Train Loss: 0.3126491 Vali Loss: 1.0975107\n",
      "Validation loss decreased (inf --> 1.097511).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/245, epoch: 2 | loss: 0.1693710\n",
      "\titers: 200/245, epoch: 2 | loss: 0.1513167\n",
      "Epoch: 2 cost time: 62.732107400894165\n",
      "Epoch: 2, Steps: 245 | Train Loss: 0.1443433 Vali Loss: 1.2699410\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/245, epoch: 3 | loss: 0.0933617\n",
      "\titers: 200/245, epoch: 3 | loss: 0.0879651\n",
      "Epoch: 3 cost time: 61.54061269760132\n",
      "Epoch: 3, Steps: 245 | Train Loss: 0.0861949 Vali Loss: 1.2754790\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/245, epoch: 4 | loss: 0.0705360\n",
      "\titers: 200/245, epoch: 4 | loss: 0.0667440\n",
      "Epoch: 4 cost time: 57.465672731399536\n",
      "Epoch: 4, Steps: 245 | Train Loss: 0.0655042 Vali Loss: 1.2575585\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "loading model\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "mse:1.1631674766540527, mae:0.8983177542686462\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on ETTh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'M', 'seq_len': 768, 'label_len': 48, 'pred_len': 48, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_ETTh1_ftM_sl768_ll48_pl48_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2833\n",
      "test 2833\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/244, epoch: 1 | loss: 0.4370204\n",
      "\titers: 200/244, epoch: 1 | loss: 0.3475726\n",
      "Epoch: 1 cost time: 54.58379626274109\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.3234349 Vali Loss: 1.1205461\n",
      "Validation loss decreased (inf --> 1.120546).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/244, epoch: 2 | loss: 0.1592776\n",
      "\titers: 200/244, epoch: 2 | loss: 0.1414197\n",
      "Epoch: 2 cost time: 59.62306833267212\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.1358476 Vali Loss: 1.0764645\n",
      "Validation loss decreased (1.120546 --> 1.076465).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/244, epoch: 3 | loss: 0.0903191\n",
      "\titers: 200/244, epoch: 3 | loss: 0.0851512\n",
      "Epoch: 3 cost time: 58.03154540061951\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.0828813 Vali Loss: 1.1099838\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/244, epoch: 4 | loss: 0.0639443\n",
      "\titers: 200/244, epoch: 4 | loss: 0.0616027\n",
      "Epoch: 4 cost time: 57.697619915008545\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.0607838 Vali Loss: 1.1262587\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/244, epoch: 5 | loss: 0.0534267\n",
      "\titers: 200/244, epoch: 5 | loss: 0.0521223\n",
      "Epoch: 5 cost time: 56.38670492172241\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.0516436 Vali Loss: 1.1405121\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "loading model\n",
      "test shape: (2816, 48, 7) (2816, 48, 7)\n",
      "test shape: (2816, 48, 7) (2816, 48, 7)\n",
      "mse:1.1755820512771606, mae:0.9014093279838562\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on ETTh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'M', 'seq_len': 768, 'label_len': 48, 'pred_len': 168, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_ETTh1_ftM_sl768_ll48_pl168_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7705\n",
      "val 2713\n",
      "test 2713\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/240, epoch: 1 | loss: 0.4734416\n",
      "\titers: 200/240, epoch: 1 | loss: 0.3768598\n",
      "Epoch: 1 cost time: 98.6751856803894\n",
      "Epoch: 1, Steps: 240 | Train Loss: 0.3492519 Vali Loss: 1.2238340\n",
      "Validation loss decreased (inf --> 1.223834).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/240, epoch: 2 | loss: 0.1697752\n",
      "\titers: 200/240, epoch: 2 | loss: 0.1532018\n",
      "Epoch: 2 cost time: 97.52516508102417\n",
      "Epoch: 2, Steps: 240 | Train Loss: 0.1477806 Vali Loss: 1.2437465\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/240, epoch: 3 | loss: 0.1045680\n",
      "\titers: 200/240, epoch: 3 | loss: 0.0970251\n",
      "Epoch: 3 cost time: 92.84672403335571\n",
      "Epoch: 3, Steps: 240 | Train Loss: 0.0942534 Vali Loss: 1.2622819\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/240, epoch: 4 | loss: 0.0761639\n",
      "\titers: 200/240, epoch: 4 | loss: 0.0734822\n",
      "Epoch: 4 cost time: 98.46623468399048\n",
      "Epoch: 4, Steps: 240 | Train Loss: 0.0723482 Vali Loss: 1.2605482\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "loading model\n",
      "test shape: (2688, 168, 7) (2688, 168, 7)\n",
      "test shape: (2688, 168, 7) (2688, 168, 7)\n",
      "mse:1.8277643918991089, mae:1.1839858293533325\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on ETTh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'M', 'seq_len': 768, 'label_len': 48, 'pred_len': 336, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_ETTh1_ftM_sl768_ll48_pl336_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7537\n",
      "val 2545\n",
      "test 2545\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/235, epoch: 1 | loss: 0.4985224\n",
      "\titers: 200/235, epoch: 1 | loss: 0.3996061\n",
      "Epoch: 1 cost time: 111.66667032241821\n",
      "Epoch: 1, Steps: 235 | Train Loss: 0.3768112 Vali Loss: 1.4521630\n",
      "Validation loss decreased (inf --> 1.452163).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/235, epoch: 2 | loss: 0.1888809\n",
      "\titers: 200/235, epoch: 2 | loss: 0.1696845\n",
      "Epoch: 2 cost time: 103.32332134246826\n",
      "Epoch: 2, Steps: 235 | Train Loss: 0.1637964 Vali Loss: 1.4063005\n",
      "Validation loss decreased (1.452163 --> 1.406301).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/235, epoch: 3 | loss: 0.1118218\n",
      "\titers: 200/235, epoch: 3 | loss: 0.1039839\n",
      "Epoch: 3 cost time: 106.74167966842651\n",
      "Epoch: 3, Steps: 235 | Train Loss: 0.1020858 Vali Loss: 1.3939459\n",
      "Validation loss decreased (1.406301 --> 1.393946).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/235, epoch: 4 | loss: 0.0824864\n",
      "\titers: 200/235, epoch: 4 | loss: 0.0792913\n",
      "Epoch: 4 cost time: 103.5741674900055\n",
      "Epoch: 4, Steps: 235 | Train Loss: 0.0779514 Vali Loss: 1.3853192\n",
      "Validation loss decreased (1.393946 --> 1.385319).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/235, epoch: 5 | loss: 0.0669865\n",
      "\titers: 200/235, epoch: 5 | loss: 0.0651296\n",
      "Epoch: 5 cost time: 103.73625159263611\n",
      "Epoch: 5, Steps: 235 | Train Loss: 0.0644834 Vali Loss: 1.3984505\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/235, epoch: 6 | loss: 0.0588928\n",
      "\titers: 200/235, epoch: 6 | loss: 0.0575359\n",
      "Epoch: 6 cost time: 105.12235474586487\n",
      "Epoch: 6, Steps: 235 | Train Loss: 0.0571567 Vali Loss: 1.3727964\n",
      "Validation loss decreased (1.385319 --> 1.372796).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/235, epoch: 7 | loss: 0.0534203\n",
      "\titers: 200/235, epoch: 7 | loss: 0.0525530\n",
      "Epoch: 7 cost time: 101.20028305053711\n",
      "Epoch: 7, Steps: 235 | Train Loss: 0.0521946 Vali Loss: 1.3706115\n",
      "Validation loss decreased (1.372796 --> 1.370612).  Saving model ...\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/235, epoch: 8 | loss: 0.0492830\n",
      "\titers: 200/235, epoch: 8 | loss: 0.0486134\n",
      "Epoch: 8 cost time: 104.29939150810242\n",
      "Epoch: 8, Steps: 235 | Train Loss: 0.0484247 Vali Loss: 1.3795398\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/235, epoch: 9 | loss: 0.0462436\n",
      "\titers: 200/235, epoch: 9 | loss: 0.0458285\n",
      "Epoch: 9 cost time: 103.58450102806091\n",
      "Epoch: 9, Steps: 235 | Train Loss: 0.0456968 Vali Loss: 1.3877409\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.3421772800000007e-05\n",
      "\titers: 100/235, epoch: 10 | loss: 0.0439468\n",
      "\titers: 200/235, epoch: 10 | loss: 0.0436805\n",
      "Epoch: 10 cost time: 110.34087800979614\n",
      "Epoch: 10, Steps: 235 | Train Loss: 0.0435805 Vali Loss: 1.3903400\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "loading model\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "mse:1.280116319656372, mae:0.9090850949287415\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on ETTh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'M', 'seq_len': 768, 'label_len': 48, 'pred_len': 720, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_ETTh1_ftM_sl768_ll48_pl720_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7153\n",
      "val 2161\n",
      "test 2161\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/223, epoch: 1 | loss: 0.4979652\n",
      "\titers: 200/223, epoch: 1 | loss: 0.3988395\n",
      "Epoch: 1 cost time: 124.90452146530151\n",
      "Epoch: 1, Steps: 223 | Train Loss: 0.3821663 Vali Loss: 1.5186874\n",
      "Validation loss decreased (inf --> 1.518687).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/223, epoch: 2 | loss: 0.2006088\n",
      "\titers: 200/223, epoch: 2 | loss: 0.1799559\n",
      "Epoch: 2 cost time: 122.0524492263794\n",
      "Epoch: 2, Steps: 223 | Train Loss: 0.1755635 Vali Loss: 1.5470660\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/223, epoch: 3 | loss: 0.1230468\n",
      "\titers: 200/223, epoch: 3 | loss: 0.1165543\n",
      "Epoch: 3 cost time: 125.06280326843262\n",
      "Epoch: 3, Steps: 223 | Train Loss: 0.1145961 Vali Loss: 1.5792354\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/223, epoch: 4 | loss: 0.0917178\n",
      "\titers: 200/223, epoch: 4 | loss: 0.0881903\n",
      "Epoch: 4 cost time: 123.02491593360901\n",
      "Epoch: 4, Steps: 223 | Train Loss: 0.0876519 Vali Loss: 1.5551506\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "loading model\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "mse:1.5351179838180542, mae:1.014822006225586\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on DEWINDh_small with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_DEWINDh_small_ftS_sl768_ll48_pl24_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12169\n",
      "val 2137\n",
      "test 2137\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/380, epoch: 1 | loss: 0.6912392\n",
      "\titers: 200/380, epoch: 1 | loss: 0.4338338\n",
      "\titers: 300/380, epoch: 1 | loss: 0.3383550\n",
      "Epoch: 1 cost time: 90.00926756858826\n",
      "Epoch: 1, Steps: 380 | Train Loss: 0.2976973 Vali Loss: 0.1747218\n",
      "Validation loss decreased (inf --> 0.174722).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/380, epoch: 2 | loss: 0.1314418\n",
      "\titers: 200/380, epoch: 2 | loss: 0.1285881\n",
      "\titers: 300/380, epoch: 2 | loss: 0.1279261\n",
      "Epoch: 2 cost time: 88.30540585517883\n",
      "Epoch: 2, Steps: 380 | Train Loss: 0.1265482 Vali Loss: 0.1316908\n",
      "Validation loss decreased (0.174722 --> 0.131691).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/380, epoch: 3 | loss: 0.1103996\n",
      "\titers: 200/380, epoch: 3 | loss: 0.1096808\n",
      "\titers: 300/380, epoch: 3 | loss: 0.1091794\n",
      "Epoch: 3 cost time: 86.70650291442871\n",
      "Epoch: 3, Steps: 380 | Train Loss: 0.1081346 Vali Loss: 0.1224693\n",
      "Validation loss decreased (0.131691 --> 0.122469).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/380, epoch: 4 | loss: 0.0960264\n",
      "\titers: 200/380, epoch: 4 | loss: 0.0962263\n",
      "\titers: 300/380, epoch: 4 | loss: 0.0952411\n",
      "Epoch: 4 cost time: 82.7106249332428\n",
      "Epoch: 4, Steps: 380 | Train Loss: 0.0926187 Vali Loss: 0.1314375\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/380, epoch: 5 | loss: 0.0797239\n",
      "\titers: 200/380, epoch: 5 | loss: 0.0784095\n",
      "\titers: 300/380, epoch: 5 | loss: 0.0777190\n",
      "Epoch: 5 cost time: 80.71273756027222\n",
      "Epoch: 5, Steps: 380 | Train Loss: 0.0755631 Vali Loss: 0.1535598\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/380, epoch: 6 | loss: 0.0605932\n",
      "\titers: 200/380, epoch: 6 | loss: 0.0599429\n",
      "\titers: 300/380, epoch: 6 | loss: 0.0596482\n",
      "Epoch: 6 cost time: 80.84835052490234\n",
      "Epoch: 6, Steps: 380 | Train Loss: 0.0584758 Vali Loss: 0.1667857\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "loading model\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.09781259298324585, mae:0.15658600628376007\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on DEWINDh_small with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_DEWINDh_small_ftS_sl768_ll48_pl48_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 2113\n",
      "test 2113\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/379, epoch: 1 | loss: 0.6847416\n",
      "\titers: 200/379, epoch: 1 | loss: 0.4451961\n",
      "\titers: 300/379, epoch: 1 | loss: 0.3562637\n",
      "Epoch: 1 cost time: 89.67564702033997\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.3151874 Vali Loss: 0.1769344\n",
      "Validation loss decreased (inf --> 0.176934).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/379, epoch: 2 | loss: 0.1520476\n",
      "\titers: 200/379, epoch: 2 | loss: 0.1490380\n",
      "\titers: 300/379, epoch: 2 | loss: 0.1460642\n",
      "Epoch: 2 cost time: 84.52808260917664\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.1432817 Vali Loss: 0.1592695\n",
      "Validation loss decreased (0.176934 --> 0.159269).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/379, epoch: 3 | loss: 0.1235578\n",
      "\titers: 200/379, epoch: 3 | loss: 0.1211524\n",
      "\titers: 300/379, epoch: 3 | loss: 0.1168787\n",
      "Epoch: 3 cost time: 82.13437032699585\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.1141753 Vali Loss: 0.1757124\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/379, epoch: 4 | loss: 0.0944561\n",
      "\titers: 200/379, epoch: 4 | loss: 0.0902063\n",
      "\titers: 300/379, epoch: 4 | loss: 0.0853983\n",
      "Epoch: 4 cost time: 81.45216202735901\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.0827838 Vali Loss: 0.1814105\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/379, epoch: 5 | loss: 0.0630260\n",
      "\titers: 200/379, epoch: 5 | loss: 0.0602967\n",
      "\titers: 300/379, epoch: 5 | loss: 0.0576443\n",
      "Epoch: 5 cost time: 161.3396143913269\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.0559271 Vali Loss: 0.1863856\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "loading model\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.1291692554950714, mae:0.20266342163085938\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on DEWINDh_small with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_DEWINDh_small_ftS_sl768_ll48_pl168_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12025\n",
      "val 1993\n",
      "test 1993\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/375, epoch: 1 | loss: 0.9368165\n",
      "\titers: 200/375, epoch: 1 | loss: 0.5835491\n",
      "\titers: 300/375, epoch: 1 | loss: 0.4549491\n",
      "Epoch: 1 cost time: 125.85222315788269\n",
      "Epoch: 1, Steps: 375 | Train Loss: 0.3995866 Vali Loss: 0.1811091\n",
      "Validation loss decreased (inf --> 0.181109).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/375, epoch: 2 | loss: 0.1663101\n",
      "\titers: 200/375, epoch: 2 | loss: 0.1609275\n",
      "\titers: 300/375, epoch: 2 | loss: 0.1561810\n",
      "Epoch: 2 cost time: 122.93323397636414\n",
      "Epoch: 2, Steps: 375 | Train Loss: 0.1528763 Vali Loss: 0.1883263\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/375, epoch: 3 | loss: 0.1243700\n",
      "\titers: 200/375, epoch: 3 | loss: 0.1216740\n",
      "\titers: 300/375, epoch: 3 | loss: 0.1165142\n",
      "Epoch: 3 cost time: 115.92749118804932\n",
      "Epoch: 3, Steps: 375 | Train Loss: 0.1126696 Vali Loss: 0.1939793\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/375, epoch: 4 | loss: 0.0870383\n",
      "\titers: 200/375, epoch: 4 | loss: 0.0833009\n",
      "\titers: 300/375, epoch: 4 | loss: 0.0801687\n",
      "Epoch: 4 cost time: 107.86172270774841\n",
      "Epoch: 4, Steps: 375 | Train Loss: 0.0770283 Vali Loss: 0.2061474\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "loading model\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.1580003947019577, mae:0.2204844206571579\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on DEWINDh_small with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_DEWINDh_small_ftS_sl768_ll48_pl336_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 11857\n",
      "val 1825\n",
      "test 1825\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/370, epoch: 1 | loss: 0.7348601\n",
      "\titers: 200/370, epoch: 1 | loss: 0.4951368\n",
      "\titers: 300/370, epoch: 1 | loss: 0.3966484\n",
      "Epoch: 1 cost time: 123.54369640350342\n",
      "Epoch: 1, Steps: 370 | Train Loss: 0.3555619 Vali Loss: 0.2057871\n",
      "Validation loss decreased (inf --> 0.205787).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/370, epoch: 2 | loss: 0.1656378\n",
      "\titers: 200/370, epoch: 2 | loss: 0.1602693\n",
      "\titers: 300/370, epoch: 2 | loss: 0.1565493\n",
      "Epoch: 2 cost time: 114.75180697441101\n",
      "Epoch: 2, Steps: 370 | Train Loss: 0.1528720 Vali Loss: 0.1832448\n",
      "Validation loss decreased (0.205787 --> 0.183245).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/370, epoch: 3 | loss: 0.1169582\n",
      "\titers: 200/370, epoch: 3 | loss: 0.1133462\n",
      "\titers: 300/370, epoch: 3 | loss: 0.1084610\n",
      "Epoch: 3 cost time: 113.74137091636658\n",
      "Epoch: 3, Steps: 370 | Train Loss: 0.1039987 Vali Loss: 0.2087818\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/370, epoch: 4 | loss: 0.0791932\n",
      "\titers: 200/370, epoch: 4 | loss: 0.0756448\n",
      "\titers: 300/370, epoch: 4 | loss: 0.0731153\n",
      "Epoch: 4 cost time: 108.27350640296936\n",
      "Epoch: 4, Steps: 370 | Train Loss: 0.0711526 Vali Loss: 0.2446782\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/370, epoch: 5 | loss: 0.0565930\n",
      "\titers: 200/370, epoch: 5 | loss: 0.0550794\n",
      "\titers: 300/370, epoch: 5 | loss: 0.0533991\n",
      "Epoch: 5 cost time: 108.3109438419342\n",
      "Epoch: 5, Steps: 370 | Train Loss: 0.0523580 Vali Loss: 0.2894727\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "loading model\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.15160559117794037, mae:0.20349851250648499\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on DEWINDh_small with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_DEWINDh_small_ftS_sl768_ll48_pl720_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 11473\n",
      "val 1441\n",
      "test 1441\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/358, epoch: 1 | loss: 0.6877884\n",
      "\titers: 200/358, epoch: 1 | loss: 0.4649989\n",
      "\titers: 300/358, epoch: 1 | loss: 0.3746893\n",
      "Epoch: 1 cost time: 135.42740988731384\n",
      "Epoch: 1, Steps: 358 | Train Loss: 0.3429752 Vali Loss: 0.1979201\n",
      "Validation loss decreased (inf --> 0.197920).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/358, epoch: 2 | loss: 0.1624141\n",
      "\titers: 200/358, epoch: 2 | loss: 0.1598682\n",
      "\titers: 300/358, epoch: 2 | loss: 0.1530417\n",
      "Epoch: 2 cost time: 135.47814655303955\n",
      "Epoch: 2, Steps: 358 | Train Loss: 0.1489108 Vali Loss: 0.2532949\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/358, epoch: 3 | loss: 0.1153456\n",
      "\titers: 200/358, epoch: 3 | loss: 0.1104375\n",
      "\titers: 300/358, epoch: 3 | loss: 0.1046855\n",
      "Epoch: 3 cost time: 134.08927488327026\n",
      "Epoch: 3, Steps: 358 | Train Loss: 0.1019153 Vali Loss: 0.2340922\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/358, epoch: 4 | loss: 0.0789619\n",
      "\titers: 200/358, epoch: 4 | loss: 0.0739036\n",
      "\titers: 300/358, epoch: 4 | loss: 0.0713381\n",
      "Epoch: 4 cost time: 136.95639419555664\n",
      "Epoch: 4, Steps: 358 | Train Loss: 0.0696942 Vali Loss: 0.2904784\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "loading model\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.13081766664981842, mae:0.18998216092586517\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTHh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTHh1_ftS_sl768_ll48_pl24_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12169\n",
      "val 2137\n",
      "test 2137\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/380, epoch: 1 | loss: 0.3740537\n",
      "\titers: 200/380, epoch: 1 | loss: 0.2144128\n",
      "\titers: 300/380, epoch: 1 | loss: 0.1547199\n",
      "Epoch: 1 cost time: 83.31643986701965\n",
      "Epoch: 1, Steps: 380 | Train Loss: 0.1293848 Vali Loss: 0.0252278\n",
      "Validation loss decreased (inf --> 0.025228).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/380, epoch: 2 | loss: 0.0246366\n",
      "\titers: 200/380, epoch: 2 | loss: 0.0241318\n",
      "\titers: 300/380, epoch: 2 | loss: 0.0240865\n",
      "Epoch: 2 cost time: 82.42467737197876\n",
      "Epoch: 2, Steps: 380 | Train Loss: 0.0235236 Vali Loss: 0.0185073\n",
      "Validation loss decreased (0.025228 --> 0.018507).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/380, epoch: 3 | loss: 0.0194683\n",
      "\titers: 200/380, epoch: 3 | loss: 0.0192241\n",
      "\titers: 300/380, epoch: 3 | loss: 0.0193632\n",
      "Epoch: 3 cost time: 86.02585411071777\n",
      "Epoch: 3, Steps: 380 | Train Loss: 0.0194976 Vali Loss: 0.0228887\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/380, epoch: 4 | loss: 0.0179715\n",
      "\titers: 200/380, epoch: 4 | loss: 0.0178767\n",
      "\titers: 300/380, epoch: 4 | loss: 0.0177041\n",
      "Epoch: 4 cost time: 80.95260787010193\n",
      "Epoch: 4, Steps: 380 | Train Loss: 0.0175888 Vali Loss: 0.0177927\n",
      "Validation loss decreased (0.018507 --> 0.017793).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/380, epoch: 5 | loss: 0.0166348\n",
      "\titers: 200/380, epoch: 5 | loss: 0.0163193\n",
      "\titers: 300/380, epoch: 5 | loss: 0.0161816\n",
      "Epoch: 5 cost time: 88.9701828956604\n",
      "Epoch: 5, Steps: 380 | Train Loss: 0.0161407 Vali Loss: 0.0160980\n",
      "Validation loss decreased (0.017793 --> 0.016098).  Saving model ...\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/380, epoch: 6 | loss: 0.0153360\n",
      "\titers: 200/380, epoch: 6 | loss: 0.0153177\n",
      "\titers: 300/380, epoch: 6 | loss: 0.0152023\n",
      "Epoch: 6 cost time: 87.07557201385498\n",
      "Epoch: 6, Steps: 380 | Train Loss: 0.0152162 Vali Loss: 0.0181565\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/380, epoch: 7 | loss: 0.0145825\n",
      "\titers: 200/380, epoch: 7 | loss: 0.0145655\n",
      "\titers: 300/380, epoch: 7 | loss: 0.0145722\n",
      "Epoch: 7 cost time: 87.1846854686737\n",
      "Epoch: 7, Steps: 380 | Train Loss: 0.0146767 Vali Loss: 0.0158954\n",
      "Validation loss decreased (0.016098 --> 0.015895).  Saving model ...\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/380, epoch: 8 | loss: 0.0141344\n",
      "\titers: 200/380, epoch: 8 | loss: 0.0141858\n",
      "\titers: 300/380, epoch: 8 | loss: 0.0140967\n",
      "Epoch: 8 cost time: 86.5896623134613\n",
      "Epoch: 8, Steps: 380 | Train Loss: 0.0140752 Vali Loss: 0.0169092\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/380, epoch: 9 | loss: 0.0136994\n",
      "\titers: 200/380, epoch: 9 | loss: 0.0135838\n",
      "\titers: 300/380, epoch: 9 | loss: 0.0136078\n",
      "Epoch: 9 cost time: 85.91311645507812\n",
      "Epoch: 9, Steps: 380 | Train Loss: 0.0136013 Vali Loss: 0.0186893\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.3421772800000007e-05\n",
      "\titers: 100/380, epoch: 10 | loss: 0.0134658\n",
      "\titers: 200/380, epoch: 10 | loss: 0.0133998\n",
      "\titers: 300/380, epoch: 10 | loss: 0.0133796\n",
      "Epoch: 10 cost time: 85.69915556907654\n",
      "Epoch: 10, Steps: 380 | Train Loss: 0.0133782 Vali Loss: 0.0162000\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "loading model\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.01752159558236599, mae:0.10452449321746826\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTHh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTHh1_ftS_sl768_ll48_pl48_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 2113\n",
      "test 2113\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/379, epoch: 1 | loss: 0.3224631\n",
      "\titers: 200/379, epoch: 1 | loss: 0.1829052\n",
      "\titers: 300/379, epoch: 1 | loss: 0.1336254\n",
      "Epoch: 1 cost time: 83.94871258735657\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.1118783 Vali Loss: 0.0221570\n",
      "Validation loss decreased (inf --> 0.022157).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/379, epoch: 2 | loss: 0.0235482\n",
      "\titers: 200/379, epoch: 2 | loss: 0.0231909\n",
      "\titers: 300/379, epoch: 2 | loss: 0.0233946\n",
      "Epoch: 2 cost time: 86.3558235168457\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.0233629 Vali Loss: 0.0215170\n",
      "Validation loss decreased (0.022157 --> 0.021517).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/379, epoch: 3 | loss: 0.0200075\n",
      "\titers: 200/379, epoch: 3 | loss: 0.0195319\n",
      "\titers: 300/379, epoch: 3 | loss: 0.0193374\n",
      "Epoch: 3 cost time: 85.53458452224731\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.0194029 Vali Loss: 0.0239852\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/379, epoch: 4 | loss: 0.0172258\n",
      "\titers: 200/379, epoch: 4 | loss: 0.0171049\n",
      "\titers: 300/379, epoch: 4 | loss: 0.0172219\n",
      "Epoch: 4 cost time: 87.9810745716095\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.0171133 Vali Loss: 0.0180046\n",
      "Validation loss decreased (0.021517 --> 0.018005).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/379, epoch: 5 | loss: 0.0160822\n",
      "\titers: 200/379, epoch: 5 | loss: 0.0160155\n",
      "\titers: 300/379, epoch: 5 | loss: 0.0161036\n",
      "Epoch: 5 cost time: 86.41643071174622\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.0160453 Vali Loss: 0.0183898\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/379, epoch: 6 | loss: 0.0154064\n",
      "\titers: 200/379, epoch: 6 | loss: 0.0154710\n",
      "\titers: 300/379, epoch: 6 | loss: 0.0155117\n",
      "Epoch: 6 cost time: 85.24639058113098\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.0154245 Vali Loss: 0.0165837\n",
      "Validation loss decreased (0.018005 --> 0.016584).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/379, epoch: 7 | loss: 0.0146820\n",
      "\titers: 200/379, epoch: 7 | loss: 0.0148641\n",
      "\titers: 300/379, epoch: 7 | loss: 0.0149293\n",
      "Epoch: 7 cost time: 89.14084267616272\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.0148586 Vali Loss: 0.0161654\n",
      "Validation loss decreased (0.016584 --> 0.016165).  Saving model ...\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/379, epoch: 8 | loss: 0.0144624\n",
      "\titers: 200/379, epoch: 8 | loss: 0.0144936\n",
      "\titers: 300/379, epoch: 8 | loss: 0.0144343\n",
      "Epoch: 8 cost time: 87.56981492042542\n",
      "Epoch: 8, Steps: 379 | Train Loss: 0.0145126 Vali Loss: 0.0173398\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/379, epoch: 9 | loss: 0.0139678\n",
      "\titers: 200/379, epoch: 9 | loss: 0.0141680\n",
      "\titers: 300/379, epoch: 9 | loss: 0.0140918\n",
      "Epoch: 9 cost time: 86.43782925605774\n",
      "Epoch: 9, Steps: 379 | Train Loss: 0.0140199 Vali Loss: 0.0198626\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.3421772800000007e-05\n",
      "\titers: 100/379, epoch: 10 | loss: 0.0138168\n",
      "\titers: 200/379, epoch: 10 | loss: 0.0137356\n",
      "\titers: 300/379, epoch: 10 | loss: 0.0137349\n",
      "Epoch: 10 cost time: 82.36343598365784\n",
      "Epoch: 10, Steps: 379 | Train Loss: 0.0137094 Vali Loss: 0.0184225\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "loading model\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.017020778730511665, mae:0.10397342592477798\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTHh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTHh1_ftS_sl768_ll48_pl168_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12025\n",
      "val 1993\n",
      "test 1993\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/375, epoch: 1 | loss: 0.4421273\n",
      "\titers: 200/375, epoch: 1 | loss: 0.2550586\n",
      "\titers: 300/375, epoch: 1 | loss: 0.1854737\n",
      "Epoch: 1 cost time: 87.41986846923828\n",
      "Epoch: 1, Steps: 375 | Train Loss: 0.1559803 Vali Loss: 0.0352443\n",
      "Validation loss decreased (inf --> 0.035244).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/375, epoch: 2 | loss: 0.0324021\n",
      "\titers: 200/375, epoch: 2 | loss: 0.0300160\n",
      "\titers: 300/375, epoch: 2 | loss: 0.0288770\n",
      "Epoch: 2 cost time: 93.30004286766052\n",
      "Epoch: 2, Steps: 375 | Train Loss: 0.0280209 Vali Loss: 0.0224930\n",
      "Validation loss decreased (0.035244 --> 0.022493).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/375, epoch: 3 | loss: 0.0231784\n",
      "\titers: 200/375, epoch: 3 | loss: 0.0225498\n",
      "\titers: 300/375, epoch: 3 | loss: 0.0221216\n",
      "Epoch: 3 cost time: 97.2384512424469\n",
      "Epoch: 3, Steps: 375 | Train Loss: 0.0219219 Vali Loss: 0.0242657\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/375, epoch: 4 | loss: 0.0201192\n",
      "\titers: 200/375, epoch: 4 | loss: 0.0200964\n",
      "\titers: 300/375, epoch: 4 | loss: 0.0200740\n",
      "Epoch: 4 cost time: 93.40097308158875\n",
      "Epoch: 4, Steps: 375 | Train Loss: 0.0198070 Vali Loss: 0.0209458\n",
      "Validation loss decreased (0.022493 --> 0.020946).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/375, epoch: 5 | loss: 0.0183080\n",
      "\titers: 200/375, epoch: 5 | loss: 0.0180344\n",
      "\titers: 300/375, epoch: 5 | loss: 0.0179121\n",
      "Epoch: 5 cost time: 90.69537281990051\n",
      "Epoch: 5, Steps: 375 | Train Loss: 0.0179030 Vali Loss: 0.0202944\n",
      "Validation loss decreased (0.020946 --> 0.020294).  Saving model ...\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/375, epoch: 6 | loss: 0.0168656\n",
      "\titers: 200/375, epoch: 6 | loss: 0.0168366\n",
      "\titers: 300/375, epoch: 6 | loss: 0.0167864\n",
      "Epoch: 6 cost time: 88.4665732383728\n",
      "Epoch: 6, Steps: 375 | Train Loss: 0.0167327 Vali Loss: 0.0237907\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/375, epoch: 7 | loss: 0.0162017\n",
      "\titers: 200/375, epoch: 7 | loss: 0.0161728\n",
      "\titers: 300/375, epoch: 7 | loss: 0.0160792\n",
      "Epoch: 7 cost time: 88.07855129241943\n",
      "Epoch: 7, Steps: 375 | Train Loss: 0.0160323 Vali Loss: 0.0176087\n",
      "Validation loss decreased (0.020294 --> 0.017609).  Saving model ...\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/375, epoch: 8 | loss: 0.0156293\n",
      "\titers: 200/375, epoch: 8 | loss: 0.0155815\n",
      "\titers: 300/375, epoch: 8 | loss: 0.0154729\n",
      "Epoch: 8 cost time: 86.91403698921204\n",
      "Epoch: 8, Steps: 375 | Train Loss: 0.0154203 Vali Loss: 0.0191060\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/375, epoch: 9 | loss: 0.0152821\n",
      "\titers: 200/375, epoch: 9 | loss: 0.0151909\n",
      "\titers: 300/375, epoch: 9 | loss: 0.0150912\n",
      "Epoch: 9 cost time: 86.20627522468567\n",
      "Epoch: 9, Steps: 375 | Train Loss: 0.0150567 Vali Loss: 0.0195046\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.3421772800000007e-05\n",
      "\titers: 100/375, epoch: 10 | loss: 0.0147275\n",
      "\titers: 200/375, epoch: 10 | loss: 0.0147755\n",
      "\titers: 300/375, epoch: 10 | loss: 0.0147907\n",
      "Epoch: 10 cost time: 88.57648825645447\n",
      "Epoch: 10, Steps: 375 | Train Loss: 0.0148066 Vali Loss: 0.0190800\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "loading model\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.018990986049175262, mae:0.1092415377497673\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTHh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTHh1_ftS_sl768_ll48_pl336_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 11857\n",
      "val 1825\n",
      "test 1825\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/370, epoch: 1 | loss: 0.4445717\n",
      "\titers: 200/370, epoch: 1 | loss: 0.2616036\n",
      "\titers: 300/370, epoch: 1 | loss: 0.1898123\n",
      "Epoch: 1 cost time: 102.88147282600403\n",
      "Epoch: 1, Steps: 370 | Train Loss: 0.1618391 Vali Loss: 0.0296027\n",
      "Validation loss decreased (inf --> 0.029603).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/370, epoch: 2 | loss: 0.0301725\n",
      "\titers: 200/370, epoch: 2 | loss: 0.0296968\n",
      "\titers: 300/370, epoch: 2 | loss: 0.0288107\n",
      "Epoch: 2 cost time: 100.80468678474426\n",
      "Epoch: 2, Steps: 370 | Train Loss: 0.0279581 Vali Loss: 0.0210820\n",
      "Validation loss decreased (0.029603 --> 0.021082).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/370, epoch: 3 | loss: 0.0243547\n",
      "\titers: 200/370, epoch: 3 | loss: 0.0232428\n",
      "\titers: 300/370, epoch: 3 | loss: 0.0225472\n",
      "Epoch: 3 cost time: 104.07401132583618\n",
      "Epoch: 3, Steps: 370 | Train Loss: 0.0224049 Vali Loss: 0.0210738\n",
      "Validation loss decreased (0.021082 --> 0.021074).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/370, epoch: 4 | loss: 0.0206867\n",
      "\titers: 200/370, epoch: 4 | loss: 0.0203620\n",
      "\titers: 300/370, epoch: 4 | loss: 0.0198975\n",
      "Epoch: 4 cost time: 102.14648985862732\n",
      "Epoch: 4, Steps: 370 | Train Loss: 0.0196811 Vali Loss: 0.0184874\n",
      "Validation loss decreased (0.021074 --> 0.018487).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/370, epoch: 5 | loss: 0.0184854\n",
      "\titers: 200/370, epoch: 5 | loss: 0.0183359\n",
      "\titers: 300/370, epoch: 5 | loss: 0.0181413\n",
      "Epoch: 5 cost time: 101.135244846344\n",
      "Epoch: 5, Steps: 370 | Train Loss: 0.0180721 Vali Loss: 0.0207087\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/370, epoch: 6 | loss: 0.0173263\n",
      "\titers: 200/370, epoch: 6 | loss: 0.0171344\n",
      "\titers: 300/370, epoch: 6 | loss: 0.0170457\n",
      "Epoch: 6 cost time: 105.43768334388733\n",
      "Epoch: 6, Steps: 370 | Train Loss: 0.0170018 Vali Loss: 0.0187222\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/370, epoch: 7 | loss: 0.0164888\n",
      "\titers: 200/370, epoch: 7 | loss: 0.0164564\n",
      "\titers: 300/370, epoch: 7 | loss: 0.0163575\n",
      "Epoch: 7 cost time: 105.01898312568665\n",
      "Epoch: 7, Steps: 370 | Train Loss: 0.0162887 Vali Loss: 0.0195239\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "loading model\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.01986066624522209, mae:0.11139887571334839\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTHh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTHh1_ftS_sl768_ll48_pl720_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 11473\n",
      "val 1441\n",
      "test 1441\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/358, epoch: 1 | loss: 0.5489918\n",
      "\titers: 200/358, epoch: 1 | loss: 0.3162272\n",
      "\titers: 300/358, epoch: 1 | loss: 0.2270633\n",
      "Epoch: 1 cost time: 128.3025369644165\n",
      "Epoch: 1, Steps: 358 | Train Loss: 0.1968356 Vali Loss: 0.0279759\n",
      "Validation loss decreased (inf --> 0.027976).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/358, epoch: 2 | loss: 0.0338764\n",
      "\titers: 200/358, epoch: 2 | loss: 0.0324762\n",
      "\titers: 300/358, epoch: 2 | loss: 0.0317660\n",
      "Epoch: 2 cost time: 127.51676154136658\n",
      "Epoch: 2, Steps: 358 | Train Loss: 0.0310406 Vali Loss: 0.0212367\n",
      "Validation loss decreased (0.027976 --> 0.021237).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/358, epoch: 3 | loss: 0.0250991\n",
      "\titers: 200/358, epoch: 3 | loss: 0.0246371\n",
      "\titers: 300/358, epoch: 3 | loss: 0.0242503\n",
      "Epoch: 3 cost time: 127.06445741653442\n",
      "Epoch: 3, Steps: 358 | Train Loss: 0.0239560 Vali Loss: 0.0213180\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/358, epoch: 4 | loss: 0.0217635\n",
      "\titers: 200/358, epoch: 4 | loss: 0.0216421\n",
      "\titers: 300/358, epoch: 4 | loss: 0.0214364\n",
      "Epoch: 4 cost time: 119.94447565078735\n",
      "Epoch: 4, Steps: 358 | Train Loss: 0.0212416 Vali Loss: 0.0198559\n",
      "Validation loss decreased (0.021237 --> 0.019856).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/358, epoch: 5 | loss: 0.0197820\n",
      "\titers: 200/358, epoch: 5 | loss: 0.0196481\n",
      "\titers: 300/358, epoch: 5 | loss: 0.0194948\n",
      "Epoch: 5 cost time: 133.7353060245514\n",
      "Epoch: 5, Steps: 358 | Train Loss: 0.0194127 Vali Loss: 0.0183436\n",
      "Validation loss decreased (0.019856 --> 0.018344).  Saving model ...\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/358, epoch: 6 | loss: 0.0185465\n",
      "\titers: 200/358, epoch: 6 | loss: 0.0184309\n",
      "\titers: 300/358, epoch: 6 | loss: 0.0183219\n",
      "Epoch: 6 cost time: 140.32495093345642\n",
      "Epoch: 6, Steps: 358 | Train Loss: 0.0182715 Vali Loss: 0.0177574\n",
      "Validation loss decreased (0.018344 --> 0.017757).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/358, epoch: 7 | loss: 0.0176603\n",
      "\titers: 200/358, epoch: 7 | loss: 0.0176368\n",
      "\titers: 300/358, epoch: 7 | loss: 0.0175261\n",
      "Epoch: 7 cost time: 126.47184896469116\n",
      "Epoch: 7, Steps: 358 | Train Loss: 0.0174877 Vali Loss: 0.0177740\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/358, epoch: 8 | loss: 0.0170166\n",
      "\titers: 200/358, epoch: 8 | loss: 0.0169920\n",
      "\titers: 300/358, epoch: 8 | loss: 0.0169025\n",
      "Epoch: 8 cost time: 122.6572437286377\n",
      "Epoch: 8, Steps: 358 | Train Loss: 0.0168740 Vali Loss: 0.0174677\n",
      "Validation loss decreased (0.017757 --> 0.017468).  Saving model ...\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/358, epoch: 9 | loss: 0.0165808\n",
      "\titers: 200/358, epoch: 9 | loss: 0.0165447\n",
      "\titers: 300/358, epoch: 9 | loss: 0.0164757\n",
      "Epoch: 9 cost time: 128.11846446990967\n",
      "Epoch: 9, Steps: 358 | Train Loss: 0.0164418 Vali Loss: 0.0177474\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.3421772800000007e-05\n",
      "\titers: 100/358, epoch: 10 | loss: 0.0162497\n",
      "\titers: 200/358, epoch: 10 | loss: 0.0161596\n",
      "\titers: 300/358, epoch: 10 | loss: 0.0161197\n",
      "Epoch: 10 cost time: 128.24687027931213\n",
      "Epoch: 10, Steps: 358 | Train Loss: 0.0160763 Vali Loss: 0.0170185\n",
      "Validation loss decreased (0.017468 --> 0.017018).  Saving model ...\n",
      "Updating learning rate to 1.0737418240000007e-05\n",
      "\titers: 100/358, epoch: 11 | loss: 0.0158459\n",
      "\titers: 200/358, epoch: 11 | loss: 0.0158076\n",
      "\titers: 300/358, epoch: 11 | loss: 0.0157848\n",
      "Epoch: 11 cost time: 125.7660174369812\n",
      "Epoch: 11, Steps: 358 | Train Loss: 0.0157686 Vali Loss: 0.0176027\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.589934592000006e-06\n",
      "\titers: 100/358, epoch: 12 | loss: 0.0156441\n",
      "\titers: 200/358, epoch: 12 | loss: 0.0155713\n",
      "\titers: 300/358, epoch: 12 | loss: 0.0155170\n",
      "Epoch: 12 cost time: 130.78892421722412\n",
      "Epoch: 12, Steps: 358 | Train Loss: 0.0155029 Vali Loss: 0.0172326\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.871947673600004e-06\n",
      "\titers: 100/358, epoch: 13 | loss: 0.0152960\n",
      "\titers: 200/358, epoch: 13 | loss: 0.0153047\n",
      "\titers: 300/358, epoch: 13 | loss: 0.0153040\n",
      "Epoch: 13 cost time: 129.3482460975647\n",
      "Epoch: 13, Steps: 358 | Train Loss: 0.0153043 Vali Loss: 0.0173824\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "loading model\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.01969720423221588, mae:0.11092212796211243\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_additive with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_additive_ftS_sl768_ll48_pl24_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12169\n",
      "val 2137\n",
      "test 2137\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/380, epoch: 1 | loss: 0.2726791\n",
      "\titers: 200/380, epoch: 1 | loss: 0.1465601\n",
      "\titers: 300/380, epoch: 1 | loss: 0.1006125\n",
      "Epoch: 1 cost time: 80.32148122787476\n",
      "Epoch: 1, Steps: 380 | Train Loss: 0.0809256 Vali Loss: 0.0185254\n",
      "Validation loss decreased (inf --> 0.018525).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/380, epoch: 2 | loss: 0.0059018\n",
      "\titers: 200/380, epoch: 2 | loss: 0.0056215\n",
      "\titers: 300/380, epoch: 2 | loss: 0.0053073\n",
      "Epoch: 2 cost time: 80.6450412273407\n",
      "Epoch: 2, Steps: 380 | Train Loss: 0.0051376 Vali Loss: 0.0110525\n",
      "Validation loss decreased (0.018525 --> 0.011052).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/380, epoch: 3 | loss: 0.0039484\n",
      "\titers: 200/380, epoch: 3 | loss: 0.0038184\n",
      "\titers: 300/380, epoch: 3 | loss: 0.0037323\n",
      "Epoch: 3 cost time: 82.77854704856873\n",
      "Epoch: 3, Steps: 380 | Train Loss: 0.0036419 Vali Loss: 0.0088639\n",
      "Validation loss decreased (0.011052 --> 0.008864).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/380, epoch: 4 | loss: 0.0032460\n",
      "\titers: 200/380, epoch: 4 | loss: 0.0031802\n",
      "\titers: 300/380, epoch: 4 | loss: 0.0030476\n",
      "Epoch: 4 cost time: 78.42303395271301\n",
      "Epoch: 4, Steps: 380 | Train Loss: 0.0029864 Vali Loss: 0.0053903\n",
      "Validation loss decreased (0.008864 --> 0.005390).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/380, epoch: 5 | loss: 0.0025618\n",
      "\titers: 200/380, epoch: 5 | loss: 0.0025409\n",
      "\titers: 300/380, epoch: 5 | loss: 0.0025474\n",
      "Epoch: 5 cost time: 77.99861717224121\n",
      "Epoch: 5, Steps: 380 | Train Loss: 0.0025314 Vali Loss: 0.0055113\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/380, epoch: 6 | loss: 0.0022942\n",
      "\titers: 200/380, epoch: 6 | loss: 0.0022981\n",
      "\titers: 300/380, epoch: 6 | loss: 0.0022694\n",
      "Epoch: 6 cost time: 81.59374523162842\n",
      "Epoch: 6, Steps: 380 | Train Loss: 0.0022530 Vali Loss: 0.0038883\n",
      "Validation loss decreased (0.005390 --> 0.003888).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/380, epoch: 7 | loss: 0.0021630\n",
      "\titers: 200/380, epoch: 7 | loss: 0.0021139\n",
      "\titers: 300/380, epoch: 7 | loss: 0.0021174\n",
      "Epoch: 7 cost time: 86.82854628562927\n",
      "Epoch: 7, Steps: 380 | Train Loss: 0.0020889 Vali Loss: 0.0033132\n",
      "Validation loss decreased (0.003888 --> 0.003313).  Saving model ...\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/380, epoch: 8 | loss: 0.0021427\n",
      "\titers: 200/380, epoch: 8 | loss: 0.0020953\n",
      "\titers: 300/380, epoch: 8 | loss: 0.0020305\n",
      "Epoch: 8 cost time: 81.90078520774841\n",
      "Epoch: 8, Steps: 380 | Train Loss: 0.0019948 Vali Loss: 0.0030566\n",
      "Validation loss decreased (0.003313 --> 0.003057).  Saving model ...\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/380, epoch: 9 | loss: 0.0018294\n",
      "\titers: 200/380, epoch: 9 | loss: 0.0018233\n",
      "\titers: 300/380, epoch: 9 | loss: 0.0018208\n",
      "Epoch: 9 cost time: 80.97607684135437\n",
      "Epoch: 9, Steps: 380 | Train Loss: 0.0018198 Vali Loss: 0.0026427\n",
      "Validation loss decreased (0.003057 --> 0.002643).  Saving model ...\n",
      "Updating learning rate to 1.3421772800000007e-05\n",
      "\titers: 100/380, epoch: 10 | loss: 0.0017758\n",
      "\titers: 200/380, epoch: 10 | loss: 0.0017668\n",
      "\titers: 300/380, epoch: 10 | loss: 0.0017514\n",
      "Epoch: 10 cost time: 81.09807205200195\n",
      "Epoch: 10, Steps: 380 | Train Loss: 0.0017437 Vali Loss: 0.0027714\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.0737418240000007e-05\n",
      "\titers: 100/380, epoch: 11 | loss: 0.0017111\n",
      "\titers: 200/380, epoch: 11 | loss: 0.0016936\n",
      "\titers: 300/380, epoch: 11 | loss: 0.0017016\n",
      "Epoch: 11 cost time: 81.38516998291016\n",
      "Epoch: 11, Steps: 380 | Train Loss: 0.0016935 Vali Loss: 0.0023063\n",
      "Validation loss decreased (0.002643 --> 0.002306).  Saving model ...\n",
      "Updating learning rate to 8.589934592000006e-06\n",
      "\titers: 100/380, epoch: 12 | loss: 0.0016409\n",
      "\titers: 200/380, epoch: 12 | loss: 0.0016258\n",
      "\titers: 300/380, epoch: 12 | loss: 0.0016225\n",
      "Epoch: 12 cost time: 81.18608784675598\n",
      "Epoch: 12, Steps: 380 | Train Loss: 0.0016181 Vali Loss: 0.0025707\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.871947673600004e-06\n",
      "\titers: 100/380, epoch: 13 | loss: 0.0015880\n",
      "\titers: 200/380, epoch: 13 | loss: 0.0016109\n",
      "\titers: 300/380, epoch: 13 | loss: 0.0016048\n",
      "Epoch: 13 cost time: 81.69890403747559\n",
      "Epoch: 13, Steps: 380 | Train Loss: 0.0015924 Vali Loss: 0.0022567\n",
      "Validation loss decreased (0.002306 --> 0.002257).  Saving model ...\n",
      "Updating learning rate to 5.497558138880004e-06\n",
      "\titers: 100/380, epoch: 14 | loss: 0.0015316\n",
      "\titers: 200/380, epoch: 14 | loss: 0.0015442\n",
      "\titers: 300/380, epoch: 14 | loss: 0.0015571\n",
      "Epoch: 14 cost time: 80.79417395591736\n",
      "Epoch: 14, Steps: 380 | Train Loss: 0.0015455 Vali Loss: 0.0027906\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.398046511104004e-06\n",
      "\titers: 100/380, epoch: 15 | loss: 0.0015296\n",
      "\titers: 200/380, epoch: 15 | loss: 0.0015224\n",
      "\titers: 300/380, epoch: 15 | loss: 0.0015125\n",
      "Epoch: 15 cost time: 80.13291430473328\n",
      "Epoch: 15, Steps: 380 | Train Loss: 0.0015150 Vali Loss: 0.0023047\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.5184372088832033e-06\n",
      "\titers: 100/380, epoch: 16 | loss: 0.0014723\n",
      "\titers: 200/380, epoch: 16 | loss: 0.0014741\n",
      "\titers: 300/380, epoch: 16 | loss: 0.0014681\n",
      "Epoch: 16 cost time: 82.41103076934814\n",
      "Epoch: 16, Steps: 380 | Train Loss: 0.0014706 Vali Loss: 0.0029267\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "loading model\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.028256459161639214, mae:0.13205815851688385\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_additive with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_additive_ftS_sl768_ll48_pl48_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 2113\n",
      "test 2113\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/379, epoch: 1 | loss: 0.2626663\n",
      "\titers: 200/379, epoch: 1 | loss: 0.1433971\n",
      "\titers: 300/379, epoch: 1 | loss: 0.0987804\n",
      "Epoch: 1 cost time: 81.24100089073181\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.0797785 Vali Loss: 0.0353612\n",
      "Validation loss decreased (inf --> 0.035361).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/379, epoch: 2 | loss: 0.0057128\n",
      "\titers: 200/379, epoch: 2 | loss: 0.0053975\n",
      "\titers: 300/379, epoch: 2 | loss: 0.0050837\n",
      "Epoch: 2 cost time: 80.79501104354858\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.0049002 Vali Loss: 0.0089449\n",
      "Validation loss decreased (0.035361 --> 0.008945).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/379, epoch: 3 | loss: 0.0038300\n",
      "\titers: 200/379, epoch: 3 | loss: 0.0036859\n",
      "\titers: 300/379, epoch: 3 | loss: 0.0035961\n",
      "Epoch: 3 cost time: 84.11911416053772\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.0035325 Vali Loss: 0.0047410\n",
      "Validation loss decreased (0.008945 --> 0.004741).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/379, epoch: 4 | loss: 0.0030562\n",
      "\titers: 200/379, epoch: 4 | loss: 0.0029360\n",
      "\titers: 300/379, epoch: 4 | loss: 0.0028839\n",
      "Epoch: 4 cost time: 82.94125413894653\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.0028543 Vali Loss: 0.0036945\n",
      "Validation loss decreased (0.004741 --> 0.003694).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/379, epoch: 5 | loss: 0.0025383\n",
      "\titers: 200/379, epoch: 5 | loss: 0.0025169\n",
      "\titers: 300/379, epoch: 5 | loss: 0.0024880\n",
      "Epoch: 5 cost time: 82.56778812408447\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.0024786 Vali Loss: 0.0033610\n",
      "Validation loss decreased (0.003694 --> 0.003361).  Saving model ...\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/379, epoch: 6 | loss: 0.0022723\n",
      "\titers: 200/379, epoch: 6 | loss: 0.0022341\n",
      "\titers: 300/379, epoch: 6 | loss: 0.0021985\n",
      "Epoch: 6 cost time: 81.89065861701965\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.0022033 Vali Loss: 0.0021684\n",
      "Validation loss decreased (0.003361 --> 0.002168).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/379, epoch: 7 | loss: 0.0021013\n",
      "\titers: 200/379, epoch: 7 | loss: 0.0020724\n",
      "\titers: 300/379, epoch: 7 | loss: 0.0020325\n",
      "Epoch: 7 cost time: 81.09468722343445\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.0020160 Vali Loss: 0.0024743\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/379, epoch: 8 | loss: 0.0019375\n",
      "\titers: 200/379, epoch: 8 | loss: 0.0019129\n",
      "\titers: 300/379, epoch: 8 | loss: 0.0018983\n",
      "Epoch: 8 cost time: 82.61112523078918\n",
      "Epoch: 8, Steps: 379 | Train Loss: 0.0018860 Vali Loss: 0.0021692\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/379, epoch: 9 | loss: 0.0017978\n",
      "\titers: 200/379, epoch: 9 | loss: 0.0018057\n",
      "\titers: 300/379, epoch: 9 | loss: 0.0018080\n",
      "Epoch: 9 cost time: 79.53989481925964\n",
      "Epoch: 9, Steps: 379 | Train Loss: 0.0017936 Vali Loss: 0.0024062\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "loading model\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.027480052784085274, mae:0.13125079870224\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_additive with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_additive_ftS_sl768_ll48_pl168_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12025\n",
      "val 1993\n",
      "test 1993\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/375, epoch: 1 | loss: 0.2763954\n",
      "\titers: 200/375, epoch: 1 | loss: 0.1565927\n",
      "\titers: 300/375, epoch: 1 | loss: 0.1093997\n",
      "Epoch: 1 cost time: 90.14784955978394\n",
      "Epoch: 1, Steps: 375 | Train Loss: 0.0894602 Vali Loss: 0.0435059\n",
      "Validation loss decreased (inf --> 0.043506).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/375, epoch: 2 | loss: 0.0070690\n",
      "\titers: 200/375, epoch: 2 | loss: 0.0064898\n",
      "\titers: 300/375, epoch: 2 | loss: 0.0060185\n",
      "Epoch: 2 cost time: 89.0586609840393\n",
      "Epoch: 2, Steps: 375 | Train Loss: 0.0057422 Vali Loss: 0.0070300\n",
      "Validation loss decreased (0.043506 --> 0.007030).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/375, epoch: 3 | loss: 0.0041938\n",
      "\titers: 200/375, epoch: 3 | loss: 0.0039777\n",
      "\titers: 300/375, epoch: 3 | loss: 0.0038791\n",
      "Epoch: 3 cost time: 89.8361930847168\n",
      "Epoch: 3, Steps: 375 | Train Loss: 0.0038383 Vali Loss: 0.0046748\n",
      "Validation loss decreased (0.007030 --> 0.004675).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/375, epoch: 4 | loss: 0.0031516\n",
      "\titers: 200/375, epoch: 4 | loss: 0.0030604\n",
      "\titers: 300/375, epoch: 4 | loss: 0.0029763\n",
      "Epoch: 4 cost time: 86.64424514770508\n",
      "Epoch: 4, Steps: 375 | Train Loss: 0.0029364 Vali Loss: 0.0042020\n",
      "Validation loss decreased (0.004675 --> 0.004202).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/375, epoch: 5 | loss: 0.0027286\n",
      "\titers: 200/375, epoch: 5 | loss: 0.0027060\n",
      "\titers: 300/375, epoch: 5 | loss: 0.0026439\n",
      "Epoch: 5 cost time: 88.0899498462677\n",
      "Epoch: 5, Steps: 375 | Train Loss: 0.0026075 Vali Loss: 0.0027282\n",
      "Validation loss decreased (0.004202 --> 0.002728).  Saving model ...\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/375, epoch: 6 | loss: 0.0023336\n",
      "\titers: 200/375, epoch: 6 | loss: 0.0023149\n",
      "\titers: 300/375, epoch: 6 | loss: 0.0023210\n",
      "Epoch: 6 cost time: 87.24334788322449\n",
      "Epoch: 6, Steps: 375 | Train Loss: 0.0023030 Vali Loss: 0.0024453\n",
      "Validation loss decreased (0.002728 --> 0.002445).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/375, epoch: 7 | loss: 0.0021600\n",
      "\titers: 200/375, epoch: 7 | loss: 0.0021532\n",
      "\titers: 300/375, epoch: 7 | loss: 0.0021591\n",
      "Epoch: 7 cost time: 87.03591728210449\n",
      "Epoch: 7, Steps: 375 | Train Loss: 0.0021482 Vali Loss: 0.0022424\n",
      "Validation loss decreased (0.002445 --> 0.002242).  Saving model ...\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/375, epoch: 8 | loss: 0.0020519\n",
      "\titers: 200/375, epoch: 8 | loss: 0.0020414\n",
      "\titers: 300/375, epoch: 8 | loss: 0.0020346\n",
      "Epoch: 8 cost time: 84.64275288581848\n",
      "Epoch: 8, Steps: 375 | Train Loss: 0.0020420 Vali Loss: 0.0020549\n",
      "Validation loss decreased (0.002242 --> 0.002055).  Saving model ...\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/375, epoch: 9 | loss: 0.0019425\n",
      "\titers: 200/375, epoch: 9 | loss: 0.0019323\n",
      "\titers: 300/375, epoch: 9 | loss: 0.0019266\n",
      "Epoch: 9 cost time: 89.43014121055603\n",
      "Epoch: 9, Steps: 375 | Train Loss: 0.0019151 Vali Loss: 0.0021026\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.3421772800000007e-05\n",
      "\titers: 100/375, epoch: 10 | loss: 0.0018458\n",
      "\titers: 200/375, epoch: 10 | loss: 0.0018418\n",
      "\titers: 300/375, epoch: 10 | loss: 0.0018311\n",
      "Epoch: 10 cost time: 88.7103202342987\n",
      "Epoch: 10, Steps: 375 | Train Loss: 0.0018252 Vali Loss: 0.0019845\n",
      "Validation loss decreased (0.002055 --> 0.001985).  Saving model ...\n",
      "Updating learning rate to 1.0737418240000007e-05\n",
      "\titers: 100/375, epoch: 11 | loss: 0.0017802\n",
      "\titers: 200/375, epoch: 11 | loss: 0.0017881\n",
      "\titers: 300/375, epoch: 11 | loss: 0.0017773\n",
      "Epoch: 11 cost time: 87.54240012168884\n",
      "Epoch: 11, Steps: 375 | Train Loss: 0.0017727 Vali Loss: 0.0020227\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.589934592000006e-06\n",
      "\titers: 100/375, epoch: 12 | loss: 0.0017410\n",
      "\titers: 200/375, epoch: 12 | loss: 0.0017279\n",
      "\titers: 300/375, epoch: 12 | loss: 0.0017296\n",
      "Epoch: 12 cost time: 88.56590175628662\n",
      "Epoch: 12, Steps: 375 | Train Loss: 0.0017315 Vali Loss: 0.0020399\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.871947673600004e-06\n",
      "\titers: 100/375, epoch: 13 | loss: 0.0016937\n",
      "\titers: 200/375, epoch: 13 | loss: 0.0016899\n",
      "\titers: 300/375, epoch: 13 | loss: 0.0016829\n",
      "Epoch: 13 cost time: 88.15748333930969\n",
      "Epoch: 13, Steps: 375 | Train Loss: 0.0016869 Vali Loss: 0.0019287\n",
      "Validation loss decreased (0.001985 --> 0.001929).  Saving model ...\n",
      "Updating learning rate to 5.497558138880004e-06\n",
      "\titers: 100/375, epoch: 14 | loss: 0.0016622\n",
      "\titers: 200/375, epoch: 14 | loss: 0.0016536\n",
      "\titers: 300/375, epoch: 14 | loss: 0.0016514\n",
      "Epoch: 14 cost time: 86.21008706092834\n",
      "Epoch: 14, Steps: 375 | Train Loss: 0.0016509 Vali Loss: 0.0019569\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.398046511104004e-06\n",
      "\titers: 100/375, epoch: 15 | loss: 0.0016360\n",
      "\titers: 200/375, epoch: 15 | loss: 0.0016262\n",
      "\titers: 300/375, epoch: 15 | loss: 0.0016241\n",
      "Epoch: 15 cost time: 89.27203893661499\n",
      "Epoch: 15, Steps: 375 | Train Loss: 0.0016212 Vali Loss: 0.0019451\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.5184372088832033e-06\n",
      "\titers: 100/375, epoch: 16 | loss: 0.0016104\n",
      "\titers: 200/375, epoch: 16 | loss: 0.0016137\n",
      "\titers: 300/375, epoch: 16 | loss: 0.0016031\n",
      "Epoch: 16 cost time: 88.13980150222778\n",
      "Epoch: 16, Steps: 375 | Train Loss: 0.0016001 Vali Loss: 0.0019185\n",
      "Validation loss decreased (0.001929 --> 0.001919).  Saving model ...\n",
      "Updating learning rate to 2.8147497671065624e-06\n",
      "\titers: 100/375, epoch: 17 | loss: 0.0015774\n",
      "\titers: 200/375, epoch: 17 | loss: 0.0015779\n",
      "\titers: 300/375, epoch: 17 | loss: 0.0015729\n",
      "Epoch: 17 cost time: 88.30272436141968\n",
      "Epoch: 17, Steps: 375 | Train Loss: 0.0015714 Vali Loss: 0.0018623\n",
      "Validation loss decreased (0.001919 --> 0.001862).  Saving model ...\n",
      "Updating learning rate to 2.2517998136852503e-06\n",
      "\titers: 100/375, epoch: 18 | loss: 0.0015666\n",
      "\titers: 200/375, epoch: 18 | loss: 0.0015632\n",
      "\titers: 300/375, epoch: 18 | loss: 0.0015587\n",
      "Epoch: 18 cost time: 85.66759467124939\n",
      "Epoch: 18, Steps: 375 | Train Loss: 0.0015612 Vali Loss: 0.0017859\n",
      "Validation loss decreased (0.001862 --> 0.001786).  Saving model ...\n",
      "Updating learning rate to 1.8014398509482004e-06\n",
      "\titers: 100/375, epoch: 19 | loss: 0.0015456\n",
      "\titers: 200/375, epoch: 19 | loss: 0.0015444\n",
      "\titers: 300/375, epoch: 19 | loss: 0.0015420\n",
      "Epoch: 19 cost time: 88.95009732246399\n",
      "Epoch: 19, Steps: 375 | Train Loss: 0.0015434 Vali Loss: 0.0018868\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.4411518807585604e-06\n",
      "\titers: 100/375, epoch: 20 | loss: 0.0015251\n",
      "\titers: 200/375, epoch: 20 | loss: 0.0015288\n",
      "\titers: 300/375, epoch: 20 | loss: 0.0015273\n",
      "Epoch: 20 cost time: 88.84467601776123\n",
      "Epoch: 20, Steps: 375 | Train Loss: 0.0015259 Vali Loss: 0.0018764\n",
      "EarlyStopping counter: 2 out of 3\n",
      "test 1993\n",
      "loading model\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.0202752985060215, mae:0.11564084142446518\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_additive with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_additive_ftS_sl768_ll48_pl336_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 11857\n",
      "val 1825\n",
      "test 1825\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/370, epoch: 1 | loss: 0.3153871\n",
      "\titers: 200/370, epoch: 1 | loss: 0.1810805\n",
      "\titers: 300/370, epoch: 1 | loss: 0.1269522\n",
      "Epoch: 1 cost time: 102.80132412910461\n",
      "Epoch: 1, Steps: 370 | Train Loss: 0.1047923 Vali Loss: 0.0333634\n",
      "Validation loss decreased (inf --> 0.033363).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/370, epoch: 2 | loss: 0.0073170\n",
      "\titers: 200/370, epoch: 2 | loss: 0.0066802\n",
      "\titers: 300/370, epoch: 2 | loss: 0.0062250\n",
      "Epoch: 2 cost time: 102.86451363563538\n",
      "Epoch: 2, Steps: 370 | Train Loss: 0.0059338 Vali Loss: 0.0086121\n",
      "Validation loss decreased (0.033363 --> 0.008612).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/370, epoch: 3 | loss: 0.0043314\n",
      "\titers: 200/370, epoch: 3 | loss: 0.0041334\n",
      "\titers: 300/370, epoch: 3 | loss: 0.0039906\n",
      "Epoch: 3 cost time: 101.86483430862427\n",
      "Epoch: 3, Steps: 370 | Train Loss: 0.0039616 Vali Loss: 0.0077036\n",
      "Validation loss decreased (0.008612 --> 0.007704).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/370, epoch: 4 | loss: 0.0035026\n",
      "\titers: 200/370, epoch: 4 | loss: 0.0033495\n",
      "\titers: 300/370, epoch: 4 | loss: 0.0032491\n",
      "Epoch: 4 cost time: 100.5008294582367\n",
      "Epoch: 4, Steps: 370 | Train Loss: 0.0032108 Vali Loss: 0.0034969\n",
      "Validation loss decreased (0.007704 --> 0.003497).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/370, epoch: 5 | loss: 0.0028265\n",
      "\titers: 200/370, epoch: 5 | loss: 0.0027982\n",
      "\titers: 300/370, epoch: 5 | loss: 0.0027797\n",
      "Epoch: 5 cost time: 103.53322339057922\n",
      "Epoch: 5, Steps: 370 | Train Loss: 0.0027593 Vali Loss: 0.0027566\n",
      "Validation loss decreased (0.003497 --> 0.002757).  Saving model ...\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/370, epoch: 6 | loss: 0.0025246\n",
      "\titers: 200/370, epoch: 6 | loss: 0.0024969\n",
      "\titers: 300/370, epoch: 6 | loss: 0.0024950\n",
      "Epoch: 6 cost time: 100.17122054100037\n",
      "Epoch: 6, Steps: 370 | Train Loss: 0.0024757 Vali Loss: 0.0025655\n",
      "Validation loss decreased (0.002757 --> 0.002565).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/370, epoch: 7 | loss: 0.0023790\n",
      "\titers: 200/370, epoch: 7 | loss: 0.0023414\n",
      "\titers: 300/370, epoch: 7 | loss: 0.0023118\n",
      "Epoch: 7 cost time: 100.20207214355469\n",
      "Epoch: 7, Steps: 370 | Train Loss: 0.0022956 Vali Loss: 0.0027986\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/370, epoch: 8 | loss: 0.0021940\n",
      "\titers: 200/370, epoch: 8 | loss: 0.0021782\n",
      "\titers: 300/370, epoch: 8 | loss: 0.0021696\n",
      "Epoch: 8 cost time: 106.01087975502014\n",
      "Epoch: 8, Steps: 370 | Train Loss: 0.0021599 Vali Loss: 0.0023080\n",
      "Validation loss decreased (0.002565 --> 0.002308).  Saving model ...\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/370, epoch: 9 | loss: 0.0020712\n",
      "\titers: 200/370, epoch: 9 | loss: 0.0020592\n",
      "\titers: 300/370, epoch: 9 | loss: 0.0020465\n",
      "Epoch: 9 cost time: 101.08350133895874\n",
      "Epoch: 9, Steps: 370 | Train Loss: 0.0020408 Vali Loss: 0.0022024\n",
      "Validation loss decreased (0.002308 --> 0.002202).  Saving model ...\n",
      "Updating learning rate to 1.3421772800000007e-05\n",
      "\titers: 100/370, epoch: 10 | loss: 0.0020008\n",
      "\titers: 200/370, epoch: 10 | loss: 0.0020015\n",
      "\titers: 300/370, epoch: 10 | loss: 0.0019911\n",
      "Epoch: 10 cost time: 105.11150693893433\n",
      "Epoch: 10, Steps: 370 | Train Loss: 0.0019815 Vali Loss: 0.0021639\n",
      "Validation loss decreased (0.002202 --> 0.002164).  Saving model ...\n",
      "Updating learning rate to 1.0737418240000007e-05\n",
      "\titers: 100/370, epoch: 11 | loss: 0.0019177\n",
      "\titers: 200/370, epoch: 11 | loss: 0.0019140\n",
      "\titers: 300/370, epoch: 11 | loss: 0.0019100\n",
      "Epoch: 11 cost time: 102.25452780723572\n",
      "Epoch: 11, Steps: 370 | Train Loss: 0.0019047 Vali Loss: 0.0020838\n",
      "Validation loss decreased (0.002164 --> 0.002084).  Saving model ...\n",
      "Updating learning rate to 8.589934592000006e-06\n",
      "\titers: 100/370, epoch: 12 | loss: 0.0018904\n",
      "\titers: 200/370, epoch: 12 | loss: 0.0018822\n",
      "\titers: 300/370, epoch: 12 | loss: 0.0018647\n",
      "Epoch: 12 cost time: 97.5075740814209\n",
      "Epoch: 12, Steps: 370 | Train Loss: 0.0018613 Vali Loss: 0.0021958\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.871947673600004e-06\n",
      "\titers: 100/370, epoch: 13 | loss: 0.0018219\n",
      "\titers: 200/370, epoch: 13 | loss: 0.0018229\n",
      "\titers: 300/370, epoch: 13 | loss: 0.0018192\n",
      "Epoch: 13 cost time: 106.03134775161743\n",
      "Epoch: 13, Steps: 370 | Train Loss: 0.0018157 Vali Loss: 0.0021125\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.497558138880004e-06\n",
      "\titers: 100/370, epoch: 14 | loss: 0.0017765\n",
      "\titers: 200/370, epoch: 14 | loss: 0.0017818\n",
      "\titers: 300/370, epoch: 14 | loss: 0.0017734\n",
      "Epoch: 14 cost time: 101.58401250839233\n",
      "Epoch: 14, Steps: 370 | Train Loss: 0.0017707 Vali Loss: 0.0020004\n",
      "Validation loss decreased (0.002084 --> 0.002000).  Saving model ...\n",
      "Updating learning rate to 4.398046511104004e-06\n",
      "\titers: 100/370, epoch: 15 | loss: 0.0017522\n",
      "\titers: 200/370, epoch: 15 | loss: 0.0017488\n",
      "\titers: 300/370, epoch: 15 | loss: 0.0017437\n",
      "Epoch: 15 cost time: 102.33284902572632\n",
      "Epoch: 15, Steps: 370 | Train Loss: 0.0017407 Vali Loss: 0.0022923\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.5184372088832033e-06\n",
      "\titers: 100/370, epoch: 16 | loss: 0.0017323\n",
      "\titers: 200/370, epoch: 16 | loss: 0.0017254\n",
      "\titers: 300/370, epoch: 16 | loss: 0.0017211\n",
      "Epoch: 16 cost time: 102.17609286308289\n",
      "Epoch: 16, Steps: 370 | Train Loss: 0.0017141 Vali Loss: 0.0020374\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.8147497671065624e-06\n",
      "\titers: 100/370, epoch: 17 | loss: 0.0016980\n",
      "\titers: 200/370, epoch: 17 | loss: 0.0016984\n",
      "\titers: 300/370, epoch: 17 | loss: 0.0016922\n",
      "Epoch: 17 cost time: 102.26507496833801\n",
      "Epoch: 17, Steps: 370 | Train Loss: 0.0016924 Vali Loss: 0.0018934\n",
      "Validation loss decreased (0.002000 --> 0.001893).  Saving model ...\n",
      "Updating learning rate to 2.2517998136852503e-06\n",
      "\titers: 100/370, epoch: 18 | loss: 0.0016811\n",
      "\titers: 200/370, epoch: 18 | loss: 0.0016821\n",
      "\titers: 300/370, epoch: 18 | loss: 0.0016733\n",
      "Epoch: 18 cost time: 104.21089458465576\n",
      "Epoch: 18, Steps: 370 | Train Loss: 0.0016730 Vali Loss: 0.0023530\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.8014398509482004e-06\n",
      "\titers: 100/370, epoch: 19 | loss: 0.0016722\n",
      "\titers: 200/370, epoch: 19 | loss: 0.0016599\n",
      "\titers: 300/370, epoch: 19 | loss: 0.0016587\n",
      "Epoch: 19 cost time: 103.90807557106018\n",
      "Epoch: 19, Steps: 370 | Train Loss: 0.0016581 Vali Loss: 0.0020668\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.4411518807585604e-06\n",
      "\titers: 100/370, epoch: 20 | loss: 0.0016405\n",
      "\titers: 200/370, epoch: 20 | loss: 0.0016428\n",
      "\titers: 300/370, epoch: 20 | loss: 0.0016427\n",
      "Epoch: 20 cost time: 102.89274716377258\n",
      "Epoch: 20, Steps: 370 | Train Loss: 0.0016389 Vali Loss: 0.0020648\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "loading model\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.016332212835550308, mae:0.09997496753931046\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_additive with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_additive_ftS_sl768_ll48_pl720_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 11473\n",
      "val 1441\n",
      "test 1441\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/358, epoch: 1 | loss: 0.3074975\n",
      "\titers: 200/358, epoch: 1 | loss: 0.1751460\n",
      "\titers: 300/358, epoch: 1 | loss: 0.1219964\n",
      "Epoch: 1 cost time: 124.9370653629303\n",
      "Epoch: 1, Steps: 358 | Train Loss: 0.1038700 Vali Loss: 0.0373167\n",
      "Validation loss decreased (inf --> 0.037317).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/358, epoch: 2 | loss: 0.0079711\n",
      "\titers: 200/358, epoch: 2 | loss: 0.0072624\n",
      "\titers: 300/358, epoch: 2 | loss: 0.0066694\n",
      "Epoch: 2 cost time: 131.71261310577393\n",
      "Epoch: 2, Steps: 358 | Train Loss: 0.0063908 Vali Loss: 0.0108490\n",
      "Validation loss decreased (0.037317 --> 0.010849).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/358, epoch: 3 | loss: 0.0044856\n",
      "\titers: 200/358, epoch: 3 | loss: 0.0046248\n",
      "\titers: 300/358, epoch: 3 | loss: 0.0044355\n",
      "Epoch: 3 cost time: 129.62631583213806\n",
      "Epoch: 3, Steps: 358 | Train Loss: 0.0043098 Vali Loss: 0.0063510\n",
      "Validation loss decreased (0.010849 --> 0.006351).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/358, epoch: 4 | loss: 0.0034805\n",
      "\titers: 200/358, epoch: 4 | loss: 0.0034362\n",
      "\titers: 300/358, epoch: 4 | loss: 0.0033733\n",
      "Epoch: 4 cost time: 124.95855474472046\n",
      "Epoch: 4, Steps: 358 | Train Loss: 0.0033302 Vali Loss: 0.0047313\n",
      "Validation loss decreased (0.006351 --> 0.004731).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/358, epoch: 5 | loss: 0.0032129\n",
      "\titers: 200/358, epoch: 5 | loss: 0.0030628\n",
      "\titers: 300/358, epoch: 5 | loss: 0.0029852\n",
      "Epoch: 5 cost time: 129.1110873222351\n",
      "Epoch: 5, Steps: 358 | Train Loss: 0.0029569 Vali Loss: 0.0035422\n",
      "Validation loss decreased (0.004731 --> 0.003542).  Saving model ...\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/358, epoch: 6 | loss: 0.0026754\n",
      "\titers: 200/358, epoch: 6 | loss: 0.0026643\n",
      "\titers: 300/358, epoch: 6 | loss: 0.0026705\n",
      "Epoch: 6 cost time: 129.92350268363953\n",
      "Epoch: 6, Steps: 358 | Train Loss: 0.0026544 Vali Loss: 0.0030287\n",
      "Validation loss decreased (0.003542 --> 0.003029).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/358, epoch: 7 | loss: 0.0024872\n",
      "\titers: 200/358, epoch: 7 | loss: 0.0024853\n",
      "\titers: 300/358, epoch: 7 | loss: 0.0024654\n",
      "Epoch: 7 cost time: 129.53911638259888\n",
      "Epoch: 7, Steps: 358 | Train Loss: 0.0024582 Vali Loss: 0.0027158\n",
      "Validation loss decreased (0.003029 --> 0.002716).  Saving model ...\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/358, epoch: 8 | loss: 0.0023580\n",
      "\titers: 200/358, epoch: 8 | loss: 0.0023374\n",
      "\titers: 300/358, epoch: 8 | loss: 0.0023181\n",
      "Epoch: 8 cost time: 128.3051564693451\n",
      "Epoch: 8, Steps: 358 | Train Loss: 0.0023076 Vali Loss: 0.0027784\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/358, epoch: 9 | loss: 0.0022489\n",
      "\titers: 200/358, epoch: 9 | loss: 0.0022329\n",
      "\titers: 300/358, epoch: 9 | loss: 0.0022191\n",
      "Epoch: 9 cost time: 127.74401926994324\n",
      "Epoch: 9, Steps: 358 | Train Loss: 0.0022149 Vali Loss: 0.0024839\n",
      "Validation loss decreased (0.002716 --> 0.002484).  Saving model ...\n",
      "Updating learning rate to 1.3421772800000007e-05\n",
      "\titers: 100/358, epoch: 10 | loss: 0.0021404\n",
      "\titers: 200/358, epoch: 10 | loss: 0.0021392\n",
      "\titers: 300/358, epoch: 10 | loss: 0.0021279\n",
      "Epoch: 10 cost time: 128.332346200943\n",
      "Epoch: 10, Steps: 358 | Train Loss: 0.0021224 Vali Loss: 0.0024370\n",
      "Validation loss decreased (0.002484 --> 0.002437).  Saving model ...\n",
      "Updating learning rate to 1.0737418240000007e-05\n",
      "\titers: 100/358, epoch: 11 | loss: 0.0020789\n",
      "\titers: 200/358, epoch: 11 | loss: 0.0020720\n",
      "\titers: 300/358, epoch: 11 | loss: 0.0020649\n",
      "Epoch: 11 cost time: 128.62133932113647\n",
      "Epoch: 11, Steps: 358 | Train Loss: 0.0020650 Vali Loss: 0.0022627\n",
      "Validation loss decreased (0.002437 --> 0.002263).  Saving model ...\n",
      "Updating learning rate to 8.589934592000006e-06\n",
      "\titers: 100/358, epoch: 12 | loss: 0.0020179\n",
      "\titers: 200/358, epoch: 12 | loss: 0.0020133\n",
      "\titers: 300/358, epoch: 12 | loss: 0.0020053\n",
      "Epoch: 12 cost time: 129.1850814819336\n",
      "Epoch: 12, Steps: 358 | Train Loss: 0.0020012 Vali Loss: 0.0023433\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.871947673600004e-06\n",
      "\titers: 100/358, epoch: 13 | loss: 0.0019735\n",
      "\titers: 200/358, epoch: 13 | loss: 0.0019661\n",
      "\titers: 300/358, epoch: 13 | loss: 0.0019710\n",
      "Epoch: 13 cost time: 128.5896291732788\n",
      "Epoch: 13, Steps: 358 | Train Loss: 0.0019677 Vali Loss: 0.0024291\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.497558138880004e-06\n",
      "\titers: 100/358, epoch: 14 | loss: 0.0019372\n",
      "\titers: 200/358, epoch: 14 | loss: 0.0019264\n",
      "\titers: 300/358, epoch: 14 | loss: 0.0019262\n",
      "Epoch: 14 cost time: 128.67220187187195\n",
      "Epoch: 14, Steps: 358 | Train Loss: 0.0019242 Vali Loss: 0.0022515\n",
      "Validation loss decreased (0.002263 --> 0.002251).  Saving model ...\n",
      "Updating learning rate to 4.398046511104004e-06\n",
      "\titers: 100/358, epoch: 15 | loss: 0.0019074\n",
      "\titers: 200/358, epoch: 15 | loss: 0.0018977\n",
      "\titers: 300/358, epoch: 15 | loss: 0.0018939\n",
      "Epoch: 15 cost time: 126.37531995773315\n",
      "Epoch: 15, Steps: 358 | Train Loss: 0.0018903 Vali Loss: 0.0023079\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.5184372088832033e-06\n",
      "\titers: 100/358, epoch: 16 | loss: 0.0018711\n",
      "\titers: 200/358, epoch: 16 | loss: 0.0018694\n",
      "\titers: 300/358, epoch: 16 | loss: 0.0018637\n",
      "Epoch: 16 cost time: 125.13388252258301\n",
      "Epoch: 16, Steps: 358 | Train Loss: 0.0018628 Vali Loss: 0.0022140\n",
      "Validation loss decreased (0.002251 --> 0.002214).  Saving model ...\n",
      "Updating learning rate to 2.8147497671065624e-06\n",
      "\titers: 100/358, epoch: 17 | loss: 0.0018526\n",
      "\titers: 200/358, epoch: 17 | loss: 0.0018415\n",
      "\titers: 300/358, epoch: 17 | loss: 0.0018399\n",
      "Epoch: 17 cost time: 127.92024254798889\n",
      "Epoch: 17, Steps: 358 | Train Loss: 0.0018387 Vali Loss: 0.0021772\n",
      "Validation loss decreased (0.002214 --> 0.002177).  Saving model ...\n",
      "Updating learning rate to 2.2517998136852503e-06\n",
      "\titers: 100/358, epoch: 18 | loss: 0.0018223\n",
      "\titers: 200/358, epoch: 18 | loss: 0.0018299\n",
      "\titers: 300/358, epoch: 18 | loss: 0.0018226\n",
      "Epoch: 18 cost time: 133.7654025554657\n",
      "Epoch: 18, Steps: 358 | Train Loss: 0.0018210 Vali Loss: 0.0023184\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.8014398509482004e-06\n",
      "\titers: 100/358, epoch: 19 | loss: 0.0018066\n",
      "\titers: 200/358, epoch: 19 | loss: 0.0018060\n",
      "\titers: 300/358, epoch: 19 | loss: 0.0018006\n",
      "Epoch: 19 cost time: 129.1366732120514\n",
      "Epoch: 19, Steps: 358 | Train Loss: 0.0018008 Vali Loss: 0.0022468\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.4411518807585604e-06\n",
      "\titers: 100/358, epoch: 20 | loss: 0.0017952\n",
      "\titers: 200/358, epoch: 20 | loss: 0.0017813\n",
      "\titers: 300/358, epoch: 20 | loss: 0.0017814\n",
      "Epoch: 20 cost time: 128.8082892894745\n",
      "Epoch: 20, Steps: 358 | Train Loss: 0.0017824 Vali Loss: 0.0022376\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "loading model\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.017010122537612915, mae:0.1033366322517395\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_additive_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_additive_reversal_ftS_sl768_ll48_pl24_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12169\n",
      "val 2137\n",
      "test 2137\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/380, epoch: 1 | loss: 0.3006894\n",
      "\titers: 200/380, epoch: 1 | loss: 0.1692302\n",
      "\titers: 300/380, epoch: 1 | loss: 0.1194825\n",
      "Epoch: 1 cost time: 80.16514611244202\n",
      "Epoch: 1, Steps: 380 | Train Loss: 0.0977299 Vali Loss: 0.5346244\n",
      "Validation loss decreased (inf --> 0.534624).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/380, epoch: 2 | loss: 0.0108656\n",
      "\titers: 200/380, epoch: 2 | loss: 0.0107221\n",
      "\titers: 300/380, epoch: 2 | loss: 0.0106638\n",
      "Epoch: 2 cost time: 81.98696303367615\n",
      "Epoch: 2, Steps: 380 | Train Loss: 0.0102672 Vali Loss: 0.3117317\n",
      "Validation loss decreased (0.534624 --> 0.311732).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/380, epoch: 3 | loss: 0.0087768\n",
      "\titers: 200/380, epoch: 3 | loss: 0.0083359\n",
      "\titers: 300/380, epoch: 3 | loss: 0.0083072\n",
      "Epoch: 3 cost time: 81.73469924926758\n",
      "Epoch: 3, Steps: 380 | Train Loss: 0.0079086 Vali Loss: 0.4424126\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/380, epoch: 4 | loss: 0.0063967\n",
      "\titers: 200/380, epoch: 4 | loss: 0.0061691\n",
      "\titers: 300/380, epoch: 4 | loss: 0.0059819\n",
      "Epoch: 4 cost time: 81.83058547973633\n",
      "Epoch: 4, Steps: 380 | Train Loss: 0.0060387 Vali Loss: 0.2831344\n",
      "Validation loss decreased (0.311732 --> 0.283134).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/380, epoch: 5 | loss: 0.0055576\n",
      "\titers: 200/380, epoch: 5 | loss: 0.0053859\n",
      "\titers: 300/380, epoch: 5 | loss: 0.0053114\n",
      "Epoch: 5 cost time: 81.08458805084229\n",
      "Epoch: 5, Steps: 380 | Train Loss: 0.0053621 Vali Loss: 0.3129753\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/380, epoch: 6 | loss: 0.0045736\n",
      "\titers: 200/380, epoch: 6 | loss: 0.0045959\n",
      "\titers: 300/380, epoch: 6 | loss: 0.0046912\n",
      "Epoch: 6 cost time: 78.28246736526489\n",
      "Epoch: 6, Steps: 380 | Train Loss: 0.0048226 Vali Loss: 0.2716094\n",
      "Validation loss decreased (0.283134 --> 0.271609).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/380, epoch: 7 | loss: 0.0042423\n",
      "\titers: 200/380, epoch: 7 | loss: 0.0043420\n",
      "\titers: 300/380, epoch: 7 | loss: 0.0043687\n",
      "Epoch: 7 cost time: 78.81584596633911\n",
      "Epoch: 7, Steps: 380 | Train Loss: 0.0043254 Vali Loss: 0.2888347\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/380, epoch: 8 | loss: 0.0040501\n",
      "\titers: 200/380, epoch: 8 | loss: 0.0040387\n",
      "\titers: 300/380, epoch: 8 | loss: 0.0040131\n",
      "Epoch: 8 cost time: 82.6647379398346\n",
      "Epoch: 8, Steps: 380 | Train Loss: 0.0040217 Vali Loss: 0.2695250\n",
      "Validation loss decreased (0.271609 --> 0.269525).  Saving model ...\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/380, epoch: 9 | loss: 0.0038559\n",
      "\titers: 200/380, epoch: 9 | loss: 0.0039161\n",
      "\titers: 300/380, epoch: 9 | loss: 0.0039292\n",
      "Epoch: 9 cost time: 88.33507823944092\n",
      "Epoch: 9, Steps: 380 | Train Loss: 0.0039085 Vali Loss: 0.2626601\n",
      "Validation loss decreased (0.269525 --> 0.262660).  Saving model ...\n",
      "Updating learning rate to 1.3421772800000007e-05\n",
      "\titers: 100/380, epoch: 10 | loss: 0.0037507\n",
      "\titers: 200/380, epoch: 10 | loss: 0.0037143\n",
      "\titers: 300/380, epoch: 10 | loss: 0.0037091\n",
      "Epoch: 10 cost time: 79.90296196937561\n",
      "Epoch: 10, Steps: 380 | Train Loss: 0.0036789 Vali Loss: 0.2951907\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.0737418240000007e-05\n",
      "\titers: 100/380, epoch: 11 | loss: 0.0035647\n",
      "\titers: 200/380, epoch: 11 | loss: 0.0036161\n",
      "\titers: 300/380, epoch: 11 | loss: 0.0035977\n",
      "Epoch: 11 cost time: 81.22482061386108\n",
      "Epoch: 11, Steps: 380 | Train Loss: 0.0035603 Vali Loss: 0.2547899\n",
      "Validation loss decreased (0.262660 --> 0.254790).  Saving model ...\n",
      "Updating learning rate to 8.589934592000006e-06\n",
      "\titers: 100/380, epoch: 12 | loss: 0.0033655\n",
      "\titers: 200/380, epoch: 12 | loss: 0.0034011\n",
      "\titers: 300/380, epoch: 12 | loss: 0.0034236\n",
      "Epoch: 12 cost time: 80.67001843452454\n",
      "Epoch: 12, Steps: 380 | Train Loss: 0.0034300 Vali Loss: 0.2709024\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.871947673600004e-06\n",
      "\titers: 100/380, epoch: 13 | loss: 0.0033759\n",
      "\titers: 200/380, epoch: 13 | loss: 0.0034192\n",
      "\titers: 300/380, epoch: 13 | loss: 0.0033696\n",
      "Epoch: 13 cost time: 79.43990921974182\n",
      "Epoch: 13, Steps: 380 | Train Loss: 0.0033489 Vali Loss: 0.2734621\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.497558138880004e-06\n",
      "\titers: 100/380, epoch: 14 | loss: 0.0032339\n",
      "\titers: 200/380, epoch: 14 | loss: 0.0032784\n",
      "\titers: 300/380, epoch: 14 | loss: 0.0032655\n",
      "Epoch: 14 cost time: 81.84896612167358\n",
      "Epoch: 14, Steps: 380 | Train Loss: 0.0032643 Vali Loss: 0.2797391\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "loading model\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.9816510677337646, mae:0.758700430393219\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_additive_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_additive_reversal_ftS_sl768_ll48_pl48_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 2113\n",
      "test 2113\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/379, epoch: 1 | loss: 0.3261065\n",
      "\titers: 200/379, epoch: 1 | loss: 0.1878316\n",
      "\titers: 300/379, epoch: 1 | loss: 0.1337127\n",
      "Epoch: 1 cost time: 82.26209926605225\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.1094079 Vali Loss: 0.3095162\n",
      "Validation loss decreased (inf --> 0.309516).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/379, epoch: 2 | loss: 0.0131145\n",
      "\titers: 200/379, epoch: 2 | loss: 0.0126611\n",
      "\titers: 300/379, epoch: 2 | loss: 0.0120047\n",
      "Epoch: 2 cost time: 81.45595026016235\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.0118739 Vali Loss: 0.1840824\n",
      "Validation loss decreased (0.309516 --> 0.184082).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/379, epoch: 3 | loss: 0.0093347\n",
      "\titers: 200/379, epoch: 3 | loss: 0.0087668\n",
      "\titers: 300/379, epoch: 3 | loss: 0.0085190\n",
      "Epoch: 3 cost time: 82.33255314826965\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.0083178 Vali Loss: 0.1101817\n",
      "Validation loss decreased (0.184082 --> 0.110182).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/379, epoch: 4 | loss: 0.0068579\n",
      "\titers: 200/379, epoch: 4 | loss: 0.0070416\n",
      "\titers: 300/379, epoch: 4 | loss: 0.0069987\n",
      "Epoch: 4 cost time: 82.75136518478394\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.0069275 Vali Loss: 0.1065447\n",
      "Validation loss decreased (0.110182 --> 0.106545).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/379, epoch: 5 | loss: 0.0061966\n",
      "\titers: 200/379, epoch: 5 | loss: 0.0061044\n",
      "\titers: 300/379, epoch: 5 | loss: 0.0061140\n",
      "Epoch: 5 cost time: 81.04856300354004\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.0061455 Vali Loss: 0.1104248\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/379, epoch: 6 | loss: 0.0055734\n",
      "\titers: 200/379, epoch: 6 | loss: 0.0055952\n",
      "\titers: 300/379, epoch: 6 | loss: 0.0054626\n",
      "Epoch: 6 cost time: 83.43101644515991\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.0053920 Vali Loss: 0.1086597\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/379, epoch: 7 | loss: 0.0047166\n",
      "\titers: 200/379, epoch: 7 | loss: 0.0047004\n",
      "\titers: 300/379, epoch: 7 | loss: 0.0047320\n",
      "Epoch: 7 cost time: 81.39015769958496\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.0047147 Vali Loss: 0.1109146\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "loading model\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.3014572858810425, mae:0.3999239206314087\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_additive_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_additive_reversal_ftS_sl768_ll48_pl168_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12025\n",
      "val 1993\n",
      "test 1993\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/375, epoch: 1 | loss: 0.4285611\n",
      "\titers: 200/375, epoch: 1 | loss: 0.2597381\n",
      "\titers: 300/375, epoch: 1 | loss: 0.1892838\n",
      "Epoch: 1 cost time: 88.19407439231873\n",
      "Epoch: 1, Steps: 375 | Train Loss: 0.1584469 Vali Loss: 0.6049383\n",
      "Validation loss decreased (inf --> 0.604938).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/375, epoch: 2 | loss: 0.0304194\n",
      "\titers: 200/375, epoch: 2 | loss: 0.0293797\n",
      "\titers: 300/375, epoch: 2 | loss: 0.0261894\n",
      "Epoch: 2 cost time: 87.89894604682922\n",
      "Epoch: 2, Steps: 375 | Train Loss: 0.0248639 Vali Loss: 0.4351381\n",
      "Validation loss decreased (0.604938 --> 0.435138).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/375, epoch: 3 | loss: 0.0175185\n",
      "\titers: 200/375, epoch: 3 | loss: 0.0158388\n",
      "\titers: 300/375, epoch: 3 | loss: 0.0151784\n",
      "Epoch: 3 cost time: 86.23630046844482\n",
      "Epoch: 3, Steps: 375 | Train Loss: 0.0145825 Vali Loss: 0.3823008\n",
      "Validation loss decreased (0.435138 --> 0.382301).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/375, epoch: 4 | loss: 0.0114043\n",
      "\titers: 200/375, epoch: 4 | loss: 0.0123097\n",
      "\titers: 300/375, epoch: 4 | loss: 0.0117844\n",
      "Epoch: 4 cost time: 88.8822283744812\n",
      "Epoch: 4, Steps: 375 | Train Loss: 0.0113515 Vali Loss: 0.3906148\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/375, epoch: 5 | loss: 0.0089661\n",
      "\titers: 200/375, epoch: 5 | loss: 0.0087205\n",
      "\titers: 300/375, epoch: 5 | loss: 0.0085558\n",
      "Epoch: 5 cost time: 88.87464666366577\n",
      "Epoch: 5, Steps: 375 | Train Loss: 0.0085579 Vali Loss: 0.3806016\n",
      "Validation loss decreased (0.382301 --> 0.380602).  Saving model ...\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/375, epoch: 6 | loss: 0.0079253\n",
      "\titers: 200/375, epoch: 6 | loss: 0.0076832\n",
      "\titers: 300/375, epoch: 6 | loss: 0.0076685\n",
      "Epoch: 6 cost time: 86.01258945465088\n",
      "Epoch: 6, Steps: 375 | Train Loss: 0.0076332 Vali Loss: 0.3466271\n",
      "Validation loss decreased (0.380602 --> 0.346627).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/375, epoch: 7 | loss: 0.0069736\n",
      "\titers: 200/375, epoch: 7 | loss: 0.0068273\n",
      "\titers: 300/375, epoch: 7 | loss: 0.0067885\n",
      "Epoch: 7 cost time: 86.97824120521545\n",
      "Epoch: 7, Steps: 375 | Train Loss: 0.0067400 Vali Loss: 0.3164884\n",
      "Validation loss decreased (0.346627 --> 0.316488).  Saving model ...\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/375, epoch: 8 | loss: 0.0062375\n",
      "\titers: 200/375, epoch: 8 | loss: 0.0062498\n",
      "\titers: 300/375, epoch: 8 | loss: 0.0061891\n",
      "Epoch: 8 cost time: 89.79951524734497\n",
      "Epoch: 8, Steps: 375 | Train Loss: 0.0061463 Vali Loss: 0.4012301\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/375, epoch: 9 | loss: 0.0059376\n",
      "\titers: 200/375, epoch: 9 | loss: 0.0057850\n",
      "\titers: 300/375, epoch: 9 | loss: 0.0057448\n",
      "Epoch: 9 cost time: 86.9979076385498\n",
      "Epoch: 9, Steps: 375 | Train Loss: 0.0057106 Vali Loss: 0.3950568\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.3421772800000007e-05\n",
      "\titers: 100/375, epoch: 10 | loss: 0.0053678\n",
      "\titers: 200/375, epoch: 10 | loss: 0.0053432\n",
      "\titers: 300/375, epoch: 10 | loss: 0.0053157\n",
      "Epoch: 10 cost time: 84.97743630409241\n",
      "Epoch: 10, Steps: 375 | Train Loss: 0.0053279 Vali Loss: 0.4088582\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "loading model\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:1.0884627103805542, mae:0.8853604793548584\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_additive_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_additive_reversal_ftS_sl768_ll48_pl336_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 11857\n",
      "val 1825\n",
      "test 1825\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/370, epoch: 1 | loss: 0.4763286\n",
      "\titers: 200/370, epoch: 1 | loss: 0.3108197\n",
      "\titers: 300/370, epoch: 1 | loss: 0.2387712\n",
      "Epoch: 1 cost time: 105.41625571250916\n",
      "Epoch: 1, Steps: 370 | Train Loss: 0.2063742 Vali Loss: 1.9872365\n",
      "Validation loss decreased (inf --> 1.987236).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/370, epoch: 2 | loss: 0.0488744\n",
      "\titers: 200/370, epoch: 2 | loss: 0.0467668\n",
      "\titers: 300/370, epoch: 2 | loss: 0.0439161\n",
      "Epoch: 2 cost time: 165.17644214630127\n",
      "Epoch: 2, Steps: 370 | Train Loss: 0.0415112 Vali Loss: 1.5494276\n",
      "Validation loss decreased (1.987236 --> 1.549428).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/370, epoch: 3 | loss: 0.0262522\n",
      "\titers: 200/370, epoch: 3 | loss: 0.0242665\n",
      "\titers: 300/370, epoch: 3 | loss: 0.0229633\n",
      "Epoch: 3 cost time: 133.6284990310669\n",
      "Epoch: 3, Steps: 370 | Train Loss: 0.0220531 Vali Loss: 1.5319077\n",
      "Validation loss decreased (1.549428 --> 1.531908).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/370, epoch: 4 | loss: 0.0167115\n",
      "\titers: 200/370, epoch: 4 | loss: 0.0161981\n",
      "\titers: 300/370, epoch: 4 | loss: 0.0155517\n",
      "Epoch: 4 cost time: 141.95479726791382\n",
      "Epoch: 4, Steps: 370 | Train Loss: 0.0153380 Vali Loss: 1.5631799\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/370, epoch: 5 | loss: 0.0130915\n",
      "\titers: 200/370, epoch: 5 | loss: 0.0124788\n",
      "\titers: 300/370, epoch: 5 | loss: 0.0121445\n",
      "Epoch: 5 cost time: 138.15674018859863\n",
      "Epoch: 5, Steps: 370 | Train Loss: 0.0121351 Vali Loss: 1.5358648\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/370, epoch: 6 | loss: 0.0102170\n",
      "\titers: 200/370, epoch: 6 | loss: 0.0102260\n",
      "\titers: 300/370, epoch: 6 | loss: 0.0101048\n",
      "Epoch: 6 cost time: 141.77264881134033\n",
      "Epoch: 6, Steps: 370 | Train Loss: 0.0101022 Vali Loss: 1.5699404\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "loading model\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:3.1718943119049072, mae:1.6415843963623047\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_additive_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_additive_reversal_ftS_sl768_ll48_pl720_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 11473\n",
      "val 1441\n",
      "test 1441\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/358, epoch: 1 | loss: 0.5198849\n",
      "\titers: 200/358, epoch: 1 | loss: 0.3598306\n",
      "\titers: 300/358, epoch: 1 | loss: 0.2879038\n",
      "Epoch: 1 cost time: 174.69487380981445\n",
      "Epoch: 1, Steps: 358 | Train Loss: 0.2579284 Vali Loss: 2.2890525\n",
      "Validation loss decreased (inf --> 2.289052).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/358, epoch: 2 | loss: 0.0781339\n",
      "\titers: 200/358, epoch: 2 | loss: 0.0690870\n",
      "\titers: 300/358, epoch: 2 | loss: 0.0608820\n",
      "Epoch: 2 cost time: 173.69760370254517\n",
      "Epoch: 2, Steps: 358 | Train Loss: 0.0563423 Vali Loss: 2.9544098\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/358, epoch: 3 | loss: 0.0310840\n",
      "\titers: 200/358, epoch: 3 | loss: 0.0277467\n",
      "\titers: 300/358, epoch: 3 | loss: 0.0262786\n",
      "Epoch: 3 cost time: 164.5565173625946\n",
      "Epoch: 3, Steps: 358 | Train Loss: 0.0252063 Vali Loss: 2.5185978\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/358, epoch: 4 | loss: 0.0184527\n",
      "\titers: 200/358, epoch: 4 | loss: 0.0178357\n",
      "\titers: 300/358, epoch: 4 | loss: 0.0176599\n",
      "Epoch: 4 cost time: 168.28691458702087\n",
      "Epoch: 4, Steps: 358 | Train Loss: 0.0175760 Vali Loss: 2.5933757\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "loading model\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:2.8784353733062744, mae:1.5731024742126465\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_multiplicative with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_multiplicative_ftS_sl768_ll48_pl24_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12169\n",
      "val 2137\n",
      "test 2137\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/380, epoch: 1 | loss: 0.3195804\n",
      "\titers: 200/380, epoch: 1 | loss: 0.1739771\n",
      "\titers: 300/380, epoch: 1 | loss: 0.1207239\n",
      "Epoch: 1 cost time: 115.19130969047546\n",
      "Epoch: 1, Steps: 380 | Train Loss: 0.0974115 Vali Loss: 0.1112461\n",
      "Validation loss decreased (inf --> 0.111246).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/380, epoch: 2 | loss: 0.0083022\n",
      "\titers: 200/380, epoch: 2 | loss: 0.0078286\n",
      "\titers: 300/380, epoch: 2 | loss: 0.0073279\n",
      "Epoch: 2 cost time: 106.18950009346008\n",
      "Epoch: 2, Steps: 380 | Train Loss: 0.0069622 Vali Loss: 0.0516896\n",
      "Validation loss decreased (0.111246 --> 0.051690).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/380, epoch: 3 | loss: 0.0051991\n",
      "\titers: 200/380, epoch: 3 | loss: 0.0050241\n",
      "\titers: 300/380, epoch: 3 | loss: 0.0049215\n",
      "Epoch: 3 cost time: 111.35886812210083\n",
      "Epoch: 3, Steps: 380 | Train Loss: 0.0048354 Vali Loss: 0.0495853\n",
      "Validation loss decreased (0.051690 --> 0.049585).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/380, epoch: 4 | loss: 0.0039856\n",
      "\titers: 200/380, epoch: 4 | loss: 0.0038932\n",
      "\titers: 300/380, epoch: 4 | loss: 0.0038545\n",
      "Epoch: 4 cost time: 106.14161562919617\n",
      "Epoch: 4, Steps: 380 | Train Loss: 0.0038357 Vali Loss: 0.0375464\n",
      "Validation loss decreased (0.049585 --> 0.037546).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/380, epoch: 5 | loss: 0.0033883\n",
      "\titers: 200/380, epoch: 5 | loss: 0.0034295\n",
      "\titers: 300/380, epoch: 5 | loss: 0.0033692\n",
      "Epoch: 5 cost time: 104.50946187973022\n",
      "Epoch: 5, Steps: 380 | Train Loss: 0.0033267 Vali Loss: 0.0194809\n",
      "Validation loss decreased (0.037546 --> 0.019481).  Saving model ...\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/380, epoch: 6 | loss: 0.0030999\n",
      "\titers: 200/380, epoch: 6 | loss: 0.0030484\n",
      "\titers: 300/380, epoch: 6 | loss: 0.0030124\n",
      "Epoch: 6 cost time: 103.28866839408875\n",
      "Epoch: 6, Steps: 380 | Train Loss: 0.0030047 Vali Loss: 0.0181889\n",
      "Validation loss decreased (0.019481 --> 0.018189).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/380, epoch: 7 | loss: 0.0028951\n",
      "\titers: 200/380, epoch: 7 | loss: 0.0028290\n",
      "\titers: 300/380, epoch: 7 | loss: 0.0028006\n",
      "Epoch: 7 cost time: 109.96557402610779\n",
      "Epoch: 7, Steps: 380 | Train Loss: 0.0028003 Vali Loss: 0.0182181\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/380, epoch: 8 | loss: 0.0026244\n",
      "\titers: 200/380, epoch: 8 | loss: 0.0026593\n",
      "\titers: 300/380, epoch: 8 | loss: 0.0026328\n",
      "Epoch: 8 cost time: 96.88442993164062\n",
      "Epoch: 8, Steps: 380 | Train Loss: 0.0026200 Vali Loss: 0.0185359\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/380, epoch: 9 | loss: 0.0024672\n",
      "\titers: 200/380, epoch: 9 | loss: 0.0024838\n",
      "\titers: 300/380, epoch: 9 | loss: 0.0024794\n",
      "Epoch: 9 cost time: 94.77315354347229\n",
      "Epoch: 9, Steps: 380 | Train Loss: 0.0024617 Vali Loss: 0.0200579\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "loading model\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.41350987553596497, mae:0.5058489441871643\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_multiplicative with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_multiplicative_ftS_sl768_ll48_pl48_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 2113\n",
      "test 2113\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/379, epoch: 1 | loss: 0.2766293\n",
      "\titers: 200/379, epoch: 1 | loss: 0.1498824\n",
      "\titers: 300/379, epoch: 1 | loss: 0.1035868\n",
      "Epoch: 1 cost time: 92.92161154747009\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.0838541 Vali Loss: 0.1075774\n",
      "Validation loss decreased (inf --> 0.107577).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/379, epoch: 2 | loss: 0.0069920\n",
      "\titers: 200/379, epoch: 2 | loss: 0.0064517\n",
      "\titers: 300/379, epoch: 2 | loss: 0.0061428\n",
      "Epoch: 2 cost time: 91.18743824958801\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.0059029 Vali Loss: 0.0567027\n",
      "Validation loss decreased (0.107577 --> 0.056703).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/379, epoch: 3 | loss: 0.0046374\n",
      "\titers: 200/379, epoch: 3 | loss: 0.0045588\n",
      "\titers: 300/379, epoch: 3 | loss: 0.0043964\n",
      "Epoch: 3 cost time: 91.15419912338257\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.0042653 Vali Loss: 0.0380864\n",
      "Validation loss decreased (0.056703 --> 0.038086).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/379, epoch: 4 | loss: 0.0036230\n",
      "\titers: 200/379, epoch: 4 | loss: 0.0035687\n",
      "\titers: 300/379, epoch: 4 | loss: 0.0035463\n",
      "Epoch: 4 cost time: 90.1669225692749\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.0035184 Vali Loss: 0.0419789\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/379, epoch: 5 | loss: 0.0032541\n",
      "\titers: 200/379, epoch: 5 | loss: 0.0031983\n",
      "\titers: 300/379, epoch: 5 | loss: 0.0031551\n",
      "Epoch: 5 cost time: 83.83908748626709\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.0031054 Vali Loss: 0.0311490\n",
      "Validation loss decreased (0.038086 --> 0.031149).  Saving model ...\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/379, epoch: 6 | loss: 0.0028241\n",
      "\titers: 200/379, epoch: 6 | loss: 0.0028560\n",
      "\titers: 300/379, epoch: 6 | loss: 0.0028451\n",
      "Epoch: 6 cost time: 86.77855896949768\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.0028363 Vali Loss: 0.0270529\n",
      "Validation loss decreased (0.031149 --> 0.027053).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/379, epoch: 7 | loss: 0.0026959\n",
      "\titers: 200/379, epoch: 7 | loss: 0.0027094\n",
      "\titers: 300/379, epoch: 7 | loss: 0.0026547\n",
      "Epoch: 7 cost time: 82.4368028640747\n",
      "Epoch: 7, Steps: 379 | Train Loss: 0.0026390 Vali Loss: 0.0254580\n",
      "Validation loss decreased (0.027053 --> 0.025458).  Saving model ...\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/379, epoch: 8 | loss: 0.0025073\n",
      "\titers: 200/379, epoch: 8 | loss: 0.0025097\n",
      "\titers: 300/379, epoch: 8 | loss: 0.0024997\n",
      "Epoch: 8 cost time: 84.06861639022827\n",
      "Epoch: 8, Steps: 379 | Train Loss: 0.0024737 Vali Loss: 0.0238548\n",
      "Validation loss decreased (0.025458 --> 0.023855).  Saving model ...\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/379, epoch: 9 | loss: 0.0023493\n",
      "\titers: 200/379, epoch: 9 | loss: 0.0023340\n",
      "\titers: 300/379, epoch: 9 | loss: 0.0023354\n",
      "Epoch: 9 cost time: 81.97000575065613\n",
      "Epoch: 9, Steps: 379 | Train Loss: 0.0023257 Vali Loss: 0.0277412\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.3421772800000007e-05\n",
      "\titers: 100/379, epoch: 10 | loss: 0.0022505\n",
      "\titers: 200/379, epoch: 10 | loss: 0.0022550\n",
      "\titers: 300/379, epoch: 10 | loss: 0.0022665\n",
      "Epoch: 10 cost time: 81.62666296958923\n",
      "Epoch: 10, Steps: 379 | Train Loss: 0.0022750 Vali Loss: 0.0293880\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.0737418240000007e-05\n",
      "\titers: 100/379, epoch: 11 | loss: 0.0021771\n",
      "\titers: 200/379, epoch: 11 | loss: 0.0021648\n",
      "\titers: 300/379, epoch: 11 | loss: 0.0021621\n",
      "Epoch: 11 cost time: 79.87206721305847\n",
      "Epoch: 11, Steps: 379 | Train Loss: 0.0021675 Vali Loss: 0.0242851\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "loading model\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.5418590307235718, mae:0.5977466106414795\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_multiplicative with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_multiplicative_ftS_sl768_ll48_pl168_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12025\n",
      "val 1993\n",
      "test 1993\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/375, epoch: 1 | loss: 0.2990855\n",
      "\titers: 200/375, epoch: 1 | loss: 0.1690068\n",
      "\titers: 300/375, epoch: 1 | loss: 0.1173481\n",
      "Epoch: 1 cost time: 83.5139708518982\n",
      "Epoch: 1, Steps: 375 | Train Loss: 0.0960237 Vali Loss: 0.0814937\n",
      "Validation loss decreased (inf --> 0.081494).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/375, epoch: 2 | loss: 0.0078793\n",
      "\titers: 200/375, epoch: 2 | loss: 0.0075262\n",
      "\titers: 300/375, epoch: 2 | loss: 0.0072230\n",
      "Epoch: 2 cost time: 85.55570363998413\n",
      "Epoch: 2, Steps: 375 | Train Loss: 0.0068554 Vali Loss: 0.0385360\n",
      "Validation loss decreased (0.081494 --> 0.038536).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/375, epoch: 3 | loss: 0.0049385\n",
      "\titers: 200/375, epoch: 3 | loss: 0.0049449\n",
      "\titers: 300/375, epoch: 3 | loss: 0.0048477\n",
      "Epoch: 3 cost time: 94.65385150909424\n",
      "Epoch: 3, Steps: 375 | Train Loss: 0.0047873 Vali Loss: 0.0279826\n",
      "Validation loss decreased (0.038536 --> 0.027983).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/375, epoch: 4 | loss: 0.0040770\n",
      "\titers: 200/375, epoch: 4 | loss: 0.0040028\n",
      "\titers: 300/375, epoch: 4 | loss: 0.0041245\n",
      "Epoch: 4 cost time: 88.26884126663208\n",
      "Epoch: 4, Steps: 375 | Train Loss: 0.0041218 Vali Loss: 0.0240747\n",
      "Validation loss decreased (0.027983 --> 0.024075).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/375, epoch: 5 | loss: 0.0035564\n",
      "\titers: 200/375, epoch: 5 | loss: 0.0034521\n",
      "\titers: 300/375, epoch: 5 | loss: 0.0034478\n",
      "Epoch: 5 cost time: 87.77631092071533\n",
      "Epoch: 5, Steps: 375 | Train Loss: 0.0034253 Vali Loss: 0.0183289\n",
      "Validation loss decreased (0.024075 --> 0.018329).  Saving model ...\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/375, epoch: 6 | loss: 0.0032106\n",
      "\titers: 200/375, epoch: 6 | loss: 0.0031675\n",
      "\titers: 300/375, epoch: 6 | loss: 0.0031259\n",
      "Epoch: 6 cost time: 86.65334463119507\n",
      "Epoch: 6, Steps: 375 | Train Loss: 0.0031112 Vali Loss: 0.0162473\n",
      "Validation loss decreased (0.018329 --> 0.016247).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/375, epoch: 7 | loss: 0.0029783\n",
      "\titers: 200/375, epoch: 7 | loss: 0.0029070\n",
      "\titers: 300/375, epoch: 7 | loss: 0.0028880\n",
      "Epoch: 7 cost time: 86.98543524742126\n",
      "Epoch: 7, Steps: 375 | Train Loss: 0.0028735 Vali Loss: 0.0155142\n",
      "Validation loss decreased (0.016247 --> 0.015514).  Saving model ...\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/375, epoch: 8 | loss: 0.0028261\n",
      "\titers: 200/375, epoch: 8 | loss: 0.0027845\n",
      "\titers: 300/375, epoch: 8 | loss: 0.0027471\n",
      "Epoch: 8 cost time: 86.41482377052307\n",
      "Epoch: 8, Steps: 375 | Train Loss: 0.0027392 Vali Loss: 0.0142886\n",
      "Validation loss decreased (0.015514 --> 0.014289).  Saving model ...\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/375, epoch: 9 | loss: 0.0026197\n",
      "\titers: 200/375, epoch: 9 | loss: 0.0026370\n",
      "\titers: 300/375, epoch: 9 | loss: 0.0026498\n",
      "Epoch: 9 cost time: 88.27876687049866\n",
      "Epoch: 9, Steps: 375 | Train Loss: 0.0026427 Vali Loss: 0.0139293\n",
      "Validation loss decreased (0.014289 --> 0.013929).  Saving model ...\n",
      "Updating learning rate to 1.3421772800000007e-05\n",
      "\titers: 100/375, epoch: 10 | loss: 0.0025169\n",
      "\titers: 200/375, epoch: 10 | loss: 0.0025278\n",
      "\titers: 300/375, epoch: 10 | loss: 0.0025285\n",
      "Epoch: 10 cost time: 147.0633566379547\n",
      "Epoch: 10, Steps: 375 | Train Loss: 0.0025315 Vali Loss: 0.0150871\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.0737418240000007e-05\n",
      "\titers: 100/375, epoch: 11 | loss: 0.0024843\n",
      "\titers: 200/375, epoch: 11 | loss: 0.0024439\n",
      "\titers: 300/375, epoch: 11 | loss: 0.0024332\n",
      "Epoch: 11 cost time: 122.2735824584961\n",
      "Epoch: 11, Steps: 375 | Train Loss: 0.0024346 Vali Loss: 0.0134294\n",
      "Validation loss decreased (0.013929 --> 0.013429).  Saving model ...\n",
      "Updating learning rate to 8.589934592000006e-06\n",
      "\titers: 100/375, epoch: 12 | loss: 0.0023794\n",
      "\titers: 200/375, epoch: 12 | loss: 0.0023879\n",
      "\titers: 300/375, epoch: 12 | loss: 0.0023674\n",
      "Epoch: 12 cost time: 113.0206880569458\n",
      "Epoch: 12, Steps: 375 | Train Loss: 0.0023580 Vali Loss: 0.0145825\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.871947673600004e-06\n",
      "\titers: 100/375, epoch: 13 | loss: 0.0023709\n",
      "\titers: 200/375, epoch: 13 | loss: 0.0023425\n",
      "\titers: 300/375, epoch: 13 | loss: 0.0023277\n",
      "Epoch: 13 cost time: 115.56270003318787\n",
      "Epoch: 13, Steps: 375 | Train Loss: 0.0023197 Vali Loss: 0.0144075\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.497558138880004e-06\n",
      "\titers: 100/375, epoch: 14 | loss: 0.0022990\n",
      "\titers: 200/375, epoch: 14 | loss: 0.0022937\n",
      "\titers: 300/375, epoch: 14 | loss: 0.0022909\n",
      "Epoch: 14 cost time: 116.6415753364563\n",
      "Epoch: 14, Steps: 375 | Train Loss: 0.0022825 Vali Loss: 0.0144044\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "loading model\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.3152545392513275, mae:0.43638893961906433\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_multiplicative with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_multiplicative_ftS_sl768_ll48_pl336_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 11857\n",
      "val 1825\n",
      "test 1825\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/370, epoch: 1 | loss: 0.3046577\n",
      "\titers: 200/370, epoch: 1 | loss: 0.1805108\n",
      "\titers: 300/370, epoch: 1 | loss: 0.1272452\n",
      "Epoch: 1 cost time: 133.7231204509735\n",
      "Epoch: 1, Steps: 370 | Train Loss: 0.1058301 Vali Loss: 0.1097919\n",
      "Validation loss decreased (inf --> 0.109792).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/370, epoch: 2 | loss: 0.0096399\n",
      "\titers: 200/370, epoch: 2 | loss: 0.0089098\n",
      "\titers: 300/370, epoch: 2 | loss: 0.0087074\n",
      "Epoch: 2 cost time: 129.96091318130493\n",
      "Epoch: 2, Steps: 370 | Train Loss: 0.0082577 Vali Loss: 0.0422805\n",
      "Validation loss decreased (0.109792 --> 0.042280).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/370, epoch: 3 | loss: 0.0058398\n",
      "\titers: 200/370, epoch: 3 | loss: 0.0057116\n",
      "\titers: 300/370, epoch: 3 | loss: 0.0056047\n",
      "Epoch: 3 cost time: 125.06020331382751\n",
      "Epoch: 3, Steps: 370 | Train Loss: 0.0054686 Vali Loss: 0.0266582\n",
      "Validation loss decreased (0.042280 --> 0.026658).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/370, epoch: 4 | loss: 0.0045837\n",
      "\titers: 200/370, epoch: 4 | loss: 0.0044580\n",
      "\titers: 300/370, epoch: 4 | loss: 0.0043917\n",
      "Epoch: 4 cost time: 120.28837203979492\n",
      "Epoch: 4, Steps: 370 | Train Loss: 0.0044006 Vali Loss: 0.0205153\n",
      "Validation loss decreased (0.026658 --> 0.020515).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/370, epoch: 5 | loss: 0.0039522\n",
      "\titers: 200/370, epoch: 5 | loss: 0.0038935\n",
      "\titers: 300/370, epoch: 5 | loss: 0.0038720\n",
      "Epoch: 5 cost time: 111.74067854881287\n",
      "Epoch: 5, Steps: 370 | Train Loss: 0.0038796 Vali Loss: 0.0169398\n",
      "Validation loss decreased (0.020515 --> 0.016940).  Saving model ...\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/370, epoch: 6 | loss: 0.0034969\n",
      "\titers: 200/370, epoch: 6 | loss: 0.0035154\n",
      "\titers: 300/370, epoch: 6 | loss: 0.0034632\n",
      "Epoch: 6 cost time: 104.9821252822876\n",
      "Epoch: 6, Steps: 370 | Train Loss: 0.0034461 Vali Loss: 0.0141037\n",
      "Validation loss decreased (0.016940 --> 0.014104).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/370, epoch: 7 | loss: 0.0032575\n",
      "\titers: 200/370, epoch: 7 | loss: 0.0032214\n",
      "\titers: 300/370, epoch: 7 | loss: 0.0032062\n",
      "Epoch: 7 cost time: 110.32161283493042\n",
      "Epoch: 7, Steps: 370 | Train Loss: 0.0031876 Vali Loss: 0.0133183\n",
      "Validation loss decreased (0.014104 --> 0.013318).  Saving model ...\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/370, epoch: 8 | loss: 0.0030493\n",
      "\titers: 200/370, epoch: 8 | loss: 0.0030263\n",
      "\titers: 300/370, epoch: 8 | loss: 0.0030234\n",
      "Epoch: 8 cost time: 110.74105429649353\n",
      "Epoch: 8, Steps: 370 | Train Loss: 0.0030065 Vali Loss: 0.0123318\n",
      "Validation loss decreased (0.013318 --> 0.012332).  Saving model ...\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/370, epoch: 9 | loss: 0.0029111\n",
      "\titers: 200/370, epoch: 9 | loss: 0.0028853\n",
      "\titers: 300/370, epoch: 9 | loss: 0.0029108\n",
      "Epoch: 9 cost time: 103.59573912620544\n",
      "Epoch: 9, Steps: 370 | Train Loss: 0.0028979 Vali Loss: 0.0119906\n",
      "Validation loss decreased (0.012332 --> 0.011991).  Saving model ...\n",
      "Updating learning rate to 1.3421772800000007e-05\n",
      "\titers: 100/370, epoch: 10 | loss: 0.0027601\n",
      "\titers: 200/370, epoch: 10 | loss: 0.0027353\n",
      "\titers: 300/370, epoch: 10 | loss: 0.0027393\n",
      "Epoch: 10 cost time: 109.16032719612122\n",
      "Epoch: 10, Steps: 370 | Train Loss: 0.0027505 Vali Loss: 0.0120211\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.0737418240000007e-05\n",
      "\titers: 100/370, epoch: 11 | loss: 0.0026998\n",
      "\titers: 200/370, epoch: 11 | loss: 0.0026634\n",
      "\titers: 300/370, epoch: 11 | loss: 0.0026599\n",
      "Epoch: 11 cost time: 107.01321244239807\n",
      "Epoch: 11, Steps: 370 | Train Loss: 0.0026549 Vali Loss: 0.0126248\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.589934592000006e-06\n",
      "\titers: 100/370, epoch: 12 | loss: 0.0026289\n",
      "\titers: 200/370, epoch: 12 | loss: 0.0026071\n",
      "\titers: 300/370, epoch: 12 | loss: 0.0025972\n",
      "Epoch: 12 cost time: 107.00300860404968\n",
      "Epoch: 12, Steps: 370 | Train Loss: 0.0025879 Vali Loss: 0.0116200\n",
      "Validation loss decreased (0.011991 --> 0.011620).  Saving model ...\n",
      "Updating learning rate to 6.871947673600004e-06\n",
      "\titers: 100/370, epoch: 13 | loss: 0.0025862\n",
      "\titers: 200/370, epoch: 13 | loss: 0.0025655\n",
      "\titers: 300/370, epoch: 13 | loss: 0.0025515\n",
      "Epoch: 13 cost time: 107.0355634689331\n",
      "Epoch: 13, Steps: 370 | Train Loss: 0.0025347 Vali Loss: 0.0110459\n",
      "Validation loss decreased (0.011620 --> 0.011046).  Saving model ...\n",
      "Updating learning rate to 5.497558138880004e-06\n",
      "\titers: 100/370, epoch: 14 | loss: 0.0024725\n",
      "\titers: 200/370, epoch: 14 | loss: 0.0024938\n",
      "\titers: 300/370, epoch: 14 | loss: 0.0024788\n",
      "Epoch: 14 cost time: 104.24656867980957\n",
      "Epoch: 14, Steps: 370 | Train Loss: 0.0024711 Vali Loss: 0.0113531\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.398046511104004e-06\n",
      "\titers: 100/370, epoch: 15 | loss: 0.0024501\n",
      "\titers: 200/370, epoch: 15 | loss: 0.0024473\n",
      "\titers: 300/370, epoch: 15 | loss: 0.0024357\n",
      "Epoch: 15 cost time: 109.61699986457825\n",
      "Epoch: 15, Steps: 370 | Train Loss: 0.0024356 Vali Loss: 0.0118453\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.5184372088832033e-06\n",
      "\titers: 100/370, epoch: 16 | loss: 0.0024221\n",
      "\titers: 200/370, epoch: 16 | loss: 0.0024035\n",
      "\titers: 300/370, epoch: 16 | loss: 0.0023980\n",
      "Epoch: 16 cost time: 106.94114327430725\n",
      "Epoch: 16, Steps: 370 | Train Loss: 0.0023988 Vali Loss: 0.0107428\n",
      "Validation loss decreased (0.011046 --> 0.010743).  Saving model ...\n",
      "Updating learning rate to 2.8147497671065624e-06\n",
      "\titers: 100/370, epoch: 17 | loss: 0.0023562\n",
      "\titers: 200/370, epoch: 17 | loss: 0.0023682\n",
      "\titers: 300/370, epoch: 17 | loss: 0.0023674\n",
      "Epoch: 17 cost time: 105.43861699104309\n",
      "Epoch: 17, Steps: 370 | Train Loss: 0.0023717 Vali Loss: 0.0106871\n",
      "Validation loss decreased (0.010743 --> 0.010687).  Saving model ...\n",
      "Updating learning rate to 2.2517998136852503e-06\n",
      "\titers: 100/370, epoch: 18 | loss: 0.0023549\n",
      "\titers: 200/370, epoch: 18 | loss: 0.0023536\n",
      "\titers: 300/370, epoch: 18 | loss: 0.0023457\n",
      "Epoch: 18 cost time: 107.00586676597595\n",
      "Epoch: 18, Steps: 370 | Train Loss: 0.0023454 Vali Loss: 0.0107517\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.8014398509482004e-06\n",
      "\titers: 100/370, epoch: 19 | loss: 0.0023264\n",
      "\titers: 200/370, epoch: 19 | loss: 0.0023170\n",
      "\titers: 300/370, epoch: 19 | loss: 0.0023186\n",
      "Epoch: 19 cost time: 106.76591849327087\n",
      "Epoch: 19, Steps: 370 | Train Loss: 0.0023250 Vali Loss: 0.0107540\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.4411518807585604e-06\n",
      "\titers: 100/370, epoch: 20 | loss: 0.0023109\n",
      "\titers: 200/370, epoch: 20 | loss: 0.0023042\n",
      "\titers: 300/370, epoch: 20 | loss: 0.0023001\n",
      "Epoch: 20 cost time: 105.8242461681366\n",
      "Epoch: 20, Steps: 370 | Train Loss: 0.0022989 Vali Loss: 0.0106691\n",
      "Validation loss decreased (0.010687 --> 0.010669).  Saving model ...\n",
      "test 1825\n",
      "loading model\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.2541406750679016, mae:0.3932349681854248\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_multiplicative with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_multiplicative_ftS_sl768_ll48_pl720_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 11473\n",
      "val 1441\n",
      "test 1441\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/358, epoch: 1 | loss: 0.2822684\n",
      "\titers: 200/358, epoch: 1 | loss: 0.1711450\n",
      "\titers: 300/358, epoch: 1 | loss: 0.1207701\n",
      "Epoch: 1 cost time: 140.40496826171875\n",
      "Epoch: 1, Steps: 358 | Train Loss: 0.1036068 Vali Loss: 0.1380519\n",
      "Validation loss decreased (inf --> 0.138052).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/358, epoch: 2 | loss: 0.0102456\n",
      "\titers: 200/358, epoch: 2 | loss: 0.0090440\n",
      "\titers: 300/358, epoch: 2 | loss: 0.0083717\n",
      "Epoch: 2 cost time: 132.01089572906494\n",
      "Epoch: 2, Steps: 358 | Train Loss: 0.0080254 Vali Loss: 0.0421973\n",
      "Validation loss decreased (0.138052 --> 0.042197).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/358, epoch: 3 | loss: 0.0056148\n",
      "\titers: 200/358, epoch: 3 | loss: 0.0054639\n",
      "\titers: 300/358, epoch: 3 | loss: 0.0053634\n",
      "Epoch: 3 cost time: 134.06151247024536\n",
      "Epoch: 3, Steps: 358 | Train Loss: 0.0052912 Vali Loss: 0.0327986\n",
      "Validation loss decreased (0.042197 --> 0.032799).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/358, epoch: 4 | loss: 0.0044648\n",
      "\titers: 200/358, epoch: 4 | loss: 0.0043275\n",
      "\titers: 300/358, epoch: 4 | loss: 0.0042481\n",
      "Epoch: 4 cost time: 127.51862955093384\n",
      "Epoch: 4, Steps: 358 | Train Loss: 0.0042121 Vali Loss: 0.0214783\n",
      "Validation loss decreased (0.032799 --> 0.021478).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/358, epoch: 5 | loss: 0.0039788\n",
      "\titers: 200/358, epoch: 5 | loss: 0.0038871\n",
      "\titers: 300/358, epoch: 5 | loss: 0.0038247\n",
      "Epoch: 5 cost time: 126.68643641471863\n",
      "Epoch: 5, Steps: 358 | Train Loss: 0.0037956 Vali Loss: 0.0218539\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/358, epoch: 6 | loss: 0.0034776\n",
      "\titers: 200/358, epoch: 6 | loss: 0.0034772\n",
      "\titers: 300/358, epoch: 6 | loss: 0.0034334\n",
      "Epoch: 6 cost time: 142.9779121875763\n",
      "Epoch: 6, Steps: 358 | Train Loss: 0.0034195 Vali Loss: 0.0170642\n",
      "Validation loss decreased (0.021478 --> 0.017064).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/358, epoch: 7 | loss: 0.0032553\n",
      "\titers: 200/358, epoch: 7 | loss: 0.0032131\n",
      "\titers: 300/358, epoch: 7 | loss: 0.0031926\n",
      "Epoch: 7 cost time: 140.40699458122253\n",
      "Epoch: 7, Steps: 358 | Train Loss: 0.0031822 Vali Loss: 0.0150468\n",
      "Validation loss decreased (0.017064 --> 0.015047).  Saving model ...\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/358, epoch: 8 | loss: 0.0030414\n",
      "\titers: 200/358, epoch: 8 | loss: 0.0030369\n",
      "\titers: 300/358, epoch: 8 | loss: 0.0030232\n",
      "Epoch: 8 cost time: 134.0037341117859\n",
      "Epoch: 8, Steps: 358 | Train Loss: 0.0030145 Vali Loss: 0.0141865\n",
      "Validation loss decreased (0.015047 --> 0.014186).  Saving model ...\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/358, epoch: 9 | loss: 0.0029119\n",
      "\titers: 200/358, epoch: 9 | loss: 0.0028967\n",
      "\titers: 300/358, epoch: 9 | loss: 0.0028866\n",
      "Epoch: 9 cost time: 133.2556345462799\n",
      "Epoch: 9, Steps: 358 | Train Loss: 0.0028760 Vali Loss: 0.0132612\n",
      "Validation loss decreased (0.014186 --> 0.013261).  Saving model ...\n",
      "Updating learning rate to 1.3421772800000007e-05\n",
      "\titers: 100/358, epoch: 10 | loss: 0.0028027\n",
      "\titers: 200/358, epoch: 10 | loss: 0.0027883\n",
      "\titers: 300/358, epoch: 10 | loss: 0.0027862\n",
      "Epoch: 10 cost time: 135.55485677719116\n",
      "Epoch: 10, Steps: 358 | Train Loss: 0.0027678 Vali Loss: 0.0123540\n",
      "Validation loss decreased (0.013261 --> 0.012354).  Saving model ...\n",
      "Updating learning rate to 1.0737418240000007e-05\n",
      "\titers: 100/358, epoch: 11 | loss: 0.0027158\n",
      "\titers: 200/358, epoch: 11 | loss: 0.0027037\n",
      "\titers: 300/358, epoch: 11 | loss: 0.0027032\n",
      "Epoch: 11 cost time: 133.42806720733643\n",
      "Epoch: 11, Steps: 358 | Train Loss: 0.0026938 Vali Loss: 0.0125518\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.589934592000006e-06\n",
      "\titers: 100/358, epoch: 12 | loss: 0.0026586\n",
      "\titers: 200/358, epoch: 12 | loss: 0.0026558\n",
      "\titers: 300/358, epoch: 12 | loss: 0.0026454\n",
      "Epoch: 12 cost time: 135.59763836860657\n",
      "Epoch: 12, Steps: 358 | Train Loss: 0.0026371 Vali Loss: 0.0123436\n",
      "Validation loss decreased (0.012354 --> 0.012344).  Saving model ...\n",
      "Updating learning rate to 6.871947673600004e-06\n",
      "\titers: 100/358, epoch: 13 | loss: 0.0025803\n",
      "\titers: 200/358, epoch: 13 | loss: 0.0025662\n",
      "\titers: 300/358, epoch: 13 | loss: 0.0025688\n",
      "Epoch: 13 cost time: 130.7575068473816\n",
      "Epoch: 13, Steps: 358 | Train Loss: 0.0025736 Vali Loss: 0.0120608\n",
      "Validation loss decreased (0.012344 --> 0.012061).  Saving model ...\n",
      "Updating learning rate to 5.497558138880004e-06\n",
      "\titers: 100/358, epoch: 14 | loss: 0.0025538\n",
      "\titers: 200/358, epoch: 14 | loss: 0.0025306\n",
      "\titers: 300/358, epoch: 14 | loss: 0.0025234\n",
      "Epoch: 14 cost time: 131.18370175361633\n",
      "Epoch: 14, Steps: 358 | Train Loss: 0.0025304 Vali Loss: 0.0123537\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.398046511104004e-06\n",
      "\titers: 100/358, epoch: 15 | loss: 0.0025078\n",
      "\titers: 200/358, epoch: 15 | loss: 0.0025156\n",
      "\titers: 300/358, epoch: 15 | loss: 0.0024933\n",
      "Epoch: 15 cost time: 133.09438300132751\n",
      "Epoch: 15, Steps: 358 | Train Loss: 0.0024874 Vali Loss: 0.0118892\n",
      "Validation loss decreased (0.012061 --> 0.011889).  Saving model ...\n",
      "Updating learning rate to 3.5184372088832033e-06\n",
      "\titers: 100/358, epoch: 16 | loss: 0.0024310\n",
      "\titers: 200/358, epoch: 16 | loss: 0.0024442\n",
      "\titers: 300/358, epoch: 16 | loss: 0.0024514\n",
      "Epoch: 16 cost time: 132.24784183502197\n",
      "Epoch: 16, Steps: 358 | Train Loss: 0.0024530 Vali Loss: 0.0119410\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.8147497671065624e-06\n",
      "\titers: 100/358, epoch: 17 | loss: 0.0024394\n",
      "\titers: 200/358, epoch: 17 | loss: 0.0024295\n",
      "\titers: 300/358, epoch: 17 | loss: 0.0024271\n",
      "Epoch: 17 cost time: 125.76248955726624\n",
      "Epoch: 17, Steps: 358 | Train Loss: 0.0024245 Vali Loss: 0.0115139\n",
      "Validation loss decreased (0.011889 --> 0.011514).  Saving model ...\n",
      "Updating learning rate to 2.2517998136852503e-06\n",
      "\titers: 100/358, epoch: 18 | loss: 0.0024200\n",
      "\titers: 200/358, epoch: 18 | loss: 0.0024061\n",
      "\titers: 300/358, epoch: 18 | loss: 0.0023954\n",
      "Epoch: 18 cost time: 131.2112033367157\n",
      "Epoch: 18, Steps: 358 | Train Loss: 0.0023968 Vali Loss: 0.0114858\n",
      "Validation loss decreased (0.011514 --> 0.011486).  Saving model ...\n",
      "Updating learning rate to 1.8014398509482004e-06\n",
      "\titers: 100/358, epoch: 19 | loss: 0.0023750\n",
      "\titers: 200/358, epoch: 19 | loss: 0.0023775\n",
      "\titers: 300/358, epoch: 19 | loss: 0.0023762\n",
      "Epoch: 19 cost time: 129.7898395061493\n",
      "Epoch: 19, Steps: 358 | Train Loss: 0.0023793 Vali Loss: 0.0113164\n",
      "Validation loss decreased (0.011486 --> 0.011316).  Saving model ...\n",
      "Updating learning rate to 1.4411518807585604e-06\n",
      "\titers: 100/358, epoch: 20 | loss: 0.0023679\n",
      "\titers: 200/358, epoch: 20 | loss: 0.0023543\n",
      "\titers: 300/358, epoch: 20 | loss: 0.0023588\n",
      "Epoch: 20 cost time: 200.58988642692566\n",
      "Epoch: 20, Steps: 358 | Train Loss: 0.0023571 Vali Loss: 0.0112888\n",
      "Validation loss decreased (0.011316 --> 0.011289).  Saving model ...\n",
      "test 1441\n",
      "loading model\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.30071768164634705, mae:0.4342319965362549\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_multiplicative_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_multiplicative_reversal_ftS_sl768_ll48_pl24_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12169\n",
      "val 2137\n",
      "test 2137\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/380, epoch: 1 | loss: 0.2802347\n",
      "\titers: 200/380, epoch: 1 | loss: 0.1550395\n",
      "\titers: 300/380, epoch: 1 | loss: 0.1087552\n",
      "Epoch: 1 cost time: 97.77694725990295\n",
      "Epoch: 1, Steps: 380 | Train Loss: 0.0886259 Vali Loss: 0.8104779\n",
      "Validation loss decreased (inf --> 0.810478).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/380, epoch: 2 | loss: 0.0112460\n",
      "\titers: 200/380, epoch: 2 | loss: 0.0107317\n",
      "\titers: 300/380, epoch: 2 | loss: 0.0100977\n",
      "Epoch: 2 cost time: 97.58943033218384\n",
      "Epoch: 2, Steps: 380 | Train Loss: 0.0096815 Vali Loss: 0.7282464\n",
      "Validation loss decreased (0.810478 --> 0.728246).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/380, epoch: 3 | loss: 0.0080200\n",
      "\titers: 200/380, epoch: 3 | loss: 0.0075298\n",
      "\titers: 300/380, epoch: 3 | loss: 0.0074646\n",
      "Epoch: 3 cost time: 100.8358964920044\n",
      "Epoch: 3, Steps: 380 | Train Loss: 0.0074120 Vali Loss: 0.6994817\n",
      "Validation loss decreased (0.728246 --> 0.699482).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/380, epoch: 4 | loss: 0.0064702\n",
      "\titers: 200/380, epoch: 4 | loss: 0.0062203\n",
      "\titers: 300/380, epoch: 4 | loss: 0.0060583\n",
      "Epoch: 4 cost time: 110.50064420700073\n",
      "Epoch: 4, Steps: 380 | Train Loss: 0.0059048 Vali Loss: 0.6680177\n",
      "Validation loss decreased (0.699482 --> 0.668018).  Saving model ...\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/380, epoch: 5 | loss: 0.0049876\n",
      "\titers: 200/380, epoch: 5 | loss: 0.0050561\n",
      "\titers: 300/380, epoch: 5 | loss: 0.0050847\n",
      "Epoch: 5 cost time: 101.49167490005493\n",
      "Epoch: 5, Steps: 380 | Train Loss: 0.0052790 Vali Loss: 0.7026450\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/380, epoch: 6 | loss: 0.0043321\n",
      "\titers: 200/380, epoch: 6 | loss: 0.0043500\n",
      "\titers: 300/380, epoch: 6 | loss: 0.0044886\n",
      "Epoch: 6 cost time: 99.85528326034546\n",
      "Epoch: 6, Steps: 380 | Train Loss: 0.0045109 Vali Loss: 0.6505221\n",
      "Validation loss decreased (0.668018 --> 0.650522).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/380, epoch: 7 | loss: 0.0044740\n",
      "\titers: 200/380, epoch: 7 | loss: 0.0042789\n",
      "\titers: 300/380, epoch: 7 | loss: 0.0042332\n",
      "Epoch: 7 cost time: 99.86779594421387\n",
      "Epoch: 7, Steps: 380 | Train Loss: 0.0041507 Vali Loss: 0.6511952\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/380, epoch: 8 | loss: 0.0038526\n",
      "\titers: 200/380, epoch: 8 | loss: 0.0038595\n",
      "\titers: 300/380, epoch: 8 | loss: 0.0038322\n",
      "Epoch: 8 cost time: 93.908864736557\n",
      "Epoch: 8, Steps: 380 | Train Loss: 0.0038638 Vali Loss: 0.6769788\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/380, epoch: 9 | loss: 0.0035454\n",
      "\titers: 200/380, epoch: 9 | loss: 0.0035851\n",
      "\titers: 300/380, epoch: 9 | loss: 0.0035860\n",
      "Epoch: 9 cost time: 84.12441802024841\n",
      "Epoch: 9, Steps: 380 | Train Loss: 0.0035810 Vali Loss: 0.6780396\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "loading model\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:1.4504799842834473, mae:1.0194969177246094\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_multiplicative_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_multiplicative_reversal_ftS_sl768_ll48_pl48_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12145\n",
      "val 2113\n",
      "test 2113\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/379, epoch: 1 | loss: 0.2832343\n",
      "\titers: 200/379, epoch: 1 | loss: 0.1582292\n",
      "\titers: 300/379, epoch: 1 | loss: 0.1113949\n",
      "Epoch: 1 cost time: 87.51024889945984\n",
      "Epoch: 1, Steps: 379 | Train Loss: 0.0911625 Vali Loss: 0.7873961\n",
      "Validation loss decreased (inf --> 0.787396).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/379, epoch: 2 | loss: 0.0108121\n",
      "\titers: 200/379, epoch: 2 | loss: 0.0105262\n",
      "\titers: 300/379, epoch: 2 | loss: 0.0103119\n",
      "Epoch: 2 cost time: 94.338374376297\n",
      "Epoch: 2, Steps: 379 | Train Loss: 0.0100849 Vali Loss: 0.7495679\n",
      "Validation loss decreased (0.787396 --> 0.749568).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/379, epoch: 3 | loss: 0.0081523\n",
      "\titers: 200/379, epoch: 3 | loss: 0.0075234\n",
      "\titers: 300/379, epoch: 3 | loss: 0.0074533\n",
      "Epoch: 3 cost time: 88.99307489395142\n",
      "Epoch: 3, Steps: 379 | Train Loss: 0.0074386 Vali Loss: 0.7344233\n",
      "Validation loss decreased (0.749568 --> 0.734423).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/379, epoch: 4 | loss: 0.0060722\n",
      "\titers: 200/379, epoch: 4 | loss: 0.0060422\n",
      "\titers: 300/379, epoch: 4 | loss: 0.0058595\n",
      "Epoch: 4 cost time: 92.08930110931396\n",
      "Epoch: 4, Steps: 379 | Train Loss: 0.0060803 Vali Loss: 0.7479861\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/379, epoch: 5 | loss: 0.0054062\n",
      "\titers: 200/379, epoch: 5 | loss: 0.0053646\n",
      "\titers: 300/379, epoch: 5 | loss: 0.0052135\n",
      "Epoch: 5 cost time: 90.12470054626465\n",
      "Epoch: 5, Steps: 379 | Train Loss: 0.0051183 Vali Loss: 0.7814295\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/379, epoch: 6 | loss: 0.0047009\n",
      "\titers: 200/379, epoch: 6 | loss: 0.0045290\n",
      "\titers: 300/379, epoch: 6 | loss: 0.0044680\n",
      "Epoch: 6 cost time: 86.47653198242188\n",
      "Epoch: 6, Steps: 379 | Train Loss: 0.0044795 Vali Loss: 0.7653998\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "loading model\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:1.6645272970199585, mae:1.0968962907791138\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_multiplicative_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_multiplicative_reversal_ftS_sl768_ll48_pl168_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12025\n",
      "val 1993\n",
      "test 1993\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/375, epoch: 1 | loss: 0.3211086\n",
      "\titers: 200/375, epoch: 1 | loss: 0.1915664\n",
      "\titers: 300/375, epoch: 1 | loss: 0.1375468\n",
      "Epoch: 1 cost time: 88.31152772903442\n",
      "Epoch: 1, Steps: 375 | Train Loss: 0.1150132 Vali Loss: 0.8431528\n",
      "Validation loss decreased (inf --> 0.843153).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/375, epoch: 2 | loss: 0.0148176\n",
      "\titers: 200/375, epoch: 2 | loss: 0.0140158\n",
      "\titers: 300/375, epoch: 2 | loss: 0.0137684\n",
      "Epoch: 2 cost time: 92.48497748374939\n",
      "Epoch: 2, Steps: 375 | Train Loss: 0.0131835 Vali Loss: 0.8527175\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/375, epoch: 3 | loss: 0.0101860\n",
      "\titers: 200/375, epoch: 3 | loss: 0.0101426\n",
      "\titers: 300/375, epoch: 3 | loss: 0.0099045\n",
      "Epoch: 3 cost time: 89.78978872299194\n",
      "Epoch: 3, Steps: 375 | Train Loss: 0.0094090 Vali Loss: 0.7595142\n",
      "Validation loss decreased (0.843153 --> 0.759514).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/375, epoch: 4 | loss: 0.0072410\n",
      "\titers: 200/375, epoch: 4 | loss: 0.0075567\n",
      "\titers: 300/375, epoch: 4 | loss: 0.0071914\n",
      "Epoch: 4 cost time: 85.99563479423523\n",
      "Epoch: 4, Steps: 375 | Train Loss: 0.0070192 Vali Loss: 0.8091872\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/375, epoch: 5 | loss: 0.0059865\n",
      "\titers: 200/375, epoch: 5 | loss: 0.0061417\n",
      "\titers: 300/375, epoch: 5 | loss: 0.0060207\n",
      "Epoch: 5 cost time: 84.579092502594\n",
      "Epoch: 5, Steps: 375 | Train Loss: 0.0059300 Vali Loss: 0.7865605\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/375, epoch: 6 | loss: 0.0051436\n",
      "\titers: 200/375, epoch: 6 | loss: 0.0050885\n",
      "\titers: 300/375, epoch: 6 | loss: 0.0050063\n",
      "Epoch: 6 cost time: 84.82278680801392\n",
      "Epoch: 6, Steps: 375 | Train Loss: 0.0049610 Vali Loss: 0.7899424\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "loading model\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:1.5226691961288452, mae:1.0233242511749268\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_multiplicative_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_multiplicative_reversal_ftS_sl768_ll48_pl336_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 11857\n",
      "val 1825\n",
      "test 1825\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100/370, epoch: 1 | loss: 0.3134073\n",
      "\titers: 200/370, epoch: 1 | loss: 0.1978377\n",
      "\titers: 300/370, epoch: 1 | loss: 0.1460499\n",
      "Epoch: 1 cost time: 100.96561598777771\n",
      "Epoch: 1, Steps: 370 | Train Loss: 0.1233580 Vali Loss: 1.0779495\n",
      "Validation loss decreased (inf --> 1.077950).  Saving model ...\n",
      "Updating learning rate to 8e-05\n",
      "\titers: 100/370, epoch: 2 | loss: 0.0220047\n",
      "\titers: 200/370, epoch: 2 | loss: 0.0197082\n",
      "\titers: 300/370, epoch: 2 | loss: 0.0200895\n",
      "Epoch: 2 cost time: 98.61082792282104\n",
      "Epoch: 2, Steps: 370 | Train Loss: 0.0191408 Vali Loss: 1.0545743\n",
      "Validation loss decreased (1.077950 --> 1.054574).  Saving model ...\n",
      "Updating learning rate to 6.400000000000001e-05\n",
      "\titers: 100/370, epoch: 3 | loss: 0.0125484\n",
      "\titers: 200/370, epoch: 3 | loss: 0.0125100\n",
      "\titers: 300/370, epoch: 3 | loss: 0.0122610\n",
      "Epoch: 3 cost time: 99.29173970222473\n",
      "Epoch: 3, Steps: 370 | Train Loss: 0.0119503 Vali Loss: 0.9984863\n",
      "Validation loss decreased (1.054574 --> 0.998486).  Saving model ...\n",
      "Updating learning rate to 5.120000000000001e-05\n",
      "\titers: 100/370, epoch: 4 | loss: 0.0099388\n",
      "\titers: 200/370, epoch: 4 | loss: 0.0093881\n",
      "\titers: 300/370, epoch: 4 | loss: 0.0089396\n",
      "Epoch: 4 cost time: 101.30700445175171\n",
      "Epoch: 4, Steps: 370 | Train Loss: 0.0087387 Vali Loss: 1.0038924\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.096000000000001e-05\n",
      "\titers: 100/370, epoch: 5 | loss: 0.0073613\n",
      "\titers: 200/370, epoch: 5 | loss: 0.0073326\n",
      "\titers: 300/370, epoch: 5 | loss: 0.0070506\n",
      "Epoch: 5 cost time: 101.93518257141113\n",
      "Epoch: 5, Steps: 370 | Train Loss: 0.0069035 Vali Loss: 0.9659939\n",
      "Validation loss decreased (0.998486 --> 0.965994).  Saving model ...\n",
      "Updating learning rate to 3.276800000000001e-05\n",
      "\titers: 100/370, epoch: 6 | loss: 0.0063524\n",
      "\titers: 200/370, epoch: 6 | loss: 0.0060645\n",
      "\titers: 300/370, epoch: 6 | loss: 0.0059935\n",
      "Epoch: 6 cost time: 101.6698567867279\n",
      "Epoch: 6, Steps: 370 | Train Loss: 0.0059272 Vali Loss: 0.9629961\n",
      "Validation loss decreased (0.965994 --> 0.962996).  Saving model ...\n",
      "Updating learning rate to 2.621440000000001e-05\n",
      "\titers: 100/370, epoch: 7 | loss: 0.0053088\n",
      "\titers: 200/370, epoch: 7 | loss: 0.0052467\n",
      "\titers: 300/370, epoch: 7 | loss: 0.0052250\n",
      "Epoch: 7 cost time: 100.74692940711975\n",
      "Epoch: 7, Steps: 370 | Train Loss: 0.0051949 Vali Loss: 0.9871308\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.097152000000001e-05\n",
      "\titers: 100/370, epoch: 8 | loss: 0.0048390\n",
      "\titers: 200/370, epoch: 8 | loss: 0.0047877\n",
      "\titers: 300/370, epoch: 8 | loss: 0.0047342\n",
      "Epoch: 8 cost time: 101.5364887714386\n",
      "Epoch: 8, Steps: 370 | Train Loss: 0.0046908 Vali Loss: 0.9650632\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.677721600000001e-05\n",
      "\titers: 100/370, epoch: 9 | loss: 0.0044838\n",
      "\titers: 200/370, epoch: 9 | loss: 0.0044255\n",
      "\titers: 300/370, epoch: 9 | loss: 0.0043918\n",
      "Epoch: 9 cost time: 101.8086142539978\n",
      "Epoch: 9, Steps: 370 | Train Loss: 0.0043775 Vali Loss: 0.9652913\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "loading model\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:1.7286763191223145, mae:1.0999388694763184\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training LogsparseTS on SYNTH_multiplicative_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'S', 'seq_len': 768, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 2}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_SYNTH_multiplicative_reversal_ftS_sl768_ll48_pl720_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 11473\n",
      "val 1441\n",
      "test 1441\n",
      "Could not load best model\n",
      "Updating learning rate to 0.0001\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 44.35 GiB of which 354.31 MiB is free. Process 384 has 1.29 GiB memory in use. Process 10346 has 1.28 GiB memory in use. Process 19020 has 7.78 GiB memory in use. Process 5885 has 33.63 GiB memory in use. Of the allocated memory 7.24 GiB is allocated by PyTorch, and 198.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/Schreibtisch/Github/TransformersEnergyTS/LogSparseAPI.py:2227\u001b[0m, in \u001b[0;36mLogsparseTS.fit\u001b[0;34m(self, data, data_root_path, batch_size, epochs, pred_len, seq_len, features, target, enc_in, dec_in, c_out, iter)\u001b[0m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m   2226\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>start training : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetting))\n\u001b[0;32m-> 2227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetting\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Schreibtisch/Github/TransformersEnergyTS/LogSparseAPI.py:1813\u001b[0m, in \u001b[0;36mExp_Logsparse.train\u001b[0;34m(self, setting)\u001b[0m\n\u001b[1;32m   1810\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(batch_x, batch_x_mark, dec_inp, batch_y_mark,\n\u001b[1;32m   1811\u001b[0m                          teacher_forcing_ratio\u001b[38;5;241m=\u001b[39mteacher_forcing_ratio, batch_y\u001b[38;5;241m=\u001b[39mbatch_y)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1812\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1813\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_x_mark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_inp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y_mark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mfeatures:\n\u001b[1;32m   1817\u001b[0m     f_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mc_out\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Schreibtisch/Github/TransformersEnergyTS/LogSparseAPI.py:1553\u001b[0m, in \u001b[0;36mLogsparse.forward\u001b[0;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask, **_)\u001b[0m\n\u001b[1;32m   1550\u001b[0m attns\u001b[38;5;241m.\u001b[39mappend(a)\n\u001b[1;32m   1552\u001b[0m dec_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec_embedding(x_dec, x_mark_dec)\n\u001b[0;32m-> 1553\u001b[0m dec_out, a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec_self_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec_enc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1554\u001b[0m attns\u001b[38;5;241m.\u001b[39mappend(a)\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_attention:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Schreibtisch/Github/TransformersEnergyTS/LogSparseAPI.py:1474\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, cross, x_mask, cross_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1472\u001b[0m attn \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m-> 1474\u001b[0m     x, a_sa, a_ca \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1475\u001b[0m     attn\u001b[38;5;241m.\u001b[39mappend(a_sa)\n\u001b[1;32m   1476\u001b[0m     attn\u001b[38;5;241m.\u001b[39mappend(a_ca)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Schreibtisch/Github/TransformersEnergyTS/LogSparseAPI.py:1454\u001b[0m, in \u001b[0;36mDecoderLayer.forward\u001b[0;34m(self, x, cross, x_mask, cross_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m   1452\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x)\n\u001b[0;32m-> 1454\u001b[0m x, a_ca \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1455\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m   1457\u001b[0m y \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Schreibtisch/Github/TransformersEnergyTS/LogSparseAPI.py:1312\u001b[0m, in \u001b[0;36mLogSparseAttentionLayer.forward\u001b[0;34m(self, queries, keys, values, attn_mask, **_)\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1310\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_projection(values)\u001b[38;5;241m.\u001b[39mview(B, S, H, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1312\u001b[0m out, attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1319\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(B, L, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_projection(out), attn\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Schreibtisch/Github/TransformersEnergyTS/LogSparseAPI.py:1264\u001b[0m, in \u001b[0;36mFullAttention.forward\u001b[0;34m(self, queries, keys, values, attn_mask)\u001b[0m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_flag \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_flag:\n\u001b[1;32m   1262\u001b[0m     scores\u001b[38;5;241m.\u001b[39mmasked_fill_(attn_mask\u001b[38;5;241m.\u001b[39mmask, \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf)\n\u001b[0;32m-> 1264\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(torch\u001b[38;5;241m.\u001b[39msoftmax(\u001b[43mscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfft_flag:\n\u001b[1;32m   1266\u001b[0m     V \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbhls,bshdc->blhdc\u001b[39m\u001b[38;5;124m\"\u001b[39m, A, values)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 576.00 MiB. GPU 0 has a total capacty of 44.35 GiB of which 354.31 MiB is free. Process 384 has 1.29 GiB memory in use. Process 10346 has 1.28 GiB memory in use. Process 19020 has 7.78 GiB memory in use. Process 5885 has 33.63 GiB memory in use. Of the allocated memory 7.24 GiB is allocated by PyTorch, and 198.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Simple loop\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "    for iter in range(1 ,model.args.itr):\n",
    "        for dataset_name, dataset_params in datasets.items():\n",
    "            for pred_len in pred_lens:\n",
    "                print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "                        # High amount of epochs to accomodate all models\n",
    "                        # Early stopping should kick in anyways\n",
    "                model.fit(\n",
    "                    iter = iter + 1,\n",
    "                    data=dataset_name,\n",
    "                    data_root_path=dataset_params[0],\n",
    "                    batch_size=32,\n",
    "                    epochs=20, # very high\n",
    "                    pred_len=pred_len,\n",
    "                    features = dataset_params[1],\n",
    "                    target = dataset_params[2],\n",
    "                    seq_len = dataset_params[3],\n",
    "                    enc_in = dataset_params[4],\n",
    "                    dec_in = dataset_params[5],\n",
    "                    c_out = dataset_params[6]\n",
    "                )\n",
    "\n",
    "                predictions = model.predict()\n",
    "\n",
    "                print(f'\\nMoving to next...\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'ETTh1': ['./ETTDataset/' , 'M'] ,\n",
    "    'DEWINDh_small': ['./WINDataset/' , 'S'] ,\n",
    "    'SYNTHh1': ['./SYNTHDataset/', 'S'] ,\n",
    "    'SYNTH_additive' : ['./SYNTHDataset/', 'S'] ,\n",
    "    'SYNTH_additive_reversal' : ['./SYNTHDataset/', 'S'] ,\n",
    "    'SYNTH_multiplicative' : ['./SYNTHDataset/', 'S'] ,\n",
    "    'SYNTH_multiplicative_reversal' : ['./SYNTHDataset/' , 'S']\n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "\n",
    "models = [InformerTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: InformerTS\n",
      "Training InformerTS on ETTh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'M', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_ETTh1_ftM_sl168_ll48_pl24_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8449\n",
      "val 2857\n",
      "test 2857\n",
      "\titers: 100, epoch: 1 | loss: 0.5217006\n",
      "\tspeed: 0.0935s/iter; left time: 484.2799s\n",
      "\titers: 200, epoch: 1 | loss: 0.2875329\n",
      "\tspeed: 0.0900s/iter; left time: 457.2593s\n",
      "Epoch: 1 cost time: 24.08019185066223\n",
      "Epoch: 1, Steps: 264 | Train Loss: 0.4108461 Vali Loss: 0.6995309 Test Loss: 0.6564247\n",
      "Validation loss decreased (inf --> 0.699531).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2550424\n",
      "\tspeed: 0.2008s/iter; left time: 987.4764s\n",
      "\titers: 200, epoch: 2 | loss: 0.2634580\n",
      "\tspeed: 0.0862s/iter; left time: 414.9995s\n",
      "Epoch: 2 cost time: 22.703473567962646\n",
      "Epoch: 2, Steps: 264 | Train Loss: 0.2587988 Vali Loss: 0.6928655 Test Loss: 0.6178744\n",
      "Validation loss decreased (0.699531 --> 0.692865).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1872599\n",
      "\tspeed: 0.2034s/iter; left time: 946.4029s\n",
      "\titers: 200, epoch: 3 | loss: 0.1887492\n",
      "\tspeed: 0.0884s/iter; left time: 402.6899s\n",
      "Epoch: 3 cost time: 23.38772487640381\n",
      "Epoch: 3, Steps: 264 | Train Loss: 0.1982838 Vali Loss: 0.7819465 Test Loss: 0.7630789\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1628836\n",
      "\tspeed: 0.2190s/iter; left time: 961.0762s\n",
      "\titers: 200, epoch: 4 | loss: 0.1641720\n",
      "\tspeed: 0.0859s/iter; left time: 368.3047s\n",
      "Epoch: 4 cost time: 23.26452922821045\n",
      "Epoch: 4, Steps: 264 | Train Loss: 0.1672992 Vali Loss: 0.7651270 Test Loss: 0.6504228\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1401930\n",
      "\tspeed: 0.1984s/iter; left time: 818.4326s\n",
      "\titers: 200, epoch: 5 | loss: 0.1465395\n",
      "\tspeed: 0.0841s/iter; left time: 338.3316s\n",
      "Epoch: 5 cost time: 22.43410015106201\n",
      "Epoch: 5, Steps: 264 | Train Loss: 0.1496767 Vali Loss: 0.8063212 Test Loss: 0.6765896\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "mse:0.6187145709991455, mae:0.5805823802947998\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on ETTh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'M', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_ETTh1_ftM_sl168_ll48_pl48_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8425\n",
      "val 2833\n",
      "test 2833\n",
      "\titers: 100, epoch: 1 | loss: 0.3954638\n",
      "\tspeed: 0.0976s/iter; left time: 503.6011s\n",
      "\titers: 200, epoch: 1 | loss: 0.3695351\n",
      "\tspeed: 0.0994s/iter; left time: 502.8749s\n",
      "Epoch: 1 cost time: 25.799476146697998\n",
      "Epoch: 1, Steps: 263 | Train Loss: 0.4456019 Vali Loss: 0.9087446 Test Loss: 0.7961289\n",
      "Validation loss decreased (inf --> 0.908745).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3078746\n",
      "\tspeed: 0.2229s/iter; left time: 1091.6577s\n",
      "\titers: 200, epoch: 2 | loss: 0.2586501\n",
      "\tspeed: 0.0911s/iter; left time: 437.0505s\n",
      "Epoch: 2 cost time: 24.21001625061035\n",
      "Epoch: 2, Steps: 263 | Train Loss: 0.2696643 Vali Loss: 0.8578157 Test Loss: 0.8342497\n",
      "Validation loss decreased (0.908745 --> 0.857816).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1952170\n",
      "\tspeed: 0.2108s/iter; left time: 977.1116s\n",
      "\titers: 200, epoch: 3 | loss: 0.1697292\n",
      "\tspeed: 0.0895s/iter; left time: 405.8566s\n",
      "Epoch: 3 cost time: 23.5573148727417\n",
      "Epoch: 3, Steps: 263 | Train Loss: 0.1959338 Vali Loss: 0.9128757 Test Loss: 0.9124063\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1622991\n",
      "\tspeed: 0.2071s/iter; left time: 905.4513s\n",
      "\titers: 200, epoch: 4 | loss: 0.1596719\n",
      "\tspeed: 0.0883s/iter; left time: 377.1055s\n",
      "Epoch: 4 cost time: 23.129156827926636\n",
      "Epoch: 4, Steps: 263 | Train Loss: 0.1658379 Vali Loss: 0.9158561 Test Loss: 0.9339561\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1572859\n",
      "\tspeed: 0.2130s/iter; left time: 875.2751s\n",
      "\titers: 200, epoch: 5 | loss: 0.1348647\n",
      "\tspeed: 0.0878s/iter; left time: 352.1068s\n",
      "Epoch: 5 cost time: 24.06042766571045\n",
      "Epoch: 5, Steps: 263 | Train Loss: 0.1517852 Vali Loss: 0.9346552 Test Loss: 0.9814777\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 7) (88, 32, 48, 7)\n",
      "test shape: (2816, 48, 7) (2816, 48, 7)\n",
      "mse:0.8328566551208496, mae:0.7038506865501404\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on ETTh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'M', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_ETTh1_ftM_sl168_ll48_pl168_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8305\n",
      "val 2713\n",
      "test 2713\n",
      "\titers: 100, epoch: 1 | loss: 0.5099945\n",
      "\tspeed: 0.1351s/iter; left time: 686.5672s\n",
      "\titers: 200, epoch: 1 | loss: 0.4833906\n",
      "\tspeed: 0.1385s/iter; left time: 689.9177s\n",
      "Epoch: 1 cost time: 35.413633823394775\n",
      "Epoch: 1, Steps: 259 | Train Loss: 0.5161863 Vali Loss: 1.3668430 Test Loss: 1.0081580\n",
      "Validation loss decreased (inf --> 1.366843).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4408689\n",
      "\tspeed: 0.3292s/iter; left time: 1587.2555s\n",
      "\titers: 200, epoch: 2 | loss: 0.3900490\n",
      "\tspeed: 0.1272s/iter; left time: 600.7816s\n",
      "Epoch: 2 cost time: 32.763131856918335\n",
      "Epoch: 2, Steps: 259 | Train Loss: 0.4050938 Vali Loss: 1.2076505 Test Loss: 0.7913985\n",
      "Validation loss decreased (1.366843 --> 1.207651).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2464029\n",
      "\tspeed: 0.3294s/iter; left time: 1503.1644s\n",
      "\titers: 200, epoch: 3 | loss: 0.2341866\n",
      "\tspeed: 0.1358s/iter; left time: 605.9008s\n",
      "Epoch: 3 cost time: 35.68930792808533\n",
      "Epoch: 3, Steps: 259 | Train Loss: 0.2425401 Vali Loss: 1.1501168 Test Loss: 0.7491309\n",
      "Validation loss decreased (1.207651 --> 1.150117).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2092643\n",
      "\tspeed: 0.3528s/iter; left time: 1518.3045s\n",
      "\titers: 200, epoch: 4 | loss: 0.2050545\n",
      "\tspeed: 0.1532s/iter; left time: 644.2529s\n",
      "Epoch: 4 cost time: 38.811644315719604\n",
      "Epoch: 4, Steps: 259 | Train Loss: 0.2053996 Vali Loss: 1.1679196 Test Loss: 0.7636334\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1897272\n",
      "\tspeed: 0.3910s/iter; left time: 1581.7316s\n",
      "\titers: 200, epoch: 5 | loss: 0.1866719\n",
      "\tspeed: 0.1564s/iter; left time: 617.1278s\n",
      "Epoch: 5 cost time: 42.23955154418945\n",
      "Epoch: 5, Steps: 259 | Train Loss: 0.1918785 Vali Loss: 1.1751287 Test Loss: 0.7831364\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1814144\n",
      "\tspeed: 0.4462s/iter; left time: 1689.3037s\n",
      "\titers: 200, epoch: 6 | loss: 0.1817422\n",
      "\tspeed: 0.1561s/iter; left time: 575.2238s\n",
      "Epoch: 6 cost time: 40.63918447494507\n",
      "Epoch: 6, Steps: 259 | Train Loss: 0.1853068 Vali Loss: 1.1884167 Test Loss: 0.7835829\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 7) (84, 32, 168, 7)\n",
      "test shape: (2688, 168, 7) (2688, 168, 7)\n",
      "mse:0.749377429485321, mae:0.6577867865562439\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on ETTh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'M', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_ETTh1_ftM_sl168_ll48_pl336_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8137\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.4741429\n",
      "\tspeed: 0.1783s/iter; left time: 887.9075s\n",
      "\titers: 200, epoch: 1 | loss: 0.4268942\n",
      "\tspeed: 0.1756s/iter; left time: 857.2844s\n",
      "Epoch: 1 cost time: 45.32536435127258\n",
      "Epoch: 1, Steps: 254 | Train Loss: 0.5205017 Vali Loss: 1.5664138 Test Loss: 1.2079780\n",
      "Validation loss decreased (inf --> 1.566414).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3859375\n",
      "\tspeed: 0.4723s/iter; left time: 2232.5085s\n",
      "\titers: 200, epoch: 2 | loss: 0.3779756\n",
      "\tspeed: 0.1777s/iter; left time: 822.4409s\n",
      "Epoch: 2 cost time: 45.5966899394989\n",
      "Epoch: 2, Steps: 254 | Train Loss: 0.4348033 Vali Loss: 1.5357910 Test Loss: 1.3214405\n",
      "Validation loss decreased (1.566414 --> 1.535791).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4257077\n",
      "\tspeed: 0.4984s/iter; left time: 2229.5037s\n",
      "\titers: 200, epoch: 3 | loss: 0.3858213\n",
      "\tspeed: 0.1861s/iter; left time: 813.7860s\n",
      "Epoch: 3 cost time: 46.87521266937256\n",
      "Epoch: 3, Steps: 254 | Train Loss: 0.4010455 Vali Loss: 1.5395753 Test Loss: 1.3827847\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3314337\n",
      "\tspeed: 0.4945s/iter; left time: 2086.2409s\n",
      "\titers: 200, epoch: 4 | loss: 0.3192121\n",
      "\tspeed: 0.1868s/iter; left time: 769.5900s\n",
      "Epoch: 4 cost time: 46.361085414886475\n",
      "Epoch: 4, Steps: 254 | Train Loss: 0.3424201 Vali Loss: 1.4560974 Test Loss: 1.2538319\n",
      "Validation loss decreased (1.535791 --> 1.456097).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2863086\n",
      "\tspeed: 0.4320s/iter; left time: 1713.0641s\n",
      "\titers: 200, epoch: 5 | loss: 0.2817907\n",
      "\tspeed: 0.1769s/iter; left time: 683.5701s\n",
      "Epoch: 5 cost time: 44.00531077384949\n",
      "Epoch: 5, Steps: 254 | Train Loss: 0.2900852 Vali Loss: 1.4083478 Test Loss: 1.2969297\n",
      "Validation loss decreased (1.456097 --> 1.408348).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2847742\n",
      "\tspeed: 0.4561s/iter; left time: 1692.5544s\n",
      "\titers: 200, epoch: 6 | loss: 0.2593801\n",
      "\tspeed: 0.1803s/iter; left time: 651.2400s\n",
      "Epoch: 6 cost time: 45.52725028991699\n",
      "Epoch: 6, Steps: 254 | Train Loss: 0.2712313 Vali Loss: 1.3940247 Test Loss: 1.3093582\n",
      "Validation loss decreased (1.408348 --> 1.394025).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2599993\n",
      "\tspeed: 0.4891s/iter; left time: 1690.7347s\n",
      "\titers: 200, epoch: 7 | loss: 0.2569312\n",
      "\tspeed: 0.1896s/iter; left time: 636.5628s\n",
      "Epoch: 7 cost time: 47.298816442489624\n",
      "Epoch: 7, Steps: 254 | Train Loss: 0.2633247 Vali Loss: 1.3911530 Test Loss: 1.2774985\n",
      "Validation loss decreased (1.394025 --> 1.391153).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2609439\n",
      "\tspeed: 0.4963s/iter; left time: 1589.6669s\n",
      "\titers: 200, epoch: 8 | loss: 0.2539196\n",
      "\tspeed: 0.1895s/iter; left time: 587.9014s\n",
      "Epoch: 8 cost time: 47.51716685295105\n",
      "Epoch: 8, Steps: 254 | Train Loss: 0.2594583 Vali Loss: 1.3986796 Test Loss: 1.2926545\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2674253\n",
      "\tspeed: 0.4586s/iter; left time: 1352.4102s\n",
      "\titers: 200, epoch: 9 | loss: 0.2609848\n",
      "\tspeed: 0.1851s/iter; left time: 527.3495s\n",
      "Epoch: 9 cost time: 46.04236698150635\n",
      "Epoch: 9, Steps: 254 | Train Loss: 0.2579494 Vali Loss: 1.3976746 Test Loss: 1.2951492\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2523626\n",
      "\tspeed: 0.4890s/iter; left time: 1317.7920s\n",
      "\titers: 200, epoch: 10 | loss: 0.2568344\n",
      "\tspeed: 0.1868s/iter; left time: 484.7138s\n",
      "Epoch: 10 cost time: 46.85307455062866\n",
      "Epoch: 10, Steps: 254 | Train Loss: 0.2567608 Vali Loss: 1.3921598 Test Loss: 1.2846520\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 7) (79, 32, 336, 7)\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "mse:1.2775903940200806, mae:0.8915536403656006\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on ETTh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'M', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_ETTh1_ftM_sl168_ll48_pl720_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7753\n",
      "val 2161\n",
      "test 2161\n",
      "\titers: 100, epoch: 1 | loss: 0.5046473\n",
      "\tspeed: 0.2385s/iter; left time: 1130.6891s\n",
      "\titers: 200, epoch: 1 | loss: 0.5007550\n",
      "\tspeed: 0.2202s/iter; left time: 1021.8975s\n",
      "Epoch: 1 cost time: 55.37479591369629\n",
      "Epoch: 1, Steps: 242 | Train Loss: 0.5358544 Vali Loss: 1.6096793 Test Loss: 1.2603108\n",
      "Validation loss decreased (inf --> 1.609679).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4221603\n",
      "\tspeed: 0.5328s/iter; left time: 2397.0176s\n",
      "\titers: 200, epoch: 2 | loss: 0.4695872\n",
      "\tspeed: 0.2485s/iter; left time: 1093.2220s\n",
      "Epoch: 2 cost time: 59.076266288757324\n",
      "Epoch: 2, Steps: 242 | Train Loss: 0.4469316 Vali Loss: 1.6272420 Test Loss: 1.2256138\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3858533\n",
      "\tspeed: 0.5418s/iter; left time: 2306.4044s\n",
      "\titers: 200, epoch: 3 | loss: 0.4375900\n",
      "\tspeed: 0.2231s/iter; left time: 927.4766s\n",
      "Epoch: 3 cost time: 54.3779993057251\n",
      "Epoch: 3, Steps: 242 | Train Loss: 0.4159012 Vali Loss: 1.6280459 Test Loss: 1.2337157\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3769131\n",
      "\tspeed: 0.4955s/iter; left time: 1989.4634s\n",
      "\titers: 200, epoch: 4 | loss: 0.3929306\n",
      "\tspeed: 0.2290s/iter; left time: 896.6023s\n",
      "Epoch: 4 cost time: 54.809842348098755\n",
      "Epoch: 4, Steps: 242 | Train Loss: 0.4015745 Vali Loss: 1.6408213 Test Loss: 1.2027516\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 7) (67, 32, 720, 7)\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "mse:1.2603299617767334, mae:0.9062066674232483\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on DEWINDh_small with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_DEWINDh_small_ftS_sl168_ll48_pl24_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.2181564\n",
      "\tspeed: 0.0879s/iter; left time: 692.5368s\n",
      "\titers: 200, epoch: 1 | loss: 0.1585830\n",
      "\tspeed: 0.0845s/iter; left time: 657.5154s\n",
      "\titers: 300, epoch: 1 | loss: 0.1861878\n",
      "\tspeed: 0.0843s/iter; left time: 647.2737s\n",
      "Epoch: 1 cost time: 34.060831785202026\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.2503805 Vali Loss: 0.1682032 Test Loss: 0.1157387\n",
      "Validation loss decreased (inf --> 0.168203).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1308473\n",
      "\tspeed: 0.2081s/iter; left time: 1557.1375s\n",
      "\titers: 200, epoch: 2 | loss: 0.1508021\n",
      "\tspeed: 0.0829s/iter; left time: 611.8851s\n",
      "\titers: 300, epoch: 2 | loss: 0.1594538\n",
      "\tspeed: 0.0826s/iter; left time: 601.4862s\n",
      "Epoch: 2 cost time: 33.06497550010681\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.1363748 Vali Loss: 0.1648518 Test Loss: 0.1145986\n",
      "Validation loss decreased (0.168203 --> 0.164852).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0625202\n",
      "\tspeed: 0.2044s/iter; left time: 1447.4621s\n",
      "\titers: 200, epoch: 3 | loss: 0.1276218\n",
      "\tspeed: 0.0843s/iter; left time: 588.7405s\n",
      "\titers: 300, epoch: 3 | loss: 0.0981306\n",
      "\tspeed: 0.0800s/iter; left time: 550.4839s\n",
      "Epoch: 3 cost time: 32.667452335357666\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.1122341 Vali Loss: 0.1279346 Test Loss: 0.0931439\n",
      "Validation loss decreased (0.164852 --> 0.127935).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0825725\n",
      "\tspeed: 0.1982s/iter; left time: 1324.4913s\n",
      "\titers: 200, epoch: 4 | loss: 0.1030510\n",
      "\tspeed: 0.0804s/iter; left time: 529.0735s\n",
      "\titers: 300, epoch: 4 | loss: 0.0701273\n",
      "\tspeed: 0.0808s/iter; left time: 523.7864s\n",
      "Epoch: 4 cost time: 32.422640562057495\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0972026 Vali Loss: 0.1324450 Test Loss: 0.0959998\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1005870\n",
      "\tspeed: 0.2036s/iter; left time: 1279.6727s\n",
      "\titers: 200, epoch: 5 | loss: 0.0922411\n",
      "\tspeed: 0.0762s/iter; left time: 471.5524s\n",
      "\titers: 300, epoch: 5 | loss: 0.0817964\n",
      "\tspeed: 0.0807s/iter; left time: 491.0176s\n",
      "Epoch: 5 cost time: 32.14623737335205\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0863226 Vali Loss: 0.1245372 Test Loss: 0.0956813\n",
      "Validation loss decreased (0.127935 --> 0.124537).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0641201\n",
      "\tspeed: 0.2022s/iter; left time: 1190.1434s\n",
      "\titers: 200, epoch: 6 | loss: 0.0648840\n",
      "\tspeed: 0.0785s/iter; left time: 454.3153s\n",
      "\titers: 300, epoch: 6 | loss: 0.0901342\n",
      "\tspeed: 0.0788s/iter; left time: 448.0272s\n",
      "Epoch: 6 cost time: 31.796497106552124\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0787938 Vali Loss: 0.1276845 Test Loss: 0.0978080\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0587520\n",
      "\tspeed: 0.1919s/iter; left time: 1053.0187s\n",
      "\titers: 200, epoch: 7 | loss: 0.0729454\n",
      "\tspeed: 0.0786s/iter; left time: 423.6239s\n",
      "\titers: 300, epoch: 7 | loss: 0.0595468\n",
      "\tspeed: 0.0792s/iter; left time: 418.6339s\n",
      "Epoch: 7 cost time: 31.319366931915283\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0742764 Vali Loss: 0.1283916 Test Loss: 0.0993613\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0810984\n",
      "\tspeed: 0.1937s/iter; left time: 985.3390s\n",
      "\titers: 200, epoch: 8 | loss: 0.0561991\n",
      "\tspeed: 0.0785s/iter; left time: 391.7877s\n",
      "\titers: 300, epoch: 8 | loss: 0.0760508\n",
      "\tspeed: 0.0818s/iter; left time: 399.7551s\n",
      "Epoch: 8 cost time: 32.10613393783569\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0719525 Vali Loss: 0.1256235 Test Loss: 0.0977488\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.09655702114105225, mae:0.16041359305381775\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on DEWINDh_small with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_DEWINDh_small_ftS_sl168_ll48_pl48_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.2417265\n",
      "\tspeed: 0.0862s/iter; left time: 677.2901s\n",
      "\titers: 200, epoch: 1 | loss: 0.1463955\n",
      "\tspeed: 0.0851s/iter; left time: 660.4185s\n",
      "\titers: 300, epoch: 1 | loss: 0.1916282\n",
      "\tspeed: 0.0862s/iter; left time: 660.3709s\n",
      "Epoch: 1 cost time: 34.17956042289734\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.2766625 Vali Loss: 0.1737697 Test Loss: 0.1430535\n",
      "Validation loss decreased (inf --> 0.173770).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1351399\n",
      "\tspeed: 0.2112s/iter; left time: 1575.8377s\n",
      "\titers: 200, epoch: 2 | loss: 0.1298091\n",
      "\tspeed: 0.0868s/iter; left time: 639.2699s\n",
      "\titers: 300, epoch: 2 | loss: 0.1589087\n",
      "\tspeed: 0.0808s/iter; left time: 586.4924s\n",
      "Epoch: 2 cost time: 33.09089803695679\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.1442045 Vali Loss: 0.1654575 Test Loss: 0.1177457\n",
      "Validation loss decreased (0.173770 --> 0.165458).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1232132\n",
      "\tspeed: 0.2027s/iter; left time: 1432.0084s\n",
      "\titers: 200, epoch: 3 | loss: 0.1168183\n",
      "\tspeed: 0.0807s/iter; left time: 562.2718s\n",
      "\titers: 300, epoch: 3 | loss: 0.1189370\n",
      "\tspeed: 0.0812s/iter; left time: 557.1339s\n",
      "Epoch: 3 cost time: 32.39022922515869\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.1179562 Vali Loss: 0.1973560 Test Loss: 0.1219780\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1012769\n",
      "\tspeed: 0.2044s/iter; left time: 1362.7211s\n",
      "\titers: 200, epoch: 4 | loss: 0.0959029\n",
      "\tspeed: 0.0839s/iter; left time: 551.0566s\n",
      "\titers: 300, epoch: 4 | loss: 0.0772754\n",
      "\tspeed: 0.0794s/iter; left time: 513.4405s\n",
      "Epoch: 4 cost time: 32.77794075012207\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.1026862 Vali Loss: 0.1697151 Test Loss: 0.1161495\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0930316\n",
      "\tspeed: 0.1942s/iter; left time: 1217.4494s\n",
      "\titers: 200, epoch: 5 | loss: 0.0706793\n",
      "\tspeed: 0.0806s/iter; left time: 497.3471s\n",
      "\titers: 300, epoch: 5 | loss: 0.0911826\n",
      "\tspeed: 0.0817s/iter; left time: 496.0760s\n",
      "Epoch: 5 cost time: 32.26669788360596\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0933920 Vali Loss: 0.1765141 Test Loss: 0.1220122\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.11794169247150421, mae:0.1736169159412384\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on DEWINDh_small with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_DEWINDh_small_ftS_sl168_ll48_pl168_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.2315295\n",
      "\tspeed: 0.1124s/iter; left time: 874.8034s\n",
      "\titers: 200, epoch: 1 | loss: 0.1931974\n",
      "\tspeed: 0.1171s/iter; left time: 899.4812s\n",
      "\titers: 300, epoch: 1 | loss: 0.1528965\n",
      "\tspeed: 0.1144s/iter; left time: 867.2195s\n",
      "Epoch: 1 cost time: 45.34205770492554\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.3171753 Vali Loss: 0.2018714 Test Loss: 0.1496063\n",
      "Validation loss decreased (inf --> 0.201871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1605725\n",
      "\tspeed: 0.3002s/iter; left time: 2217.7442s\n",
      "\titers: 200, epoch: 2 | loss: 0.1632677\n",
      "\tspeed: 0.1137s/iter; left time: 828.1881s\n",
      "\titers: 300, epoch: 2 | loss: 0.1669094\n",
      "\tspeed: 0.1153s/iter; left time: 828.9599s\n",
      "Epoch: 2 cost time: 45.72208046913147\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.1555275 Vali Loss: 0.1782429 Test Loss: 0.1284375\n",
      "Validation loss decreased (0.201871 --> 0.178243).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1671633\n",
      "\tspeed: 0.2950s/iter; left time: 2062.7007s\n",
      "\titers: 200, epoch: 3 | loss: 0.1520357\n",
      "\tspeed: 0.1179s/iter; left time: 812.8093s\n",
      "\titers: 300, epoch: 3 | loss: 0.1462277\n",
      "\tspeed: 0.1075s/iter; left time: 730.5115s\n",
      "Epoch: 3 cost time: 44.81014537811279\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.1342220 Vali Loss: 0.1767594 Test Loss: 0.1195866\n",
      "Validation loss decreased (0.178243 --> 0.176759).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1211728\n",
      "\tspeed: 0.2755s/iter; left time: 1818.1604s\n",
      "\titers: 200, epoch: 4 | loss: 0.1053190\n",
      "\tspeed: 0.1097s/iter; left time: 712.8004s\n",
      "\titers: 300, epoch: 4 | loss: 0.1042621\n",
      "\tspeed: 0.1088s/iter; left time: 696.1196s\n",
      "Epoch: 4 cost time: 43.29195785522461\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.1194432 Vali Loss: 0.1770164 Test Loss: 0.1165650\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1128850\n",
      "\tspeed: 0.2756s/iter; left time: 1709.8295s\n",
      "\titers: 200, epoch: 5 | loss: 0.1429059\n",
      "\tspeed: 0.1097s/iter; left time: 669.8514s\n",
      "\titers: 300, epoch: 5 | loss: 0.1095480\n",
      "\tspeed: 0.1079s/iter; left time: 648.0033s\n",
      "Epoch: 5 cost time: 43.410502433776855\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.1102143 Vali Loss: 0.1710142 Test Loss: 0.1166027\n",
      "Validation loss decreased (0.176759 --> 0.171014).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1069119\n",
      "\tspeed: 0.2917s/iter; left time: 1695.2557s\n",
      "\titers: 200, epoch: 6 | loss: 0.1240410\n",
      "\tspeed: 0.1139s/iter; left time: 650.5849s\n",
      "\titers: 300, epoch: 6 | loss: 0.0908174\n",
      "\tspeed: 0.1174s/iter; left time: 658.8579s\n",
      "Epoch: 6 cost time: 45.29831099510193\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.1045591 Vali Loss: 0.1740659 Test Loss: 0.1157176\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0898139\n",
      "\tspeed: 0.2855s/iter; left time: 1546.7523s\n",
      "\titers: 200, epoch: 7 | loss: 0.1069785\n",
      "\tspeed: 0.1156s/iter; left time: 614.9047s\n",
      "\titers: 300, epoch: 7 | loss: 0.1105203\n",
      "\tspeed: 0.1146s/iter; left time: 597.8415s\n",
      "Epoch: 7 cost time: 45.50804567337036\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.1013030 Vali Loss: 0.1697549 Test Loss: 0.1155440\n",
      "Validation loss decreased (0.171014 --> 0.169755).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0827300\n",
      "\tspeed: 0.2861s/iter; left time: 1436.9487s\n",
      "\titers: 200, epoch: 8 | loss: 0.0969321\n",
      "\tspeed: 0.1163s/iter; left time: 572.7886s\n",
      "\titers: 300, epoch: 8 | loss: 0.1184580\n",
      "\tspeed: 0.1133s/iter; left time: 546.6403s\n",
      "Epoch: 8 cost time: 45.14381790161133\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0996669 Vali Loss: 0.1688294 Test Loss: 0.1160487\n",
      "Validation loss decreased (0.169755 --> 0.168829).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1266516\n",
      "\tspeed: 0.2831s/iter; left time: 1310.4772s\n",
      "\titers: 200, epoch: 9 | loss: 0.0986254\n",
      "\tspeed: 0.1143s/iter; left time: 517.7533s\n",
      "\titers: 300, epoch: 9 | loss: 0.0971469\n",
      "\tspeed: 0.1137s/iter; left time: 503.4931s\n",
      "Epoch: 9 cost time: 44.23472547531128\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0989727 Vali Loss: 0.1723500 Test Loss: 0.1169749\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0972122\n",
      "\tspeed: 0.2714s/iter; left time: 1149.3523s\n",
      "\titers: 200, epoch: 10 | loss: 0.0758753\n",
      "\tspeed: 0.1092s/iter; left time: 451.3552s\n",
      "\titers: 300, epoch: 10 | loss: 0.1129533\n",
      "\tspeed: 0.1090s/iter; left time: 439.8417s\n",
      "Epoch: 10 cost time: 42.948650598526\n",
      "Epoch: 10, Steps: 394 | Train Loss: 0.0985479 Vali Loss: 0.1728732 Test Loss: 0.1170397\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0903719\n",
      "\tspeed: 0.2769s/iter; left time: 1063.5420s\n",
      "\titers: 200, epoch: 11 | loss: 0.0855881\n",
      "\tspeed: 0.1114s/iter; left time: 416.9200s\n",
      "\titers: 300, epoch: 11 | loss: 0.1154608\n",
      "\tspeed: 0.1158s/iter; left time: 421.7813s\n",
      "Epoch: 11 cost time: 45.23279857635498\n",
      "Epoch: 11, Steps: 394 | Train Loss: 0.0982418 Vali Loss: 0.1722798 Test Loss: 0.1163901\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.11570653319358826, mae:0.1651981621980667\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on DEWINDh_small with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_DEWINDh_small_ftS_sl168_ll48_pl336_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.6994384\n",
      "\tspeed: 0.1448s/iter; left time: 1111.8896s\n",
      "\titers: 200, epoch: 1 | loss: 0.1754936\n",
      "\tspeed: 0.1388s/iter; left time: 1052.5741s\n",
      "\titers: 300, epoch: 1 | loss: 0.1941728\n",
      "\tspeed: 0.1323s/iter; left time: 989.4586s\n",
      "Epoch: 1 cost time: 53.618693590164185\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.4071524 Vali Loss: 0.2003873 Test Loss: 0.1705275\n",
      "Validation loss decreased (inf --> 0.200387).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1644085\n",
      "\tspeed: 0.3309s/iter; left time: 2412.9504s\n",
      "\titers: 200, epoch: 2 | loss: 0.1878518\n",
      "\tspeed: 0.1451s/iter; left time: 1043.5423s\n",
      "\titers: 300, epoch: 2 | loss: 0.1637649\n",
      "\tspeed: 0.1392s/iter; left time: 987.1376s\n",
      "Epoch: 2 cost time: 54.197659730911255\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.1627209 Vali Loss: 0.1937849 Test Loss: 0.1642788\n",
      "Validation loss decreased (0.200387 --> 0.193785).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1420117\n",
      "\tspeed: 0.3382s/iter; left time: 2334.7989s\n",
      "\titers: 200, epoch: 3 | loss: 0.1380732\n",
      "\tspeed: 0.1491s/iter; left time: 1014.2642s\n",
      "\titers: 300, epoch: 3 | loss: 0.1485458\n",
      "\tspeed: 0.1460s/iter; left time: 978.8116s\n",
      "Epoch: 3 cost time: 56.24699258804321\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.1456075 Vali Loss: 0.1922455 Test Loss: 0.1470484\n",
      "Validation loss decreased (0.193785 --> 0.192246).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1274631\n",
      "\tspeed: 0.3432s/iter; left time: 2235.3346s\n",
      "\titers: 200, epoch: 4 | loss: 0.1564033\n",
      "\tspeed: 0.1525s/iter; left time: 978.4550s\n",
      "\titers: 300, epoch: 4 | loss: 0.1517518\n",
      "\tspeed: 0.1452s/iter; left time: 917.0960s\n",
      "Epoch: 4 cost time: 56.30557084083557\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.1347258 Vali Loss: 0.1831891 Test Loss: 0.1471882\n",
      "Validation loss decreased (0.192246 --> 0.183189).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1283072\n",
      "\tspeed: 0.3556s/iter; left time: 2178.2189s\n",
      "\titers: 200, epoch: 5 | loss: 0.1306993\n",
      "\tspeed: 0.1537s/iter; left time: 926.2899s\n",
      "\titers: 300, epoch: 5 | loss: 0.1285323\n",
      "\tspeed: 0.1439s/iter; left time: 852.6365s\n",
      "Epoch: 5 cost time: 57.53630709648132\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.1261707 Vali Loss: 0.1912243 Test Loss: 0.1543260\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1129745\n",
      "\tspeed: 0.3553s/iter; left time: 2038.2345s\n",
      "\titers: 200, epoch: 6 | loss: 0.1293508\n",
      "\tspeed: 0.1436s/iter; left time: 809.4136s\n",
      "\titers: 300, epoch: 6 | loss: 0.1403188\n",
      "\tspeed: 0.1432s/iter; left time: 792.8208s\n",
      "Epoch: 6 cost time: 56.119593381881714\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.1200052 Vali Loss: 0.1922905 Test Loss: 0.1495447\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1319649\n",
      "\tspeed: 0.3393s/iter; left time: 1814.2340s\n",
      "\titers: 200, epoch: 7 | loss: 0.1006560\n",
      "\tspeed: 0.1415s/iter; left time: 742.4165s\n",
      "\titers: 300, epoch: 7 | loss: 0.1051432\n",
      "\tspeed: 0.1327s/iter; left time: 682.9190s\n",
      "Epoch: 7 cost time: 54.14783692359924\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.1163262 Vali Loss: 0.1904549 Test Loss: 0.1503187\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.1474824994802475, mae:0.18427105247974396\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on DEWINDh_small with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_DEWINDh_small_ftS_sl168_ll48_pl720_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.9096685\n",
      "\tspeed: 0.1961s/iter; left time: 1458.8930s\n",
      "\titers: 200, epoch: 1 | loss: 0.8589295\n",
      "\tspeed: 0.1935s/iter; left time: 1420.1441s\n",
      "\titers: 300, epoch: 1 | loss: 0.2018156\n",
      "\tspeed: 0.2035s/iter; left time: 1473.3444s\n",
      "Epoch: 1 cost time: 75.11178159713745\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.6474771 Vali Loss: 0.2172523 Test Loss: 0.1687097\n",
      "Validation loss decreased (inf --> 0.217252).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1944901\n",
      "\tspeed: 0.4254s/iter; left time: 3005.1617s\n",
      "\titers: 200, epoch: 2 | loss: 0.1660769\n",
      "\tspeed: 0.1773s/iter; left time: 1235.0221s\n",
      "\titers: 300, epoch: 2 | loss: 0.1991476\n",
      "\tspeed: 0.1894s/iter; left time: 1300.3711s\n",
      "Epoch: 2 cost time: 69.51024723052979\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.1712855 Vali Loss: 0.2033328 Test Loss: 0.1579460\n",
      "Validation loss decreased (0.217252 --> 0.203333).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1465859\n",
      "\tspeed: 0.4254s/iter; left time: 2844.6303s\n",
      "\titers: 200, epoch: 3 | loss: 0.1620242\n",
      "\tspeed: 0.1923s/iter; left time: 1266.5051s\n",
      "\titers: 300, epoch: 3 | loss: 0.1634589\n",
      "\tspeed: 0.1986s/iter; left time: 1288.5584s\n",
      "Epoch: 3 cost time: 74.09332609176636\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.1524179 Vali Loss: 0.2011440 Test Loss: 0.1404117\n",
      "Validation loss decreased (0.203333 --> 0.201144).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1498488\n",
      "\tspeed: 0.4252s/iter; left time: 2683.2635s\n",
      "\titers: 200, epoch: 4 | loss: 0.1359136\n",
      "\tspeed: 0.1902s/iter; left time: 1181.4295s\n",
      "\titers: 300, epoch: 4 | loss: 0.1243945\n",
      "\tspeed: 0.2041s/iter; left time: 1247.0848s\n",
      "Epoch: 4 cost time: 74.0849142074585\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.1452806 Vali Loss: 0.1953998 Test Loss: 0.1356483\n",
      "Validation loss decreased (0.201144 --> 0.195400).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1613455\n",
      "\tspeed: 0.4234s/iter; left time: 2511.8039s\n",
      "\titers: 200, epoch: 5 | loss: 0.1331688\n",
      "\tspeed: 0.2014s/iter; left time: 1174.4785s\n",
      "\titers: 300, epoch: 5 | loss: 0.1392963\n",
      "\tspeed: 0.1978s/iter; left time: 1134.0402s\n",
      "Epoch: 5 cost time: 73.50520300865173\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.1394240 Vali Loss: 0.1951465 Test Loss: 0.1349102\n",
      "Validation loss decreased (0.195400 --> 0.195146).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1345499\n",
      "\tspeed: 0.4283s/iter; left time: 2379.3627s\n",
      "\titers: 200, epoch: 6 | loss: 0.1332881\n",
      "\tspeed: 0.1973s/iter; left time: 1076.7116s\n",
      "\titers: 300, epoch: 6 | loss: 0.1322229\n",
      "\tspeed: 0.1938s/iter; left time: 1037.9087s\n",
      "Epoch: 6 cost time: 75.48313164710999\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.1356600 Vali Loss: 0.1978568 Test Loss: 0.1329515\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1293676\n",
      "\tspeed: 0.4300s/iter; left time: 2226.9078s\n",
      "\titers: 200, epoch: 7 | loss: 0.1366700\n",
      "\tspeed: 0.1918s/iter; left time: 974.1751s\n",
      "\titers: 300, epoch: 7 | loss: 0.1356141\n",
      "\tspeed: 0.2037s/iter; left time: 1014.2666s\n",
      "Epoch: 7 cost time: 73.69037342071533\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.1332721 Vali Loss: 0.1977947 Test Loss: 0.1335969\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1243444\n",
      "\tspeed: 0.4245s/iter; left time: 2038.4493s\n",
      "\titers: 200, epoch: 8 | loss: 0.1215523\n",
      "\tspeed: 0.1995s/iter; left time: 938.0789s\n",
      "\titers: 300, epoch: 8 | loss: 0.1386589\n",
      "\tspeed: 0.2039s/iter; left time: 938.2484s\n",
      "Epoch: 8 cost time: 75.34371399879456\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.1317155 Vali Loss: 0.1980076 Test Loss: 0.1332332\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.13489919900894165, mae:0.17901983857154846\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTHh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTHh1_ftS_sl168_ll48_pl24_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.1502159\n",
      "\tspeed: 0.0862s/iter; left time: 679.3629s\n",
      "\titers: 200, epoch: 1 | loss: 0.0662987\n",
      "\tspeed: 0.0812s/iter; left time: 632.1563s\n",
      "\titers: 300, epoch: 1 | loss: 0.0576789\n",
      "\tspeed: 0.0805s/iter; left time: 618.5300s\n",
      "Epoch: 1 cost time: 32.797231912612915\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.1534495 Vali Loss: 0.0607034 Test Loss: 0.0687796\n",
      "Validation loss decreased (inf --> 0.060703).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0322477\n",
      "\tspeed: 0.1973s/iter; left time: 1476.4556s\n",
      "\titers: 200, epoch: 2 | loss: 0.0318800\n",
      "\tspeed: 0.0804s/iter; left time: 593.4681s\n",
      "\titers: 300, epoch: 2 | loss: 0.0320282\n",
      "\tspeed: 0.0812s/iter; left time: 591.0287s\n",
      "Epoch: 2 cost time: 32.301369428634644\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0322195 Vali Loss: 0.0233619 Test Loss: 0.0261440\n",
      "Validation loss decreased (0.060703 --> 0.023362).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0201680\n",
      "\tspeed: 0.1976s/iter; left time: 1399.6110s\n",
      "\titers: 200, epoch: 3 | loss: 0.0209452\n",
      "\tspeed: 0.0795s/iter; left time: 555.4387s\n",
      "\titers: 300, epoch: 3 | loss: 0.0212907\n",
      "\tspeed: 0.0797s/iter; left time: 548.8224s\n",
      "Epoch: 3 cost time: 31.99296760559082\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0215603 Vali Loss: 0.0228029 Test Loss: 0.0257134\n",
      "Validation loss decreased (0.023362 --> 0.022803).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0186938\n",
      "\tspeed: 0.2033s/iter; left time: 1358.9524s\n",
      "\titers: 200, epoch: 4 | loss: 0.0193556\n",
      "\tspeed: 0.0836s/iter; left time: 550.1958s\n",
      "\titers: 300, epoch: 4 | loss: 0.0174046\n",
      "\tspeed: 0.0837s/iter; left time: 542.8665s\n",
      "Epoch: 4 cost time: 33.039886713027954\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0192934 Vali Loss: 0.0181914 Test Loss: 0.0201591\n",
      "Validation loss decreased (0.022803 --> 0.018191).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0178455\n",
      "\tspeed: 0.1956s/iter; left time: 1229.0613s\n",
      "\titers: 200, epoch: 5 | loss: 0.0175119\n",
      "\tspeed: 0.0830s/iter; left time: 513.4153s\n",
      "\titers: 300, epoch: 5 | loss: 0.0196733\n",
      "\tspeed: 0.0798s/iter; left time: 485.6725s\n",
      "Epoch: 5 cost time: 32.43282866477966\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0177879 Vali Loss: 0.0192691 Test Loss: 0.0218650\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0187796\n",
      "\tspeed: 0.1936s/iter; left time: 1139.3018s\n",
      "\titers: 200, epoch: 6 | loss: 0.0171497\n",
      "\tspeed: 0.0846s/iter; left time: 489.2153s\n",
      "\titers: 300, epoch: 6 | loss: 0.0178273\n",
      "\tspeed: 0.0825s/iter; left time: 469.1073s\n",
      "Epoch: 6 cost time: 32.38812971115112\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0171204 Vali Loss: 0.0183841 Test Loss: 0.0208378\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0164605\n",
      "\tspeed: 0.1991s/iter; left time: 1092.6483s\n",
      "\titers: 200, epoch: 7 | loss: 0.0179644\n",
      "\tspeed: 0.0845s/iter; left time: 455.2191s\n",
      "\titers: 300, epoch: 7 | loss: 0.0172135\n",
      "\tspeed: 0.0851s/iter; left time: 450.1541s\n",
      "Epoch: 7 cost time: 33.873082876205444\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0167743 Vali Loss: 0.0181511 Test Loss: 0.0206117\n",
      "Validation loss decreased (0.018191 --> 0.018151).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0161919\n",
      "\tspeed: 0.2043s/iter; left time: 1039.6926s\n",
      "\titers: 200, epoch: 8 | loss: 0.0160264\n",
      "\tspeed: 0.0789s/iter; left time: 393.7450s\n",
      "\titers: 300, epoch: 8 | loss: 0.0175843\n",
      "\tspeed: 0.0791s/iter; left time: 386.8338s\n",
      "Epoch: 8 cost time: 32.127387285232544\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0165549 Vali Loss: 0.0190294 Test Loss: 0.0214782\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0149575\n",
      "\tspeed: 0.2016s/iter; left time: 945.3323s\n",
      "\titers: 200, epoch: 9 | loss: 0.0167440\n",
      "\tspeed: 0.0832s/iter; left time: 381.8613s\n",
      "\titers: 300, epoch: 9 | loss: 0.0168618\n",
      "\tspeed: 0.0851s/iter; left time: 381.8241s\n",
      "Epoch: 9 cost time: 33.55641007423401\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0164245 Vali Loss: 0.0185174 Test Loss: 0.0210046\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0158318\n",
      "\tspeed: 0.2033s/iter; left time: 872.3352s\n",
      "\titers: 200, epoch: 10 | loss: 0.0165276\n",
      "\tspeed: 0.0794s/iter; left time: 332.6006s\n",
      "\titers: 300, epoch: 10 | loss: 0.0164043\n",
      "\tspeed: 0.0791s/iter; left time: 323.6836s\n",
      "Epoch: 10 cost time: 32.42030310630798\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0163792 Vali Loss: 0.0179222 Test Loss: 0.0205582\n",
      "Validation loss decreased (0.018151 --> 0.017922).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0151415\n",
      "\tspeed: 0.2021s/iter; left time: 786.5545s\n",
      "\titers: 200, epoch: 11 | loss: 0.0182032\n",
      "\tspeed: 0.0829s/iter; left time: 314.3526s\n",
      "\titers: 300, epoch: 11 | loss: 0.0181914\n",
      "\tspeed: 0.0824s/iter; left time: 304.2820s\n",
      "Epoch: 11 cost time: 32.787012338638306\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0163415 Vali Loss: 0.0183018 Test Loss: 0.0208961\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0159692\n",
      "\tspeed: 0.1870s/iter; left time: 653.0645s\n",
      "\titers: 200, epoch: 12 | loss: 0.0159891\n",
      "\tspeed: 0.0758s/iter; left time: 257.0622s\n",
      "\titers: 300, epoch: 12 | loss: 0.0159446\n",
      "\tspeed: 0.0812s/iter; left time: 267.3352s\n",
      "Epoch: 12 cost time: 30.980855703353882\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0163224 Vali Loss: 0.0180967 Test Loss: 0.0204621\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0168970\n",
      "\tspeed: 0.1932s/iter; left time: 597.4690s\n",
      "\titers: 200, epoch: 13 | loss: 0.0167940\n",
      "\tspeed: 0.0783s/iter; left time: 234.3272s\n",
      "\titers: 300, epoch: 13 | loss: 0.0153720\n",
      "\tspeed: 0.0793s/iter; left time: 229.4033s\n",
      "Epoch: 13 cost time: 31.788681983947754\n",
      "Epoch: 13, Steps: 399 | Train Loss: 0.0162748 Vali Loss: 0.0184027 Test Loss: 0.0207420\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.020547043532133102, mae:0.11296423524618149\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTHh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTHh1_ftS_sl168_ll48_pl48_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.3306390\n",
      "\tspeed: 0.0875s/iter; left time: 687.9816s\n",
      "\titers: 200, epoch: 1 | loss: 0.0786317\n",
      "\tspeed: 0.0868s/iter; left time: 673.3019s\n",
      "\titers: 300, epoch: 1 | loss: 0.0393534\n",
      "\tspeed: 0.0849s/iter; left time: 650.5595s\n",
      "Epoch: 1 cost time: 33.99665880203247\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.1859316 Vali Loss: 0.0492943 Test Loss: 0.0552643\n",
      "Validation loss decreased (inf --> 0.049294).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0336803\n",
      "\tspeed: 0.2051s/iter; left time: 1530.3620s\n",
      "\titers: 200, epoch: 2 | loss: 0.0318648\n",
      "\tspeed: 0.0863s/iter; left time: 635.3768s\n",
      "\titers: 300, epoch: 2 | loss: 0.0325721\n",
      "\tspeed: 0.0823s/iter; left time: 597.5512s\n",
      "Epoch: 2 cost time: 33.52786993980408\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0375621 Vali Loss: 0.0269729 Test Loss: 0.0316580\n",
      "Validation loss decreased (0.049294 --> 0.026973).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0230805\n",
      "\tspeed: 0.2060s/iter; left time: 1455.3065s\n",
      "\titers: 200, epoch: 3 | loss: 0.0210679\n",
      "\tspeed: 0.0877s/iter; left time: 610.6880s\n",
      "\titers: 300, epoch: 3 | loss: 0.0241144\n",
      "\tspeed: 0.0875s/iter; left time: 600.3806s\n",
      "Epoch: 3 cost time: 34.749205350875854\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0240709 Vali Loss: 0.0194032 Test Loss: 0.0223724\n",
      "Validation loss decreased (0.026973 --> 0.019403).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0186830\n",
      "\tspeed: 0.2080s/iter; left time: 1387.0477s\n",
      "\titers: 200, epoch: 4 | loss: 0.0217189\n",
      "\tspeed: 0.0823s/iter; left time: 540.5932s\n",
      "\titers: 300, epoch: 4 | loss: 0.0162430\n",
      "\tspeed: 0.0884s/iter; left time: 571.8343s\n",
      "Epoch: 4 cost time: 33.889907121658325\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0207209 Vali Loss: 0.0209769 Test Loss: 0.0242308\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0200165\n",
      "\tspeed: 0.2133s/iter; left time: 1337.0199s\n",
      "\titers: 200, epoch: 5 | loss: 0.0191055\n",
      "\tspeed: 0.0887s/iter; left time: 547.0201s\n",
      "\titers: 300, epoch: 5 | loss: 0.0173639\n",
      "\tspeed: 0.0856s/iter; left time: 519.3143s\n",
      "Epoch: 5 cost time: 34.25328183174133\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0191170 Vali Loss: 0.0197143 Test Loss: 0.0236279\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0191570\n",
      "\tspeed: 0.1950s/iter; left time: 1145.0178s\n",
      "\titers: 200, epoch: 6 | loss: 0.0179509\n",
      "\tspeed: 0.0832s/iter; left time: 480.1332s\n",
      "\titers: 300, epoch: 6 | loss: 0.0206170\n",
      "\tspeed: 0.0858s/iter; left time: 486.6432s\n",
      "Epoch: 6 cost time: 33.27029085159302\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0183282 Vali Loss: 0.0183807 Test Loss: 0.0216777\n",
      "Validation loss decreased (0.019403 --> 0.018381).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0177182\n",
      "\tspeed: 0.2087s/iter; left time: 1142.3952s\n",
      "\titers: 200, epoch: 7 | loss: 0.0186395\n",
      "\tspeed: 0.0863s/iter; left time: 463.4923s\n",
      "\titers: 300, epoch: 7 | loss: 0.0186844\n",
      "\tspeed: 0.0840s/iter; left time: 443.0991s\n",
      "Epoch: 7 cost time: 33.58974623680115\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0179344 Vali Loss: 0.0182069 Test Loss: 0.0214209\n",
      "Validation loss decreased (0.018381 --> 0.018207).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0198128\n",
      "\tspeed: 0.2020s/iter; left time: 1024.9865s\n",
      "\titers: 200, epoch: 8 | loss: 0.0175045\n",
      "\tspeed: 0.0813s/iter; left time: 404.4015s\n",
      "\titers: 300, epoch: 8 | loss: 0.0191491\n",
      "\tspeed: 0.0814s/iter; left time: 396.9316s\n",
      "Epoch: 8 cost time: 32.65370178222656\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0176337 Vali Loss: 0.0185454 Test Loss: 0.0218046\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0184079\n",
      "\tspeed: 0.2102s/iter; left time: 982.9166s\n",
      "\titers: 200, epoch: 9 | loss: 0.0180896\n",
      "\tspeed: 0.0886s/iter; left time: 405.3694s\n",
      "\titers: 300, epoch: 9 | loss: 0.0173361\n",
      "\tspeed: 0.0869s/iter; left time: 388.9308s\n",
      "Epoch: 9 cost time: 34.673609256744385\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0175239 Vali Loss: 0.0185318 Test Loss: 0.0220140\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0176551\n",
      "\tspeed: 0.2090s/iter; left time: 894.4096s\n",
      "\titers: 200, epoch: 10 | loss: 0.0157047\n",
      "\tspeed: 0.0855s/iter; left time: 357.2325s\n",
      "\titers: 300, epoch: 10 | loss: 0.0174050\n",
      "\tspeed: 0.0874s/iter; left time: 356.3986s\n",
      "Epoch: 10 cost time: 34.90835738182068\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.0174755 Vali Loss: 0.0185969 Test Loss: 0.0218537\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.021284976974129677, mae:0.11513884365558624\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTHh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTHh1_ftS_sl168_ll48_pl168_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.3272734\n",
      "\tspeed: 0.1097s/iter; left time: 853.3370s\n",
      "\titers: 200, epoch: 1 | loss: 0.0793005\n",
      "\tspeed: 0.1172s/iter; left time: 900.0249s\n",
      "\titers: 300, epoch: 1 | loss: 0.0554341\n",
      "\tspeed: 0.1169s/iter; left time: 886.4326s\n",
      "Epoch: 1 cost time: 45.40029525756836\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.2098390 Vali Loss: 0.0504757 Test Loss: 0.0557573\n",
      "Validation loss decreased (inf --> 0.050476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0353456\n",
      "\tspeed: 0.2928s/iter; left time: 2163.0276s\n",
      "\titers: 200, epoch: 2 | loss: 0.0304793\n",
      "\tspeed: 0.1101s/iter; left time: 802.5832s\n",
      "\titers: 300, epoch: 2 | loss: 0.0290882\n",
      "\tspeed: 0.1087s/iter; left time: 781.0946s\n",
      "Epoch: 2 cost time: 43.9651563167572\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0376153 Vali Loss: 0.0299380 Test Loss: 0.0348425\n",
      "Validation loss decreased (0.050476 --> 0.029938).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0296105\n",
      "\tspeed: 0.2887s/iter; left time: 2018.9828s\n",
      "\titers: 200, epoch: 3 | loss: 0.0230730\n",
      "\tspeed: 0.1083s/iter; left time: 746.1801s\n",
      "\titers: 300, epoch: 3 | loss: 0.0286173\n",
      "\tspeed: 0.1069s/iter; left time: 726.1557s\n",
      "Epoch: 3 cost time: 44.40710926055908\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0253492 Vali Loss: 0.0284725 Test Loss: 0.0341270\n",
      "Validation loss decreased (0.029938 --> 0.028473).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0228449\n",
      "\tspeed: 0.2909s/iter; left time: 1919.6707s\n",
      "\titers: 200, epoch: 4 | loss: 0.0221941\n",
      "\tspeed: 0.1142s/iter; left time: 742.5046s\n",
      "\titers: 300, epoch: 4 | loss: 0.0254592\n",
      "\tspeed: 0.1185s/iter; left time: 758.0175s\n",
      "Epoch: 4 cost time: 45.174660205841064\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0216876 Vali Loss: 0.0198028 Test Loss: 0.0239204\n",
      "Validation loss decreased (0.028473 --> 0.019803).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0193579\n",
      "\tspeed: 0.2770s/iter; left time: 1718.9010s\n",
      "\titers: 200, epoch: 5 | loss: 0.0196433\n",
      "\tspeed: 0.1118s/iter; left time: 682.5751s\n",
      "\titers: 300, epoch: 5 | loss: 0.0196477\n",
      "\tspeed: 0.1121s/iter; left time: 673.2865s\n",
      "Epoch: 5 cost time: 44.328938007354736\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0199807 Vali Loss: 0.0233391 Test Loss: 0.0304638\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0196511\n",
      "\tspeed: 0.2745s/iter; left time: 1595.0844s\n",
      "\titers: 200, epoch: 6 | loss: 0.0199006\n",
      "\tspeed: 0.1160s/iter; left time: 662.7169s\n",
      "\titers: 300, epoch: 6 | loss: 0.0180884\n",
      "\tspeed: 0.1115s/iter; left time: 625.5782s\n",
      "Epoch: 6 cost time: 44.60327172279358\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0191972 Vali Loss: 0.0235121 Test Loss: 0.0298998\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0178127\n",
      "\tspeed: 0.2864s/iter; left time: 1551.3082s\n",
      "\titers: 200, epoch: 7 | loss: 0.0194571\n",
      "\tspeed: 0.1121s/iter; left time: 596.1335s\n",
      "\titers: 300, epoch: 7 | loss: 0.0186183\n",
      "\tspeed: 0.1120s/iter; left time: 584.1650s\n",
      "Epoch: 7 cost time: 44.8646457195282\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0187951 Vali Loss: 0.0240370 Test Loss: 0.0307854\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.02388818934559822, mae:0.12188655138015747\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTHh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTHh1_ftS_sl168_ll48_pl336_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.3435148\n",
      "\tspeed: 0.1452s/iter; left time: 1115.3330s\n",
      "\titers: 200, epoch: 1 | loss: 0.3125064\n",
      "\tspeed: 0.1408s/iter; left time: 1067.1191s\n",
      "\titers: 300, epoch: 1 | loss: 0.0690861\n",
      "\tspeed: 0.1291s/iter; left time: 965.9527s\n",
      "Epoch: 1 cost time: 53.96660542488098\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.2774419 Vali Loss: 0.0560062 Test Loss: 0.0734877\n",
      "Validation loss decreased (inf --> 0.056006).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0398379\n",
      "\tspeed: 0.3391s/iter; left time: 2472.6519s\n",
      "\titers: 200, epoch: 2 | loss: 0.0393158\n",
      "\tspeed: 0.1389s/iter; left time: 999.1412s\n",
      "\titers: 300, epoch: 2 | loss: 0.0294511\n",
      "\tspeed: 0.1362s/iter; left time: 966.0734s\n",
      "Epoch: 2 cost time: 54.27446222305298\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0417693 Vali Loss: 0.0266518 Test Loss: 0.0314253\n",
      "Validation loss decreased (0.056006 --> 0.026652).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0322820\n",
      "\tspeed: 0.3392s/iter; left time: 2341.5143s\n",
      "\titers: 200, epoch: 3 | loss: 0.0271890\n",
      "\tspeed: 0.1390s/iter; left time: 945.7200s\n",
      "\titers: 300, epoch: 3 | loss: 0.0235112\n",
      "\tspeed: 0.1348s/iter; left time: 903.7505s\n",
      "Epoch: 3 cost time: 53.264317989349365\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0253965 Vali Loss: 0.0229685 Test Loss: 0.0261951\n",
      "Validation loss decreased (0.026652 --> 0.022968).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0205787\n",
      "\tspeed: 0.3301s/iter; left time: 2150.1085s\n",
      "\titers: 200, epoch: 4 | loss: 0.0202871\n",
      "\tspeed: 0.1457s/iter; left time: 934.3305s\n",
      "\titers: 300, epoch: 4 | loss: 0.0214256\n",
      "\tspeed: 0.1472s/iter; left time: 929.6189s\n",
      "Epoch: 4 cost time: 56.54840564727783\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0215306 Vali Loss: 0.0217954 Test Loss: 0.0245267\n",
      "Validation loss decreased (0.022968 --> 0.021795).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0228725\n",
      "\tspeed: 0.3536s/iter; left time: 2165.8962s\n",
      "\titers: 200, epoch: 5 | loss: 0.0203547\n",
      "\tspeed: 0.1384s/iter; left time: 833.7170s\n",
      "\titers: 300, epoch: 5 | loss: 0.0196130\n",
      "\tspeed: 0.1486s/iter; left time: 880.6897s\n",
      "Epoch: 5 cost time: 56.8484833240509\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0202277 Vali Loss: 0.0200829 Test Loss: 0.0230931\n",
      "Validation loss decreased (0.021795 --> 0.020083).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0187119\n",
      "\tspeed: 0.3606s/iter; left time: 2068.5431s\n",
      "\titers: 200, epoch: 6 | loss: 0.0201814\n",
      "\tspeed: 0.1479s/iter; left time: 833.4850s\n",
      "\titers: 300, epoch: 6 | loss: 0.0192375\n",
      "\tspeed: 0.1447s/iter; left time: 800.8407s\n",
      "Epoch: 6 cost time: 56.219247341156006\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0196562 Vali Loss: 0.0196677 Test Loss: 0.0228173\n",
      "Validation loss decreased (0.020083 --> 0.019668).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0202380\n",
      "\tspeed: 0.3394s/iter; left time: 1815.0312s\n",
      "\titers: 200, epoch: 7 | loss: 0.0187638\n",
      "\tspeed: 0.1532s/iter; left time: 803.6527s\n",
      "\titers: 300, epoch: 7 | loss: 0.0190022\n",
      "\tspeed: 0.1463s/iter; left time: 753.0613s\n",
      "Epoch: 7 cost time: 56.2969331741333\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.0194543 Vali Loss: 0.0210967 Test Loss: 0.0239761\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0197616\n",
      "\tspeed: 0.3396s/iter; left time: 1683.6171s\n",
      "\titers: 200, epoch: 8 | loss: 0.0200182\n",
      "\tspeed: 0.1444s/iter; left time: 701.6435s\n",
      "\titers: 300, epoch: 8 | loss: 0.0197001\n",
      "\tspeed: 0.1455s/iter; left time: 692.3232s\n",
      "Epoch: 8 cost time: 55.823201417922974\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.0191694 Vali Loss: 0.0209628 Test Loss: 0.0242150\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0201103\n",
      "\tspeed: 0.3474s/iter; left time: 1587.2958s\n",
      "\titers: 200, epoch: 9 | loss: 0.0189106\n",
      "\tspeed: 0.1469s/iter; left time: 656.4863s\n",
      "\titers: 300, epoch: 9 | loss: 0.0190034\n",
      "\tspeed: 0.1401s/iter; left time: 611.9282s\n",
      "Epoch: 9 cost time: 56.20698618888855\n",
      "Epoch: 9, Steps: 389 | Train Loss: 0.0190584 Vali Loss: 0.0208587 Test Loss: 0.0240344\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.02294190786778927, mae:0.11921347677707672\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTHh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTHh1_ftS_sl168_ll48_pl720_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.3818513\n",
      "\tspeed: 0.1925s/iter; left time: 1432.2212s\n",
      "\titers: 200, epoch: 1 | loss: 0.3217693\n",
      "\tspeed: 0.1994s/iter; left time: 1464.1161s\n",
      "\titers: 300, epoch: 1 | loss: 0.2961449\n",
      "\tspeed: 0.2070s/iter; left time: 1498.6155s\n",
      "Epoch: 1 cost time: 76.04594111442566\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.3734612 Vali Loss: 0.2083809 Test Loss: 0.2150048\n",
      "Validation loss decreased (inf --> 0.208381).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0932350\n",
      "\tspeed: 0.4493s/iter; left time: 3173.5513s\n",
      "\titers: 200, epoch: 2 | loss: 0.0398085\n",
      "\tspeed: 0.1890s/iter; left time: 1316.0773s\n",
      "\titers: 300, epoch: 2 | loss: 0.0301513\n",
      "\tspeed: 0.1997s/iter; left time: 1371.0561s\n",
      "Epoch: 2 cost time: 72.96009802818298\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0678059 Vali Loss: 0.0229305 Test Loss: 0.0248639\n",
      "Validation loss decreased (0.208381 --> 0.022931).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0247197\n",
      "\tspeed: 0.4219s/iter; left time: 2821.2145s\n",
      "\titers: 200, epoch: 3 | loss: 0.0239144\n",
      "\tspeed: 0.1992s/iter; left time: 1311.8369s\n",
      "\titers: 300, epoch: 3 | loss: 0.0242122\n",
      "\tspeed: 0.1914s/iter; left time: 1241.6774s\n",
      "Epoch: 3 cost time: 72.9268147945404\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0243844 Vali Loss: 0.0217445 Test Loss: 0.0233849\n",
      "Validation loss decreased (0.022931 --> 0.021745).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0213372\n",
      "\tspeed: 0.4087s/iter; left time: 2579.1780s\n",
      "\titers: 200, epoch: 4 | loss: 0.0210969\n",
      "\tspeed: 0.1970s/iter; left time: 1223.1404s\n",
      "\titers: 300, epoch: 4 | loss: 0.0198717\n",
      "\tspeed: 0.1992s/iter; left time: 1217.1123s\n",
      "Epoch: 4 cost time: 73.45285606384277\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0218754 Vali Loss: 0.0208689 Test Loss: 0.0214239\n",
      "Validation loss decreased (0.021745 --> 0.020869).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0202940\n",
      "\tspeed: 0.4261s/iter; left time: 2527.9747s\n",
      "\titers: 200, epoch: 5 | loss: 0.0208841\n",
      "\tspeed: 0.1997s/iter; left time: 1164.6477s\n",
      "\titers: 300, epoch: 5 | loss: 0.0217885\n",
      "\tspeed: 0.2026s/iter; left time: 1161.6301s\n",
      "Epoch: 5 cost time: 75.30228233337402\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0203668 Vali Loss: 0.0198921 Test Loss: 0.0208296\n",
      "Validation loss decreased (0.020869 --> 0.019892).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0197803\n",
      "\tspeed: 0.4397s/iter; left time: 2443.1001s\n",
      "\titers: 200, epoch: 6 | loss: 0.0191907\n",
      "\tspeed: 0.2013s/iter; left time: 1098.4837s\n",
      "\titers: 300, epoch: 6 | loss: 0.0190738\n",
      "\tspeed: 0.1970s/iter; left time: 1055.2261s\n",
      "Epoch: 6 cost time: 75.17676115036011\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0195704 Vali Loss: 0.0187467 Test Loss: 0.0196915\n",
      "Validation loss decreased (0.019892 --> 0.018747).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0184191\n",
      "\tspeed: 0.4338s/iter; left time: 2246.6992s\n",
      "\titers: 200, epoch: 7 | loss: 0.0195653\n",
      "\tspeed: 0.1972s/iter; left time: 1001.5247s\n",
      "\titers: 300, epoch: 7 | loss: 0.0189899\n",
      "\tspeed: 0.1918s/iter; left time: 955.1091s\n",
      "Epoch: 7 cost time: 72.76934790611267\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0191831 Vali Loss: 0.0190107 Test Loss: 0.0199517\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0192067\n",
      "\tspeed: 0.4177s/iter; left time: 2005.8003s\n",
      "\titers: 200, epoch: 8 | loss: 0.0192385\n",
      "\tspeed: 0.2023s/iter; left time: 951.2112s\n",
      "\titers: 300, epoch: 8 | loss: 0.0187612\n",
      "\tspeed: 0.1916s/iter; left time: 881.7032s\n",
      "Epoch: 8 cost time: 74.40973329544067\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.0189663 Vali Loss: 0.0187606 Test Loss: 0.0195218\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0184013\n",
      "\tspeed: 0.4303s/iter; left time: 1904.1128s\n",
      "\titers: 200, epoch: 9 | loss: 0.0185546\n",
      "\tspeed: 0.1888s/iter; left time: 816.4865s\n",
      "\titers: 300, epoch: 9 | loss: 0.0186824\n",
      "\tspeed: 0.1969s/iter; left time: 831.9619s\n",
      "Epoch: 9 cost time: 73.67214298248291\n",
      "Epoch: 9, Steps: 377 | Train Loss: 0.0188644 Vali Loss: 0.0184598 Test Loss: 0.0193572\n",
      "Validation loss decreased (0.018747 --> 0.018460).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0187831\n",
      "\tspeed: 0.4365s/iter; left time: 1766.9116s\n",
      "\titers: 200, epoch: 10 | loss: 0.0191653\n",
      "\tspeed: 0.1987s/iter; left time: 784.4429s\n",
      "\titers: 300, epoch: 10 | loss: 0.0197830\n",
      "\tspeed: 0.1986s/iter; left time: 764.2620s\n",
      "Epoch: 10 cost time: 74.67033529281616\n",
      "Epoch: 10, Steps: 377 | Train Loss: 0.0187990 Vali Loss: 0.0186375 Test Loss: 0.0194430\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0188576\n",
      "\tspeed: 0.4124s/iter; left time: 1514.0380s\n",
      "\titers: 200, epoch: 11 | loss: 0.0189524\n",
      "\tspeed: 0.1975s/iter; left time: 705.3741s\n",
      "\titers: 300, epoch: 11 | loss: 0.0193308\n",
      "\tspeed: 0.1893s/iter; left time: 657.1063s\n",
      "Epoch: 11 cost time: 71.94794225692749\n",
      "Epoch: 11, Steps: 377 | Train Loss: 0.0187976 Vali Loss: 0.0186843 Test Loss: 0.0196467\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0182049\n",
      "\tspeed: 0.4145s/iter; left time: 1365.4111s\n",
      "\titers: 200, epoch: 12 | loss: 0.0187084\n",
      "\tspeed: 0.2017s/iter; left time: 644.0963s\n",
      "\titers: 300, epoch: 12 | loss: 0.0185552\n",
      "\tspeed: 0.1902s/iter; left time: 588.4195s\n",
      "Epoch: 12 cost time: 73.48108744621277\n",
      "Epoch: 12, Steps: 377 | Train Loss: 0.0187476 Vali Loss: 0.0185930 Test Loss: 0.0193376\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.01935240440070629, mae:0.11012013256549835\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_ftS_sl168_ll48_pl24_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.0550207\n",
      "\tspeed: 0.0880s/iter; left time: 693.9108s\n",
      "\titers: 200, epoch: 1 | loss: 0.0360117\n",
      "\tspeed: 0.0870s/iter; left time: 677.2579s\n",
      "\titers: 300, epoch: 1 | loss: 0.0161163\n",
      "\tspeed: 0.0813s/iter; left time: 624.7652s\n",
      "Epoch: 1 cost time: 33.790857553482056\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.0633819 Vali Loss: 0.0264718 Test Loss: 0.1138027\n",
      "Validation loss decreased (inf --> 0.026472).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0084126\n",
      "\tspeed: 0.2081s/iter; left time: 1557.2599s\n",
      "\titers: 200, epoch: 2 | loss: 0.0063681\n",
      "\tspeed: 0.0851s/iter; left time: 628.0318s\n",
      "\titers: 300, epoch: 2 | loss: 0.0140544\n",
      "\tspeed: 0.0836s/iter; left time: 608.4145s\n",
      "Epoch: 2 cost time: 33.520615100860596\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0102615 Vali Loss: 0.0080881 Test Loss: 0.0531119\n",
      "Validation loss decreased (0.026472 --> 0.008088).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0045804\n",
      "\tspeed: 0.2022s/iter; left time: 1432.2631s\n",
      "\titers: 200, epoch: 3 | loss: 0.0042942\n",
      "\tspeed: 0.0853s/iter; left time: 595.6723s\n",
      "\titers: 300, epoch: 3 | loss: 0.0046195\n",
      "\tspeed: 0.0823s/iter; left time: 566.5204s\n",
      "Epoch: 3 cost time: 33.49415636062622\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0045044 Vali Loss: 0.0070992 Test Loss: 0.0502439\n",
      "Validation loss decreased (0.008088 --> 0.007099).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0037540\n",
      "\tspeed: 0.2085s/iter; left time: 1393.5863s\n",
      "\titers: 200, epoch: 4 | loss: 0.0045808\n",
      "\tspeed: 0.0856s/iter; left time: 563.3334s\n",
      "\titers: 300, epoch: 4 | loss: 0.0039802\n",
      "\tspeed: 0.0850s/iter; left time: 551.1121s\n",
      "Epoch: 4 cost time: 33.92714786529541\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0033850 Vali Loss: 0.0041263 Test Loss: 0.0369059\n",
      "Validation loss decreased (0.007099 --> 0.004126).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0036150\n",
      "\tspeed: 0.2037s/iter; left time: 1280.1252s\n",
      "\titers: 200, epoch: 5 | loss: 0.0034463\n",
      "\tspeed: 0.0825s/iter; left time: 510.4258s\n",
      "\titers: 300, epoch: 5 | loss: 0.0030676\n",
      "\tspeed: 0.0829s/iter; left time: 504.4993s\n",
      "Epoch: 5 cost time: 33.06817293167114\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0030239 Vali Loss: 0.0033567 Test Loss: 0.0278242\n",
      "Validation loss decreased (0.004126 --> 0.003357).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0027182\n",
      "\tspeed: 0.2057s/iter; left time: 1210.6459s\n",
      "\titers: 200, epoch: 6 | loss: 0.0025088\n",
      "\tspeed: 0.0780s/iter; left time: 451.3021s\n",
      "\titers: 300, epoch: 6 | loss: 0.0028859\n",
      "\tspeed: 0.0819s/iter; left time: 465.8575s\n",
      "Epoch: 6 cost time: 32.16096258163452\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0028637 Vali Loss: 0.0036557 Test Loss: 0.0320250\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0026493\n",
      "\tspeed: 0.1958s/iter; left time: 1074.4774s\n",
      "\titers: 200, epoch: 7 | loss: 0.0025094\n",
      "\tspeed: 0.0794s/iter; left time: 427.9020s\n",
      "\titers: 300, epoch: 7 | loss: 0.0027649\n",
      "\tspeed: 0.0790s/iter; left time: 417.9285s\n",
      "Epoch: 7 cost time: 31.711714506149292\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0027804 Vali Loss: 0.0039044 Test Loss: 0.0338162\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0031958\n",
      "\tspeed: 0.1993s/iter; left time: 1014.1433s\n",
      "\titers: 200, epoch: 8 | loss: 0.0027509\n",
      "\tspeed: 0.0823s/iter; left time: 410.3629s\n",
      "\titers: 300, epoch: 8 | loss: 0.0028020\n",
      "\tspeed: 0.0812s/iter; left time: 396.8995s\n",
      "Epoch: 8 cost time: 33.099282026290894\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0027255 Vali Loss: 0.0035476 Test Loss: 0.0317101\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.02839338406920433, mae:0.13146208226680756\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_ftS_sl168_ll48_pl48_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.0865280\n",
      "\tspeed: 0.0846s/iter; left time: 664.9221s\n",
      "\titers: 200, epoch: 1 | loss: 0.0431427\n",
      "\tspeed: 0.0851s/iter; left time: 660.5374s\n",
      "\titers: 300, epoch: 1 | loss: 0.0350169\n",
      "\tspeed: 0.0854s/iter; left time: 654.3287s\n",
      "Epoch: 1 cost time: 33.838871717453\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0640377 Vali Loss: 0.0303108 Test Loss: 0.1364252\n",
      "Validation loss decreased (inf --> 0.030311).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0149707\n",
      "\tspeed: 0.2077s/iter; left time: 1549.8751s\n",
      "\titers: 200, epoch: 2 | loss: 0.0063246\n",
      "\tspeed: 0.0839s/iter; left time: 617.9394s\n",
      "\titers: 300, epoch: 2 | loss: 0.0055784\n",
      "\tspeed: 0.0855s/iter; left time: 621.2995s\n",
      "Epoch: 2 cost time: 33.60913634300232\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0092792 Vali Loss: 0.0094790 Test Loss: 0.0628979\n",
      "Validation loss decreased (0.030311 --> 0.009479).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0040396\n",
      "\tspeed: 0.2110s/iter; left time: 1490.6353s\n",
      "\titers: 200, epoch: 3 | loss: 0.0041334\n",
      "\tspeed: 0.0837s/iter; left time: 583.1044s\n",
      "\titers: 300, epoch: 3 | loss: 0.0049368\n",
      "\tspeed: 0.0818s/iter; left time: 561.4978s\n",
      "Epoch: 3 cost time: 33.119974851608276\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0043887 Vali Loss: 0.0073873 Test Loss: 0.0428569\n",
      "Validation loss decreased (0.009479 --> 0.007387).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0032036\n",
      "\tspeed: 0.1992s/iter; left time: 1327.7805s\n",
      "\titers: 200, epoch: 4 | loss: 0.0027943\n",
      "\tspeed: 0.0840s/iter; left time: 551.7770s\n",
      "\titers: 300, epoch: 4 | loss: 0.0030611\n",
      "\tspeed: 0.0876s/iter; left time: 566.2094s\n",
      "Epoch: 4 cost time: 33.93858027458191\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0034557 Vali Loss: 0.0051424 Test Loss: 0.0347031\n",
      "Validation loss decreased (0.007387 --> 0.005142).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0031031\n",
      "\tspeed: 0.2134s/iter; left time: 1337.6295s\n",
      "\titers: 200, epoch: 5 | loss: 0.0026754\n",
      "\tspeed: 0.0872s/iter; left time: 537.8891s\n",
      "\titers: 300, epoch: 5 | loss: 0.0025833\n",
      "\tspeed: 0.0830s/iter; left time: 503.7883s\n",
      "Epoch: 5 cost time: 34.087873220443726\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0029783 Vali Loss: 0.0046932 Test Loss: 0.0311860\n",
      "Validation loss decreased (0.005142 --> 0.004693).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0027499\n",
      "\tspeed: 0.2098s/iter; left time: 1231.5877s\n",
      "\titers: 200, epoch: 6 | loss: 0.0025998\n",
      "\tspeed: 0.0819s/iter; left time: 472.6716s\n",
      "\titers: 300, epoch: 6 | loss: 0.0028027\n",
      "\tspeed: 0.0820s/iter; left time: 465.3012s\n",
      "Epoch: 6 cost time: 32.7248260974884\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0028236 Vali Loss: 0.0033392 Test Loss: 0.0248738\n",
      "Validation loss decreased (0.004693 --> 0.003339).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0027839\n",
      "\tspeed: 0.2011s/iter; left time: 1100.6775s\n",
      "\titers: 200, epoch: 7 | loss: 0.0025709\n",
      "\tspeed: 0.0835s/iter; left time: 448.7955s\n",
      "\titers: 300, epoch: 7 | loss: 0.0028814\n",
      "\tspeed: 0.0836s/iter; left time: 440.6141s\n",
      "Epoch: 7 cost time: 33.17650032043457\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0026913 Vali Loss: 0.0035072 Test Loss: 0.0244771\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0030540\n",
      "\tspeed: 0.2035s/iter; left time: 1032.8326s\n",
      "\titers: 200, epoch: 8 | loss: 0.0025497\n",
      "\tspeed: 0.0833s/iter; left time: 414.6093s\n",
      "\titers: 300, epoch: 8 | loss: 0.0029143\n",
      "\tspeed: 0.0843s/iter; left time: 411.0726s\n",
      "Epoch: 8 cost time: 33.930859088897705\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0026424 Vali Loss: 0.0032892 Test Loss: 0.0246262\n",
      "Validation loss decreased (0.003339 --> 0.003289).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0024231\n",
      "\tspeed: 0.2176s/iter; left time: 1017.9469s\n",
      "\titers: 200, epoch: 9 | loss: 0.0025987\n",
      "\tspeed: 0.0841s/iter; left time: 384.9246s\n",
      "\titers: 300, epoch: 9 | loss: 0.0027222\n",
      "\tspeed: 0.0865s/iter; left time: 387.2060s\n",
      "Epoch: 9 cost time: 34.43897294998169\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0026187 Vali Loss: 0.0037508 Test Loss: 0.0267507\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0026798\n",
      "\tspeed: 0.2161s/iter; left time: 924.7641s\n",
      "\titers: 200, epoch: 10 | loss: 0.0025758\n",
      "\tspeed: 0.0913s/iter; left time: 381.5162s\n",
      "\titers: 300, epoch: 10 | loss: 0.0024115\n",
      "\tspeed: 0.0873s/iter; left time: 355.9294s\n",
      "Epoch: 10 cost time: 34.88785409927368\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.0025989 Vali Loss: 0.0034613 Test Loss: 0.0242441\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0026075\n",
      "\tspeed: 0.2067s/iter; left time: 802.2091s\n",
      "\titers: 200, epoch: 11 | loss: 0.0031846\n",
      "\tspeed: 0.0867s/iter; left time: 327.7305s\n",
      "\titers: 300, epoch: 11 | loss: 0.0025695\n",
      "\tspeed: 0.0860s/iter; left time: 316.3962s\n",
      "Epoch: 11 cost time: 34.285465240478516\n",
      "Epoch: 11, Steps: 398 | Train Loss: 0.0025979 Vali Loss: 0.0034565 Test Loss: 0.0245024\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.024316217750310898, mae:0.12166380882263184\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_ftS_sl168_ll48_pl168_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.0653856\n",
      "\tspeed: 0.1083s/iter; left time: 842.4957s\n",
      "\titers: 200, epoch: 1 | loss: 0.0559801\n",
      "\tspeed: 0.1079s/iter; left time: 828.9706s\n",
      "\titers: 300, epoch: 1 | loss: 0.0429578\n",
      "\tspeed: 0.1097s/iter; left time: 832.0048s\n",
      "Epoch: 1 cost time: 42.75586938858032\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.0726650 Vali Loss: 0.0487791 Test Loss: 0.1705907\n",
      "Validation loss decreased (inf --> 0.048779).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0162021\n",
      "\tspeed: 0.2687s/iter; left time: 1984.6648s\n",
      "\titers: 200, epoch: 2 | loss: 0.0103688\n",
      "\tspeed: 0.1180s/iter; left time: 859.9149s\n",
      "\titers: 300, epoch: 2 | loss: 0.0085225\n",
      "\tspeed: 0.1132s/iter; left time: 813.3129s\n",
      "Epoch: 2 cost time: 44.915024757385254\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0173681 Vali Loss: 0.0175036 Test Loss: 0.1220923\n",
      "Validation loss decreased (0.048779 --> 0.017504).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0065756\n",
      "\tspeed: 0.2745s/iter; left time: 1919.4828s\n",
      "\titers: 200, epoch: 3 | loss: 0.0072196\n",
      "\tspeed: 0.1138s/iter; left time: 784.0893s\n",
      "\titers: 300, epoch: 3 | loss: 0.0051852\n",
      "\tspeed: 0.1108s/iter; left time: 752.8486s\n",
      "Epoch: 3 cost time: 44.03745985031128\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0063741 Vali Loss: 0.0246749 Test Loss: 0.1331271\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0046492\n",
      "\tspeed: 0.2787s/iter; left time: 1839.2288s\n",
      "\titers: 200, epoch: 4 | loss: 0.0050624\n",
      "\tspeed: 0.1175s/iter; left time: 763.7765s\n",
      "\titers: 300, epoch: 4 | loss: 0.0042835\n",
      "\tspeed: 0.1141s/iter; left time: 729.9833s\n",
      "Epoch: 4 cost time: 45.43990349769592\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0047465 Vali Loss: 0.0126075 Test Loss: 0.0807101\n",
      "Validation loss decreased (0.017504 --> 0.012608).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0035142\n",
      "\tspeed: 0.2863s/iter; left time: 1776.8011s\n",
      "\titers: 200, epoch: 5 | loss: 0.0036649\n",
      "\tspeed: 0.1061s/iter; left time: 647.4387s\n",
      "\titers: 300, epoch: 5 | loss: 0.0045762\n",
      "\tspeed: 0.1112s/iter; left time: 667.4897s\n",
      "Epoch: 5 cost time: 43.25263595581055\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0041533 Vali Loss: 0.0071966 Test Loss: 0.0561201\n",
      "Validation loss decreased (0.012608 --> 0.007197).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0038413\n",
      "\tspeed: 0.2828s/iter; left time: 1643.3308s\n",
      "\titers: 200, epoch: 6 | loss: 0.0042220\n",
      "\tspeed: 0.1127s/iter; left time: 643.7136s\n",
      "\titers: 300, epoch: 6 | loss: 0.0047968\n",
      "\tspeed: 0.1098s/iter; left time: 616.0416s\n",
      "Epoch: 6 cost time: 44.641361474990845\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0038971 Vali Loss: 0.0062112 Test Loss: 0.0520818\n",
      "Validation loss decreased (0.007197 --> 0.006211).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0036976\n",
      "\tspeed: 0.2828s/iter; left time: 1531.7764s\n",
      "\titers: 200, epoch: 7 | loss: 0.0034259\n",
      "\tspeed: 0.1181s/iter; left time: 627.9544s\n",
      "\titers: 300, epoch: 7 | loss: 0.0052402\n",
      "\tspeed: 0.1153s/iter; left time: 601.6811s\n",
      "Epoch: 7 cost time: 44.860111951828\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0037518 Vali Loss: 0.0080066 Test Loss: 0.0611937\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0033600\n",
      "\tspeed: 0.2648s/iter; left time: 1329.8686s\n",
      "\titers: 200, epoch: 8 | loss: 0.0035146\n",
      "\tspeed: 0.1086s/iter; left time: 534.7878s\n",
      "\titers: 300, epoch: 8 | loss: 0.0033649\n",
      "\tspeed: 0.1108s/iter; left time: 534.3296s\n",
      "Epoch: 8 cost time: 43.6448540687561\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0036694 Vali Loss: 0.0067403 Test Loss: 0.0544449\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0032827\n",
      "\tspeed: 0.2808s/iter; left time: 1299.8926s\n",
      "\titers: 200, epoch: 9 | loss: 0.0038098\n",
      "\tspeed: 0.1162s/iter; left time: 526.2504s\n",
      "\titers: 300, epoch: 9 | loss: 0.0035086\n",
      "\tspeed: 0.1182s/iter; left time: 523.4324s\n",
      "Epoch: 9 cost time: 45.99188542366028\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0035967 Vali Loss: 0.0072534 Test Loss: 0.0571025\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.05181847885251045, mae:0.19465994834899902\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_ftS_sl168_ll48_pl336_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.0866028\n",
      "\tspeed: 0.1410s/iter; left time: 1083.3623s\n",
      "\titers: 200, epoch: 1 | loss: 0.0562561\n",
      "\tspeed: 0.1308s/iter; left time: 991.4962s\n",
      "\titers: 300, epoch: 1 | loss: 0.0601606\n",
      "\tspeed: 0.1335s/iter; left time: 999.0482s\n",
      "Epoch: 1 cost time: 52.754626512527466\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.0786390 Vali Loss: 0.0565225 Test Loss: 0.2567067\n",
      "Validation loss decreased (inf --> 0.056523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0380041\n",
      "\tspeed: 0.3366s/iter; left time: 2454.2885s\n",
      "\titers: 200, epoch: 2 | loss: 0.0280114\n",
      "\tspeed: 0.1451s/iter; left time: 1043.7725s\n",
      "\titers: 300, epoch: 2 | loss: 0.0189467\n",
      "\tspeed: 0.1447s/iter; left time: 1026.2775s\n",
      "Epoch: 2 cost time: 56.69324827194214\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0286903 Vali Loss: 0.0490113 Test Loss: 0.2342414\n",
      "Validation loss decreased (0.056523 --> 0.049011).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0105152\n",
      "\tspeed: 0.3490s/iter; left time: 2409.0864s\n",
      "\titers: 200, epoch: 3 | loss: 0.0064494\n",
      "\tspeed: 0.1330s/iter; left time: 904.5783s\n",
      "\titers: 300, epoch: 3 | loss: 0.0105272\n",
      "\tspeed: 0.1424s/iter; left time: 954.3676s\n",
      "Epoch: 3 cost time: 54.68060827255249\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0075008 Vali Loss: 0.0104685 Test Loss: 0.0852192\n",
      "Validation loss decreased (0.049011 --> 0.010469).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0085451\n",
      "\tspeed: 0.3398s/iter; left time: 2213.2418s\n",
      "\titers: 200, epoch: 4 | loss: 0.0070969\n",
      "\tspeed: 0.1279s/iter; left time: 820.1639s\n",
      "\titers: 300, epoch: 4 | loss: 0.0041199\n",
      "\tspeed: 0.1272s/iter; left time: 803.1206s\n",
      "Epoch: 4 cost time: 52.0012788772583\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0054520 Vali Loss: 0.0081574 Test Loss: 0.0571172\n",
      "Validation loss decreased (0.010469 --> 0.008157).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0047282\n",
      "\tspeed: 0.3280s/iter; left time: 2008.7748s\n",
      "\titers: 200, epoch: 5 | loss: 0.0043045\n",
      "\tspeed: 0.1377s/iter; left time: 829.9130s\n",
      "\titers: 300, epoch: 5 | loss: 0.0037848\n",
      "\tspeed: 0.1413s/iter; left time: 837.2328s\n",
      "Epoch: 5 cost time: 53.668482065200806\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0046646 Vali Loss: 0.0102622 Test Loss: 0.0715717\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0038860\n",
      "\tspeed: 0.3254s/iter; left time: 1866.5558s\n",
      "\titers: 200, epoch: 6 | loss: 0.0050161\n",
      "\tspeed: 0.1368s/iter; left time: 770.8844s\n",
      "\titers: 300, epoch: 6 | loss: 0.0039520\n",
      "\tspeed: 0.1429s/iter; left time: 790.8209s\n",
      "Epoch: 6 cost time: 54.73139524459839\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0043319 Vali Loss: 0.0087985 Test Loss: 0.0641497\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0035366\n",
      "\tspeed: 0.3480s/iter; left time: 1861.0080s\n",
      "\titers: 200, epoch: 7 | loss: 0.0042481\n",
      "\tspeed: 0.1351s/iter; left time: 708.8403s\n",
      "\titers: 300, epoch: 7 | loss: 0.0062771\n",
      "\tspeed: 0.1417s/iter; left time: 729.5084s\n",
      "Epoch: 7 cost time: 55.31308698654175\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.0041733 Vali Loss: 0.0093884 Test Loss: 0.0684892\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.05716238170862198, mae:0.1932796835899353\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_ftS_sl168_ll48_pl720_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.0743357\n",
      "\tspeed: 0.1874s/iter; left time: 1394.7055s\n",
      "\titers: 200, epoch: 1 | loss: 0.0559032\n",
      "\tspeed: 0.1948s/iter; left time: 1429.9654s\n",
      "\titers: 300, epoch: 1 | loss: 0.0582833\n",
      "\tspeed: 0.2021s/iter; left time: 1463.4298s\n",
      "Epoch: 1 cost time: 73.16293668746948\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.0801290 Vali Loss: 0.0674477 Test Loss: 0.2670905\n",
      "Validation loss decreased (inf --> 0.067448).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0398229\n",
      "\tspeed: 0.4324s/iter; left time: 3054.5984s\n",
      "\titers: 200, epoch: 2 | loss: 0.0410497\n",
      "\tspeed: 0.1969s/iter; left time: 1371.3592s\n",
      "\titers: 300, epoch: 2 | loss: 0.0366259\n",
      "\tspeed: 0.1963s/iter; left time: 1347.1978s\n",
      "Epoch: 2 cost time: 75.48045563697815\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0399974 Vali Loss: 0.0476819 Test Loss: 0.1728790\n",
      "Validation loss decreased (0.067448 --> 0.047682).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0352848\n",
      "\tspeed: 0.4445s/iter; left time: 2972.3358s\n",
      "\titers: 200, epoch: 3 | loss: 0.0340951\n",
      "\tspeed: 0.2048s/iter; left time: 1349.3433s\n",
      "\titers: 300, epoch: 3 | loss: 0.0326748\n",
      "\tspeed: 0.1909s/iter; left time: 1238.4398s\n",
      "Epoch: 3 cost time: 74.8788149356842\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0338755 Vali Loss: 0.0382499 Test Loss: 0.1313635\n",
      "Validation loss decreased (0.047682 --> 0.038250).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0166529\n",
      "\tspeed: 0.4223s/iter; left time: 2664.4228s\n",
      "\titers: 200, epoch: 4 | loss: 0.0142299\n",
      "\tspeed: 0.1956s/iter; left time: 1214.7220s\n",
      "\titers: 300, epoch: 4 | loss: 0.0110919\n",
      "\tspeed: 0.1900s/iter; left time: 1161.1804s\n",
      "Epoch: 4 cost time: 72.97242021560669\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0151198 Vali Loss: 0.0157230 Test Loss: 0.1019332\n",
      "Validation loss decreased (0.038250 --> 0.015723).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0062651\n",
      "\tspeed: 0.4261s/iter; left time: 2527.8856s\n",
      "\titers: 200, epoch: 5 | loss: 0.0064634\n",
      "\tspeed: 0.1943s/iter; left time: 1133.6053s\n",
      "\titers: 300, epoch: 5 | loss: 0.0057283\n",
      "\tspeed: 0.1946s/iter; left time: 1115.4616s\n",
      "Epoch: 5 cost time: 73.73055005073547\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0068766 Vali Loss: 0.0144736 Test Loss: 0.0941703\n",
      "Validation loss decreased (0.015723 --> 0.014474).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0061283\n",
      "\tspeed: 0.4255s/iter; left time: 2363.9454s\n",
      "\titers: 200, epoch: 6 | loss: 0.0069415\n",
      "\tspeed: 0.1930s/iter; left time: 1052.9130s\n",
      "\titers: 300, epoch: 6 | loss: 0.0051560\n",
      "\tspeed: 0.2011s/iter; left time: 1076.9158s\n",
      "Epoch: 6 cost time: 73.66760015487671\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0057966 Vali Loss: 0.0165337 Test Loss: 0.1066175\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0050776\n",
      "\tspeed: 0.4267s/iter; left time: 2209.7324s\n",
      "\titers: 200, epoch: 7 | loss: 0.0055688\n",
      "\tspeed: 0.1920s/iter; left time: 974.9578s\n",
      "\titers: 300, epoch: 7 | loss: 0.0045753\n",
      "\tspeed: 0.1939s/iter; left time: 965.5375s\n",
      "Epoch: 7 cost time: 73.33861327171326\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0053581 Vali Loss: 0.0109658 Test Loss: 0.0791100\n",
      "Validation loss decreased (0.014474 --> 0.010966).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0064224\n",
      "\tspeed: 0.4262s/iter; left time: 2046.5766s\n",
      "\titers: 200, epoch: 8 | loss: 0.0045962\n",
      "\tspeed: 0.1977s/iter; left time: 929.7856s\n",
      "\titers: 300, epoch: 8 | loss: 0.0056463\n",
      "\tspeed: 0.1900s/iter; left time: 874.5484s\n",
      "Epoch: 8 cost time: 73.31381320953369\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.0052137 Vali Loss: 0.0121510 Test Loss: 0.0853563\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0046093\n",
      "\tspeed: 0.4261s/iter; left time: 1885.3226s\n",
      "\titers: 200, epoch: 9 | loss: 0.0045042\n",
      "\tspeed: 0.1915s/iter; left time: 828.0449s\n",
      "\titers: 300, epoch: 9 | loss: 0.0051506\n",
      "\tspeed: 0.1898s/iter; left time: 801.8978s\n",
      "Epoch: 9 cost time: 72.6057858467102\n",
      "Epoch: 9, Steps: 377 | Train Loss: 0.0050967 Vali Loss: 0.0113569 Test Loss: 0.0812301\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0047275\n",
      "\tspeed: 0.4232s/iter; left time: 1713.0139s\n",
      "\titers: 200, epoch: 10 | loss: 0.0044184\n",
      "\tspeed: 0.2048s/iter; left time: 808.3593s\n",
      "\titers: 300, epoch: 10 | loss: 0.0051744\n",
      "\tspeed: 0.1997s/iter; left time: 768.4048s\n",
      "Epoch: 10 cost time: 75.74115061759949\n",
      "Epoch: 10, Steps: 377 | Train Loss: 0.0051130 Vali Loss: 0.0105561 Test Loss: 0.0788823\n",
      "Validation loss decreased (0.010966 --> 0.010556).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0044590\n",
      "\tspeed: 0.4269s/iter; left time: 1567.1543s\n",
      "\titers: 200, epoch: 11 | loss: 0.0045736\n",
      "\tspeed: 0.1974s/iter; left time: 705.0528s\n",
      "\titers: 300, epoch: 11 | loss: 0.0047521\n",
      "\tspeed: 0.1875s/iter; left time: 650.8242s\n",
      "Epoch: 11 cost time: 72.08674383163452\n",
      "Epoch: 11, Steps: 377 | Train Loss: 0.0050360 Vali Loss: 0.0100114 Test Loss: 0.0748573\n",
      "Validation loss decreased (0.010556 --> 0.010011).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0048835\n",
      "\tspeed: 0.4055s/iter; left time: 1335.7647s\n",
      "\titers: 200, epoch: 12 | loss: 0.0051109\n",
      "\tspeed: 0.1957s/iter; left time: 625.0564s\n",
      "\titers: 300, epoch: 12 | loss: 0.0060639\n",
      "\tspeed: 0.1993s/iter; left time: 616.4836s\n",
      "Epoch: 12 cost time: 73.84615564346313\n",
      "Epoch: 12, Steps: 377 | Train Loss: 0.0050827 Vali Loss: 0.0101443 Test Loss: 0.0773656\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0043908\n",
      "\tspeed: 0.4348s/iter; left time: 1268.2885s\n",
      "\titers: 200, epoch: 13 | loss: 0.0049548\n",
      "\tspeed: 0.1889s/iter; left time: 532.2249s\n",
      "\titers: 300, epoch: 13 | loss: 0.0053179\n",
      "\tspeed: 0.2093s/iter; left time: 568.5814s\n",
      "Epoch: 13 cost time: 75.11869645118713\n",
      "Epoch: 13, Steps: 377 | Train Loss: 0.0050361 Vali Loss: 0.0096975 Test Loss: 0.0746436\n",
      "Validation loss decreased (0.010011 --> 0.009697).  Saving model ...\n",
      "Updating learning rate to 2.44140625e-08\n",
      "\titers: 100, epoch: 14 | loss: 0.0046353\n",
      "\tspeed: 0.4311s/iter; left time: 1094.9520s\n",
      "\titers: 200, epoch: 14 | loss: 0.0048272\n",
      "\tspeed: 0.1922s/iter; left time: 468.9881s\n",
      "\titers: 300, epoch: 14 | loss: 0.0044034\n",
      "\tspeed: 0.1943s/iter; left time: 454.5597s\n",
      "Epoch: 14 cost time: 72.93745231628418\n",
      "Epoch: 14, Steps: 377 | Train Loss: 0.0049942 Vali Loss: 0.0104252 Test Loss: 0.0785816\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "\titers: 100, epoch: 15 | loss: 0.0048096\n",
      "\tspeed: 0.4174s/iter; left time: 902.8157s\n",
      "\titers: 200, epoch: 15 | loss: 0.0046020\n",
      "\tspeed: 0.1956s/iter; left time: 403.5885s\n",
      "\titers: 300, epoch: 15 | loss: 0.0049024\n",
      "\tspeed: 0.2045s/iter; left time: 401.4214s\n",
      "Epoch: 15 cost time: 73.73339033126831\n",
      "Epoch: 15, Steps: 377 | Train Loss: 0.0049673 Vali Loss: 0.0105294 Test Loss: 0.0775816\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.103515625e-09\n",
      "\titers: 100, epoch: 16 | loss: 0.0053691\n",
      "\tspeed: 0.4281s/iter; left time: 764.6339s\n",
      "\titers: 200, epoch: 16 | loss: 0.0047166\n",
      "\tspeed: 0.1970s/iter; left time: 332.2118s\n",
      "\titers: 300, epoch: 16 | loss: 0.0048443\n",
      "\tspeed: 0.1874s/iter; left time: 297.2590s\n",
      "Epoch: 16 cost time: 74.14920330047607\n",
      "Epoch: 16, Steps: 377 | Train Loss: 0.0050165 Vali Loss: 0.0107249 Test Loss: 0.0789507\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.0748269259929657, mae:0.23177570104599\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_reversal_ftS_sl168_ll48_pl24_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.0730351\n",
      "\tspeed: 0.0843s/iter; left time: 664.1941s\n",
      "\titers: 200, epoch: 1 | loss: 0.0442499\n",
      "\tspeed: 0.0825s/iter; left time: 641.5452s\n",
      "\titers: 300, epoch: 1 | loss: 0.0223497\n",
      "\tspeed: 0.0797s/iter; left time: 611.9611s\n",
      "Epoch: 1 cost time: 32.82591509819031\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.0954116 Vali Loss: 0.0569209 Test Loss: 0.0703572\n",
      "Validation loss decreased (inf --> 0.056921).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0158934\n",
      "\tspeed: 0.2069s/iter; left time: 1548.3944s\n",
      "\titers: 200, epoch: 2 | loss: 0.0153504\n",
      "\tspeed: 0.0855s/iter; left time: 631.1154s\n",
      "\titers: 300, epoch: 2 | loss: 0.0066194\n",
      "\tspeed: 0.0850s/iter; left time: 618.9805s\n",
      "Epoch: 2 cost time: 33.99209713935852\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0119569 Vali Loss: 0.0606335 Test Loss: 0.0975946\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0085357\n",
      "\tspeed: 0.2067s/iter; left time: 1463.8864s\n",
      "\titers: 200, epoch: 3 | loss: 0.0060841\n",
      "\tspeed: 0.0861s/iter; left time: 601.2865s\n",
      "\titers: 300, epoch: 3 | loss: 0.0052784\n",
      "\tspeed: 0.0854s/iter; left time: 588.1455s\n",
      "Epoch: 3 cost time: 34.11212110519409\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0071621 Vali Loss: 0.0380631 Test Loss: 0.0695357\n",
      "Validation loss decreased (0.056921 --> 0.038063).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0055477\n",
      "\tspeed: 0.2092s/iter; left time: 1398.1859s\n",
      "\titers: 200, epoch: 4 | loss: 0.0051459\n",
      "\tspeed: 0.0839s/iter; left time: 552.6960s\n",
      "\titers: 300, epoch: 4 | loss: 0.0048092\n",
      "\tspeed: 0.0814s/iter; left time: 528.0439s\n",
      "Epoch: 4 cost time: 32.705262184143066\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0056112 Vali Loss: 0.0424590 Test Loss: 0.0769266\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0050489\n",
      "\tspeed: 0.1913s/iter; left time: 1202.1323s\n",
      "\titers: 200, epoch: 5 | loss: 0.0054749\n",
      "\tspeed: 0.0810s/iter; left time: 501.0948s\n",
      "\titers: 300, epoch: 5 | loss: 0.0053340\n",
      "\tspeed: 0.0819s/iter; left time: 498.1361s\n",
      "Epoch: 5 cost time: 32.1018385887146\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0050028 Vali Loss: 0.0274143 Test Loss: 0.0560401\n",
      "Validation loss decreased (0.038063 --> 0.027414).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0050231\n",
      "\tspeed: 0.1948s/iter; left time: 1146.4636s\n",
      "\titers: 200, epoch: 6 | loss: 0.0046180\n",
      "\tspeed: 0.0801s/iter; left time: 463.6214s\n",
      "\titers: 300, epoch: 6 | loss: 0.0041730\n",
      "\tspeed: 0.0758s/iter; left time: 431.1549s\n",
      "Epoch: 6 cost time: 30.904783964157104\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0047818 Vali Loss: 0.0366128 Test Loss: 0.0713704\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0049478\n",
      "\tspeed: 0.1865s/iter; left time: 1023.5182s\n",
      "\titers: 200, epoch: 7 | loss: 0.0044093\n",
      "\tspeed: 0.0796s/iter; left time: 428.6380s\n",
      "\titers: 300, epoch: 7 | loss: 0.0047492\n",
      "\tspeed: 0.0808s/iter; left time: 426.9955s\n",
      "Epoch: 7 cost time: 32.200764656066895\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0045816 Vali Loss: 0.0328377 Test Loss: 0.0643133\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0048626\n",
      "\tspeed: 0.2010s/iter; left time: 1022.5156s\n",
      "\titers: 200, epoch: 8 | loss: 0.0047647\n",
      "\tspeed: 0.0800s/iter; left time: 399.2796s\n",
      "\titers: 300, epoch: 8 | loss: 0.0043428\n",
      "\tspeed: 0.0857s/iter; left time: 418.9354s\n",
      "Epoch: 8 cost time: 32.775991916656494\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0044761 Vali Loss: 0.0309074 Test Loss: 0.0621756\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.056332312524318695, mae:0.18070156872272491\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_reversal_ftS_sl168_ll48_pl48_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.1437348\n",
      "\tspeed: 0.0826s/iter; left time: 649.2763s\n",
      "\titers: 200, epoch: 1 | loss: 0.0528804\n",
      "\tspeed: 0.0819s/iter; left time: 635.6559s\n",
      "\titers: 300, epoch: 1 | loss: 0.0189766\n",
      "\tspeed: 0.0821s/iter; left time: 628.6252s\n",
      "Epoch: 1 cost time: 33.14710712432861\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0975805 Vali Loss: 0.0743603 Test Loss: 0.0989831\n",
      "Validation loss decreased (inf --> 0.074360).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0157482\n",
      "\tspeed: 0.2152s/iter; left time: 1606.1937s\n",
      "\titers: 200, epoch: 2 | loss: 0.0122125\n",
      "\tspeed: 0.0923s/iter; left time: 679.5893s\n",
      "\titers: 300, epoch: 2 | loss: 0.0125404\n",
      "\tspeed: 0.0872s/iter; left time: 633.1298s\n",
      "Epoch: 2 cost time: 34.8822820186615\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0154004 Vali Loss: 0.0528326 Test Loss: 0.0830802\n",
      "Validation loss decreased (0.074360 --> 0.052833).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0071767\n",
      "\tspeed: 0.2027s/iter; left time: 1432.1440s\n",
      "\titers: 200, epoch: 3 | loss: 0.0073311\n",
      "\tspeed: 0.0823s/iter; left time: 573.3766s\n",
      "\titers: 300, epoch: 3 | loss: 0.0076659\n",
      "\tspeed: 0.0850s/iter; left time: 583.1958s\n",
      "Epoch: 3 cost time: 33.83421492576599\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0085654 Vali Loss: 0.0438602 Test Loss: 0.0680934\n",
      "Validation loss decreased (0.052833 --> 0.043860).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0060738\n",
      "\tspeed: 0.2203s/iter; left time: 1468.7613s\n",
      "\titers: 200, epoch: 4 | loss: 0.0069190\n",
      "\tspeed: 0.0835s/iter; left time: 548.0984s\n",
      "\titers: 300, epoch: 4 | loss: 0.0055724\n",
      "\tspeed: 0.0854s/iter; left time: 552.4928s\n",
      "Epoch: 4 cost time: 34.13128638267517\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0066024 Vali Loss: 0.0348486 Test Loss: 0.0620568\n",
      "Validation loss decreased (0.043860 --> 0.034849).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0069007\n",
      "\tspeed: 0.2107s/iter; left time: 1320.6870s\n",
      "\titers: 200, epoch: 5 | loss: 0.0058358\n",
      "\tspeed: 0.0876s/iter; left time: 540.2563s\n",
      "\titers: 300, epoch: 5 | loss: 0.0066208\n",
      "\tspeed: 0.0831s/iter; left time: 504.5845s\n",
      "Epoch: 5 cost time: 33.784032583236694\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0059944 Vali Loss: 0.0414196 Test Loss: 0.0739442\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0048740\n",
      "\tspeed: 0.2040s/iter; left time: 1197.8522s\n",
      "\titers: 200, epoch: 6 | loss: 0.0063183\n",
      "\tspeed: 0.0858s/iter; left time: 494.8748s\n",
      "\titers: 300, epoch: 6 | loss: 0.0050596\n",
      "\tspeed: 0.0855s/iter; left time: 484.7036s\n",
      "Epoch: 6 cost time: 34.123271226882935\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0055726 Vali Loss: 0.0289271 Test Loss: 0.0543548\n",
      "Validation loss decreased (0.034849 --> 0.028927).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0058270\n",
      "\tspeed: 0.2126s/iter; left time: 1163.7983s\n",
      "\titers: 200, epoch: 7 | loss: 0.0065274\n",
      "\tspeed: 0.0825s/iter; left time: 443.0577s\n",
      "\titers: 300, epoch: 7 | loss: 0.0058854\n",
      "\tspeed: 0.0844s/iter; left time: 445.1057s\n",
      "Epoch: 7 cost time: 33.65916657447815\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0053763 Vali Loss: 0.0315965 Test Loss: 0.0603249\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0053142\n",
      "\tspeed: 0.2037s/iter; left time: 1033.9234s\n",
      "\titers: 200, epoch: 8 | loss: 0.0060169\n",
      "\tspeed: 0.0850s/iter; left time: 423.0812s\n",
      "\titers: 300, epoch: 8 | loss: 0.0053482\n",
      "\tspeed: 0.0909s/iter; left time: 442.9837s\n",
      "Epoch: 8 cost time: 34.6083562374115\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0052395 Vali Loss: 0.0339913 Test Loss: 0.0643842\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0051714\n",
      "\tspeed: 0.2111s/iter; left time: 987.1748s\n",
      "\titers: 200, epoch: 9 | loss: 0.0055163\n",
      "\tspeed: 0.0854s/iter; left time: 391.0459s\n",
      "\titers: 300, epoch: 9 | loss: 0.0051206\n",
      "\tspeed: 0.0848s/iter; left time: 379.6486s\n",
      "Epoch: 9 cost time: 33.93978810310364\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0051965 Vali Loss: 0.0303401 Test Loss: 0.0577758\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.05414028838276863, mae:0.16947467625141144\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_reversal_ftS_sl168_ll48_pl168_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.1437270\n",
      "\tspeed: 0.1122s/iter; left time: 873.1445s\n",
      "\titers: 200, epoch: 1 | loss: 0.1071458\n",
      "\tspeed: 0.1146s/iter; left time: 879.8756s\n",
      "\titers: 300, epoch: 1 | loss: 0.0814889\n",
      "\tspeed: 0.1108s/iter; left time: 839.9454s\n",
      "Epoch: 1 cost time: 44.30554127693176\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.1284128 Vali Loss: 0.2017586 Test Loss: 0.1806417\n",
      "Validation loss decreased (inf --> 0.201759).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0417535\n",
      "\tspeed: 0.2703s/iter; left time: 1997.0616s\n",
      "\titers: 200, epoch: 2 | loss: 0.0240193\n",
      "\tspeed: 0.1073s/iter; left time: 781.6749s\n",
      "\titers: 300, epoch: 2 | loss: 0.0247321\n",
      "\tspeed: 0.1091s/iter; left time: 784.0443s\n",
      "Epoch: 2 cost time: 43.083322286605835\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0298033 Vali Loss: 0.0750665 Test Loss: 0.0795347\n",
      "Validation loss decreased (0.201759 --> 0.075066).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0108982\n",
      "\tspeed: 0.2762s/iter; left time: 1931.5015s\n",
      "\titers: 200, epoch: 3 | loss: 0.0129761\n",
      "\tspeed: 0.1082s/iter; left time: 745.8678s\n",
      "\titers: 300, epoch: 3 | loss: 0.0161012\n",
      "\tspeed: 0.1090s/iter; left time: 740.2522s\n",
      "Epoch: 3 cost time: 43.468097448349\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0179872 Vali Loss: 0.0636828 Test Loss: 0.0875457\n",
      "Validation loss decreased (0.075066 --> 0.063683).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0132028\n",
      "\tspeed: 0.2884s/iter; left time: 1903.2278s\n",
      "\titers: 200, epoch: 4 | loss: 0.0099298\n",
      "\tspeed: 0.1178s/iter; left time: 765.3274s\n",
      "\titers: 300, epoch: 4 | loss: 0.0137654\n",
      "\tspeed: 0.1102s/iter; left time: 704.8534s\n",
      "Epoch: 4 cost time: 45.14921498298645\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0142194 Vali Loss: 0.0445122 Test Loss: 0.0693262\n",
      "Validation loss decreased (0.063683 --> 0.044512).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0113218\n",
      "\tspeed: 0.2865s/iter; left time: 1777.6018s\n",
      "\titers: 200, epoch: 5 | loss: 0.0120669\n",
      "\tspeed: 0.1201s/iter; left time: 732.9391s\n",
      "\titers: 300, epoch: 5 | loss: 0.0167396\n",
      "\tspeed: 0.1089s/iter; left time: 654.0356s\n",
      "Epoch: 5 cost time: 46.08922863006592\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0124993 Vali Loss: 0.0480901 Test Loss: 0.0638960\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0092742\n",
      "\tspeed: 0.2901s/iter; left time: 1685.7023s\n",
      "\titers: 200, epoch: 6 | loss: 0.0084513\n",
      "\tspeed: 0.1208s/iter; left time: 689.7953s\n",
      "\titers: 300, epoch: 6 | loss: 0.0124790\n",
      "\tspeed: 0.1172s/iter; left time: 657.3694s\n",
      "Epoch: 6 cost time: 46.41875386238098\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0116153 Vali Loss: 0.0476726 Test Loss: 0.0683008\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0130673\n",
      "\tspeed: 0.2822s/iter; left time: 1528.8199s\n",
      "\titers: 200, epoch: 7 | loss: 0.0146671\n",
      "\tspeed: 0.1139s/iter; left time: 605.5616s\n",
      "\titers: 300, epoch: 7 | loss: 0.0114399\n",
      "\tspeed: 0.1183s/iter; left time: 617.4282s\n",
      "Epoch: 7 cost time: 44.58144545555115\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0112424 Vali Loss: 0.0473797 Test Loss: 0.0628524\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.06916719675064087, mae:0.2014487087726593\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_reversal_ftS_sl168_ll48_pl336_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.2480417\n",
      "\tspeed: 0.1326s/iter; left time: 1018.2655s\n",
      "\titers: 200, epoch: 1 | loss: 0.2304004\n",
      "\tspeed: 0.1376s/iter; left time: 1043.0625s\n",
      "\titers: 300, epoch: 1 | loss: 0.1718912\n",
      "\tspeed: 0.1383s/iter; left time: 1034.5773s\n",
      "Epoch: 1 cost time: 53.776294231414795\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1833786 Vali Loss: 0.8208898 Test Loss: 0.8331637\n",
      "Validation loss decreased (inf --> 0.820890).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0837664\n",
      "\tspeed: 0.3491s/iter; left time: 2545.7134s\n",
      "\titers: 200, epoch: 2 | loss: 0.0616254\n",
      "\tspeed: 0.1371s/iter; left time: 985.7960s\n",
      "\titers: 300, epoch: 2 | loss: 0.0510816\n",
      "\tspeed: 0.1392s/iter; left time: 987.4481s\n",
      "Epoch: 2 cost time: 54.52887535095215\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0655216 Vali Loss: 0.6001673 Test Loss: 0.7043035\n",
      "Validation loss decreased (0.820890 --> 0.600167).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0388414\n",
      "\tspeed: 0.3495s/iter; left time: 2412.5829s\n",
      "\titers: 200, epoch: 3 | loss: 0.0374572\n",
      "\tspeed: 0.1381s/iter; left time: 939.7569s\n",
      "\titers: 300, epoch: 3 | loss: 0.0292778\n",
      "\tspeed: 0.1414s/iter; left time: 947.7195s\n",
      "Epoch: 3 cost time: 55.93764114379883\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0317480 Vali Loss: 0.3902849 Test Loss: 0.4587609\n",
      "Validation loss decreased (0.600167 --> 0.390285).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0213910\n",
      "\tspeed: 0.3455s/iter; left time: 2250.6613s\n",
      "\titers: 200, epoch: 4 | loss: 0.0193383\n",
      "\tspeed: 0.1371s/iter; left time: 879.5593s\n",
      "\titers: 300, epoch: 4 | loss: 0.0319174\n",
      "\tspeed: 0.1360s/iter; left time: 858.9259s\n",
      "Epoch: 4 cost time: 54.42972755432129\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0227843 Vali Loss: 0.4787952 Test Loss: 0.5823324\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0156494\n",
      "\tspeed: 0.3507s/iter; left time: 2147.8253s\n",
      "\titers: 200, epoch: 5 | loss: 0.0158172\n",
      "\tspeed: 0.1412s/iter; left time: 850.9093s\n",
      "\titers: 300, epoch: 5 | loss: 0.0187064\n",
      "\tspeed: 0.1414s/iter; left time: 838.0306s\n",
      "Epoch: 5 cost time: 55.84549951553345\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0184727 Vali Loss: 0.4096768 Test Loss: 0.5154946\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0137150\n",
      "\tspeed: 0.3392s/iter; left time: 1945.4147s\n",
      "\titers: 200, epoch: 6 | loss: 0.0127353\n",
      "\tspeed: 0.1362s/iter; left time: 767.3645s\n",
      "\titers: 300, epoch: 6 | loss: 0.0161394\n",
      "\tspeed: 0.1341s/iter; left time: 742.6205s\n",
      "Epoch: 6 cost time: 53.642043113708496\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0161183 Vali Loss: 0.4639228 Test Loss: 0.5767332\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.4593085050582886, mae:0.5437710285186768\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_reversal_ftS_sl168_ll48_pl720_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.2630633\n",
      "\tspeed: 0.1953s/iter; left time: 1452.9784s\n",
      "\titers: 200, epoch: 1 | loss: 0.2017213\n",
      "\tspeed: 0.2013s/iter; left time: 1477.4683s\n",
      "\titers: 300, epoch: 1 | loss: 0.2096246\n",
      "\tspeed: 0.2023s/iter; left time: 1464.6024s\n",
      "Epoch: 1 cost time: 75.57018899917603\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.2443557 Vali Loss: 1.8320141 Test Loss: 1.4567195\n",
      "Validation loss decreased (inf --> 1.832014).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1778477\n",
      "\tspeed: 0.4491s/iter; left time: 3172.7243s\n",
      "\titers: 200, epoch: 2 | loss: 0.1394464\n",
      "\tspeed: 0.2022s/iter; left time: 1407.9740s\n",
      "\titers: 300, epoch: 2 | loss: 0.1189735\n",
      "\tspeed: 0.1961s/iter; left time: 1346.0102s\n",
      "Epoch: 2 cost time: 75.83491039276123\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.1360625 Vali Loss: 1.4370948 Test Loss: 0.9830819\n",
      "Validation loss decreased (1.832014 --> 1.437095).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0977248\n",
      "\tspeed: 0.4179s/iter; left time: 2794.1815s\n",
      "\titers: 200, epoch: 3 | loss: 0.0910730\n",
      "\tspeed: 0.1979s/iter; left time: 1303.6079s\n",
      "\titers: 300, epoch: 3 | loss: 0.0743486\n",
      "\tspeed: 0.1975s/iter; left time: 1281.1700s\n",
      "Epoch: 3 cost time: 73.78054356575012\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0883798 Vali Loss: 1.2398891 Test Loss: 0.6929644\n",
      "Validation loss decreased (1.437095 --> 1.239889).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0381568\n",
      "\tspeed: 0.4275s/iter; left time: 2697.7351s\n",
      "\titers: 200, epoch: 4 | loss: 0.0257988\n",
      "\tspeed: 0.1989s/iter; left time: 1235.4376s\n",
      "\titers: 300, epoch: 4 | loss: 0.0237918\n",
      "\tspeed: 0.2014s/iter; left time: 1230.3817s\n",
      "Epoch: 4 cost time: 74.35822653770447\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0324203 Vali Loss: 1.1733465 Test Loss: 0.6770657\n",
      "Validation loss decreased (1.239889 --> 1.173347).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0188413\n",
      "\tspeed: 0.4149s/iter; left time: 2461.6076s\n",
      "\titers: 200, epoch: 5 | loss: 0.0201956\n",
      "\tspeed: 0.1920s/iter; left time: 1120.1113s\n",
      "\titers: 300, epoch: 5 | loss: 0.0210228\n",
      "\tspeed: 0.2023s/iter; left time: 1159.6197s\n",
      "Epoch: 5 cost time: 73.54884243011475\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0199541 Vali Loss: 1.2922933 Test Loss: 0.7625583\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0157085\n",
      "\tspeed: 0.4184s/iter; left time: 2324.6901s\n",
      "\titers: 200, epoch: 6 | loss: 0.0144265\n",
      "\tspeed: 0.1955s/iter; left time: 1066.8927s\n",
      "\titers: 300, epoch: 6 | loss: 0.0150171\n",
      "\tspeed: 0.2142s/iter; left time: 1147.1181s\n",
      "Epoch: 6 cost time: 76.07845664024353\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0170907 Vali Loss: 1.3095062 Test Loss: 0.7643901\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0162974\n",
      "\tspeed: 0.4401s/iter; left time: 2279.1569s\n",
      "\titers: 200, epoch: 7 | loss: 0.0132107\n",
      "\tspeed: 0.1971s/iter; left time: 1000.9162s\n",
      "\titers: 300, epoch: 7 | loss: 0.0176582\n",
      "\tspeed: 0.1989s/iter; left time: 990.4865s\n",
      "Epoch: 7 cost time: 74.51044821739197\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0159069 Vali Loss: 1.2885832 Test Loss: 0.7483655\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.6756630539894104, mae:0.6871305704116821\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_ftS_sl168_ll48_pl24_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.0709875\n",
      "\tspeed: 0.0833s/iter; left time: 656.4772s\n",
      "\titers: 200, epoch: 1 | loss: 0.0413207\n",
      "\tspeed: 0.0879s/iter; left time: 684.2784s\n",
      "\titers: 300, epoch: 1 | loss: 0.0165523\n",
      "\tspeed: 0.0849s/iter; left time: 651.8198s\n",
      "Epoch: 1 cost time: 33.6042263507843\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.0712330 Vali Loss: 0.0463006 Test Loss: 0.4405722\n",
      "Validation loss decreased (inf --> 0.046301).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0091125\n",
      "\tspeed: 0.1992s/iter; left time: 1490.0964s\n",
      "\titers: 200, epoch: 2 | loss: 0.0077068\n",
      "\tspeed: 0.0839s/iter; left time: 619.6192s\n",
      "\titers: 300, epoch: 2 | loss: 0.0073648\n",
      "\tspeed: 0.0806s/iter; left time: 587.0199s\n",
      "Epoch: 2 cost time: 32.352219581604004\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0099214 Vali Loss: 0.0348078 Test Loss: 0.4426169\n",
      "Validation loss decreased (0.046301 --> 0.034808).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0053383\n",
      "\tspeed: 0.1940s/iter; left time: 1374.2904s\n",
      "\titers: 200, epoch: 3 | loss: 0.0063626\n",
      "\tspeed: 0.0792s/iter; left time: 553.1094s\n",
      "\titers: 300, epoch: 3 | loss: 0.0046864\n",
      "\tspeed: 0.0792s/iter; left time: 545.3490s\n",
      "Epoch: 3 cost time: 31.651877880096436\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0052140 Vali Loss: 0.0288070 Test Loss: 0.4056729\n",
      "Validation loss decreased (0.034808 --> 0.028807).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0042338\n",
      "\tspeed: 0.2009s/iter; left time: 1342.7186s\n",
      "\titers: 200, epoch: 4 | loss: 0.0041875\n",
      "\tspeed: 0.0852s/iter; left time: 561.2255s\n",
      "\titers: 300, epoch: 4 | loss: 0.0051278\n",
      "\tspeed: 0.0865s/iter; left time: 560.7301s\n",
      "Epoch: 4 cost time: 34.20325326919556\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0041916 Vali Loss: 0.0195001 Test Loss: 0.3398147\n",
      "Validation loss decreased (0.028807 --> 0.019500).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0039161\n",
      "\tspeed: 0.2120s/iter; left time: 1332.6729s\n",
      "\titers: 200, epoch: 5 | loss: 0.0037910\n",
      "\tspeed: 0.0861s/iter; left time: 532.3096s\n",
      "\titers: 300, epoch: 5 | loss: 0.0040069\n",
      "\tspeed: 0.0860s/iter; left time: 523.1205s\n",
      "Epoch: 5 cost time: 34.38912510871887\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0037252 Vali Loss: 0.0174869 Test Loss: 0.3083947\n",
      "Validation loss decreased (0.019500 --> 0.017487).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0033216\n",
      "\tspeed: 0.2059s/iter; left time: 1211.9621s\n",
      "\titers: 200, epoch: 6 | loss: 0.0035896\n",
      "\tspeed: 0.0824s/iter; left time: 476.8901s\n",
      "\titers: 300, epoch: 6 | loss: 0.0037592\n",
      "\tspeed: 0.0816s/iter; left time: 463.7417s\n",
      "Epoch: 6 cost time: 32.58814334869385\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0035013 Vali Loss: 0.0163842 Test Loss: 0.2954637\n",
      "Validation loss decreased (0.017487 --> 0.016384).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0029053\n",
      "\tspeed: 0.1992s/iter; left time: 1092.9826s\n",
      "\titers: 200, epoch: 7 | loss: 0.0031917\n",
      "\tspeed: 0.0822s/iter; left time: 442.8728s\n",
      "\titers: 300, epoch: 7 | loss: 0.0027931\n",
      "\tspeed: 0.0833s/iter; left time: 440.5742s\n",
      "Epoch: 7 cost time: 32.71142578125\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0033849 Vali Loss: 0.0153213 Test Loss: 0.2909353\n",
      "Validation loss decreased (0.016384 --> 0.015321).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0034088\n",
      "\tspeed: 0.1925s/iter; left time: 979.3835s\n",
      "\titers: 200, epoch: 8 | loss: 0.0033820\n",
      "\tspeed: 0.0762s/iter; left time: 380.0946s\n",
      "\titers: 300, epoch: 8 | loss: 0.0031284\n",
      "\tspeed: 0.0764s/iter; left time: 373.6214s\n",
      "Epoch: 8 cost time: 30.7475802898407\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0033131 Vali Loss: 0.0147040 Test Loss: 0.2779515\n",
      "Validation loss decreased (0.015321 --> 0.014704).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0033586\n",
      "\tspeed: 0.1956s/iter; left time: 917.0781s\n",
      "\titers: 200, epoch: 9 | loss: 0.0032495\n",
      "\tspeed: 0.0795s/iter; left time: 364.9361s\n",
      "\titers: 300, epoch: 9 | loss: 0.0032530\n",
      "\tspeed: 0.0831s/iter; left time: 372.9710s\n",
      "Epoch: 9 cost time: 32.71901607513428\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0032439 Vali Loss: 0.0147198 Test Loss: 0.2776706\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0036328\n",
      "\tspeed: 0.2068s/iter; left time: 887.2939s\n",
      "\titers: 200, epoch: 10 | loss: 0.0028916\n",
      "\tspeed: 0.0856s/iter; left time: 358.7809s\n",
      "\titers: 300, epoch: 10 | loss: 0.0028993\n",
      "\tspeed: 0.0858s/iter; left time: 350.9834s\n",
      "Epoch: 10 cost time: 34.12523150444031\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0032415 Vali Loss: 0.0152615 Test Loss: 0.2877443\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0035137\n",
      "\tspeed: 0.2081s/iter; left time: 809.7470s\n",
      "\titers: 200, epoch: 11 | loss: 0.0037801\n",
      "\tspeed: 0.0838s/iter; left time: 317.7072s\n",
      "\titers: 300, epoch: 11 | loss: 0.0029736\n",
      "\tspeed: 0.0853s/iter; left time: 314.6991s\n",
      "Epoch: 11 cost time: 33.99514842033386\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0032354 Vali Loss: 0.0149097 Test Loss: 0.2832302\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.27907368540763855, mae:0.4030056595802307\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_ftS_sl168_ll48_pl48_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.1189814\n",
      "\tspeed: 0.0896s/iter; left time: 704.2272s\n",
      "\titers: 200, epoch: 1 | loss: 0.0619161\n",
      "\tspeed: 0.0887s/iter; left time: 688.3334s\n",
      "\titers: 300, epoch: 1 | loss: 0.0318685\n",
      "\tspeed: 0.0885s/iter; left time: 677.6885s\n",
      "Epoch: 1 cost time: 35.41476607322693\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0803646 Vali Loss: 0.0783490 Test Loss: 0.6347160\n",
      "Validation loss decreased (inf --> 0.078349).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0239113\n",
      "\tspeed: 0.2018s/iter; left time: 1506.2181s\n",
      "\titers: 200, epoch: 2 | loss: 0.0089415\n",
      "\tspeed: 0.0757s/iter; left time: 557.1165s\n",
      "\titers: 300, epoch: 2 | loss: 0.0157382\n",
      "\tspeed: 0.0772s/iter; left time: 560.8845s\n",
      "Epoch: 2 cost time: 30.407499074935913\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0123205 Vali Loss: 0.0429016 Test Loss: 0.4704244\n",
      "Validation loss decreased (0.078349 --> 0.042902).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0064462\n",
      "\tspeed: 0.1953s/iter; left time: 1379.6335s\n",
      "\titers: 200, epoch: 3 | loss: 0.0067221\n",
      "\tspeed: 0.0829s/iter; left time: 577.2123s\n",
      "\titers: 300, epoch: 3 | loss: 0.0052836\n",
      "\tspeed: 0.0837s/iter; left time: 574.6576s\n",
      "Epoch: 3 cost time: 33.029725551605225\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0065149 Vali Loss: 0.0273806 Test Loss: 0.3908650\n",
      "Validation loss decreased (0.042902 --> 0.027381).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0057135\n",
      "\tspeed: 0.2091s/iter; left time: 1394.2952s\n",
      "\titers: 200, epoch: 4 | loss: 0.0048889\n",
      "\tspeed: 0.0889s/iter; left time: 583.6745s\n",
      "\titers: 300, epoch: 4 | loss: 0.0035620\n",
      "\tspeed: 0.0823s/iter; left time: 532.1544s\n",
      "Epoch: 4 cost time: 33.97735834121704\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0050955 Vali Loss: 0.0325542 Test Loss: 0.4293780\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0048406\n",
      "\tspeed: 0.1995s/iter; left time: 1250.7759s\n",
      "\titers: 200, epoch: 5 | loss: 0.0044803\n",
      "\tspeed: 0.0824s/iter; left time: 508.3437s\n",
      "\titers: 300, epoch: 5 | loss: 0.0045298\n",
      "\tspeed: 0.0819s/iter; left time: 497.1492s\n",
      "Epoch: 5 cost time: 32.756853342056274\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0043372 Vali Loss: 0.0248422 Test Loss: 0.3877282\n",
      "Validation loss decreased (0.027381 --> 0.024842).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0033699\n",
      "\tspeed: 0.2010s/iter; left time: 1180.0595s\n",
      "\titers: 200, epoch: 6 | loss: 0.0043785\n",
      "\tspeed: 0.0821s/iter; left time: 473.8596s\n",
      "\titers: 300, epoch: 6 | loss: 0.0034431\n",
      "\tspeed: 0.0829s/iter; left time: 470.1786s\n",
      "Epoch: 6 cost time: 32.87012076377869\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0039612 Vali Loss: 0.0245214 Test Loss: 0.3832417\n",
      "Validation loss decreased (0.024842 --> 0.024521).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0031206\n",
      "\tspeed: 0.2027s/iter; left time: 1109.5000s\n",
      "\titers: 200, epoch: 7 | loss: 0.0050072\n",
      "\tspeed: 0.0864s/iter; left time: 464.4425s\n",
      "\titers: 300, epoch: 7 | loss: 0.0040405\n",
      "\tspeed: 0.0894s/iter; left time: 471.3704s\n",
      "Epoch: 7 cost time: 34.50669550895691\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0038101 Vali Loss: 0.0235488 Test Loss: 0.3604463\n",
      "Validation loss decreased (0.024521 --> 0.023549).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0042272\n",
      "\tspeed: 0.2215s/iter; left time: 1124.2743s\n",
      "\titers: 200, epoch: 8 | loss: 0.0029119\n",
      "\tspeed: 0.0890s/iter; left time: 442.7405s\n",
      "\titers: 300, epoch: 8 | loss: 0.0036264\n",
      "\tspeed: 0.0888s/iter; left time: 432.9347s\n",
      "Epoch: 8 cost time: 34.97637176513672\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0037016 Vali Loss: 0.0234905 Test Loss: 0.3697325\n",
      "Validation loss decreased (0.023549 --> 0.023491).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0040701\n",
      "\tspeed: 0.2112s/iter; left time: 987.8692s\n",
      "\titers: 200, epoch: 9 | loss: 0.0035747\n",
      "\tspeed: 0.0884s/iter; left time: 404.7900s\n",
      "\titers: 300, epoch: 9 | loss: 0.0032920\n",
      "\tspeed: 0.0854s/iter; left time: 382.5382s\n",
      "Epoch: 9 cost time: 34.27611708641052\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0036727 Vali Loss: 0.0221879 Test Loss: 0.3568000\n",
      "Validation loss decreased (0.023491 --> 0.022188).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0034509\n",
      "\tspeed: 0.2007s/iter; left time: 858.5931s\n",
      "\titers: 200, epoch: 10 | loss: 0.0031166\n",
      "\tspeed: 0.0814s/iter; left time: 340.2797s\n",
      "\titers: 300, epoch: 10 | loss: 0.0038938\n",
      "\tspeed: 0.0817s/iter; left time: 333.1993s\n",
      "Epoch: 10 cost time: 33.462438106536865\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.0036617 Vali Loss: 0.0229751 Test Loss: 0.3590141\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0030996\n",
      "\tspeed: 0.2227s/iter; left time: 864.4492s\n",
      "\titers: 200, epoch: 11 | loss: 0.0039268\n",
      "\tspeed: 0.0885s/iter; left time: 334.6034s\n",
      "\titers: 300, epoch: 11 | loss: 0.0029410\n",
      "\tspeed: 0.0854s/iter; left time: 314.3035s\n",
      "Epoch: 11 cost time: 34.896162033081055\n",
      "Epoch: 11, Steps: 398 | Train Loss: 0.0036516 Vali Loss: 0.0237713 Test Loss: 0.3709689\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0035711\n",
      "\tspeed: 0.2062s/iter; left time: 718.1801s\n",
      "\titers: 200, epoch: 12 | loss: 0.0030145\n",
      "\tspeed: 0.0848s/iter; left time: 286.9958s\n",
      "\titers: 300, epoch: 12 | loss: 0.0036728\n",
      "\tspeed: 0.0847s/iter; left time: 278.0491s\n",
      "Epoch: 12 cost time: 33.753849029541016\n",
      "Epoch: 12, Steps: 398 | Train Loss: 0.0036235 Vali Loss: 0.0230408 Test Loss: 0.3600222\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.3566693067550659, mae:0.4794018268585205\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_ftS_sl168_ll48_pl168_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.1106737\n",
      "\tspeed: 0.1140s/iter; left time: 887.1306s\n",
      "\titers: 200, epoch: 1 | loss: 0.0796935\n",
      "\tspeed: 0.1123s/iter; left time: 862.3283s\n",
      "\titers: 300, epoch: 1 | loss: 0.0434881\n",
      "\tspeed: 0.1122s/iter; left time: 850.3966s\n",
      "Epoch: 1 cost time: 44.6513512134552\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.0842339 Vali Loss: 0.1727020 Test Loss: 1.1505983\n",
      "Validation loss decreased (inf --> 0.172702).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0133157\n",
      "\tspeed: 0.2829s/iter; left time: 2089.8084s\n",
      "\titers: 200, epoch: 2 | loss: 0.0103792\n",
      "\tspeed: 0.1152s/iter; left time: 839.7209s\n",
      "\titers: 300, epoch: 2 | loss: 0.0084785\n",
      "\tspeed: 0.1123s/iter; left time: 807.2755s\n",
      "Epoch: 2 cost time: 45.11807465553284\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0150310 Vali Loss: 0.0604440 Test Loss: 0.7048779\n",
      "Validation loss decreased (0.172702 --> 0.060444).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0075979\n",
      "\tspeed: 0.2814s/iter; left time: 1967.5621s\n",
      "\titers: 200, epoch: 3 | loss: 0.0060919\n",
      "\tspeed: 0.1160s/iter; left time: 799.6727s\n",
      "\titers: 300, epoch: 3 | loss: 0.0066660\n",
      "\tspeed: 0.1177s/iter; left time: 799.6046s\n",
      "Epoch: 3 cost time: 45.568835496902466\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0069972 Vali Loss: 0.0431865 Test Loss: 0.5998013\n",
      "Validation loss decreased (0.060444 --> 0.043187).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0056928\n",
      "\tspeed: 0.2805s/iter; left time: 1851.1436s\n",
      "\titers: 200, epoch: 4 | loss: 0.0067103\n",
      "\tspeed: 0.1094s/iter; left time: 711.0037s\n",
      "\titers: 300, epoch: 4 | loss: 0.0056568\n",
      "\tspeed: 0.1156s/iter; left time: 739.6013s\n",
      "Epoch: 4 cost time: 44.50547218322754\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0056684 Vali Loss: 0.0405430 Test Loss: 0.5575246\n",
      "Validation loss decreased (0.043187 --> 0.040543).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0052807\n",
      "\tspeed: 0.2887s/iter; left time: 1791.2216s\n",
      "\titers: 200, epoch: 5 | loss: 0.0059955\n",
      "\tspeed: 0.1110s/iter; left time: 677.6214s\n",
      "\titers: 300, epoch: 5 | loss: 0.0047407\n",
      "\tspeed: 0.1054s/iter; left time: 632.9017s\n",
      "Epoch: 5 cost time: 43.70111441612244\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0049940 Vali Loss: 0.0443663 Test Loss: 0.5546237\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0041529\n",
      "\tspeed: 0.2766s/iter; left time: 1607.4350s\n",
      "\titers: 200, epoch: 6 | loss: 0.0049938\n",
      "\tspeed: 0.1155s/iter; left time: 659.8524s\n",
      "\titers: 300, epoch: 6 | loss: 0.0054694\n",
      "\tspeed: 0.1133s/iter; left time: 635.7690s\n",
      "Epoch: 6 cost time: 44.36100244522095\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0046369 Vali Loss: 0.0359066 Test Loss: 0.5314389\n",
      "Validation loss decreased (0.040543 --> 0.035907).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0063136\n",
      "\tspeed: 0.2713s/iter; left time: 1469.7631s\n",
      "\titers: 200, epoch: 7 | loss: 0.0047906\n",
      "\tspeed: 0.1137s/iter; left time: 604.7330s\n",
      "\titers: 300, epoch: 7 | loss: 0.0038972\n",
      "\tspeed: 0.1131s/iter; left time: 590.0072s\n",
      "Epoch: 7 cost time: 44.68898296356201\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0044809 Vali Loss: 0.0388395 Test Loss: 0.5406097\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0049675\n",
      "\tspeed: 0.2765s/iter; left time: 1388.7285s\n",
      "\titers: 200, epoch: 8 | loss: 0.0047197\n",
      "\tspeed: 0.1094s/iter; left time: 538.4265s\n",
      "\titers: 300, epoch: 8 | loss: 0.0044398\n",
      "\tspeed: 0.1134s/iter; left time: 546.9509s\n",
      "Epoch: 8 cost time: 44.012943744659424\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0044689 Vali Loss: 0.0398115 Test Loss: 0.5519401\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0040386\n",
      "\tspeed: 0.2806s/iter; left time: 1299.1039s\n",
      "\titers: 200, epoch: 9 | loss: 0.0044795\n",
      "\tspeed: 0.1100s/iter; left time: 497.9858s\n",
      "\titers: 300, epoch: 9 | loss: 0.0043776\n",
      "\tspeed: 0.1051s/iter; left time: 465.2918s\n",
      "Epoch: 9 cost time: 43.43558931350708\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0043910 Vali Loss: 0.0368665 Test Loss: 0.5305538\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.5328617095947266, mae:0.6176535487174988\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_ftS_sl168_ll48_pl336_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.1114707\n",
      "\tspeed: 0.1426s/iter; left time: 1095.2399s\n",
      "\titers: 200, epoch: 1 | loss: 0.0701915\n",
      "\tspeed: 0.1395s/iter; left time: 1057.7836s\n",
      "\titers: 300, epoch: 1 | loss: 0.0682192\n",
      "\tspeed: 0.1376s/iter; left time: 1029.1818s\n",
      "Epoch: 1 cost time: 55.21339750289917\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1051325 Vali Loss: 0.2411487 Test Loss: 1.1796904\n",
      "Validation loss decreased (inf --> 0.241149).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0327751\n",
      "\tspeed: 0.3555s/iter; left time: 2592.3889s\n",
      "\titers: 200, epoch: 2 | loss: 0.0179230\n",
      "\tspeed: 0.1426s/iter; left time: 1025.4399s\n",
      "\titers: 300, epoch: 2 | loss: 0.0139239\n",
      "\tspeed: 0.1380s/iter; left time: 978.3983s\n",
      "Epoch: 2 cost time: 55.38012385368347\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0270973 Vali Loss: 0.0718090 Test Loss: 0.7881631\n",
      "Validation loss decreased (0.241149 --> 0.071809).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0150934\n",
      "\tspeed: 0.3413s/iter; left time: 2356.3219s\n",
      "\titers: 200, epoch: 3 | loss: 0.0086865\n",
      "\tspeed: 0.1407s/iter; left time: 957.0352s\n",
      "\titers: 300, epoch: 3 | loss: 0.0095566\n",
      "\tspeed: 0.1383s/iter; left time: 926.8540s\n",
      "Epoch: 3 cost time: 54.34113335609436\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0089716 Vali Loss: 0.0758080 Test Loss: 0.8589453\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0056774\n",
      "\tspeed: 0.3261s/iter; left time: 2124.2769s\n",
      "\titers: 200, epoch: 4 | loss: 0.0063822\n",
      "\tspeed: 0.1418s/iter; left time: 909.6351s\n",
      "\titers: 300, epoch: 4 | loss: 0.0062793\n",
      "\tspeed: 0.1457s/iter; left time: 919.6504s\n",
      "Epoch: 4 cost time: 55.466060638427734\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0066865 Vali Loss: 0.0451323 Test Loss: 0.6737106\n",
      "Validation loss decreased (0.071809 --> 0.045132).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0068001\n",
      "\tspeed: 0.3415s/iter; left time: 2091.7274s\n",
      "\titers: 200, epoch: 5 | loss: 0.0055689\n",
      "\tspeed: 0.1417s/iter; left time: 853.9791s\n",
      "\titers: 300, epoch: 5 | loss: 0.0054114\n",
      "\tspeed: 0.1451s/iter; left time: 859.5758s\n",
      "Epoch: 5 cost time: 55.60383343696594\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0058492 Vali Loss: 0.0427795 Test Loss: 0.6668917\n",
      "Validation loss decreased (0.045132 --> 0.042779).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0054188\n",
      "\tspeed: 0.3405s/iter; left time: 1953.3899s\n",
      "\titers: 200, epoch: 6 | loss: 0.0084855\n",
      "\tspeed: 0.1435s/iter; left time: 808.4903s\n",
      "\titers: 300, epoch: 6 | loss: 0.0044812\n",
      "\tspeed: 0.1431s/iter; left time: 792.0398s\n",
      "Epoch: 6 cost time: 55.39739942550659\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0054692 Vali Loss: 0.0419486 Test Loss: 0.6629272\n",
      "Validation loss decreased (0.042779 --> 0.041949).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0044345\n",
      "\tspeed: 0.3402s/iter; left time: 1819.1570s\n",
      "\titers: 200, epoch: 7 | loss: 0.0048354\n",
      "\tspeed: 0.1404s/iter; left time: 736.5764s\n",
      "\titers: 300, epoch: 7 | loss: 0.0088441\n",
      "\tspeed: 0.1419s/iter; left time: 730.2572s\n",
      "Epoch: 7 cost time: 55.04693579673767\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.0053059 Vali Loss: 0.0398266 Test Loss: 0.6358681\n",
      "Validation loss decreased (0.041949 --> 0.039827).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0057188\n",
      "\tspeed: 0.3469s/iter; left time: 1719.9252s\n",
      "\titers: 200, epoch: 8 | loss: 0.0054310\n",
      "\tspeed: 0.1462s/iter; left time: 710.0639s\n",
      "\titers: 300, epoch: 8 | loss: 0.0045425\n",
      "\tspeed: 0.1455s/iter; left time: 692.0952s\n",
      "Epoch: 8 cost time: 56.00218105316162\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.0051650 Vali Loss: 0.0411809 Test Loss: 0.6462417\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0054731\n",
      "\tspeed: 0.3209s/iter; left time: 1465.9744s\n",
      "\titers: 200, epoch: 9 | loss: 0.0058334\n",
      "\tspeed: 0.1430s/iter; left time: 639.0444s\n",
      "\titers: 300, epoch: 9 | loss: 0.0039746\n",
      "\tspeed: 0.1419s/iter; left time: 620.0443s\n",
      "Epoch: 9 cost time: 53.87673306465149\n",
      "Epoch: 9, Steps: 389 | Train Loss: 0.0050896 Vali Loss: 0.0408002 Test Loss: 0.6442739\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0044123\n",
      "\tspeed: 0.3309s/iter; left time: 1383.2292s\n",
      "\titers: 200, epoch: 10 | loss: 0.0046860\n",
      "\tspeed: 0.1463s/iter; left time: 597.1033s\n",
      "\titers: 300, epoch: 10 | loss: 0.0080123\n",
      "\tspeed: 0.1438s/iter; left time: 572.1598s\n",
      "Epoch: 10 cost time: 55.57811784744263\n",
      "Epoch: 10, Steps: 389 | Train Loss: 0.0050631 Vali Loss: 0.0411367 Test Loss: 0.6560875\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.6357367634773254, mae:0.68711918592453\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_ftS_sl168_ll48_pl720_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.0987491\n",
      "\tspeed: 0.1960s/iter; left time: 1458.1417s\n",
      "\titers: 200, epoch: 1 | loss: 0.0740563\n",
      "\tspeed: 0.1950s/iter; left time: 1431.2483s\n",
      "\titers: 300, epoch: 1 | loss: 0.0633344\n",
      "\tspeed: 0.1972s/iter; left time: 1427.8381s\n",
      "Epoch: 1 cost time: 74.13971757888794\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.1079163 Vali Loss: 0.3010982 Test Loss: 1.4094404\n",
      "Validation loss decreased (inf --> 0.301098).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0664768\n",
      "\tspeed: 0.4314s/iter; left time: 3047.2553s\n",
      "\titers: 200, epoch: 2 | loss: 0.0574495\n",
      "\tspeed: 0.1932s/iter; left time: 1345.6867s\n",
      "\titers: 300, epoch: 2 | loss: 0.0571256\n",
      "\tspeed: 0.1950s/iter; left time: 1338.3493s\n",
      "Epoch: 2 cost time: 73.60745811462402\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0610070 Vali Loss: 0.2547243 Test Loss: 1.2465460\n",
      "Validation loss decreased (0.301098 --> 0.254724).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0479107\n",
      "\tspeed: 0.4296s/iter; left time: 2873.0431s\n",
      "\titers: 200, epoch: 3 | loss: 0.0278419\n",
      "\tspeed: 0.1938s/iter; left time: 1276.7585s\n",
      "\titers: 300, epoch: 3 | loss: 0.0160688\n",
      "\tspeed: 0.2037s/iter; left time: 1321.5179s\n",
      "Epoch: 3 cost time: 74.87947988510132\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0359927 Vali Loss: 0.0726250 Test Loss: 0.8504102\n",
      "Validation loss decreased (0.254724 --> 0.072625).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0085582\n",
      "\tspeed: 0.4203s/iter; left time: 2651.9040s\n",
      "\titers: 200, epoch: 4 | loss: 0.0099265\n",
      "\tspeed: 0.1965s/iter; left time: 1220.1420s\n",
      "\titers: 300, epoch: 4 | loss: 0.0095714\n",
      "\tspeed: 0.1931s/iter; left time: 1179.7694s\n",
      "Epoch: 4 cost time: 72.86386680603027\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0084073 Vali Loss: 0.0663192 Test Loss: 0.7926688\n",
      "Validation loss decreased (0.072625 --> 0.066319).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0058720\n",
      "\tspeed: 0.4252s/iter; left time: 2522.7530s\n",
      "\titers: 200, epoch: 5 | loss: 0.0062666\n",
      "\tspeed: 0.1944s/iter; left time: 1133.8216s\n",
      "\titers: 300, epoch: 5 | loss: 0.0061400\n",
      "\tspeed: 0.1978s/iter; left time: 1133.8058s\n",
      "Epoch: 5 cost time: 73.70633840560913\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0067149 Vali Loss: 0.0627557 Test Loss: 0.7525733\n",
      "Validation loss decreased (0.066319 --> 0.062756).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0070033\n",
      "\tspeed: 0.4261s/iter; left time: 2367.2668s\n",
      "\titers: 200, epoch: 6 | loss: 0.0054441\n",
      "\tspeed: 0.1932s/iter; left time: 1054.0588s\n",
      "\titers: 300, epoch: 6 | loss: 0.0052415\n",
      "\tspeed: 0.1998s/iter; left time: 1069.9217s\n",
      "Epoch: 6 cost time: 74.02557277679443\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0060669 Vali Loss: 0.0612023 Test Loss: 0.7130259\n",
      "Validation loss decreased (0.062756 --> 0.061202).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0068831\n",
      "\tspeed: 0.4289s/iter; left time: 2221.3787s\n",
      "\titers: 200, epoch: 7 | loss: 0.0045242\n",
      "\tspeed: 0.1937s/iter; left time: 984.0125s\n",
      "\titers: 300, epoch: 7 | loss: 0.0048654\n",
      "\tspeed: 0.1990s/iter; left time: 990.9422s\n",
      "Epoch: 7 cost time: 74.27898263931274\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0057586 Vali Loss: 0.0559540 Test Loss: 0.7161196\n",
      "Validation loss decreased (0.061202 --> 0.055954).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0049342\n",
      "\tspeed: 0.4301s/iter; left time: 2065.2256s\n",
      "\titers: 200, epoch: 8 | loss: 0.0051221\n",
      "\tspeed: 0.1919s/iter; left time: 902.2898s\n",
      "\titers: 300, epoch: 8 | loss: 0.0062023\n",
      "\tspeed: 0.1909s/iter; left time: 878.5245s\n",
      "Epoch: 8 cost time: 71.57868695259094\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.0056631 Vali Loss: 0.0582231 Test Loss: 0.7088310\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0066100\n",
      "\tspeed: 0.4313s/iter; left time: 1908.6343s\n",
      "\titers: 200, epoch: 9 | loss: 0.0048551\n",
      "\tspeed: 0.2066s/iter; left time: 893.3712s\n",
      "\titers: 300, epoch: 9 | loss: 0.0054645\n",
      "\tspeed: 0.1867s/iter; left time: 788.6428s\n",
      "Epoch: 9 cost time: 74.26580357551575\n",
      "Epoch: 9, Steps: 377 | Train Loss: 0.0055768 Vali Loss: 0.0542264 Test Loss: 0.7074735\n",
      "Validation loss decreased (0.055954 --> 0.054226).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0056722\n",
      "\tspeed: 0.4253s/iter; left time: 1721.6724s\n",
      "\titers: 200, epoch: 10 | loss: 0.0049374\n",
      "\tspeed: 0.1900s/iter; left time: 750.2428s\n",
      "\titers: 300, epoch: 10 | loss: 0.0048769\n",
      "\tspeed: 0.1967s/iter; left time: 756.7615s\n",
      "Epoch: 10 cost time: 73.22450375556946\n",
      "Epoch: 10, Steps: 377 | Train Loss: 0.0054995 Vali Loss: 0.0527761 Test Loss: 0.6983357\n",
      "Validation loss decreased (0.054226 --> 0.052776).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0046815\n",
      "\tspeed: 0.4292s/iter; left time: 1575.6889s\n",
      "\titers: 200, epoch: 11 | loss: 0.0062488\n",
      "\tspeed: 0.1900s/iter; left time: 678.5306s\n",
      "\titers: 300, epoch: 11 | loss: 0.0064277\n",
      "\tspeed: 0.1950s/iter; left time: 676.8400s\n",
      "Epoch: 11 cost time: 73.57129621505737\n",
      "Epoch: 11, Steps: 377 | Train Loss: 0.0054405 Vali Loss: 0.0529261 Test Loss: 0.6906855\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0049122\n",
      "\tspeed: 0.4262s/iter; left time: 1403.9713s\n",
      "\titers: 200, epoch: 12 | loss: 0.0056192\n",
      "\tspeed: 0.1976s/iter; left time: 631.0312s\n",
      "\titers: 300, epoch: 12 | loss: 0.0049241\n",
      "\tspeed: 0.1903s/iter; left time: 588.7440s\n",
      "Epoch: 12 cost time: 72.53834795951843\n",
      "Epoch: 12, Steps: 377 | Train Loss: 0.0054668 Vali Loss: 0.0525578 Test Loss: 0.6955802\n",
      "Validation loss decreased (0.052776 --> 0.052558).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0053727\n",
      "\tspeed: 0.4209s/iter; left time: 1227.6496s\n",
      "\titers: 200, epoch: 13 | loss: 0.0047626\n",
      "\tspeed: 0.1984s/iter; left time: 558.8459s\n",
      "\titers: 300, epoch: 13 | loss: 0.0050755\n",
      "\tspeed: 0.1943s/iter; left time: 527.8692s\n",
      "Epoch: 13 cost time: 73.7551064491272\n",
      "Epoch: 13, Steps: 377 | Train Loss: 0.0054182 Vali Loss: 0.0528836 Test Loss: 0.6830003\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "\titers: 100, epoch: 14 | loss: 0.0047696\n",
      "\tspeed: 0.4289s/iter; left time: 1089.5241s\n",
      "\titers: 200, epoch: 14 | loss: 0.0058091\n",
      "\tspeed: 0.1943s/iter; left time: 474.1790s\n",
      "\titers: 300, epoch: 14 | loss: 0.0050923\n",
      "\tspeed: 0.1964s/iter; left time: 459.6376s\n",
      "Epoch: 14 cost time: 74.1397864818573\n",
      "Epoch: 14, Steps: 377 | Train Loss: 0.0054143 Vali Loss: 0.0538357 Test Loss: 0.6858308\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "\titers: 100, epoch: 15 | loss: 0.0044430\n",
      "\tspeed: 0.4325s/iter; left time: 935.5677s\n",
      "\titers: 200, epoch: 15 | loss: 0.0050487\n",
      "\tspeed: 0.1953s/iter; left time: 402.8841s\n",
      "\titers: 300, epoch: 15 | loss: 0.0045103\n",
      "\tspeed: 0.2007s/iter; left time: 394.0166s\n",
      "Epoch: 15 cost time: 75.21496891975403\n",
      "Epoch: 15, Steps: 377 | Train Loss: 0.0054773 Vali Loss: 0.0521083 Test Loss: 0.6944690\n",
      "Validation loss decreased (0.052558 --> 0.052108).  Saving model ...\n",
      "Updating learning rate to 6.103515625e-09\n",
      "\titers: 100, epoch: 16 | loss: 0.0051935\n",
      "\tspeed: 0.4280s/iter; left time: 764.3233s\n",
      "\titers: 200, epoch: 16 | loss: 0.0058416\n",
      "\tspeed: 0.1965s/iter; left time: 331.3271s\n",
      "\titers: 300, epoch: 16 | loss: 0.0048542\n",
      "\tspeed: 0.1977s/iter; left time: 313.5107s\n",
      "Epoch: 16 cost time: 73.99346160888672\n",
      "Epoch: 16, Steps: 377 | Train Loss: 0.0054206 Vali Loss: 0.0528468 Test Loss: 0.6842472\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.0517578125e-09\n",
      "\titers: 100, epoch: 17 | loss: 0.0080427\n",
      "\tspeed: 0.4293s/iter; left time: 604.9119s\n",
      "\titers: 200, epoch: 17 | loss: 0.0049215\n",
      "\tspeed: 0.1943s/iter; left time: 254.3060s\n",
      "\titers: 300, epoch: 17 | loss: 0.0045906\n",
      "\tspeed: 0.1945s/iter; left time: 235.1595s\n",
      "Epoch: 17 cost time: 73.8154628276825\n",
      "Epoch: 17, Steps: 377 | Train Loss: 0.0054209 Vali Loss: 0.0527031 Test Loss: 0.6935501\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.52587890625e-09\n",
      "\titers: 100, epoch: 18 | loss: 0.0066229\n",
      "\tspeed: 0.4308s/iter; left time: 444.6214s\n",
      "\titers: 200, epoch: 18 | loss: 0.0047277\n",
      "\tspeed: 0.1945s/iter; left time: 181.3133s\n",
      "\titers: 300, epoch: 18 | loss: 0.0042332\n",
      "\tspeed: 0.1993s/iter; left time: 165.8483s\n",
      "Epoch: 18 cost time: 74.5923502445221\n",
      "Epoch: 18, Steps: 377 | Train Loss: 0.0055031 Vali Loss: 0.0518420 Test Loss: 0.6839349\n",
      "Validation loss decreased (0.052108 --> 0.051842).  Saving model ...\n",
      "Updating learning rate to 7.62939453125e-10\n",
      "\titers: 100, epoch: 19 | loss: 0.0050086\n",
      "\tspeed: 0.4281s/iter; left time: 280.3902s\n",
      "\titers: 200, epoch: 19 | loss: 0.0047925\n",
      "\tspeed: 0.2029s/iter; left time: 112.6162s\n",
      "\titers: 300, epoch: 19 | loss: 0.0046053\n",
      "\tspeed: 0.2012s/iter; left time: 91.5436s\n",
      "Epoch: 19 cost time: 73.51172637939453\n",
      "Epoch: 19, Steps: 377 | Train Loss: 0.0054610 Vali Loss: 0.0515663 Test Loss: 0.6886514\n",
      "Validation loss decreased (0.051842 --> 0.051566).  Saving model ...\n",
      "Updating learning rate to 3.814697265625e-10\n",
      "\titers: 100, epoch: 20 | loss: 0.0048238\n",
      "\tspeed: 0.4210s/iter; left time: 117.0518s\n",
      "\titers: 200, epoch: 20 | loss: 0.0051247\n",
      "\tspeed: 0.2001s/iter; left time: 35.6241s\n",
      "\titers: 300, epoch: 20 | loss: 0.0047970\n",
      "\tspeed: 0.1860s/iter; left time: 14.5097s\n",
      "Epoch: 20 cost time: 73.75545763969421\n",
      "Epoch: 20, Steps: 377 | Train Loss: 0.0054222 Vali Loss: 0.0516541 Test Loss: 0.6852044\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.9073486328125e-10\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.6885851621627808, mae:0.6986867189407349\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl24_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.0788680\n",
      "\tspeed: 0.0815s/iter; left time: 642.5728s\n",
      "\titers: 200, epoch: 1 | loss: 0.0451894\n",
      "\tspeed: 0.0812s/iter; left time: 631.4282s\n",
      "\titers: 300, epoch: 1 | loss: 0.0267968\n",
      "\tspeed: 0.0847s/iter; left time: 650.2594s\n",
      "Epoch: 1 cost time: 32.77257800102234\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.0775373 Vali Loss: 0.1734807 Test Loss: 0.6354374\n",
      "Validation loss decreased (inf --> 0.173481).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0151230\n",
      "\tspeed: 0.2035s/iter; left time: 1522.5425s\n",
      "\titers: 200, epoch: 2 | loss: 0.0075593\n",
      "\tspeed: 0.0822s/iter; left time: 606.5279s\n",
      "\titers: 300, epoch: 2 | loss: 0.0094819\n",
      "\tspeed: 0.0826s/iter; left time: 601.2315s\n",
      "Epoch: 2 cost time: 32.976473331451416\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0128043 Vali Loss: 0.1257701 Test Loss: 0.5368348\n",
      "Validation loss decreased (0.173481 --> 0.125770).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0204367\n",
      "\tspeed: 0.2013s/iter; left time: 1425.9604s\n",
      "\titers: 200, epoch: 3 | loss: 0.0046413\n",
      "\tspeed: 0.0794s/iter; left time: 554.1828s\n",
      "\titers: 300, epoch: 3 | loss: 0.0058349\n",
      "\tspeed: 0.0828s/iter; left time: 569.8236s\n",
      "Epoch: 3 cost time: 32.2604763507843\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0068773 Vali Loss: 0.0990217 Test Loss: 0.4171907\n",
      "Validation loss decreased (0.125770 --> 0.099022).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0051727\n",
      "\tspeed: 0.1983s/iter; left time: 1325.4524s\n",
      "\titers: 200, epoch: 4 | loss: 0.0049312\n",
      "\tspeed: 0.0848s/iter; left time: 558.2777s\n",
      "\titers: 300, epoch: 4 | loss: 0.0053783\n",
      "\tspeed: 0.0841s/iter; left time: 545.5636s\n",
      "Epoch: 4 cost time: 33.475058794021606\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0056902 Vali Loss: 0.0929940 Test Loss: 0.3679719\n",
      "Validation loss decreased (0.099022 --> 0.092994).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0044738\n",
      "\tspeed: 0.2003s/iter; left time: 1258.9936s\n",
      "\titers: 200, epoch: 5 | loss: 0.0037029\n",
      "\tspeed: 0.0816s/iter; left time: 504.4737s\n",
      "\titers: 300, epoch: 5 | loss: 0.0037891\n",
      "\tspeed: 0.0828s/iter; left time: 503.7835s\n",
      "Epoch: 5 cost time: 32.644954681396484\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0052264 Vali Loss: 0.0891112 Test Loss: 0.3893256\n",
      "Validation loss decreased (0.092994 --> 0.089111).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0044139\n",
      "\tspeed: 0.2032s/iter; left time: 1195.9184s\n",
      "\titers: 200, epoch: 6 | loss: 0.0073102\n",
      "\tspeed: 0.0818s/iter; left time: 473.2326s\n",
      "\titers: 300, epoch: 6 | loss: 0.0045035\n",
      "\tspeed: 0.0821s/iter; left time: 466.8812s\n",
      "Epoch: 6 cost time: 32.5547137260437\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0048354 Vali Loss: 0.0909925 Test Loss: 0.4038185\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0033632\n",
      "\tspeed: 0.1961s/iter; left time: 1076.0959s\n",
      "\titers: 200, epoch: 7 | loss: 0.0037053\n",
      "\tspeed: 0.0811s/iter; left time: 436.8447s\n",
      "\titers: 300, epoch: 7 | loss: 0.0038456\n",
      "\tspeed: 0.0823s/iter; left time: 435.1037s\n",
      "Epoch: 7 cost time: 32.4980309009552\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0046033 Vali Loss: 0.0864102 Test Loss: 0.3683278\n",
      "Validation loss decreased (0.089111 --> 0.086410).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0037280\n",
      "\tspeed: 0.2001s/iter; left time: 1018.2807s\n",
      "\titers: 200, epoch: 8 | loss: 0.0046203\n",
      "\tspeed: 0.0815s/iter; left time: 406.5601s\n",
      "\titers: 300, epoch: 8 | loss: 0.0032921\n",
      "\tspeed: 0.0814s/iter; left time: 397.9331s\n",
      "Epoch: 8 cost time: 32.47343158721924\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0045594 Vali Loss: 0.0866644 Test Loss: 0.3655929\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0041162\n",
      "\tspeed: 0.2000s/iter; left time: 937.7293s\n",
      "\titers: 200, epoch: 9 | loss: 0.0073035\n",
      "\tspeed: 0.0818s/iter; left time: 375.5065s\n",
      "\titers: 300, epoch: 9 | loss: 0.0040763\n",
      "\tspeed: 0.0819s/iter; left time: 367.5751s\n",
      "Epoch: 9 cost time: 32.565524101257324\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0044945 Vali Loss: 0.0865685 Test Loss: 0.3714269\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0032137\n",
      "\tspeed: 0.1991s/iter; left time: 853.9756s\n",
      "\titers: 200, epoch: 10 | loss: 0.0032570\n",
      "\tspeed: 0.0841s/iter; left time: 352.4201s\n",
      "\titers: 300, epoch: 10 | loss: 0.0042729\n",
      "\tspeed: 0.0827s/iter; left time: 338.2666s\n",
      "Epoch: 10 cost time: 32.96140456199646\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0044477 Vali Loss: 0.0857561 Test Loss: 0.3761317\n",
      "Validation loss decreased (0.086410 --> 0.085756).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0036513\n",
      "\tspeed: 0.2003s/iter; left time: 779.2016s\n",
      "\titers: 200, epoch: 11 | loss: 0.0042454\n",
      "\tspeed: 0.0828s/iter; left time: 314.0698s\n",
      "\titers: 300, epoch: 11 | loss: 0.0031923\n",
      "\tspeed: 0.0836s/iter; left time: 308.3978s\n",
      "Epoch: 11 cost time: 32.91977262496948\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0044323 Vali Loss: 0.0872888 Test Loss: 0.3743701\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0034631\n",
      "\tspeed: 0.1996s/iter; left time: 696.9418s\n",
      "\titers: 200, epoch: 12 | loss: 0.0043062\n",
      "\tspeed: 0.0822s/iter; left time: 278.8795s\n",
      "\titers: 300, epoch: 12 | loss: 0.0029944\n",
      "\tspeed: 0.0822s/iter; left time: 270.5827s\n",
      "Epoch: 12 cost time: 33.19589328765869\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0044450 Vali Loss: 0.0869936 Test Loss: 0.3746516\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0034783\n",
      "\tspeed: 0.2021s/iter; left time: 625.0987s\n",
      "\titers: 200, epoch: 13 | loss: 0.0056272\n",
      "\tspeed: 0.0820s/iter; left time: 245.5359s\n",
      "\titers: 300, epoch: 13 | loss: 0.0033028\n",
      "\tspeed: 0.0814s/iter; left time: 235.3797s\n",
      "Epoch: 13 cost time: 32.61154913902283\n",
      "Epoch: 13, Steps: 399 | Train Loss: 0.0044363 Vali Loss: 0.0870006 Test Loss: 0.3754101\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.3758069574832916, mae:0.4230295419692993\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl48_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.0969763\n",
      "\tspeed: 0.0831s/iter; left time: 653.1921s\n",
      "\titers: 200, epoch: 1 | loss: 0.0516783\n",
      "\tspeed: 0.0839s/iter; left time: 651.0358s\n",
      "\titers: 300, epoch: 1 | loss: 0.0333562\n",
      "\tspeed: 0.0858s/iter; left time: 657.3917s\n",
      "Epoch: 1 cost time: 33.67626333236694\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0900650 Vali Loss: 0.2661161 Test Loss: 0.9067699\n",
      "Validation loss decreased (inf --> 0.266116).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0196231\n",
      "\tspeed: 0.2117s/iter; left time: 1579.6786s\n",
      "\titers: 200, epoch: 2 | loss: 0.0079478\n",
      "\tspeed: 0.0877s/iter; left time: 645.8115s\n",
      "\titers: 300, epoch: 2 | loss: 0.0082865\n",
      "\tspeed: 0.0841s/iter; left time: 611.1160s\n",
      "Epoch: 2 cost time: 34.03175926208496\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0159517 Vali Loss: 0.1956289 Test Loss: 0.6917968\n",
      "Validation loss decreased (0.266116 --> 0.195629).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0063318\n",
      "\tspeed: 0.2037s/iter; left time: 1439.1527s\n",
      "\titers: 200, epoch: 3 | loss: 0.0060156\n",
      "\tspeed: 0.0838s/iter; left time: 583.9507s\n",
      "\titers: 300, epoch: 3 | loss: 0.0167897\n",
      "\tspeed: 0.0862s/iter; left time: 591.9077s\n",
      "Epoch: 3 cost time: 33.942678689956665\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0088350 Vali Loss: 0.1695427 Test Loss: 0.5806086\n",
      "Validation loss decreased (0.195629 --> 0.169543).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0071693\n",
      "\tspeed: 0.2140s/iter; left time: 1426.6320s\n",
      "\titers: 200, epoch: 4 | loss: 0.0047909\n",
      "\tspeed: 0.0797s/iter; left time: 523.0704s\n",
      "\titers: 300, epoch: 4 | loss: 0.0061140\n",
      "\tspeed: 0.0794s/iter; left time: 513.5542s\n",
      "Epoch: 4 cost time: 33.01140785217285\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0071342 Vali Loss: 0.1607888 Test Loss: 0.6161938\n",
      "Validation loss decreased (0.169543 --> 0.160789).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0044574\n",
      "\tspeed: 0.2094s/iter; left time: 1312.7939s\n",
      "\titers: 200, epoch: 5 | loss: 0.0060797\n",
      "\tspeed: 0.0841s/iter; left time: 519.0986s\n",
      "\titers: 300, epoch: 5 | loss: 0.0288944\n",
      "\tspeed: 0.0842s/iter; left time: 511.3061s\n",
      "Epoch: 5 cost time: 33.588133811950684\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0062270 Vali Loss: 0.1560760 Test Loss: 0.6010795\n",
      "Validation loss decreased (0.160789 --> 0.156076).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0066017\n",
      "\tspeed: 0.2119s/iter; left time: 1243.7805s\n",
      "\titers: 200, epoch: 6 | loss: 0.0117868\n",
      "\tspeed: 0.0833s/iter; left time: 480.5695s\n",
      "\titers: 300, epoch: 6 | loss: 0.0043798\n",
      "\tspeed: 0.0841s/iter; left time: 477.0390s\n",
      "Epoch: 6 cost time: 33.30384540557861\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0057254 Vali Loss: 0.1585039 Test Loss: 0.6124299\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0043770\n",
      "\tspeed: 0.2044s/iter; left time: 1118.7211s\n",
      "\titers: 200, epoch: 7 | loss: 0.0036151\n",
      "\tspeed: 0.0846s/iter; left time: 454.6768s\n",
      "\titers: 300, epoch: 7 | loss: 0.0039277\n",
      "\tspeed: 0.0842s/iter; left time: 444.0154s\n",
      "Epoch: 7 cost time: 33.74958610534668\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0054963 Vali Loss: 0.1555986 Test Loss: 0.6116016\n",
      "Validation loss decreased (0.156076 --> 0.155599).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0042226\n",
      "\tspeed: 0.2120s/iter; left time: 1076.0555s\n",
      "\titers: 200, epoch: 8 | loss: 0.0043092\n",
      "\tspeed: 0.0858s/iter; left time: 426.7802s\n",
      "\titers: 300, epoch: 8 | loss: 0.0086763\n",
      "\tspeed: 0.0859s/iter; left time: 418.7288s\n",
      "Epoch: 8 cost time: 34.11226010322571\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0053729 Vali Loss: 0.1558451 Test Loss: 0.6051303\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0038314\n",
      "\tspeed: 0.2085s/iter; left time: 975.2761s\n",
      "\titers: 200, epoch: 9 | loss: 0.0073820\n",
      "\tspeed: 0.0856s/iter; left time: 391.8057s\n",
      "\titers: 300, epoch: 9 | loss: 0.0040625\n",
      "\tspeed: 0.0836s/iter; left time: 374.3155s\n",
      "Epoch: 9 cost time: 33.48830723762512\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0053214 Vali Loss: 0.1559082 Test Loss: 0.6056042\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0045705\n",
      "\tspeed: 0.2024s/iter; left time: 866.2327s\n",
      "\titers: 200, epoch: 10 | loss: 0.0045905\n",
      "\tspeed: 0.0853s/iter; left time: 356.3645s\n",
      "\titers: 300, epoch: 10 | loss: 0.0047215\n",
      "\tspeed: 0.0834s/iter; left time: 340.0471s\n",
      "Epoch: 10 cost time: 33.623674631118774\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.0053125 Vali Loss: 0.1534781 Test Loss: 0.5936347\n",
      "Validation loss decreased (0.155599 --> 0.153478).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0037103\n",
      "\tspeed: 0.2083s/iter; left time: 808.3945s\n",
      "\titers: 200, epoch: 11 | loss: 0.0048407\n",
      "\tspeed: 0.0854s/iter; left time: 323.0632s\n",
      "\titers: 300, epoch: 11 | loss: 0.0051624\n",
      "\tspeed: 0.0859s/iter; left time: 316.0955s\n",
      "Epoch: 11 cost time: 34.111783266067505\n",
      "Epoch: 11, Steps: 398 | Train Loss: 0.0052491 Vali Loss: 0.1535037 Test Loss: 0.5911185\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0048095\n",
      "\tspeed: 0.2090s/iter; left time: 727.8787s\n",
      "\titers: 200, epoch: 12 | loss: 0.0042890\n",
      "\tspeed: 0.0840s/iter; left time: 284.0525s\n",
      "\titers: 300, epoch: 12 | loss: 0.0049809\n",
      "\tspeed: 0.0840s/iter; left time: 275.6960s\n",
      "Epoch: 12 cost time: 33.61678385734558\n",
      "Epoch: 12, Steps: 398 | Train Loss: 0.0052398 Vali Loss: 0.1538228 Test Loss: 0.5892992\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0038522\n",
      "\tspeed: 0.2071s/iter; left time: 639.0437s\n",
      "\titers: 200, epoch: 13 | loss: 0.0040671\n",
      "\tspeed: 0.0833s/iter; left time: 248.7177s\n",
      "\titers: 300, epoch: 13 | loss: 0.0037946\n",
      "\tspeed: 0.0841s/iter; left time: 242.6536s\n",
      "Epoch: 13 cost time: 33.39165663719177\n",
      "Epoch: 13, Steps: 398 | Train Loss: 0.0052030 Vali Loss: 0.1543660 Test Loss: 0.5982865\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.5931435823440552, mae:0.5664237141609192\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl168_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.1307663\n",
      "\tspeed: 0.1123s/iter; left time: 874.1406s\n",
      "\titers: 200, epoch: 1 | loss: 0.0827389\n",
      "\tspeed: 0.1105s/iter; left time: 848.4511s\n",
      "\titers: 300, epoch: 1 | loss: 0.0538803\n",
      "\tspeed: 0.1138s/iter; left time: 862.5424s\n",
      "Epoch: 1 cost time: 44.2152636051178\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.0929664 Vali Loss: 0.4270364 Test Loss: 1.0866045\n",
      "Validation loss decreased (inf --> 0.427036).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0301779\n",
      "\tspeed: 0.2819s/iter; left time: 2082.3215s\n",
      "\titers: 200, epoch: 2 | loss: 0.0172033\n",
      "\tspeed: 0.1128s/iter; left time: 821.7360s\n",
      "\titers: 300, epoch: 2 | loss: 0.0251836\n",
      "\tspeed: 0.1135s/iter; left time: 815.9659s\n",
      "Epoch: 2 cost time: 44.65716576576233\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0198668 Vali Loss: 0.3581498 Test Loss: 0.8582063\n",
      "Validation loss decreased (0.427036 --> 0.358150).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0163492\n",
      "\tspeed: 0.2863s/iter; left time: 2001.9319s\n",
      "\titers: 200, epoch: 3 | loss: 0.0086393\n",
      "\tspeed: 0.1141s/iter; left time: 786.2871s\n",
      "\titers: 300, epoch: 3 | loss: 0.0149249\n",
      "\tspeed: 0.1115s/iter; left time: 757.4880s\n",
      "Epoch: 3 cost time: 44.70605969429016\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0101433 Vali Loss: 0.3632949 Test Loss: 0.8374136\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0060505\n",
      "\tspeed: 0.2844s/iter; left time: 1876.5990s\n",
      "\titers: 200, epoch: 4 | loss: 0.0057782\n",
      "\tspeed: 0.1120s/iter; left time: 728.1483s\n",
      "\titers: 300, epoch: 4 | loss: 0.0075108\n",
      "\tspeed: 0.1125s/iter; left time: 719.6074s\n",
      "Epoch: 4 cost time: 44.30906939506531\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0078695 Vali Loss: 0.3446993 Test Loss: 0.8169286\n",
      "Validation loss decreased (0.358150 --> 0.344699).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0061383\n",
      "\tspeed: 0.2835s/iter; left time: 1758.8689s\n",
      "\titers: 200, epoch: 5 | loss: 0.0057941\n",
      "\tspeed: 0.1148s/iter; left time: 700.8271s\n",
      "\titers: 300, epoch: 5 | loss: 0.0068496\n",
      "\tspeed: 0.1129s/iter; left time: 677.9105s\n",
      "Epoch: 5 cost time: 44.63812017440796\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0066796 Vali Loss: 0.3491194 Test Loss: 0.8125885\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0062225\n",
      "\tspeed: 0.2765s/iter; left time: 1606.7472s\n",
      "\titers: 200, epoch: 6 | loss: 0.0059490\n",
      "\tspeed: 0.1140s/iter; left time: 651.2843s\n",
      "\titers: 300, epoch: 6 | loss: 0.0058703\n",
      "\tspeed: 0.1133s/iter; left time: 635.7743s\n",
      "Epoch: 6 cost time: 44.08200120925903\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0061830 Vali Loss: 0.3474482 Test Loss: 0.8086171\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0065807\n",
      "\tspeed: 0.2757s/iter; left time: 1493.4743s\n",
      "\titers: 200, epoch: 7 | loss: 0.0067910\n",
      "\tspeed: 0.1115s/iter; left time: 592.9045s\n",
      "\titers: 300, epoch: 7 | loss: 0.0067178\n",
      "\tspeed: 0.1118s/iter; left time: 583.3214s\n",
      "Epoch: 7 cost time: 44.40922260284424\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0058294 Vali Loss: 0.3430699 Test Loss: 0.8092433\n",
      "Validation loss decreased (0.344699 --> 0.343070).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0049116\n",
      "\tspeed: 0.2897s/iter; left time: 1455.1835s\n",
      "\titers: 200, epoch: 8 | loss: 0.0060845\n",
      "\tspeed: 0.1148s/iter; left time: 565.0472s\n",
      "\titers: 300, epoch: 8 | loss: 0.0063204\n",
      "\tspeed: 0.1130s/iter; left time: 544.9916s\n",
      "Epoch: 8 cost time: 45.278481006622314\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0057435 Vali Loss: 0.3418657 Test Loss: 0.8143306\n",
      "Validation loss decreased (0.343070 --> 0.341866).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0049513\n",
      "\tspeed: 0.2902s/iter; left time: 1343.4839s\n",
      "\titers: 200, epoch: 9 | loss: 0.0040881\n",
      "\tspeed: 0.1124s/iter; left time: 509.2756s\n",
      "\titers: 300, epoch: 9 | loss: 0.0053312\n",
      "\tspeed: 0.1128s/iter; left time: 499.6861s\n",
      "Epoch: 9 cost time: 44.79348134994507\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0056493 Vali Loss: 0.3421928 Test Loss: 0.7994193\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0055043\n",
      "\tspeed: 0.2830s/iter; left time: 1198.3039s\n",
      "\titers: 200, epoch: 10 | loss: 0.0061333\n",
      "\tspeed: 0.1149s/iter; left time: 475.1399s\n",
      "\titers: 300, epoch: 10 | loss: 0.0053112\n",
      "\tspeed: 0.1060s/iter; left time: 427.7957s\n",
      "Epoch: 10 cost time: 43.860697746276855\n",
      "Epoch: 10, Steps: 394 | Train Loss: 0.0056562 Vali Loss: 0.3442896 Test Loss: 0.8077086\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0052528\n",
      "\tspeed: 0.2892s/iter; left time: 1110.7424s\n",
      "\titers: 200, epoch: 11 | loss: 0.0045372\n",
      "\tspeed: 0.1165s/iter; left time: 435.9793s\n",
      "\titers: 300, epoch: 11 | loss: 0.0046646\n",
      "\tspeed: 0.1144s/iter; left time: 416.4531s\n",
      "Epoch: 11 cost time: 44.974528789520264\n",
      "Epoch: 11, Steps: 394 | Train Loss: 0.0055673 Vali Loss: 0.3412831 Test Loss: 0.8055159\n",
      "Validation loss decreased (0.341866 --> 0.341283).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0082765\n",
      "\tspeed: 0.2789s/iter; left time: 961.4251s\n",
      "\titers: 200, epoch: 12 | loss: 0.0069628\n",
      "\tspeed: 0.1155s/iter; left time: 386.4335s\n",
      "\titers: 300, epoch: 12 | loss: 0.0046950\n",
      "\tspeed: 0.1147s/iter; left time: 372.4652s\n",
      "Epoch: 12 cost time: 44.496193647384644\n",
      "Epoch: 12, Steps: 394 | Train Loss: 0.0056425 Vali Loss: 0.3427100 Test Loss: 0.8045099\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0038325\n",
      "\tspeed: 0.2727s/iter; left time: 832.5342s\n",
      "\titers: 200, epoch: 13 | loss: 0.0058810\n",
      "\tspeed: 0.1124s/iter; left time: 331.9198s\n",
      "\titers: 300, epoch: 13 | loss: 0.0040364\n",
      "\tspeed: 0.1117s/iter; left time: 318.7155s\n",
      "Epoch: 13 cost time: 44.36970138549805\n",
      "Epoch: 13, Steps: 394 | Train Loss: 0.0056255 Vali Loss: 0.3439753 Test Loss: 0.8070402\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "\titers: 100, epoch: 14 | loss: 0.0050070\n",
      "\tspeed: 0.2810s/iter; left time: 747.3054s\n",
      "\titers: 200, epoch: 14 | loss: 0.0043614\n",
      "\tspeed: 0.1075s/iter; left time: 275.0087s\n",
      "\titers: 300, epoch: 14 | loss: 0.0056130\n",
      "\tspeed: 0.1139s/iter; left time: 279.9774s\n",
      "Epoch: 14 cost time: 44.45697641372681\n",
      "Epoch: 14, Steps: 394 | Train Loss: 0.0056210 Vali Loss: 0.3419331 Test Loss: 0.8036113\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.8068427443504333, mae:0.6756572723388672\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl336_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.1186665\n",
      "\tspeed: 0.1423s/iter; left time: 1092.6447s\n",
      "\titers: 200, epoch: 1 | loss: 0.1196853\n",
      "\tspeed: 0.1387s/iter; left time: 1051.8126s\n",
      "\titers: 300, epoch: 1 | loss: 0.0897109\n",
      "\tspeed: 0.1409s/iter; left time: 1054.0319s\n",
      "Epoch: 1 cost time: 55.0786874294281\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1239798 Vali Loss: 0.7080996 Test Loss: 1.5836403\n",
      "Validation loss decreased (inf --> 0.708100).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0400511\n",
      "\tspeed: 0.3498s/iter; left time: 2551.0116s\n",
      "\titers: 200, epoch: 2 | loss: 0.0275644\n",
      "\tspeed: 0.1370s/iter; left time: 985.3957s\n",
      "\titers: 300, epoch: 2 | loss: 0.0212841\n",
      "\tspeed: 0.1363s/iter; left time: 966.9928s\n",
      "Epoch: 2 cost time: 54.11231589317322\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0372996 Vali Loss: 0.5277823 Test Loss: 1.1139053\n",
      "Validation loss decreased (0.708100 --> 0.527782).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0108615\n",
      "\tspeed: 0.3388s/iter; left time: 2338.5422s\n",
      "\titers: 200, epoch: 3 | loss: 0.0115880\n",
      "\tspeed: 0.1427s/iter; left time: 970.5280s\n",
      "\titers: 300, epoch: 3 | loss: 0.0147027\n",
      "\tspeed: 0.1388s/iter; left time: 930.4986s\n",
      "Epoch: 3 cost time: 54.50358486175537\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0133125 Vali Loss: 0.5671356 Test Loss: 1.1996883\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0133007\n",
      "\tspeed: 0.3383s/iter; left time: 2203.9887s\n",
      "\titers: 200, epoch: 4 | loss: 0.0144548\n",
      "\tspeed: 0.1433s/iter; left time: 919.3122s\n",
      "\titers: 300, epoch: 4 | loss: 0.0075100\n",
      "\tspeed: 0.1443s/iter; left time: 911.1670s\n",
      "Epoch: 4 cost time: 55.53387212753296\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0098326 Vali Loss: 0.5289514 Test Loss: 1.0760512\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0092571\n",
      "\tspeed: 0.3418s/iter; left time: 2093.6460s\n",
      "\titers: 200, epoch: 5 | loss: 0.0067297\n",
      "\tspeed: 0.1450s/iter; left time: 873.4702s\n",
      "\titers: 300, epoch: 5 | loss: 0.0089560\n",
      "\tspeed: 0.1389s/iter; left time: 822.9204s\n",
      "Epoch: 5 cost time: 54.99205708503723\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0084120 Vali Loss: 0.5578831 Test Loss: 1.1527705\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:1.1128435134887695, mae:0.843783438205719\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 2, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl720_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.1584318\n",
      "\tspeed: 0.1951s/iter; left time: 1451.4889s\n",
      "\titers: 200, epoch: 1 | loss: 0.1059442\n",
      "\tspeed: 0.1915s/iter; left time: 1405.9487s\n",
      "\titers: 300, epoch: 1 | loss: 0.0939039\n",
      "\tspeed: 0.1933s/iter; left time: 1399.7322s\n",
      "Epoch: 1 cost time: 73.1161379814148\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.1337024 Vali Loss: 1.0337024 Test Loss: 2.0993080\n",
      "Validation loss decreased (inf --> 1.033702).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0871752\n",
      "\tspeed: 0.4274s/iter; left time: 3019.3417s\n",
      "\titers: 200, epoch: 2 | loss: 0.0634473\n",
      "\tspeed: 0.1943s/iter; left time: 1353.0104s\n",
      "\titers: 300, epoch: 2 | loss: 0.0583416\n",
      "\tspeed: 0.1966s/iter; left time: 1349.5666s\n",
      "Epoch: 2 cost time: 73.59724426269531\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0716132 Vali Loss: 1.0571358 Test Loss: 1.7321919\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0603775\n",
      "\tspeed: 0.4194s/iter; left time: 2804.5784s\n",
      "\titers: 200, epoch: 3 | loss: 0.0502134\n",
      "\tspeed: 0.1946s/iter; left time: 1281.5096s\n",
      "\titers: 300, epoch: 3 | loss: 0.0303482\n",
      "\tspeed: 0.1994s/iter; left time: 1293.3924s\n",
      "Epoch: 3 cost time: 72.78395390510559\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0495223 Vali Loss: 0.9839169 Test Loss: 1.5184377\n",
      "Validation loss decreased (1.033702 --> 0.983917).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0125635\n",
      "\tspeed: 0.4169s/iter; left time: 2630.4246s\n",
      "\titers: 200, epoch: 4 | loss: 0.0110092\n",
      "\tspeed: 0.1978s/iter; left time: 1228.3727s\n",
      "\titers: 300, epoch: 4 | loss: 0.0128564\n",
      "\tspeed: 0.1943s/iter; left time: 1186.9949s\n",
      "Epoch: 4 cost time: 73.45994567871094\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0151866 Vali Loss: 0.9520419 Test Loss: 1.4951420\n",
      "Validation loss decreased (0.983917 --> 0.952042).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0098301\n",
      "\tspeed: 0.4345s/iter; left time: 2577.7306s\n",
      "\titers: 200, epoch: 5 | loss: 0.0104378\n",
      "\tspeed: 0.1953s/iter; left time: 1139.3524s\n",
      "\titers: 300, epoch: 5 | loss: 0.0107805\n",
      "\tspeed: 0.1945s/iter; left time: 1115.0427s\n",
      "Epoch: 5 cost time: 73.7022078037262\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0109165 Vali Loss: 0.9467257 Test Loss: 1.5112027\n",
      "Validation loss decreased (0.952042 --> 0.946726).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0087493\n",
      "\tspeed: 0.4244s/iter; left time: 2357.8304s\n",
      "\titers: 200, epoch: 6 | loss: 0.0110718\n",
      "\tspeed: 0.1938s/iter; left time: 1057.6028s\n",
      "\titers: 300, epoch: 6 | loss: 0.0074062\n",
      "\tspeed: 0.1933s/iter; left time: 1035.3242s\n",
      "Epoch: 6 cost time: 73.03607964515686\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0096566 Vali Loss: 0.9475017 Test Loss: 1.5028032\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0110501\n",
      "\tspeed: 0.4233s/iter; left time: 2192.0825s\n",
      "\titers: 200, epoch: 7 | loss: 0.0079982\n",
      "\tspeed: 0.1958s/iter; left time: 994.7097s\n",
      "\titers: 300, epoch: 7 | loss: 0.0093553\n",
      "\tspeed: 0.1943s/iter; left time: 967.4260s\n",
      "Epoch: 7 cost time: 73.5646071434021\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0091190 Vali Loss: 0.9602391 Test Loss: 1.5516694\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0081508\n",
      "\tspeed: 0.4250s/iter; left time: 2041.0887s\n",
      "\titers: 200, epoch: 8 | loss: 0.0090481\n",
      "\tspeed: 0.1969s/iter; left time: 925.8222s\n",
      "\titers: 300, epoch: 8 | loss: 0.0080662\n",
      "\tspeed: 0.1879s/iter; left time: 864.9363s\n",
      "Epoch: 8 cost time: 72.73563170433044\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.0088577 Vali Loss: 0.9487746 Test Loss: 1.5173445\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:1.5097432136535645, mae:1.0249255895614624\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on ETTh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'M', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_ETTh1_ftM_sl168_ll48_pl24_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8449\n",
      "val 2857\n",
      "test 2857\n",
      "\titers: 100, epoch: 1 | loss: 0.3959294\n",
      "\tspeed: 0.0891s/iter; left time: 461.4574s\n",
      "\titers: 200, epoch: 1 | loss: 0.3925056\n",
      "\tspeed: 0.0923s/iter; left time: 468.9255s\n",
      "Epoch: 1 cost time: 24.045822143554688\n",
      "Epoch: 1, Steps: 264 | Train Loss: 0.4209887 Vali Loss: 0.7499394 Test Loss: 0.5918127\n",
      "Validation loss decreased (inf --> 0.749939).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2430836\n",
      "\tspeed: 0.2155s/iter; left time: 1059.6766s\n",
      "\titers: 200, epoch: 2 | loss: 0.2547334\n",
      "\tspeed: 0.0907s/iter; left time: 437.1135s\n",
      "Epoch: 2 cost time: 23.886199712753296\n",
      "Epoch: 2, Steps: 264 | Train Loss: 0.2606006 Vali Loss: 0.6999019 Test Loss: 0.6099537\n",
      "Validation loss decreased (0.749939 --> 0.699902).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2055632\n",
      "\tspeed: 0.2134s/iter; left time: 992.7943s\n",
      "\titers: 200, epoch: 3 | loss: 0.1963969\n",
      "\tspeed: 0.0904s/iter; left time: 411.8178s\n",
      "Epoch: 3 cost time: 23.889543771743774\n",
      "Epoch: 3, Steps: 264 | Train Loss: 0.1947676 Vali Loss: 0.7256826 Test Loss: 0.6947342\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1411854\n",
      "\tspeed: 0.2142s/iter; left time: 940.2997s\n",
      "\titers: 200, epoch: 4 | loss: 0.1620864\n",
      "\tspeed: 0.0905s/iter; left time: 388.1628s\n",
      "Epoch: 4 cost time: 24.041773080825806\n",
      "Epoch: 4, Steps: 264 | Train Loss: 0.1595075 Vali Loss: 0.7540212 Test Loss: 0.7252738\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1388726\n",
      "\tspeed: 0.2169s/iter; left time: 894.8763s\n",
      "\titers: 200, epoch: 5 | loss: 0.1271810\n",
      "\tspeed: 0.0918s/iter; left time: 369.4733s\n",
      "Epoch: 5 cost time: 24.128790378570557\n",
      "Epoch: 5, Steps: 264 | Train Loss: 0.1423789 Vali Loss: 0.7706507 Test Loss: 0.7875736\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "mse:0.6098174452781677, mae:0.5829904675483704\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on ETTh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'M', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_ETTh1_ftM_sl168_ll48_pl48_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8425\n",
      "val 2833\n",
      "test 2833\n",
      "\titers: 100, epoch: 1 | loss: 0.5096516\n",
      "\tspeed: 0.0953s/iter; left time: 491.8401s\n",
      "\titers: 200, epoch: 1 | loss: 0.4274790\n",
      "\tspeed: 0.0947s/iter; left time: 479.0804s\n",
      "Epoch: 1 cost time: 24.912140607833862\n",
      "Epoch: 1, Steps: 263 | Train Loss: 0.4510699 Vali Loss: 0.8426701 Test Loss: 0.7979612\n",
      "Validation loss decreased (inf --> 0.842670).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2605085\n",
      "\tspeed: 0.2215s/iter; left time: 1084.7518s\n",
      "\titers: 200, epoch: 2 | loss: 0.2633418\n",
      "\tspeed: 0.0906s/iter; left time: 434.5996s\n",
      "Epoch: 2 cost time: 23.92552399635315\n",
      "Epoch: 2, Steps: 263 | Train Loss: 0.2726096 Vali Loss: 0.7879664 Test Loss: 0.6781321\n",
      "Validation loss decreased (0.842670 --> 0.787966).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1872171\n",
      "\tspeed: 0.2027s/iter; left time: 939.5197s\n",
      "\titers: 200, epoch: 3 | loss: 0.1894364\n",
      "\tspeed: 0.0885s/iter; left time: 401.2527s\n",
      "Epoch: 3 cost time: 23.39130926132202\n",
      "Epoch: 3, Steps: 263 | Train Loss: 0.1977634 Vali Loss: 0.8383524 Test Loss: 0.7238064\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1812595\n",
      "\tspeed: 0.2217s/iter; left time: 969.1676s\n",
      "\titers: 200, epoch: 4 | loss: 0.1519629\n",
      "\tspeed: 0.0945s/iter; left time: 403.6525s\n",
      "Epoch: 4 cost time: 24.4559383392334\n",
      "Epoch: 4, Steps: 263 | Train Loss: 0.1694381 Vali Loss: 0.8428419 Test Loss: 0.7444069\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1580450\n",
      "\tspeed: 0.2067s/iter; left time: 849.1781s\n",
      "\titers: 200, epoch: 5 | loss: 0.1542019\n",
      "\tspeed: 0.0913s/iter; left time: 365.8851s\n",
      "Epoch: 5 cost time: 23.70999312400818\n",
      "Epoch: 5, Steps: 263 | Train Loss: 0.1557095 Vali Loss: 0.8512684 Test Loss: 0.7508928\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 7) (88, 32, 48, 7)\n",
      "test shape: (2816, 48, 7) (2816, 48, 7)\n",
      "mse:0.6778011322021484, mae:0.6232616901397705\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on ETTh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'M', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_ETTh1_ftM_sl168_ll48_pl168_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8305\n",
      "val 2713\n",
      "test 2713\n",
      "\titers: 100, epoch: 1 | loss: 0.4760758\n",
      "\tspeed: 0.1474s/iter; left time: 749.1644s\n",
      "\titers: 200, epoch: 1 | loss: 0.4858489\n",
      "\tspeed: 0.1468s/iter; left time: 731.0729s\n",
      "Epoch: 1 cost time: 37.54584813117981\n",
      "Epoch: 1, Steps: 259 | Train Loss: 0.5165741 Vali Loss: 1.3563150 Test Loss: 1.0070078\n",
      "Validation loss decreased (inf --> 1.356315).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3953726\n",
      "\tspeed: 0.3868s/iter; left time: 1865.1757s\n",
      "\titers: 200, epoch: 2 | loss: 0.3163360\n",
      "\tspeed: 0.1480s/iter; left time: 698.7722s\n",
      "Epoch: 2 cost time: 38.23230290412903\n",
      "Epoch: 2, Steps: 259 | Train Loss: 0.3822912 Vali Loss: 1.1023973 Test Loss: 0.7732230\n",
      "Validation loss decreased (1.356315 --> 1.102397).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2398285\n",
      "\tspeed: 0.3793s/iter; left time: 1730.8734s\n",
      "\titers: 200, epoch: 3 | loss: 0.2024239\n",
      "\tspeed: 0.1454s/iter; left time: 648.9071s\n",
      "Epoch: 3 cost time: 37.760947704315186\n",
      "Epoch: 3, Steps: 259 | Train Loss: 0.2342309 Vali Loss: 1.1100219 Test Loss: 0.7750941\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2019347\n",
      "\tspeed: 0.3767s/iter; left time: 1621.1595s\n",
      "\titers: 200, epoch: 4 | loss: 0.1956258\n",
      "\tspeed: 0.1458s/iter; left time: 612.8493s\n",
      "Epoch: 4 cost time: 37.31002616882324\n",
      "Epoch: 4, Steps: 259 | Train Loss: 0.1990256 Vali Loss: 1.1276280 Test Loss: 0.8098598\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1921108\n",
      "\tspeed: 0.3911s/iter; left time: 1581.8112s\n",
      "\titers: 200, epoch: 5 | loss: 0.1838749\n",
      "\tspeed: 0.1445s/iter; left time: 569.9976s\n",
      "Epoch: 5 cost time: 36.35221457481384\n",
      "Epoch: 5, Steps: 259 | Train Loss: 0.1861373 Vali Loss: 1.1475710 Test Loss: 0.8076323\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 7) (84, 32, 168, 7)\n",
      "test shape: (2688, 168, 7) (2688, 168, 7)\n",
      "mse:0.7729138731956482, mae:0.6679147481918335\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on ETTh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'M', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_ETTh1_ftM_sl168_ll48_pl336_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8137\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.5486797\n",
      "\tspeed: 0.1658s/iter; left time: 825.8767s\n",
      "\titers: 200, epoch: 1 | loss: 0.4286678\n",
      "\tspeed: 0.1733s/iter; left time: 845.9274s\n",
      "Epoch: 1 cost time: 43.485082149505615\n",
      "Epoch: 1, Steps: 254 | Train Loss: 0.5234414 Vali Loss: 1.5366596 Test Loss: 1.0811106\n",
      "Validation loss decreased (inf --> 1.536660).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4294099\n",
      "\tspeed: 0.4355s/iter; left time: 2058.4099s\n",
      "\titers: 200, epoch: 2 | loss: 0.3851319\n",
      "\tspeed: 0.1749s/iter; left time: 809.1479s\n",
      "Epoch: 2 cost time: 44.19653344154358\n",
      "Epoch: 2, Steps: 254 | Train Loss: 0.4347508 Vali Loss: 1.5223320 Test Loss: 1.1218393\n",
      "Validation loss decreased (1.536660 --> 1.522332).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3757828\n",
      "\tspeed: 0.4459s/iter; left time: 1994.6124s\n",
      "\titers: 200, epoch: 3 | loss: 0.3386756\n",
      "\tspeed: 0.1688s/iter; left time: 738.1658s\n",
      "Epoch: 3 cost time: 44.241929054260254\n",
      "Epoch: 3, Steps: 254 | Train Loss: 0.3786385 Vali Loss: 1.3715984 Test Loss: 1.2133710\n",
      "Validation loss decreased (1.522332 --> 1.371598).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2742570\n",
      "\tspeed: 0.4552s/iter; left time: 1920.3602s\n",
      "\titers: 200, epoch: 4 | loss: 0.2767752\n",
      "\tspeed: 0.1617s/iter; left time: 666.1363s\n",
      "Epoch: 4 cost time: 42.89470458030701\n",
      "Epoch: 4, Steps: 254 | Train Loss: 0.2801992 Vali Loss: 1.3356078 Test Loss: 1.0468303\n",
      "Validation loss decreased (1.371598 --> 1.335608).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2438316\n",
      "\tspeed: 0.4287s/iter; left time: 1699.8747s\n",
      "\titers: 200, epoch: 5 | loss: 0.2450002\n",
      "\tspeed: 0.1678s/iter; left time: 648.4885s\n",
      "Epoch: 5 cost time: 43.06055402755737\n",
      "Epoch: 5, Steps: 254 | Train Loss: 0.2497444 Vali Loss: 1.3141905 Test Loss: 1.0037564\n",
      "Validation loss decreased (1.335608 --> 1.314191).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2455850\n",
      "\tspeed: 0.4458s/iter; left time: 1654.4398s\n",
      "\titers: 200, epoch: 6 | loss: 0.2411518\n",
      "\tspeed: 0.1704s/iter; left time: 615.2542s\n",
      "Epoch: 6 cost time: 44.73305630683899\n",
      "Epoch: 6, Steps: 254 | Train Loss: 0.2392572 Vali Loss: 1.3231392 Test Loss: 1.0241195\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2382100\n",
      "\tspeed: 0.4302s/iter; left time: 1487.2197s\n",
      "\titers: 200, epoch: 7 | loss: 0.2399936\n",
      "\tspeed: 0.1731s/iter; left time: 581.1412s\n",
      "Epoch: 7 cost time: 43.29399633407593\n",
      "Epoch: 7, Steps: 254 | Train Loss: 0.2345790 Vali Loss: 1.3209261 Test Loss: 1.0164584\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2278561\n",
      "\tspeed: 0.4297s/iter; left time: 1376.2929s\n",
      "\titers: 200, epoch: 8 | loss: 0.2281778\n",
      "\tspeed: 0.1694s/iter; left time: 525.8019s\n",
      "Epoch: 8 cost time: 42.89304566383362\n",
      "Epoch: 8, Steps: 254 | Train Loss: 0.2322058 Vali Loss: 1.3236465 Test Loss: 0.9953815\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 7) (79, 32, 336, 7)\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "mse:1.0048785209655762, mae:0.7597531676292419\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on ETTh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'M', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_ETTh1_ftM_sl168_ll48_pl720_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7753\n",
      "val 2161\n",
      "test 2161\n",
      "\titers: 100, epoch: 1 | loss: 0.5005845\n",
      "\tspeed: 0.2321s/iter; left time: 1100.2300s\n",
      "\titers: 200, epoch: 1 | loss: 0.4626971\n",
      "\tspeed: 0.2252s/iter; left time: 1045.1805s\n",
      "Epoch: 1 cost time: 55.26003956794739\n",
      "Epoch: 1, Steps: 242 | Train Loss: 0.5289072 Vali Loss: 1.6708537 Test Loss: 1.2524824\n",
      "Validation loss decreased (inf --> 1.670854).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4423320\n",
      "\tspeed: 0.5069s/iter; left time: 2280.3764s\n",
      "\titers: 200, epoch: 2 | loss: 0.4299708\n",
      "\tspeed: 0.2247s/iter; left time: 988.3673s\n",
      "Epoch: 2 cost time: 54.77299404144287\n",
      "Epoch: 2, Steps: 242 | Train Loss: 0.4461914 Vali Loss: 1.6310357 Test Loss: 1.2840385\n",
      "Validation loss decreased (1.670854 --> 1.631036).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4308802\n",
      "\tspeed: 0.4989s/iter; left time: 2123.6660s\n",
      "\titers: 200, epoch: 3 | loss: 0.3991117\n",
      "\tspeed: 0.2319s/iter; left time: 963.8346s\n",
      "Epoch: 3 cost time: 55.34836268424988\n",
      "Epoch: 3, Steps: 242 | Train Loss: 0.4148105 Vali Loss: 1.6404673 Test Loss: 1.2713228\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4501023\n",
      "\tspeed: 0.4857s/iter; left time: 1950.1334s\n",
      "\titers: 200, epoch: 4 | loss: 0.3381703\n",
      "\tspeed: 0.2325s/iter; left time: 910.3135s\n",
      "Epoch: 4 cost time: 55.03633904457092\n",
      "Epoch: 4, Steps: 242 | Train Loss: 0.4007768 Vali Loss: 1.6343077 Test Loss: 1.3070211\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4455584\n",
      "\tspeed: 0.5030s/iter; left time: 1897.6337s\n",
      "\titers: 200, epoch: 5 | loss: 0.4033179\n",
      "\tspeed: 0.2283s/iter; left time: 838.5644s\n",
      "Epoch: 5 cost time: 54.81059241294861\n",
      "Epoch: 5, Steps: 242 | Train Loss: 0.3939746 Vali Loss: 1.6318551 Test Loss: 1.2389259\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 7) (67, 32, 720, 7)\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "mse:1.2839438915252686, mae:0.9131882190704346\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on DEWINDh_small with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_DEWINDh_small_ftS_sl168_ll48_pl24_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.2342571\n",
      "\tspeed: 0.0852s/iter; left time: 671.5514s\n",
      "\titers: 200, epoch: 1 | loss: 0.1326926\n",
      "\tspeed: 0.0835s/iter; left time: 650.0631s\n",
      "\titers: 300, epoch: 1 | loss: 0.1338814\n",
      "\tspeed: 0.0825s/iter; left time: 633.4201s\n",
      "Epoch: 1 cost time: 33.43373703956604\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.2798173 Vali Loss: 0.1494075 Test Loss: 0.1196126\n",
      "Validation loss decreased (inf --> 0.149407).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1239098\n",
      "\tspeed: 0.2046s/iter; left time: 1530.8814s\n",
      "\titers: 200, epoch: 2 | loss: 0.1529272\n",
      "\tspeed: 0.0800s/iter; left time: 590.5386s\n",
      "\titers: 300, epoch: 2 | loss: 0.1507877\n",
      "\tspeed: 0.0807s/iter; left time: 587.6072s\n",
      "Epoch: 2 cost time: 32.45258164405823\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.1359759 Vali Loss: 0.1537978 Test Loss: 0.0996295\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1439369\n",
      "\tspeed: 0.1984s/iter; left time: 1405.3395s\n",
      "\titers: 200, epoch: 3 | loss: 0.1497024\n",
      "\tspeed: 0.0835s/iter; left time: 583.0246s\n",
      "\titers: 300, epoch: 3 | loss: 0.0986108\n",
      "\tspeed: 0.0827s/iter; left time: 569.3314s\n",
      "Epoch: 3 cost time: 32.88504672050476\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.1098382 Vali Loss: 0.1351777 Test Loss: 0.0916907\n",
      "Validation loss decreased (0.149407 --> 0.135178).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1080145\n",
      "\tspeed: 0.2052s/iter; left time: 1371.6858s\n",
      "\titers: 200, epoch: 4 | loss: 0.1129579\n",
      "\tspeed: 0.0814s/iter; left time: 535.6493s\n",
      "\titers: 300, epoch: 4 | loss: 0.0884067\n",
      "\tspeed: 0.0817s/iter; left time: 529.6163s\n",
      "Epoch: 4 cost time: 32.92323327064514\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0934900 Vali Loss: 0.1292382 Test Loss: 0.0920144\n",
      "Validation loss decreased (0.135178 --> 0.129238).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0891856\n",
      "\tspeed: 0.2006s/iter; left time: 1260.7324s\n",
      "\titers: 200, epoch: 5 | loss: 0.0866517\n",
      "\tspeed: 0.0812s/iter; left time: 502.3499s\n",
      "\titers: 300, epoch: 5 | loss: 0.1113002\n",
      "\tspeed: 0.0813s/iter; left time: 494.5105s\n",
      "Epoch: 5 cost time: 32.50397205352783\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0819076 Vali Loss: 0.1320841 Test Loss: 0.0906671\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0793967\n",
      "\tspeed: 0.2040s/iter; left time: 1200.5956s\n",
      "\titers: 200, epoch: 6 | loss: 0.0680807\n",
      "\tspeed: 0.0842s/iter; left time: 487.2043s\n",
      "\titers: 300, epoch: 6 | loss: 0.0810109\n",
      "\tspeed: 0.0828s/iter; left time: 470.8182s\n",
      "Epoch: 6 cost time: 33.379499673843384\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0745876 Vali Loss: 0.1408133 Test Loss: 0.0889472\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0499717\n",
      "\tspeed: 0.2025s/iter; left time: 1111.1081s\n",
      "\titers: 200, epoch: 7 | loss: 0.0843361\n",
      "\tspeed: 0.0847s/iter; left time: 456.4877s\n",
      "\titers: 300, epoch: 7 | loss: 0.0540269\n",
      "\tspeed: 0.0836s/iter; left time: 441.8894s\n",
      "Epoch: 7 cost time: 33.03670120239258\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0713751 Vali Loss: 0.1389565 Test Loss: 0.0894792\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.09217752516269684, mae:0.1634521633386612\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on DEWINDh_small with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_DEWINDh_small_ftS_sl168_ll48_pl48_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.3118103\n",
      "\tspeed: 0.0860s/iter; left time: 676.2342s\n",
      "\titers: 200, epoch: 1 | loss: 0.1757418\n",
      "\tspeed: 0.0860s/iter; left time: 667.3619s\n",
      "\titers: 300, epoch: 1 | loss: 0.1313552\n",
      "\tspeed: 0.0848s/iter; left time: 649.7767s\n",
      "Epoch: 1 cost time: 34.13902711868286\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.2701072 Vali Loss: 0.1823238 Test Loss: 0.1277973\n",
      "Validation loss decreased (inf --> 0.182324).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1721987\n",
      "\tspeed: 0.2103s/iter; left time: 1569.2447s\n",
      "\titers: 200, epoch: 2 | loss: 0.1320051\n",
      "\tspeed: 0.0857s/iter; left time: 631.3127s\n",
      "\titers: 300, epoch: 2 | loss: 0.1460656\n",
      "\tspeed: 0.0809s/iter; left time: 587.3721s\n",
      "Epoch: 2 cost time: 33.368672370910645\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.1465739 Vali Loss: 0.1755656 Test Loss: 0.1255164\n",
      "Validation loss decreased (0.182324 --> 0.175566).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1673447\n",
      "\tspeed: 0.2045s/iter; left time: 1444.8671s\n",
      "\titers: 200, epoch: 3 | loss: 0.1413429\n",
      "\tspeed: 0.0832s/iter; left time: 579.6814s\n",
      "\titers: 300, epoch: 3 | loss: 0.1076416\n",
      "\tspeed: 0.0836s/iter; left time: 574.0484s\n",
      "Epoch: 3 cost time: 33.53196048736572\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.1196944 Vali Loss: 0.1611675 Test Loss: 0.1283418\n",
      "Validation loss decreased (0.175566 --> 0.161168).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0992833\n",
      "\tspeed: 0.2101s/iter; left time: 1400.9303s\n",
      "\titers: 200, epoch: 4 | loss: 0.1160891\n",
      "\tspeed: 0.0817s/iter; left time: 536.3138s\n",
      "\titers: 300, epoch: 4 | loss: 0.1008638\n",
      "\tspeed: 0.0833s/iter; left time: 538.4414s\n",
      "Epoch: 4 cost time: 33.216532945632935\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.1038699 Vali Loss: 0.1712718 Test Loss: 0.1092481\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0806907\n",
      "\tspeed: 0.2035s/iter; left time: 1275.8337s\n",
      "\titers: 200, epoch: 5 | loss: 0.1148252\n",
      "\tspeed: 0.0830s/iter; left time: 512.0685s\n",
      "\titers: 300, epoch: 5 | loss: 0.0755803\n",
      "\tspeed: 0.0890s/iter; left time: 540.1912s\n",
      "Epoch: 5 cost time: 34.05538892745972\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0934580 Vali Loss: 0.1731375 Test Loss: 0.1128795\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1018693\n",
      "\tspeed: 0.2063s/iter; left time: 1211.0731s\n",
      "\titers: 200, epoch: 6 | loss: 0.0904590\n",
      "\tspeed: 0.0833s/iter; left time: 480.6759s\n",
      "\titers: 300, epoch: 6 | loss: 0.1007018\n",
      "\tspeed: 0.0833s/iter; left time: 472.1612s\n",
      "Epoch: 6 cost time: 33.22438287734985\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0879544 Vali Loss: 0.1776410 Test Loss: 0.1157347\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.12818343937397003, mae:0.19312262535095215\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on DEWINDh_small with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_DEWINDh_small_ftS_sl168_ll48_pl168_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.3731507\n",
      "\tspeed: 0.1118s/iter; left time: 869.9524s\n",
      "\titers: 200, epoch: 1 | loss: 0.2006236\n",
      "\tspeed: 0.1147s/iter; left time: 881.0145s\n",
      "\titers: 300, epoch: 1 | loss: 0.1748046\n",
      "\tspeed: 0.1145s/iter; left time: 868.0790s\n",
      "Epoch: 1 cost time: 44.64084243774414\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.3606934 Vali Loss: 0.1956107 Test Loss: 0.1514788\n",
      "Validation loss decreased (inf --> 0.195611).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1792036\n",
      "\tspeed: 0.2816s/iter; left time: 2080.1541s\n",
      "\titers: 200, epoch: 2 | loss: 0.1441642\n",
      "\tspeed: 0.1154s/iter; left time: 840.5783s\n",
      "\titers: 300, epoch: 2 | loss: 0.1724436\n",
      "\tspeed: 0.1217s/iter; left time: 874.4984s\n",
      "Epoch: 2 cost time: 45.618279695510864\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.1572194 Vali Loss: 0.2032263 Test Loss: 0.1407205\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1426393\n",
      "\tspeed: 0.2829s/iter; left time: 1978.1055s\n",
      "\titers: 200, epoch: 3 | loss: 0.1313301\n",
      "\tspeed: 0.1141s/iter; left time: 786.6823s\n",
      "\titers: 300, epoch: 3 | loss: 0.1172978\n",
      "\tspeed: 0.1140s/iter; left time: 774.7318s\n",
      "Epoch: 3 cost time: 44.82547736167908\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.1372328 Vali Loss: 0.1990386 Test Loss: 0.1327850\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1360203\n",
      "\tspeed: 0.2780s/iter; left time: 1834.3191s\n",
      "\titers: 200, epoch: 4 | loss: 0.1138347\n",
      "\tspeed: 0.1112s/iter; left time: 722.7343s\n",
      "\titers: 300, epoch: 4 | loss: 0.1094904\n",
      "\tspeed: 0.1115s/iter; left time: 713.4773s\n",
      "Epoch: 4 cost time: 43.7607524394989\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.1250629 Vali Loss: 0.1754915 Test Loss: 0.1195521\n",
      "Validation loss decreased (0.195611 --> 0.175491).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1163726\n",
      "\tspeed: 0.2825s/iter; left time: 1753.0171s\n",
      "\titers: 200, epoch: 5 | loss: 0.1055234\n",
      "\tspeed: 0.1115s/iter; left time: 680.6123s\n",
      "\titers: 300, epoch: 5 | loss: 0.0954389\n",
      "\tspeed: 0.1109s/iter; left time: 666.2318s\n",
      "Epoch: 5 cost time: 44.01708126068115\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.1160198 Vali Loss: 0.1904362 Test Loss: 0.1212984\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1308563\n",
      "\tspeed: 0.2769s/iter; left time: 1609.2037s\n",
      "\titers: 200, epoch: 6 | loss: 0.1070116\n",
      "\tspeed: 0.1121s/iter; left time: 640.3678s\n",
      "\titers: 300, epoch: 6 | loss: 0.1049578\n",
      "\tspeed: 0.1125s/iter; left time: 631.4612s\n",
      "Epoch: 6 cost time: 44.012179374694824\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.1103649 Vali Loss: 0.1846629 Test Loss: 0.1177700\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1059084\n",
      "\tspeed: 0.2757s/iter; left time: 1493.3135s\n",
      "\titers: 200, epoch: 7 | loss: 0.1179656\n",
      "\tspeed: 0.1101s/iter; left time: 585.3425s\n",
      "\titers: 300, epoch: 7 | loss: 0.1038472\n",
      "\tspeed: 0.1155s/iter; left time: 602.5254s\n",
      "Epoch: 7 cost time: 44.74456429481506\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.1072293 Vali Loss: 0.1800070 Test Loss: 0.1182581\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.11923990398645401, mae:0.17331303656101227\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on DEWINDh_small with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_DEWINDh_small_ftS_sl168_ll48_pl336_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.6416976\n",
      "\tspeed: 0.1468s/iter; left time: 1127.8634s\n",
      "\titers: 200, epoch: 1 | loss: 0.1934649\n",
      "\tspeed: 0.1466s/iter; left time: 1111.6078s\n",
      "\titers: 300, epoch: 1 | loss: 0.2113533\n",
      "\tspeed: 0.1431s/iter; left time: 1070.4387s\n",
      "Epoch: 1 cost time: 55.89592695236206\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.3862973 Vali Loss: 0.1970418 Test Loss: 0.1602557\n",
      "Validation loss decreased (inf --> 0.197042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1652640\n",
      "\tspeed: 0.3402s/iter; left time: 2480.5598s\n",
      "\titers: 200, epoch: 2 | loss: 0.1410236\n",
      "\tspeed: 0.1381s/iter; left time: 993.0055s\n",
      "\titers: 300, epoch: 2 | loss: 0.1482910\n",
      "\tspeed: 0.1402s/iter; left time: 994.0791s\n",
      "Epoch: 2 cost time: 55.29107046127319\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.1601575 Vali Loss: 0.1868398 Test Loss: 0.1513315\n",
      "Validation loss decreased (0.197042 --> 0.186840).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1462536\n",
      "\tspeed: 0.3544s/iter; left time: 2446.5243s\n",
      "\titers: 200, epoch: 3 | loss: 0.1339526\n",
      "\tspeed: 0.1451s/iter; left time: 986.9996s\n",
      "\titers: 300, epoch: 3 | loss: 0.1273523\n",
      "\tspeed: 0.1448s/iter; left time: 970.5964s\n",
      "Epoch: 3 cost time: 55.92637300491333\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.1417035 Vali Loss: 0.1827696 Test Loss: 0.1493465\n",
      "Validation loss decreased (0.186840 --> 0.182770).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1235528\n",
      "\tspeed: 0.3393s/iter; left time: 2210.5156s\n",
      "\titers: 200, epoch: 4 | loss: 0.1308063\n",
      "\tspeed: 0.1391s/iter; left time: 892.4740s\n",
      "\titers: 300, epoch: 4 | loss: 0.1006948\n",
      "\tspeed: 0.1394s/iter; left time: 880.2120s\n",
      "Epoch: 4 cost time: 53.99850368499756\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.1278268 Vali Loss: 0.1786285 Test Loss: 0.1462633\n",
      "Validation loss decreased (0.182770 --> 0.178629).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1062930\n",
      "\tspeed: 0.3377s/iter; left time: 2068.1208s\n",
      "\titers: 200, epoch: 5 | loss: 0.1138979\n",
      "\tspeed: 0.1426s/iter; left time: 859.3553s\n",
      "\titers: 300, epoch: 5 | loss: 0.1116258\n",
      "\tspeed: 0.1413s/iter; left time: 837.1058s\n",
      "Epoch: 5 cost time: 54.98148703575134\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.1161468 Vali Loss: 0.1858451 Test Loss: 0.1461278\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1194132\n",
      "\tspeed: 0.3364s/iter; left time: 1929.6309s\n",
      "\titers: 200, epoch: 6 | loss: 0.1025288\n",
      "\tspeed: 0.1439s/iter; left time: 810.8850s\n",
      "\titers: 300, epoch: 6 | loss: 0.1193746\n",
      "\tspeed: 0.1404s/iter; left time: 777.0602s\n",
      "Epoch: 6 cost time: 55.264965534210205\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.1081987 Vali Loss: 0.1854225 Test Loss: 0.1478679\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1006990\n",
      "\tspeed: 0.3443s/iter; left time: 1841.2308s\n",
      "\titers: 200, epoch: 7 | loss: 0.1132256\n",
      "\tspeed: 0.1398s/iter; left time: 733.5811s\n",
      "\titers: 300, epoch: 7 | loss: 0.1175832\n",
      "\tspeed: 0.1430s/iter; left time: 736.2146s\n",
      "Epoch: 7 cost time: 55.46640753746033\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.1042192 Vali Loss: 0.1878647 Test Loss: 0.1498454\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.14633294939994812, mae:0.18437108397483826\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on DEWINDh_small with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_DEWINDh_small_ftS_sl168_ll48_pl720_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.9255087\n",
      "\tspeed: 0.1919s/iter; left time: 1428.2449s\n",
      "\titers: 200, epoch: 1 | loss: 0.5779694\n",
      "\tspeed: 0.1913s/iter; left time: 1404.4863s\n",
      "\titers: 300, epoch: 1 | loss: 0.1976005\n",
      "\tspeed: 0.1929s/iter; left time: 1396.6327s\n",
      "Epoch: 1 cost time: 72.78654026985168\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.6196037 Vali Loss: 0.2137297 Test Loss: 0.1631086\n",
      "Validation loss decreased (inf --> 0.213730).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1509124\n",
      "\tspeed: 0.4256s/iter; left time: 3006.2665s\n",
      "\titers: 200, epoch: 2 | loss: 0.1738576\n",
      "\tspeed: 0.1926s/iter; left time: 1341.5429s\n",
      "\titers: 300, epoch: 2 | loss: 0.1620038\n",
      "\tspeed: 0.2012s/iter; left time: 1380.9858s\n",
      "Epoch: 2 cost time: 73.73312783241272\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.1708182 Vali Loss: 0.1943917 Test Loss: 0.1478026\n",
      "Validation loss decreased (0.213730 --> 0.194392).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1436988\n",
      "\tspeed: 0.4258s/iter; left time: 2847.3819s\n",
      "\titers: 200, epoch: 3 | loss: 0.1447031\n",
      "\tspeed: 0.2000s/iter; left time: 1317.4180s\n",
      "\titers: 300, epoch: 3 | loss: 0.1393002\n",
      "\tspeed: 0.1991s/iter; left time: 1291.5550s\n",
      "Epoch: 3 cost time: 73.94508671760559\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.1535159 Vali Loss: 0.1939798 Test Loss: 0.1347186\n",
      "Validation loss decreased (0.194392 --> 0.193980).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1516993\n",
      "\tspeed: 0.4273s/iter; left time: 2696.2449s\n",
      "\titers: 200, epoch: 4 | loss: 0.1456342\n",
      "\tspeed: 0.1998s/iter; left time: 1240.4623s\n",
      "\titers: 300, epoch: 4 | loss: 0.1480450\n",
      "\tspeed: 0.1995s/iter; left time: 1219.2082s\n",
      "Epoch: 4 cost time: 74.62861824035645\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.1451062 Vali Loss: 0.1942770 Test Loss: 0.1325922\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1271140\n",
      "\tspeed: 0.4159s/iter; left time: 2467.7355s\n",
      "\titers: 200, epoch: 5 | loss: 0.1291268\n",
      "\tspeed: 0.1967s/iter; left time: 1147.3435s\n",
      "\titers: 300, epoch: 5 | loss: 0.1368720\n",
      "\tspeed: 0.1939s/iter; left time: 1111.7657s\n",
      "Epoch: 5 cost time: 72.74223160743713\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.1396968 Vali Loss: 0.1949900 Test Loss: 0.1294352\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1316512\n",
      "\tspeed: 0.4179s/iter; left time: 2321.8421s\n",
      "\titers: 200, epoch: 6 | loss: 0.1356839\n",
      "\tspeed: 0.1937s/iter; left time: 1056.9971s\n",
      "\titers: 300, epoch: 6 | loss: 0.1295524\n",
      "\tspeed: 0.1909s/iter; left time: 1022.5282s\n",
      "Epoch: 6 cost time: 73.02812361717224\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.1356604 Vali Loss: 0.1947480 Test Loss: 0.1296416\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.13478423655033112, mae:0.18251988291740417\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTHh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTHh1_ftS_sl168_ll48_pl24_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.1385587\n",
      "\tspeed: 0.0825s/iter; left time: 650.1386s\n",
      "\titers: 200, epoch: 1 | loss: 0.0548813\n",
      "\tspeed: 0.0832s/iter; left time: 647.1385s\n",
      "\titers: 300, epoch: 1 | loss: 0.0492933\n",
      "\tspeed: 0.0804s/iter; left time: 617.9029s\n",
      "Epoch: 1 cost time: 32.81384992599487\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.1425301 Vali Loss: 0.0396113 Test Loss: 0.0457503\n",
      "Validation loss decreased (inf --> 0.039611).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0258129\n",
      "\tspeed: 0.2014s/iter; left time: 1507.0184s\n",
      "\titers: 200, epoch: 2 | loss: 0.0295163\n",
      "\tspeed: 0.0826s/iter; left time: 610.0396s\n",
      "\titers: 300, epoch: 2 | loss: 0.0291498\n",
      "\tspeed: 0.0859s/iter; left time: 625.8753s\n",
      "Epoch: 2 cost time: 33.240447759628296\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0300546 Vali Loss: 0.0279234 Test Loss: 0.0307074\n",
      "Validation loss decreased (0.039611 --> 0.027923).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0263225\n",
      "\tspeed: 0.2035s/iter; left time: 1441.6213s\n",
      "\titers: 200, epoch: 3 | loss: 0.0222599\n",
      "\tspeed: 0.0789s/iter; left time: 550.7069s\n",
      "\titers: 300, epoch: 3 | loss: 0.0274424\n",
      "\tspeed: 0.0811s/iter; left time: 558.1823s\n",
      "Epoch: 3 cost time: 32.123823404312134\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0220829 Vali Loss: 0.0240627 Test Loss: 0.0274715\n",
      "Validation loss decreased (0.027923 --> 0.024063).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0181317\n",
      "\tspeed: 0.2011s/iter; left time: 1344.0123s\n",
      "\titers: 200, epoch: 4 | loss: 0.0209294\n",
      "\tspeed: 0.0845s/iter; left time: 556.0831s\n",
      "\titers: 300, epoch: 4 | loss: 0.0199051\n",
      "\tspeed: 0.0845s/iter; left time: 548.0676s\n",
      "Epoch: 4 cost time: 33.396305561065674\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0187619 Vali Loss: 0.0212218 Test Loss: 0.0236470\n",
      "Validation loss decreased (0.024063 --> 0.021222).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0204581\n",
      "\tspeed: 0.1982s/iter; left time: 1245.4346s\n",
      "\titers: 200, epoch: 5 | loss: 0.0161403\n",
      "\tspeed: 0.0809s/iter; left time: 500.5394s\n",
      "\titers: 300, epoch: 5 | loss: 0.0155734\n",
      "\tspeed: 0.0796s/iter; left time: 484.0835s\n",
      "Epoch: 5 cost time: 31.948642253875732\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0175227 Vali Loss: 0.0196465 Test Loss: 0.0213873\n",
      "Validation loss decreased (0.021222 --> 0.019647).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0193503\n",
      "\tspeed: 0.2025s/iter; left time: 1191.8273s\n",
      "\titers: 200, epoch: 6 | loss: 0.0177214\n",
      "\tspeed: 0.0822s/iter; left time: 475.7948s\n",
      "\titers: 300, epoch: 6 | loss: 0.0162295\n",
      "\tspeed: 0.0829s/iter; left time: 471.4258s\n",
      "Epoch: 6 cost time: 32.85561394691467\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0169520 Vali Loss: 0.0189876 Test Loss: 0.0209856\n",
      "Validation loss decreased (0.019647 --> 0.018988).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0151894\n",
      "\tspeed: 0.1985s/iter; left time: 1089.4014s\n",
      "\titers: 200, epoch: 7 | loss: 0.0159147\n",
      "\tspeed: 0.0810s/iter; left time: 436.5336s\n",
      "\titers: 300, epoch: 7 | loss: 0.0165370\n",
      "\tspeed: 0.0828s/iter; left time: 437.8534s\n",
      "Epoch: 7 cost time: 32.75242209434509\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0166129 Vali Loss: 0.0197348 Test Loss: 0.0218671\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0149954\n",
      "\tspeed: 0.2023s/iter; left time: 1029.4387s\n",
      "\titers: 200, epoch: 8 | loss: 0.0154038\n",
      "\tspeed: 0.0827s/iter; left time: 412.6490s\n",
      "\titers: 300, epoch: 8 | loss: 0.0165617\n",
      "\tspeed: 0.0809s/iter; left time: 395.6380s\n",
      "Epoch: 8 cost time: 32.67867350578308\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0164098 Vali Loss: 0.0186660 Test Loss: 0.0209657\n",
      "Validation loss decreased (0.018988 --> 0.018666).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0158141\n",
      "\tspeed: 0.1999s/iter; left time: 937.1362s\n",
      "\titers: 200, epoch: 9 | loss: 0.0168008\n",
      "\tspeed: 0.0811s/iter; left time: 372.2982s\n",
      "\titers: 300, epoch: 9 | loss: 0.0155598\n",
      "\tspeed: 0.0814s/iter; left time: 365.2029s\n",
      "Epoch: 9 cost time: 32.41492247581482\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0162764 Vali Loss: 0.0188494 Test Loss: 0.0209128\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0178043\n",
      "\tspeed: 0.1971s/iter; left time: 845.7628s\n",
      "\titers: 200, epoch: 10 | loss: 0.0197560\n",
      "\tspeed: 0.0840s/iter; left time: 351.8905s\n",
      "\titers: 300, epoch: 10 | loss: 0.0143480\n",
      "\tspeed: 0.0853s/iter; left time: 348.6936s\n",
      "Epoch: 10 cost time: 33.36870098114014\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0161873 Vali Loss: 0.0184443 Test Loss: 0.0205588\n",
      "Validation loss decreased (0.018666 --> 0.018444).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0169888\n",
      "\tspeed: 0.2083s/iter; left time: 810.4008s\n",
      "\titers: 200, epoch: 11 | loss: 0.0156219\n",
      "\tspeed: 0.0848s/iter; left time: 321.4473s\n",
      "\titers: 300, epoch: 11 | loss: 0.0151664\n",
      "\tspeed: 0.0851s/iter; left time: 314.2872s\n",
      "Epoch: 11 cost time: 33.98357152938843\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0162068 Vali Loss: 0.0186830 Test Loss: 0.0209630\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0161510\n",
      "\tspeed: 0.2048s/iter; left time: 715.1599s\n",
      "\titers: 200, epoch: 12 | loss: 0.0150393\n",
      "\tspeed: 0.0752s/iter; left time: 255.1221s\n",
      "\titers: 300, epoch: 12 | loss: 0.0206994\n",
      "\tspeed: 0.0788s/iter; left time: 259.5453s\n",
      "Epoch: 12 cost time: 31.69704794883728\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0161815 Vali Loss: 0.0188475 Test Loss: 0.0210472\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0153857\n",
      "\tspeed: 0.1983s/iter; left time: 613.3108s\n",
      "\titers: 200, epoch: 13 | loss: 0.0169184\n",
      "\tspeed: 0.0829s/iter; left time: 248.2238s\n",
      "\titers: 300, epoch: 13 | loss: 0.0136228\n",
      "\tspeed: 0.0826s/iter; left time: 238.8202s\n",
      "Epoch: 13 cost time: 32.768359661102295\n",
      "Epoch: 13, Steps: 399 | Train Loss: 0.0160949 Vali Loss: 0.0188302 Test Loss: 0.0212424\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.020342199131846428, mae:0.11310264468193054\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTHh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTHh1_ftS_sl168_ll48_pl48_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.2939665\n",
      "\tspeed: 0.0821s/iter; left time: 645.7541s\n",
      "\titers: 200, epoch: 1 | loss: 0.0673346\n",
      "\tspeed: 0.0830s/iter; left time: 644.4025s\n",
      "\titers: 300, epoch: 1 | loss: 0.0790553\n",
      "\tspeed: 0.0830s/iter; left time: 635.9298s\n",
      "Epoch: 1 cost time: 33.03925347328186\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.1966636 Vali Loss: 0.0622008 Test Loss: 0.0703715\n",
      "Validation loss decreased (inf --> 0.062201).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0352479\n",
      "\tspeed: 0.2042s/iter; left time: 1524.2099s\n",
      "\titers: 200, epoch: 2 | loss: 0.0526814\n",
      "\tspeed: 0.0836s/iter; left time: 615.4335s\n",
      "\titers: 300, epoch: 2 | loss: 0.0343213\n",
      "\tspeed: 0.0879s/iter; left time: 638.1769s\n",
      "Epoch: 2 cost time: 33.891746044158936\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0411066 Vali Loss: 0.0401039 Test Loss: 0.0445990\n",
      "Validation loss decreased (0.062201 --> 0.040104).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0275587\n",
      "\tspeed: 0.2059s/iter; left time: 1454.4611s\n",
      "\titers: 200, epoch: 3 | loss: 0.0209400\n",
      "\tspeed: 0.0837s/iter; left time: 582.6726s\n",
      "\titers: 300, epoch: 3 | loss: 0.0225935\n",
      "\tspeed: 0.0828s/iter; left time: 568.2696s\n",
      "Epoch: 3 cost time: 33.19939088821411\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0258711 Vali Loss: 0.0355127 Test Loss: 0.0380596\n",
      "Validation loss decreased (0.040104 --> 0.035513).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0286506\n",
      "\tspeed: 0.2087s/iter; left time: 1391.3805s\n",
      "\titers: 200, epoch: 4 | loss: 0.0247024\n",
      "\tspeed: 0.0853s/iter; left time: 559.9963s\n",
      "\titers: 300, epoch: 4 | loss: 0.0219893\n",
      "\tspeed: 0.0847s/iter; left time: 547.8772s\n",
      "Epoch: 4 cost time: 33.84147334098816\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0223677 Vali Loss: 0.0181284 Test Loss: 0.0209577\n",
      "Validation loss decreased (0.035513 --> 0.018128).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0173236\n",
      "\tspeed: 0.2049s/iter; left time: 1284.7370s\n",
      "\titers: 200, epoch: 5 | loss: 0.0204628\n",
      "\tspeed: 0.0836s/iter; left time: 515.8360s\n",
      "\titers: 300, epoch: 5 | loss: 0.0180553\n",
      "\tspeed: 0.0829s/iter; left time: 503.2885s\n",
      "Epoch: 5 cost time: 33.49941372871399\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0203268 Vali Loss: 0.0205628 Test Loss: 0.0240580\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0201747\n",
      "\tspeed: 0.2097s/iter; left time: 1230.9520s\n",
      "\titers: 200, epoch: 6 | loss: 0.0203397\n",
      "\tspeed: 0.0842s/iter; left time: 485.8364s\n",
      "\titers: 300, epoch: 6 | loss: 0.0186917\n",
      "\tspeed: 0.0852s/iter; left time: 483.2334s\n",
      "Epoch: 6 cost time: 33.86338257789612\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0194753 Vali Loss: 0.0186224 Test Loss: 0.0206922\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0168163\n",
      "\tspeed: 0.2066s/iter; left time: 1130.5304s\n",
      "\titers: 200, epoch: 7 | loss: 0.0198472\n",
      "\tspeed: 0.0867s/iter; left time: 466.0153s\n",
      "\titers: 300, epoch: 7 | loss: 0.0194498\n",
      "\tspeed: 0.0864s/iter; left time: 455.3699s\n",
      "Epoch: 7 cost time: 34.154157638549805\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0188054 Vali Loss: 0.0195798 Test Loss: 0.0222315\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.020990444347262383, mae:0.11421643942594528\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTHh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTHh1_ftS_sl168_ll48_pl168_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.3579816\n",
      "\tspeed: 0.1118s/iter; left time: 870.0119s\n",
      "\titers: 200, epoch: 1 | loss: 0.0808680\n",
      "\tspeed: 0.1126s/iter; left time: 864.8869s\n",
      "\titers: 300, epoch: 1 | loss: 0.0647323\n",
      "\tspeed: 0.1121s/iter; left time: 849.8139s\n",
      "Epoch: 1 cost time: 44.3581109046936\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.2188700 Vali Loss: 0.0411116 Test Loss: 0.0478894\n",
      "Validation loss decreased (inf --> 0.041112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0340762\n",
      "\tspeed: 0.2838s/iter; left time: 2096.6274s\n",
      "\titers: 200, epoch: 2 | loss: 0.0296842\n",
      "\tspeed: 0.1091s/iter; left time: 794.6519s\n",
      "\titers: 300, epoch: 2 | loss: 0.0345519\n",
      "\tspeed: 0.1121s/iter; left time: 806.0214s\n",
      "Epoch: 2 cost time: 43.7948203086853\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0363730 Vali Loss: 0.0358068 Test Loss: 0.0394326\n",
      "Validation loss decreased (0.041112 --> 0.035807).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0262531\n",
      "\tspeed: 0.2819s/iter; left time: 1971.4776s\n",
      "\titers: 200, epoch: 3 | loss: 0.0242176\n",
      "\tspeed: 0.1150s/iter; left time: 792.8151s\n",
      "\titers: 300, epoch: 3 | loss: 0.0293945\n",
      "\tspeed: 0.1126s/iter; left time: 764.5930s\n",
      "Epoch: 3 cost time: 44.81955003738403\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0256266 Vali Loss: 0.0262057 Test Loss: 0.0323254\n",
      "Validation loss decreased (0.035807 --> 0.026206).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0201524\n",
      "\tspeed: 0.2815s/iter; left time: 1857.6052s\n",
      "\titers: 200, epoch: 4 | loss: 0.0210953\n",
      "\tspeed: 0.1150s/iter; left time: 747.5163s\n",
      "\titers: 300, epoch: 4 | loss: 0.0208922\n",
      "\tspeed: 0.1178s/iter; left time: 753.8213s\n",
      "Epoch: 4 cost time: 45.2354736328125\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0216198 Vali Loss: 0.0206410 Test Loss: 0.0242406\n",
      "Validation loss decreased (0.026206 --> 0.020641).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0208705\n",
      "\tspeed: 0.2848s/iter; left time: 1767.4766s\n",
      "\titers: 200, epoch: 5 | loss: 0.0232031\n",
      "\tspeed: 0.1106s/iter; left time: 674.9986s\n",
      "\titers: 300, epoch: 5 | loss: 0.0192909\n",
      "\tspeed: 0.1110s/iter; left time: 666.4408s\n",
      "Epoch: 5 cost time: 44.02482199668884\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0200816 Vali Loss: 0.0233013 Test Loss: 0.0279412\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0177787\n",
      "\tspeed: 0.2873s/iter; left time: 1669.6180s\n",
      "\titers: 200, epoch: 6 | loss: 0.0189145\n",
      "\tspeed: 0.1144s/iter; left time: 653.5814s\n",
      "\titers: 300, epoch: 6 | loss: 0.0186758\n",
      "\tspeed: 0.1130s/iter; left time: 634.0944s\n",
      "Epoch: 6 cost time: 45.01673936843872\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0193167 Vali Loss: 0.0217846 Test Loss: 0.0272099\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0193504\n",
      "\tspeed: 0.2831s/iter; left time: 1533.3817s\n",
      "\titers: 200, epoch: 7 | loss: 0.0204557\n",
      "\tspeed: 0.1082s/iter; left time: 575.3120s\n",
      "\titers: 300, epoch: 7 | loss: 0.0194833\n",
      "\tspeed: 0.1167s/iter; left time: 608.8085s\n",
      "Epoch: 7 cost time: 45.06373476982117\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0188667 Vali Loss: 0.0233872 Test Loss: 0.0293359\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.024227099493145943, mae:0.1235165223479271\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTHh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTHh1_ftS_sl168_ll48_pl336_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.3584157\n",
      "\tspeed: 0.1429s/iter; left time: 1097.6244s\n",
      "\titers: 200, epoch: 1 | loss: 0.3126921\n",
      "\tspeed: 0.1391s/iter; left time: 1054.4345s\n",
      "\titers: 300, epoch: 1 | loss: 0.1005030\n",
      "\tspeed: 0.1417s/iter; left time: 1059.8676s\n",
      "Epoch: 1 cost time: 54.74343490600586\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.2942166 Vali Loss: 0.0573941 Test Loss: 0.0641270\n",
      "Validation loss decreased (inf --> 0.057394).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0427111\n",
      "\tspeed: 0.3405s/iter; left time: 2483.1532s\n",
      "\titers: 200, epoch: 2 | loss: 0.0379466\n",
      "\tspeed: 0.1359s/iter; left time: 977.7308s\n",
      "\titers: 300, epoch: 2 | loss: 0.0341249\n",
      "\tspeed: 0.1402s/iter; left time: 994.6053s\n",
      "Epoch: 2 cost time: 54.098655223846436\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0396525 Vali Loss: 0.0380160 Test Loss: 0.0442488\n",
      "Validation loss decreased (0.057394 --> 0.038016).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0253879\n",
      "\tspeed: 0.3440s/iter; left time: 2374.4074s\n",
      "\titers: 200, epoch: 3 | loss: 0.0250365\n",
      "\tspeed: 0.1381s/iter; left time: 939.6078s\n",
      "\titers: 300, epoch: 3 | loss: 0.0242091\n",
      "\tspeed: 0.1398s/iter; left time: 937.3142s\n",
      "Epoch: 3 cost time: 54.52620077133179\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0254621 Vali Loss: 0.0240366 Test Loss: 0.0270887\n",
      "Validation loss decreased (0.038016 --> 0.024037).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0228844\n",
      "\tspeed: 0.3372s/iter; left time: 2196.2312s\n",
      "\titers: 200, epoch: 4 | loss: 0.0200413\n",
      "\tspeed: 0.1436s/iter; left time: 920.8407s\n",
      "\titers: 300, epoch: 4 | loss: 0.0235896\n",
      "\tspeed: 0.1463s/iter; left time: 923.8890s\n",
      "Epoch: 4 cost time: 55.975717067718506\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0216175 Vali Loss: 0.0215275 Test Loss: 0.0238660\n",
      "Validation loss decreased (0.024037 --> 0.021527).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0225944\n",
      "\tspeed: 0.3527s/iter; left time: 2160.3372s\n",
      "\titers: 200, epoch: 5 | loss: 0.0206760\n",
      "\tspeed: 0.1388s/iter; left time: 836.4383s\n",
      "\titers: 300, epoch: 5 | loss: 0.0198566\n",
      "\tspeed: 0.1402s/iter; left time: 830.6275s\n",
      "Epoch: 5 cost time: 54.81995439529419\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0203659 Vali Loss: 0.0240752 Test Loss: 0.0259855\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0216308\n",
      "\tspeed: 0.3397s/iter; left time: 1948.2978s\n",
      "\titers: 200, epoch: 6 | loss: 0.0202575\n",
      "\tspeed: 0.1400s/iter; left time: 788.9871s\n",
      "\titers: 300, epoch: 6 | loss: 0.0190191\n",
      "\tspeed: 0.1438s/iter; left time: 796.0593s\n",
      "Epoch: 6 cost time: 55.668482303619385\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0195508 Vali Loss: 0.0213655 Test Loss: 0.0238692\n",
      "Validation loss decreased (0.021527 --> 0.021366).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0185130\n",
      "\tspeed: 0.3517s/iter; left time: 1880.3710s\n",
      "\titers: 200, epoch: 7 | loss: 0.0191803\n",
      "\tspeed: 0.1379s/iter; left time: 723.3934s\n",
      "\titers: 300, epoch: 7 | loss: 0.0195407\n",
      "\tspeed: 0.1423s/iter; left time: 732.2796s\n",
      "Epoch: 7 cost time: 55.33133912086487\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.0191319 Vali Loss: 0.0203129 Test Loss: 0.0237920\n",
      "Validation loss decreased (0.021366 --> 0.020313).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0184781\n",
      "\tspeed: 0.3553s/iter; left time: 1761.5402s\n",
      "\titers: 200, epoch: 8 | loss: 0.0192174\n",
      "\tspeed: 0.1393s/iter; left time: 676.7532s\n",
      "\titers: 300, epoch: 8 | loss: 0.0186328\n",
      "\tspeed: 0.1367s/iter; left time: 650.4911s\n",
      "Epoch: 8 cost time: 54.674346685409546\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.0189403 Vali Loss: 0.0209745 Test Loss: 0.0240376\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0188818\n",
      "\tspeed: 0.3372s/iter; left time: 1540.6068s\n",
      "\titers: 200, epoch: 9 | loss: 0.0197961\n",
      "\tspeed: 0.1410s/iter; left time: 630.0038s\n",
      "\titers: 300, epoch: 9 | loss: 0.0187468\n",
      "\tspeed: 0.1403s/iter; left time: 612.9963s\n",
      "Epoch: 9 cost time: 54.99120116233826\n",
      "Epoch: 9, Steps: 389 | Train Loss: 0.0188691 Vali Loss: 0.0210089 Test Loss: 0.0241637\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0185629\n",
      "\tspeed: 0.3464s/iter; left time: 1447.8151s\n",
      "\titers: 200, epoch: 10 | loss: 0.0187211\n",
      "\tspeed: 0.1444s/iter; left time: 589.2008s\n",
      "\titers: 300, epoch: 10 | loss: 0.0189057\n",
      "\tspeed: 0.1379s/iter; left time: 549.0345s\n",
      "Epoch: 10 cost time: 55.07955288887024\n",
      "Epoch: 10, Steps: 389 | Train Loss: 0.0187838 Vali Loss: 0.0210097 Test Loss: 0.0240949\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.023693760856986046, mae:0.12157853692770004\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTHh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTHh1_ftS_sl168_ll48_pl720_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.3824033\n",
      "\tspeed: 0.2023s/iter; left time: 1505.5092s\n",
      "\titers: 200, epoch: 1 | loss: 0.3190116\n",
      "\tspeed: 0.1916s/iter; left time: 1406.2821s\n",
      "\titers: 300, epoch: 1 | loss: 0.3009192\n",
      "\tspeed: 0.2032s/iter; left time: 1471.3525s\n",
      "Epoch: 1 cost time: 75.28584599494934\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.3717073 Vali Loss: 0.2091303 Test Loss: 0.2106963\n",
      "Validation loss decreased (inf --> 0.209130).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1624848\n",
      "\tspeed: 0.4356s/iter; left time: 3076.9883s\n",
      "\titers: 200, epoch: 2 | loss: 0.0362698\n",
      "\tspeed: 0.1943s/iter; left time: 1352.9948s\n",
      "\titers: 300, epoch: 2 | loss: 0.0366126\n",
      "\tspeed: 0.1982s/iter; left time: 1360.5094s\n",
      "Epoch: 2 cost time: 74.05992913246155\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0733179 Vali Loss: 0.0254328 Test Loss: 0.0258448\n",
      "Validation loss decreased (0.209130 --> 0.025433).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0268228\n",
      "\tspeed: 0.4213s/iter; left time: 2817.0328s\n",
      "\titers: 200, epoch: 3 | loss: 0.0249377\n",
      "\tspeed: 0.1974s/iter; left time: 1300.3046s\n",
      "\titers: 300, epoch: 3 | loss: 0.0234978\n",
      "\tspeed: 0.1908s/iter; left time: 1237.7226s\n",
      "Epoch: 3 cost time: 72.95667219161987\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0249452 Vali Loss: 0.0222793 Test Loss: 0.0236431\n",
      "Validation loss decreased (0.025433 --> 0.022279).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0213919\n",
      "\tspeed: 0.4368s/iter; left time: 2756.4306s\n",
      "\titers: 200, epoch: 4 | loss: 0.0221663\n",
      "\tspeed: 0.1931s/iter; left time: 1199.4113s\n",
      "\titers: 300, epoch: 4 | loss: 0.0212530\n",
      "\tspeed: 0.1920s/iter; left time: 1173.2908s\n",
      "Epoch: 4 cost time: 74.13402080535889\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0217885 Vali Loss: 0.0192364 Test Loss: 0.0204811\n",
      "Validation loss decreased (0.022279 --> 0.019236).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0225600\n",
      "\tspeed: 0.4294s/iter; left time: 2547.4095s\n",
      "\titers: 200, epoch: 5 | loss: 0.0202571\n",
      "\tspeed: 0.1896s/iter; left time: 1105.7674s\n",
      "\titers: 300, epoch: 5 | loss: 0.0199379\n",
      "\tspeed: 0.2005s/iter; left time: 1149.4660s\n",
      "Epoch: 5 cost time: 73.39553499221802\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0204674 Vali Loss: 0.0193912 Test Loss: 0.0205945\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0203657\n",
      "\tspeed: 0.4226s/iter; left time: 2348.0941s\n",
      "\titers: 200, epoch: 6 | loss: 0.0201250\n",
      "\tspeed: 0.1890s/iter; left time: 1031.4395s\n",
      "\titers: 300, epoch: 6 | loss: 0.0192097\n",
      "\tspeed: 0.1939s/iter; left time: 1038.5347s\n",
      "Epoch: 6 cost time: 71.83331656455994\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0197988 Vali Loss: 0.0198901 Test Loss: 0.0209847\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0194832\n",
      "\tspeed: 0.4225s/iter; left time: 2188.0386s\n",
      "\titers: 200, epoch: 7 | loss: 0.0193490\n",
      "\tspeed: 0.2014s/iter; left time: 1022.9075s\n",
      "\titers: 300, epoch: 7 | loss: 0.0195733\n",
      "\tspeed: 0.1947s/iter; left time: 969.3988s\n",
      "Epoch: 7 cost time: 74.49657940864563\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0194494 Vali Loss: 0.0192688 Test Loss: 0.0205144\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.02047882042825222, mae:0.11290141940116882\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_ftS_sl168_ll48_pl24_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.0680237\n",
      "\tspeed: 0.0811s/iter; left time: 639.2243s\n",
      "\titers: 200, epoch: 1 | loss: 0.0511553\n",
      "\tspeed: 0.0811s/iter; left time: 631.0059s\n",
      "\titers: 300, epoch: 1 | loss: 0.0214603\n",
      "\tspeed: 0.0814s/iter; left time: 624.8983s\n",
      "Epoch: 1 cost time: 32.64716958999634\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.0706126 Vali Loss: 0.0194820 Test Loss: 0.0954105\n",
      "Validation loss decreased (inf --> 0.019482).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0114488\n",
      "\tspeed: 0.2052s/iter; left time: 1535.4616s\n",
      "\titers: 200, epoch: 2 | loss: 0.0187068\n",
      "\tspeed: 0.0816s/iter; left time: 602.5901s\n",
      "\titers: 300, epoch: 2 | loss: 0.0133269\n",
      "\tspeed: 0.0832s/iter; left time: 606.0923s\n",
      "Epoch: 2 cost time: 33.041974782943726\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0104199 Vali Loss: 0.0088625 Test Loss: 0.0683966\n",
      "Validation loss decreased (0.019482 --> 0.008863).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0046463\n",
      "\tspeed: 0.2024s/iter; left time: 1433.3075s\n",
      "\titers: 200, epoch: 3 | loss: 0.0047929\n",
      "\tspeed: 0.0832s/iter; left time: 581.1278s\n",
      "\titers: 300, epoch: 3 | loss: 0.0035103\n",
      "\tspeed: 0.0818s/iter; left time: 562.7206s\n",
      "Epoch: 3 cost time: 33.11867141723633\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0047890 Vali Loss: 0.0054002 Test Loss: 0.0486728\n",
      "Validation loss decreased (0.008863 --> 0.005400).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0042715\n",
      "\tspeed: 0.2038s/iter; left time: 1362.4328s\n",
      "\titers: 200, epoch: 4 | loss: 0.0032246\n",
      "\tspeed: 0.0828s/iter; left time: 545.2637s\n",
      "\titers: 300, epoch: 4 | loss: 0.0032141\n",
      "\tspeed: 0.0835s/iter; left time: 541.3589s\n",
      "Epoch: 4 cost time: 33.07530093193054\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0036377 Vali Loss: 0.0046344 Test Loss: 0.0435886\n",
      "Validation loss decreased (0.005400 --> 0.004634).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0031454\n",
      "\tspeed: 0.2040s/iter; left time: 1282.0127s\n",
      "\titers: 200, epoch: 5 | loss: 0.0041853\n",
      "\tspeed: 0.0797s/iter; left time: 493.1159s\n",
      "\titers: 300, epoch: 5 | loss: 0.0029580\n",
      "\tspeed: 0.0819s/iter; left time: 498.2029s\n",
      "Epoch: 5 cost time: 32.41299629211426\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0032428 Vali Loss: 0.0039978 Test Loss: 0.0240976\n",
      "Validation loss decreased (0.004634 --> 0.003998).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0027839\n",
      "\tspeed: 0.1965s/iter; left time: 1156.5758s\n",
      "\titers: 200, epoch: 6 | loss: 0.0029387\n",
      "\tspeed: 0.0807s/iter; left time: 466.8126s\n",
      "\titers: 300, epoch: 6 | loss: 0.0033882\n",
      "\tspeed: 0.0803s/iter; left time: 456.4013s\n",
      "Epoch: 6 cost time: 32.03975987434387\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0030061 Vali Loss: 0.0031288 Test Loss: 0.0302090\n",
      "Validation loss decreased (0.003998 --> 0.003129).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0029191\n",
      "\tspeed: 0.2000s/iter; left time: 1097.2647s\n",
      "\titers: 200, epoch: 7 | loss: 0.0029185\n",
      "\tspeed: 0.0854s/iter; left time: 460.1721s\n",
      "\titers: 300, epoch: 7 | loss: 0.0032760\n",
      "\tspeed: 0.0809s/iter; left time: 427.6129s\n",
      "Epoch: 7 cost time: 32.8887414932251\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0029367 Vali Loss: 0.0033233 Test Loss: 0.0306156\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0027758\n",
      "\tspeed: 0.1954s/iter; left time: 994.1944s\n",
      "\titers: 200, epoch: 8 | loss: 0.0032916\n",
      "\tspeed: 0.0808s/iter; left time: 402.8087s\n",
      "\titers: 300, epoch: 8 | loss: 0.0027544\n",
      "\tspeed: 0.0807s/iter; left time: 394.2889s\n",
      "Epoch: 8 cost time: 32.45216131210327\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0028675 Vali Loss: 0.0034411 Test Loss: 0.0327913\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0032885\n",
      "\tspeed: 0.2037s/iter; left time: 955.3748s\n",
      "\titers: 200, epoch: 9 | loss: 0.0027297\n",
      "\tspeed: 0.0805s/iter; left time: 369.2157s\n",
      "\titers: 300, epoch: 9 | loss: 0.0029457\n",
      "\tspeed: 0.0811s/iter; left time: 363.8489s\n",
      "Epoch: 9 cost time: 32.392399311065674\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0028093 Vali Loss: 0.0031637 Test Loss: 0.0285308\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.03053630329668522, mae:0.13602662086486816\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_ftS_sl168_ll48_pl48_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.0555826\n",
      "\tspeed: 0.0822s/iter; left time: 645.9926s\n",
      "\titers: 200, epoch: 1 | loss: 0.0342832\n",
      "\tspeed: 0.0840s/iter; left time: 651.9641s\n",
      "\titers: 300, epoch: 1 | loss: 0.0281978\n",
      "\tspeed: 0.0868s/iter; left time: 664.6660s\n",
      "Epoch: 1 cost time: 34.05521631240845\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0645165 Vali Loss: 0.0176637 Test Loss: 0.1235562\n",
      "Validation loss decreased (inf --> 0.017664).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0156899\n",
      "\tspeed: 0.2151s/iter; left time: 1605.0950s\n",
      "\titers: 200, epoch: 2 | loss: 0.0066373\n",
      "\tspeed: 0.0858s/iter; left time: 631.4272s\n",
      "\titers: 300, epoch: 2 | loss: 0.0071129\n",
      "\tspeed: 0.0829s/iter; left time: 602.1490s\n",
      "Epoch: 2 cost time: 33.77593636512756\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0095578 Vali Loss: 0.0136960 Test Loss: 0.1030454\n",
      "Validation loss decreased (0.017664 --> 0.013696).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0041399\n",
      "\tspeed: 0.2062s/iter; left time: 1456.8947s\n",
      "\titers: 200, epoch: 3 | loss: 0.0038596\n",
      "\tspeed: 0.0902s/iter; left time: 628.0880s\n",
      "\titers: 300, epoch: 3 | loss: 0.0036814\n",
      "\tspeed: 0.0847s/iter; left time: 581.2736s\n",
      "Epoch: 3 cost time: 34.119367599487305\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0046735 Vali Loss: 0.0096526 Test Loss: 0.0720668\n",
      "Validation loss decreased (0.013696 --> 0.009653).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0044774\n",
      "\tspeed: 0.2046s/iter; left time: 1363.8860s\n",
      "\titers: 200, epoch: 4 | loss: 0.0032428\n",
      "\tspeed: 0.0845s/iter; left time: 555.1832s\n",
      "\titers: 300, epoch: 4 | loss: 0.0031321\n",
      "\tspeed: 0.0836s/iter; left time: 540.4206s\n",
      "Epoch: 4 cost time: 33.33104491233826\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0036751 Vali Loss: 0.0047327 Test Loss: 0.0458262\n",
      "Validation loss decreased (0.009653 --> 0.004733).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0032799\n",
      "\tspeed: 0.2121s/iter; left time: 1329.8259s\n",
      "\titers: 200, epoch: 5 | loss: 0.0032417\n",
      "\tspeed: 0.0832s/iter; left time: 513.3236s\n",
      "\titers: 300, epoch: 5 | loss: 0.0031546\n",
      "\tspeed: 0.0829s/iter; left time: 503.3436s\n",
      "Epoch: 5 cost time: 33.769049644470215\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0032898 Vali Loss: 0.0045075 Test Loss: 0.0451929\n",
      "Validation loss decreased (0.004733 --> 0.004507).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0033026\n",
      "\tspeed: 0.2052s/iter; left time: 1204.6841s\n",
      "\titers: 200, epoch: 6 | loss: 0.0025274\n",
      "\tspeed: 0.0832s/iter; left time: 480.3081s\n",
      "\titers: 300, epoch: 6 | loss: 0.0031327\n",
      "\tspeed: 0.0831s/iter; left time: 471.0491s\n",
      "Epoch: 6 cost time: 33.88031339645386\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0030416 Vali Loss: 0.0038320 Test Loss: 0.0387966\n",
      "Validation loss decreased (0.004507 --> 0.003832).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0031086\n",
      "\tspeed: 0.2158s/iter; left time: 1181.2286s\n",
      "\titers: 200, epoch: 7 | loss: 0.0032904\n",
      "\tspeed: 0.0834s/iter; left time: 448.3186s\n",
      "\titers: 300, epoch: 7 | loss: 0.0034438\n",
      "\tspeed: 0.0833s/iter; left time: 439.3446s\n",
      "Epoch: 7 cost time: 33.29153299331665\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0029247 Vali Loss: 0.0042232 Test Loss: 0.0403314\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0028538\n",
      "\tspeed: 0.2008s/iter; left time: 1019.1699s\n",
      "\titers: 200, epoch: 8 | loss: 0.0029011\n",
      "\tspeed: 0.0831s/iter; left time: 413.2923s\n",
      "\titers: 300, epoch: 8 | loss: 0.0028498\n",
      "\tspeed: 0.0886s/iter; left time: 431.9713s\n",
      "Epoch: 8 cost time: 33.77758812904358\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0028778 Vali Loss: 0.0042551 Test Loss: 0.0416230\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0025961\n",
      "\tspeed: 0.2078s/iter; left time: 972.0964s\n",
      "\titers: 200, epoch: 9 | loss: 0.0028039\n",
      "\tspeed: 0.0867s/iter; left time: 396.6950s\n",
      "\titers: 300, epoch: 9 | loss: 0.0028882\n",
      "\tspeed: 0.0872s/iter; left time: 390.3559s\n",
      "Epoch: 9 cost time: 34.37469124794006\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0028391 Vali Loss: 0.0037389 Test Loss: 0.0376021\n",
      "Validation loss decreased (0.003832 --> 0.003739).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0024303\n",
      "\tspeed: 0.2136s/iter; left time: 913.9065s\n",
      "\titers: 200, epoch: 10 | loss: 0.0026825\n",
      "\tspeed: 0.0835s/iter; left time: 349.1444s\n",
      "\titers: 300, epoch: 10 | loss: 0.0025776\n",
      "\tspeed: 0.0871s/iter; left time: 355.1196s\n",
      "Epoch: 10 cost time: 34.32714343070984\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.0028097 Vali Loss: 0.0037696 Test Loss: 0.0370276\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0027850\n",
      "\tspeed: 0.2098s/iter; left time: 814.2621s\n",
      "\titers: 200, epoch: 11 | loss: 0.0031130\n",
      "\tspeed: 0.0863s/iter; left time: 326.4837s\n",
      "\titers: 300, epoch: 11 | loss: 0.0030389\n",
      "\tspeed: 0.0871s/iter; left time: 320.7052s\n",
      "Epoch: 11 cost time: 34.517303466796875\n",
      "Epoch: 11, Steps: 398 | Train Loss: 0.0027973 Vali Loss: 0.0037747 Test Loss: 0.0374484\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0029785\n",
      "\tspeed: 0.2059s/iter; left time: 717.2415s\n",
      "\titers: 200, epoch: 12 | loss: 0.0028389\n",
      "\tspeed: 0.0769s/iter; left time: 260.2257s\n",
      "\titers: 300, epoch: 12 | loss: 0.0026331\n",
      "\tspeed: 0.0781s/iter; left time: 256.4185s\n",
      "Epoch: 12 cost time: 31.97978949546814\n",
      "Epoch: 12, Steps: 398 | Train Loss: 0.0027974 Vali Loss: 0.0037646 Test Loss: 0.0373253\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.0373866893351078, mae:0.15821103751659393\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_ftS_sl168_ll48_pl168_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.0581883\n",
      "\tspeed: 0.1125s/iter; left time: 875.6625s\n",
      "\titers: 200, epoch: 1 | loss: 0.0603623\n",
      "\tspeed: 0.1129s/iter; left time: 867.2144s\n",
      "\titers: 300, epoch: 1 | loss: 0.0423413\n",
      "\tspeed: 0.1076s/iter; left time: 815.6664s\n",
      "Epoch: 1 cost time: 44.014535427093506\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.0748737 Vali Loss: 0.0432366 Test Loss: 0.1586512\n",
      "Validation loss decreased (inf --> 0.043237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0467654\n",
      "\tspeed: 0.2839s/iter; left time: 2097.1857s\n",
      "\titers: 200, epoch: 2 | loss: 0.0165828\n",
      "\tspeed: 0.1108s/iter; left time: 807.0659s\n",
      "\titers: 300, epoch: 2 | loss: 0.0102890\n",
      "\tspeed: 0.1120s/iter; left time: 805.2808s\n",
      "Epoch: 2 cost time: 43.93101215362549\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0236232 Vali Loss: 0.0114473 Test Loss: 0.0621535\n",
      "Validation loss decreased (0.043237 --> 0.011447).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0060290\n",
      "\tspeed: 0.2775s/iter; left time: 1940.8488s\n",
      "\titers: 200, epoch: 3 | loss: 0.0054112\n",
      "\tspeed: 0.1128s/iter; left time: 777.1911s\n",
      "\titers: 300, epoch: 3 | loss: 0.0055987\n",
      "\tspeed: 0.1116s/iter; left time: 758.2036s\n",
      "Epoch: 3 cost time: 44.21815872192383\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0063757 Vali Loss: 0.0079075 Test Loss: 0.0636510\n",
      "Validation loss decreased (0.011447 --> 0.007907).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0042679\n",
      "\tspeed: 0.2833s/iter; left time: 1869.4671s\n",
      "\titers: 200, epoch: 4 | loss: 0.0048573\n",
      "\tspeed: 0.1122s/iter; left time: 728.9398s\n",
      "\titers: 300, epoch: 4 | loss: 0.0050720\n",
      "\tspeed: 0.1130s/iter; left time: 722.7934s\n",
      "Epoch: 4 cost time: 44.764071464538574\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0046393 Vali Loss: 0.0066424 Test Loss: 0.0544613\n",
      "Validation loss decreased (0.007907 --> 0.006642).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0033812\n",
      "\tspeed: 0.2849s/iter; left time: 1767.8916s\n",
      "\titers: 200, epoch: 5 | loss: 0.0039346\n",
      "\tspeed: 0.1141s/iter; left time: 696.5105s\n",
      "\titers: 300, epoch: 5 | loss: 0.0040928\n",
      "\tspeed: 0.1157s/iter; left time: 694.7528s\n",
      "Epoch: 5 cost time: 44.971208572387695\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0040528 Vali Loss: 0.0055700 Test Loss: 0.0442494\n",
      "Validation loss decreased (0.006642 --> 0.005570).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0035487\n",
      "\tspeed: 0.2883s/iter; left time: 1675.4080s\n",
      "\titers: 200, epoch: 6 | loss: 0.0039989\n",
      "\tspeed: 0.1132s/iter; left time: 646.3476s\n",
      "\titers: 300, epoch: 6 | loss: 0.0040371\n",
      "\tspeed: 0.1109s/iter; left time: 622.0237s\n",
      "Epoch: 6 cost time: 44.75172686576843\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0037980 Vali Loss: 0.0053102 Test Loss: 0.0435058\n",
      "Validation loss decreased (0.005570 --> 0.005310).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0040746\n",
      "\tspeed: 0.2844s/iter; left time: 1540.6933s\n",
      "\titers: 200, epoch: 7 | loss: 0.0041697\n",
      "\tspeed: 0.1108s/iter; left time: 589.2068s\n",
      "\titers: 300, epoch: 7 | loss: 0.0035960\n",
      "\tspeed: 0.1100s/iter; left time: 573.9202s\n",
      "Epoch: 7 cost time: 43.76573634147644\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0035893 Vali Loss: 0.0054244 Test Loss: 0.0458054\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0031662\n",
      "\tspeed: 0.2735s/iter; left time: 1373.6042s\n",
      "\titers: 200, epoch: 8 | loss: 0.0034533\n",
      "\tspeed: 0.1080s/iter; left time: 531.7736s\n",
      "\titers: 300, epoch: 8 | loss: 0.0030516\n",
      "\tspeed: 0.1101s/iter; left time: 530.7786s\n",
      "Epoch: 8 cost time: 43.02282524108887\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0035419 Vali Loss: 0.0048761 Test Loss: 0.0402545\n",
      "Validation loss decreased (0.005310 --> 0.004876).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0035602\n",
      "\tspeed: 0.2802s/iter; left time: 1297.0046s\n",
      "\titers: 200, epoch: 9 | loss: 0.0030794\n",
      "\tspeed: 0.1148s/iter; left time: 519.8210s\n",
      "\titers: 300, epoch: 9 | loss: 0.0030697\n",
      "\tspeed: 0.1108s/iter; left time: 490.8158s\n",
      "Epoch: 9 cost time: 44.387540102005005\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0034686 Vali Loss: 0.0049236 Test Loss: 0.0409235\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0032877\n",
      "\tspeed: 0.2831s/iter; left time: 1198.9263s\n",
      "\titers: 200, epoch: 10 | loss: 0.0031214\n",
      "\tspeed: 0.1170s/iter; left time: 483.6235s\n",
      "\titers: 300, epoch: 10 | loss: 0.0039872\n",
      "\tspeed: 0.1137s/iter; left time: 458.5867s\n",
      "Epoch: 10 cost time: 45.02426362037659\n",
      "Epoch: 10, Steps: 394 | Train Loss: 0.0034573 Vali Loss: 0.0045224 Test Loss: 0.0356176\n",
      "Validation loss decreased (0.004876 --> 0.004522).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0032268\n",
      "\tspeed: 0.2763s/iter; left time: 1061.1211s\n",
      "\titers: 200, epoch: 11 | loss: 0.0033302\n",
      "\tspeed: 0.1095s/iter; left time: 409.6862s\n",
      "\titers: 300, epoch: 11 | loss: 0.0030520\n",
      "\tspeed: 0.1132s/iter; left time: 412.1623s\n",
      "Epoch: 11 cost time: 43.65671467781067\n",
      "Epoch: 11, Steps: 394 | Train Loss: 0.0034228 Vali Loss: 0.0048971 Test Loss: 0.0417425\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0031925\n",
      "\tspeed: 0.2778s/iter; left time: 957.5807s\n",
      "\titers: 200, epoch: 12 | loss: 0.0043667\n",
      "\tspeed: 0.1130s/iter; left time: 378.3520s\n",
      "\titers: 300, epoch: 12 | loss: 0.0034168\n",
      "\tspeed: 0.1130s/iter; left time: 366.8804s\n",
      "Epoch: 12 cost time: 44.567596435546875\n",
      "Epoch: 12, Steps: 394 | Train Loss: 0.0034247 Vali Loss: 0.0056648 Test Loss: 0.0455627\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0035994\n",
      "\tspeed: 0.2880s/iter; left time: 879.1223s\n",
      "\titers: 200, epoch: 13 | loss: 0.0030893\n",
      "\tspeed: 0.1156s/iter; left time: 341.2866s\n",
      "\titers: 300, epoch: 13 | loss: 0.0033788\n",
      "\tspeed: 0.1099s/iter; left time: 313.5202s\n",
      "Epoch: 13 cost time: 45.01495862007141\n",
      "Epoch: 13, Steps: 394 | Train Loss: 0.0034368 Vali Loss: 0.0049199 Test Loss: 0.0414397\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.03562350198626518, mae:0.15127727389335632\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_ftS_sl168_ll48_pl336_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.0708752\n",
      "\tspeed: 0.1424s/iter; left time: 1093.5797s\n",
      "\titers: 200, epoch: 1 | loss: 0.0522592\n",
      "\tspeed: 0.1397s/iter; left time: 1058.8097s\n",
      "\titers: 300, epoch: 1 | loss: 0.0470091\n",
      "\tspeed: 0.1386s/iter; left time: 1036.4934s\n",
      "Epoch: 1 cost time: 54.45237421989441\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.0765138 Vali Loss: 0.0660991 Test Loss: 0.2728320\n",
      "Validation loss decreased (inf --> 0.066099).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0390797\n",
      "\tspeed: 0.3411s/iter; left time: 2487.0269s\n",
      "\titers: 200, epoch: 2 | loss: 0.0320502\n",
      "\tspeed: 0.1423s/iter; left time: 1023.3975s\n",
      "\titers: 300, epoch: 2 | loss: 0.0233355\n",
      "\tspeed: 0.1409s/iter; left time: 999.1828s\n",
      "Epoch: 2 cost time: 54.94065594673157\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0314550 Vali Loss: 0.0402250 Test Loss: 0.1554345\n",
      "Validation loss decreased (0.066099 --> 0.040225).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0070654\n",
      "\tspeed: 0.3462s/iter; left time: 2389.6829s\n",
      "\titers: 200, epoch: 3 | loss: 0.0109749\n",
      "\tspeed: 0.1442s/iter; left time: 980.9766s\n",
      "\titers: 300, epoch: 3 | loss: 0.0059977\n",
      "\tspeed: 0.1419s/iter; left time: 951.4214s\n",
      "Epoch: 3 cost time: 55.71354031562805\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0081820 Vali Loss: 0.0186694 Test Loss: 0.0999404\n",
      "Validation loss decreased (0.040225 --> 0.018669).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0066560\n",
      "\tspeed: 0.3481s/iter; left time: 2267.6076s\n",
      "\titers: 200, epoch: 4 | loss: 0.0061562\n",
      "\tspeed: 0.1408s/iter; left time: 902.8899s\n",
      "\titers: 300, epoch: 4 | loss: 0.0061232\n",
      "\tspeed: 0.1420s/iter; left time: 896.8050s\n",
      "Epoch: 4 cost time: 55.558568716049194\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0058280 Vali Loss: 0.0071924 Test Loss: 0.0584347\n",
      "Validation loss decreased (0.018669 --> 0.007192).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0053017\n",
      "\tspeed: 0.3507s/iter; left time: 2147.7691s\n",
      "\titers: 200, epoch: 5 | loss: 0.0058829\n",
      "\tspeed: 0.1329s/iter; left time: 800.6117s\n",
      "\titers: 300, epoch: 5 | loss: 0.0070936\n",
      "\tspeed: 0.1412s/iter; left time: 836.7206s\n",
      "Epoch: 5 cost time: 54.22786569595337\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0048175 Vali Loss: 0.0127263 Test Loss: 0.0753441\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0037647\n",
      "\tspeed: 0.3361s/iter; left time: 1927.9786s\n",
      "\titers: 200, epoch: 6 | loss: 0.0045598\n",
      "\tspeed: 0.1411s/iter; left time: 795.4621s\n",
      "\titers: 300, epoch: 6 | loss: 0.0043756\n",
      "\tspeed: 0.1466s/iter; left time: 811.7962s\n",
      "Epoch: 6 cost time: 55.672367572784424\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0044806 Vali Loss: 0.0062486 Test Loss: 0.0498129\n",
      "Validation loss decreased (0.007192 --> 0.006249).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0042293\n",
      "\tspeed: 0.3492s/iter; left time: 1867.4227s\n",
      "\titers: 200, epoch: 7 | loss: 0.0047385\n",
      "\tspeed: 0.1357s/iter; left time: 712.1284s\n",
      "\titers: 300, epoch: 7 | loss: 0.0059181\n",
      "\tspeed: 0.1384s/iter; left time: 712.0949s\n",
      "Epoch: 7 cost time: 54.294185161590576\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.0043333 Vali Loss: 0.0065099 Test Loss: 0.0507863\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0045360\n",
      "\tspeed: 0.3472s/iter; left time: 1721.2478s\n",
      "\titers: 200, epoch: 8 | loss: 0.0072859\n",
      "\tspeed: 0.1419s/iter; left time: 689.5033s\n",
      "\titers: 300, epoch: 8 | loss: 0.0041719\n",
      "\tspeed: 0.1413s/iter; left time: 672.3237s\n",
      "Epoch: 8 cost time: 55.2245831489563\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.0041567 Vali Loss: 0.0072644 Test Loss: 0.0553221\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0046538\n",
      "\tspeed: 0.3434s/iter; left time: 1569.0808s\n",
      "\titers: 200, epoch: 9 | loss: 0.0034801\n",
      "\tspeed: 0.1451s/iter; left time: 648.5882s\n",
      "\titers: 300, epoch: 9 | loss: 0.0038921\n",
      "\tspeed: 0.1389s/iter; left time: 606.9526s\n",
      "Epoch: 9 cost time: 55.439881801605225\n",
      "Epoch: 9, Steps: 389 | Train Loss: 0.0040917 Vali Loss: 0.0076379 Test Loss: 0.0561980\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.049756500869989395, mae:0.18004068732261658\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_ftS_sl168_ll48_pl720_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.0966808\n",
      "\tspeed: 0.1964s/iter; left time: 1461.5545s\n",
      "\titers: 200, epoch: 1 | loss: 0.0562355\n",
      "\tspeed: 0.1990s/iter; left time: 1460.5955s\n",
      "\titers: 300, epoch: 1 | loss: 0.0484192\n",
      "\tspeed: 0.1973s/iter; left time: 1428.6368s\n",
      "Epoch: 1 cost time: 74.85225367546082\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.0837333 Vali Loss: 0.0542255 Test Loss: 0.1877834\n",
      "Validation loss decreased (inf --> 0.054225).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0421451\n",
      "\tspeed: 0.4372s/iter; left time: 3088.4138s\n",
      "\titers: 200, epoch: 2 | loss: 0.0389282\n",
      "\tspeed: 0.1977s/iter; left time: 1376.7325s\n",
      "\titers: 300, epoch: 2 | loss: 0.0412530\n",
      "\tspeed: 0.2005s/iter; left time: 1376.0385s\n",
      "Epoch: 2 cost time: 74.72602367401123\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0409078 Vali Loss: 0.0477355 Test Loss: 0.1899784\n",
      "Validation loss decreased (0.054225 --> 0.047735).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0353160\n",
      "\tspeed: 0.4233s/iter; left time: 2830.3058s\n",
      "\titers: 200, epoch: 3 | loss: 0.0349025\n",
      "\tspeed: 0.1968s/iter; left time: 1296.0553s\n",
      "\titers: 300, epoch: 3 | loss: 0.0332740\n",
      "\tspeed: 0.1981s/iter; left time: 1284.9044s\n",
      "Epoch: 3 cost time: 73.86974883079529\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0348721 Vali Loss: 0.0424383 Test Loss: 0.1360387\n",
      "Validation loss decreased (0.047735 --> 0.042438).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0287258\n",
      "\tspeed: 0.4403s/iter; left time: 2778.3063s\n",
      "\titers: 200, epoch: 4 | loss: 0.0230663\n",
      "\tspeed: 0.1924s/iter; left time: 1195.0975s\n",
      "\titers: 300, epoch: 4 | loss: 0.0141773\n",
      "\tspeed: 0.1966s/iter; left time: 1201.1425s\n",
      "Epoch: 4 cost time: 73.88781976699829\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0217255 Vali Loss: 0.0237342 Test Loss: 0.1087497\n",
      "Validation loss decreased (0.042438 --> 0.023734).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0072785\n",
      "\tspeed: 0.4257s/iter; left time: 2525.4524s\n",
      "\titers: 200, epoch: 5 | loss: 0.0078893\n",
      "\tspeed: 0.1923s/iter; left time: 1121.4642s\n",
      "\titers: 300, epoch: 5 | loss: 0.0068004\n",
      "\tspeed: 0.1910s/iter; left time: 1095.2332s\n",
      "Epoch: 5 cost time: 72.41013193130493\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0079369 Vali Loss: 0.0122042 Test Loss: 0.0831602\n",
      "Validation loss decreased (0.023734 --> 0.012204).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0067813\n",
      "\tspeed: 0.4241s/iter; left time: 2356.5090s\n",
      "\titers: 200, epoch: 6 | loss: 0.0077563\n",
      "\tspeed: 0.2008s/iter; left time: 1095.8229s\n",
      "\titers: 300, epoch: 6 | loss: 0.0054801\n",
      "\tspeed: 0.2015s/iter; left time: 1079.2271s\n",
      "Epoch: 6 cost time: 74.0809736251831\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0061343 Vali Loss: 0.0127011 Test Loss: 0.0824389\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0068783\n",
      "\tspeed: 0.4184s/iter; left time: 2166.9322s\n",
      "\titers: 200, epoch: 7 | loss: 0.0050092\n",
      "\tspeed: 0.1984s/iter; left time: 1007.7348s\n",
      "\titers: 300, epoch: 7 | loss: 0.0050923\n",
      "\tspeed: 0.1907s/iter; left time: 949.6491s\n",
      "Epoch: 7 cost time: 74.08261203765869\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0055628 Vali Loss: 0.0109987 Test Loss: 0.0759851\n",
      "Validation loss decreased (0.012204 --> 0.010999).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0055175\n",
      "\tspeed: 0.4314s/iter; left time: 2071.5687s\n",
      "\titers: 200, epoch: 8 | loss: 0.0066277\n",
      "\tspeed: 0.1951s/iter; left time: 917.5132s\n",
      "\titers: 300, epoch: 8 | loss: 0.0066906\n",
      "\tspeed: 0.2001s/iter; left time: 921.0589s\n",
      "Epoch: 8 cost time: 74.5496916770935\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.0053372 Vali Loss: 0.0099014 Test Loss: 0.0728248\n",
      "Validation loss decreased (0.010999 --> 0.009901).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0049955\n",
      "\tspeed: 0.4291s/iter; left time: 1898.9206s\n",
      "\titers: 200, epoch: 9 | loss: 0.0058749\n",
      "\tspeed: 0.1973s/iter; left time: 853.1672s\n",
      "\titers: 300, epoch: 9 | loss: 0.0090941\n",
      "\tspeed: 0.1964s/iter; left time: 829.6429s\n",
      "Epoch: 9 cost time: 73.31795883178711\n",
      "Epoch: 9, Steps: 377 | Train Loss: 0.0052445 Vali Loss: 0.0095545 Test Loss: 0.0681466\n",
      "Validation loss decreased (0.009901 --> 0.009555).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0054770\n",
      "\tspeed: 0.4220s/iter; left time: 1708.4172s\n",
      "\titers: 200, epoch: 10 | loss: 0.0054260\n",
      "\tspeed: 0.1967s/iter; left time: 776.6797s\n",
      "\titers: 300, epoch: 10 | loss: 0.0067654\n",
      "\tspeed: 0.1934s/iter; left time: 744.1259s\n",
      "Epoch: 10 cost time: 73.34566259384155\n",
      "Epoch: 10, Steps: 377 | Train Loss: 0.0052184 Vali Loss: 0.0093592 Test Loss: 0.0686453\n",
      "Validation loss decreased (0.009555 --> 0.009359).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0050168\n",
      "\tspeed: 0.4353s/iter; left time: 1598.1441s\n",
      "\titers: 200, epoch: 11 | loss: 0.0052729\n",
      "\tspeed: 0.1998s/iter; left time: 713.5064s\n",
      "\titers: 300, epoch: 11 | loss: 0.0044555\n",
      "\tspeed: 0.1865s/iter; left time: 647.5111s\n",
      "Epoch: 11 cost time: 74.02551651000977\n",
      "Epoch: 11, Steps: 377 | Train Loss: 0.0051813 Vali Loss: 0.0091462 Test Loss: 0.0697917\n",
      "Validation loss decreased (0.009359 --> 0.009146).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0044966\n",
      "\tspeed: 0.4327s/iter; left time: 1425.4255s\n",
      "\titers: 200, epoch: 12 | loss: 0.0047820\n",
      "\tspeed: 0.1850s/iter; left time: 590.8264s\n",
      "\titers: 300, epoch: 12 | loss: 0.0052541\n",
      "\tspeed: 0.1931s/iter; left time: 597.5225s\n",
      "Epoch: 12 cost time: 72.11005759239197\n",
      "Epoch: 12, Steps: 377 | Train Loss: 0.0051105 Vali Loss: 0.0095195 Test Loss: 0.0707612\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0048050\n",
      "\tspeed: 0.4163s/iter; left time: 1214.3641s\n",
      "\titers: 200, epoch: 13 | loss: 0.0053374\n",
      "\tspeed: 0.1923s/iter; left time: 541.8156s\n",
      "\titers: 300, epoch: 13 | loss: 0.0048203\n",
      "\tspeed: 0.1938s/iter; left time: 526.5775s\n",
      "Epoch: 13 cost time: 73.04616975784302\n",
      "Epoch: 13, Steps: 377 | Train Loss: 0.0051445 Vali Loss: 0.0097360 Test Loss: 0.0706417\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "\titers: 100, epoch: 14 | loss: 0.0048181\n",
      "\tspeed: 0.4324s/iter; left time: 1098.3916s\n",
      "\titers: 200, epoch: 14 | loss: 0.0048488\n",
      "\tspeed: 0.2017s/iter; left time: 492.2537s\n",
      "\titers: 300, epoch: 14 | loss: 0.0053692\n",
      "\tspeed: 0.2016s/iter; left time: 471.8204s\n",
      "Epoch: 14 cost time: 75.11825704574585\n",
      "Epoch: 14, Steps: 377 | Train Loss: 0.0050753 Vali Loss: 0.0103747 Test Loss: 0.0722736\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.06984902173280716, mae:0.2154848426580429\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_reversal_ftS_sl168_ll48_pl24_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.1028166\n",
      "\tspeed: 0.0861s/iter; left time: 678.9423s\n",
      "\titers: 200, epoch: 1 | loss: 0.0490617\n",
      "\tspeed: 0.0835s/iter; left time: 649.4364s\n",
      "\titers: 300, epoch: 1 | loss: 0.0172922\n",
      "\tspeed: 0.0833s/iter; left time: 639.5888s\n",
      "Epoch: 1 cost time: 33.546212911605835\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.0909906 Vali Loss: 0.0766161 Test Loss: 0.1292718\n",
      "Validation loss decreased (inf --> 0.076616).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0128280\n",
      "\tspeed: 0.2004s/iter; left time: 1499.5094s\n",
      "\titers: 200, epoch: 2 | loss: 0.0092912\n",
      "\tspeed: 0.0810s/iter; left time: 598.2559s\n",
      "\titers: 300, epoch: 2 | loss: 0.0170504\n",
      "\tspeed: 0.0834s/iter; left time: 607.6527s\n",
      "Epoch: 2 cost time: 32.6368842124939\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0121365 Vali Loss: 0.0737069 Test Loss: 0.1258331\n",
      "Validation loss decreased (0.076616 --> 0.073707).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0069864\n",
      "\tspeed: 0.2016s/iter; left time: 1428.0613s\n",
      "\titers: 200, epoch: 3 | loss: 0.0072385\n",
      "\tspeed: 0.0805s/iter; left time: 562.3787s\n",
      "\titers: 300, epoch: 3 | loss: 0.0063878\n",
      "\tspeed: 0.0820s/iter; left time: 564.6842s\n",
      "Epoch: 3 cost time: 32.52075457572937\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0066115 Vali Loss: 0.0349164 Test Loss: 0.0753498\n",
      "Validation loss decreased (0.073707 --> 0.034916).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0066372\n",
      "\tspeed: 0.2040s/iter; left time: 1363.2133s\n",
      "\titers: 200, epoch: 4 | loss: 0.0049452\n",
      "\tspeed: 0.0841s/iter; left time: 553.9850s\n",
      "\titers: 300, epoch: 4 | loss: 0.0048463\n",
      "\tspeed: 0.0843s/iter; left time: 546.8749s\n",
      "Epoch: 4 cost time: 33.64787530899048\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0054099 Vali Loss: 0.0267132 Test Loss: 0.0578644\n",
      "Validation loss decreased (0.034916 --> 0.026713).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0045919\n",
      "\tspeed: 0.2072s/iter; left time: 1301.9932s\n",
      "\titers: 200, epoch: 5 | loss: 0.0056179\n",
      "\tspeed: 0.0829s/iter; left time: 512.9583s\n",
      "\titers: 300, epoch: 5 | loss: 0.0045321\n",
      "\tspeed: 0.0785s/iter; left time: 477.6299s\n",
      "Epoch: 5 cost time: 31.864139318466187\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0048934 Vali Loss: 0.0318595 Test Loss: 0.0691311\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0040775\n",
      "\tspeed: 0.1899s/iter; left time: 1117.5631s\n",
      "\titers: 200, epoch: 6 | loss: 0.0045895\n",
      "\tspeed: 0.0803s/iter; left time: 464.7751s\n",
      "\titers: 300, epoch: 6 | loss: 0.0044051\n",
      "\tspeed: 0.0809s/iter; left time: 459.8631s\n",
      "Epoch: 6 cost time: 32.28416395187378\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0045979 Vali Loss: 0.0272666 Test Loss: 0.0589648\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0047723\n",
      "\tspeed: 0.2006s/iter; left time: 1100.4232s\n",
      "\titers: 200, epoch: 7 | loss: 0.0047816\n",
      "\tspeed: 0.0825s/iter; left time: 444.2874s\n",
      "\titers: 300, epoch: 7 | loss: 0.0040526\n",
      "\tspeed: 0.0822s/iter; left time: 434.6732s\n",
      "Epoch: 7 cost time: 32.96061897277832\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0044698 Vali Loss: 0.0291570 Test Loss: 0.0619414\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.0579170361161232, mae:0.1888786256313324\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_reversal_ftS_sl168_ll48_pl48_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.0986303\n",
      "\tspeed: 0.0842s/iter; left time: 661.7590s\n",
      "\titers: 200, epoch: 1 | loss: 0.0467545\n",
      "\tspeed: 0.0845s/iter; left time: 656.0162s\n",
      "\titers: 300, epoch: 1 | loss: 0.0199121\n",
      "\tspeed: 0.0854s/iter; left time: 654.3176s\n",
      "Epoch: 1 cost time: 33.71470832824707\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0897296 Vali Loss: 0.0646953 Test Loss: 0.0762054\n",
      "Validation loss decreased (inf --> 0.064695).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0216399\n",
      "\tspeed: 0.2100s/iter; left time: 1567.2088s\n",
      "\titers: 200, epoch: 2 | loss: 0.0146584\n",
      "\tspeed: 0.0816s/iter; left time: 601.0360s\n",
      "\titers: 300, epoch: 2 | loss: 0.0145634\n",
      "\tspeed: 0.0818s/iter; left time: 593.9429s\n",
      "Epoch: 2 cost time: 32.663259744644165\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0134525 Vali Loss: 0.0274579 Test Loss: 0.0356510\n",
      "Validation loss decreased (0.064695 --> 0.027458).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0070732\n",
      "\tspeed: 0.2042s/iter; left time: 1442.9412s\n",
      "\titers: 200, epoch: 3 | loss: 0.0089069\n",
      "\tspeed: 0.0821s/iter; left time: 571.5189s\n",
      "\titers: 300, epoch: 3 | loss: 0.0114250\n",
      "\tspeed: 0.0831s/iter; left time: 570.7853s\n",
      "Epoch: 3 cost time: 33.376863956451416\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0078370 Vali Loss: 0.0209824 Test Loss: 0.0410348\n",
      "Validation loss decreased (0.027458 --> 0.020982).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0065041\n",
      "\tspeed: 0.2124s/iter; left time: 1415.7457s\n",
      "\titers: 200, epoch: 4 | loss: 0.0074566\n",
      "\tspeed: 0.0830s/iter; left time: 545.2334s\n",
      "\titers: 300, epoch: 4 | loss: 0.0070066\n",
      "\tspeed: 0.0832s/iter; left time: 538.1334s\n",
      "Epoch: 4 cost time: 33.162063121795654\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0064761 Vali Loss: 0.0230442 Test Loss: 0.0539975\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0046818\n",
      "\tspeed: 0.2048s/iter; left time: 1284.1862s\n",
      "\titers: 200, epoch: 5 | loss: 0.0066848\n",
      "\tspeed: 0.0894s/iter; left time: 551.7375s\n",
      "\titers: 300, epoch: 5 | loss: 0.0051152\n",
      "\tspeed: 0.0883s/iter; left time: 535.7607s\n",
      "Epoch: 5 cost time: 34.734580516815186\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0058414 Vali Loss: 0.0170303 Test Loss: 0.0380957\n",
      "Validation loss decreased (0.020982 --> 0.017030).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0049373\n",
      "\tspeed: 0.2070s/iter; left time: 1215.0153s\n",
      "\titers: 200, epoch: 6 | loss: 0.0051580\n",
      "\tspeed: 0.0832s/iter; left time: 479.8983s\n",
      "\titers: 300, epoch: 6 | loss: 0.0058462\n",
      "\tspeed: 0.0868s/iter; left time: 492.2055s\n",
      "Epoch: 6 cost time: 33.80115509033203\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0053529 Vali Loss: 0.0199732 Test Loss: 0.0503133\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0049394\n",
      "\tspeed: 0.2116s/iter; left time: 1158.2380s\n",
      "\titers: 200, epoch: 7 | loss: 0.0048498\n",
      "\tspeed: 0.0858s/iter; left time: 460.7470s\n",
      "\titers: 300, epoch: 7 | loss: 0.0053639\n",
      "\tspeed: 0.0838s/iter; left time: 442.0616s\n",
      "Epoch: 7 cost time: 34.12086248397827\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0051547 Vali Loss: 0.0185338 Test Loss: 0.0471090\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0049916\n",
      "\tspeed: 0.2099s/iter; left time: 1065.2981s\n",
      "\titers: 200, epoch: 8 | loss: 0.0053510\n",
      "\tspeed: 0.0885s/iter; left time: 440.0938s\n",
      "\titers: 300, epoch: 8 | loss: 0.0046344\n",
      "\tspeed: 0.0865s/iter; left time: 421.7457s\n",
      "Epoch: 8 cost time: 34.646119117736816\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0050753 Vali Loss: 0.0208644 Test Loss: 0.0539966\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.03813615068793297, mae:0.14084915816783905\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_reversal_ftS_sl168_ll48_pl168_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.1237224\n",
      "\tspeed: 0.1074s/iter; left time: 835.7308s\n",
      "\titers: 200, epoch: 1 | loss: 0.1040645\n",
      "\tspeed: 0.1098s/iter; left time: 843.1941s\n",
      "\titers: 300, epoch: 1 | loss: 0.0611429\n",
      "\tspeed: 0.1097s/iter; left time: 831.6636s\n",
      "Epoch: 1 cost time: 42.988399267196655\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.1243409 Vali Loss: 0.2275242 Test Loss: 0.1862402\n",
      "Validation loss decreased (inf --> 0.227524).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0266450\n",
      "\tspeed: 0.2826s/iter; left time: 2087.7470s\n",
      "\titers: 200, epoch: 2 | loss: 0.0292974\n",
      "\tspeed: 0.1135s/iter; left time: 826.8207s\n",
      "\titers: 300, epoch: 2 | loss: 0.0306624\n",
      "\tspeed: 0.1134s/iter; left time: 814.8213s\n",
      "Epoch: 2 cost time: 44.96057605743408\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0291325 Vali Loss: 0.0939205 Test Loss: 0.0883326\n",
      "Validation loss decreased (0.227524 --> 0.093921).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0172273\n",
      "\tspeed: 0.2776s/iter; left time: 1941.3758s\n",
      "\titers: 200, epoch: 3 | loss: 0.0202401\n",
      "\tspeed: 0.1166s/iter; left time: 804.0473s\n",
      "\titers: 300, epoch: 3 | loss: 0.0145572\n",
      "\tspeed: 0.1143s/iter; left time: 776.6694s\n",
      "Epoch: 3 cost time: 44.875290870666504\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0170934 Vali Loss: 0.0572704 Test Loss: 0.0691613\n",
      "Validation loss decreased (0.093921 --> 0.057270).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0111753\n",
      "\tspeed: 0.2821s/iter; left time: 1861.7072s\n",
      "\titers: 200, epoch: 4 | loss: 0.0122620\n",
      "\tspeed: 0.1149s/iter; left time: 746.8327s\n",
      "\titers: 300, epoch: 4 | loss: 0.0151480\n",
      "\tspeed: 0.1190s/iter; left time: 761.4321s\n",
      "Epoch: 4 cost time: 44.71487855911255\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0139113 Vali Loss: 0.0479625 Test Loss: 0.0681362\n",
      "Validation loss decreased (0.057270 --> 0.047962).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0110161\n",
      "\tspeed: 0.2747s/iter; left time: 1704.3824s\n",
      "\titers: 200, epoch: 5 | loss: 0.0090307\n",
      "\tspeed: 0.1101s/iter; left time: 672.1563s\n",
      "\titers: 300, epoch: 5 | loss: 0.0142017\n",
      "\tspeed: 0.1141s/iter; left time: 685.3017s\n",
      "Epoch: 5 cost time: 43.817506074905396\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0121129 Vali Loss: 0.0474334 Test Loss: 0.0660377\n",
      "Validation loss decreased (0.047962 --> 0.047433).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0126661\n",
      "\tspeed: 0.2807s/iter; left time: 1631.0974s\n",
      "\titers: 200, epoch: 6 | loss: 0.0082078\n",
      "\tspeed: 0.1140s/iter; left time: 651.0086s\n",
      "\titers: 300, epoch: 6 | loss: 0.0104733\n",
      "\tspeed: 0.1157s/iter; left time: 649.2565s\n",
      "Epoch: 6 cost time: 45.18291759490967\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0111397 Vali Loss: 0.0450852 Test Loss: 0.0635705\n",
      "Validation loss decreased (0.047433 --> 0.045085).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0092244\n",
      "\tspeed: 0.2812s/iter; left time: 1523.0878s\n",
      "\titers: 200, epoch: 7 | loss: 0.0109238\n",
      "\tspeed: 0.1169s/iter; left time: 621.5946s\n",
      "\titers: 300, epoch: 7 | loss: 0.0090293\n",
      "\tspeed: 0.1190s/iter; left time: 621.0453s\n",
      "Epoch: 7 cost time: 46.292237758636475\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0107261 Vali Loss: 0.0469174 Test Loss: 0.0655211\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0090003\n",
      "\tspeed: 0.2895s/iter; left time: 1453.9188s\n",
      "\titers: 200, epoch: 8 | loss: 0.0092773\n",
      "\tspeed: 0.1138s/iter; left time: 560.2812s\n",
      "\titers: 300, epoch: 8 | loss: 0.0100225\n",
      "\tspeed: 0.1036s/iter; left time: 499.6465s\n",
      "Epoch: 8 cost time: 44.03853440284729\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0106617 Vali Loss: 0.0520552 Test Loss: 0.0701441\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0134438\n",
      "\tspeed: 0.2880s/iter; left time: 1333.2416s\n",
      "\titers: 200, epoch: 9 | loss: 0.0120085\n",
      "\tspeed: 0.1174s/iter; left time: 531.9278s\n",
      "\titers: 300, epoch: 9 | loss: 0.0129595\n",
      "\tspeed: 0.1157s/iter; left time: 512.4464s\n",
      "Epoch: 9 cost time: 45.07982921600342\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0104554 Vali Loss: 0.0452611 Test Loss: 0.0644984\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.0633552074432373, mae:0.19043536484241486\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_reversal_ftS_sl168_ll48_pl336_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.1632015\n",
      "\tspeed: 0.1304s/iter; left time: 1001.5075s\n",
      "\titers: 200, epoch: 1 | loss: 0.1576056\n",
      "\tspeed: 0.1413s/iter; left time: 1071.1104s\n",
      "\titers: 300, epoch: 1 | loss: 0.1408649\n",
      "\tspeed: 0.1441s/iter; left time: 1077.6954s\n",
      "Epoch: 1 cost time: 54.343217849731445\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1799503 Vali Loss: 0.6644047 Test Loss: 0.6352499\n",
      "Validation loss decreased (inf --> 0.664405).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0592123\n",
      "\tspeed: 0.3382s/iter; left time: 2466.2747s\n",
      "\titers: 200, epoch: 2 | loss: 0.0614320\n",
      "\tspeed: 0.1413s/iter; left time: 1016.0178s\n",
      "\titers: 300, epoch: 2 | loss: 0.0504478\n",
      "\tspeed: 0.1430s/iter; left time: 1014.4633s\n",
      "Epoch: 2 cost time: 54.96580934524536\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0651129 Vali Loss: 0.4308426 Test Loss: 0.4660212\n",
      "Validation loss decreased (0.664405 --> 0.430843).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0318185\n",
      "\tspeed: 0.3527s/iter; left time: 2434.5877s\n",
      "\titers: 200, epoch: 3 | loss: 0.0327826\n",
      "\tspeed: 0.1452s/iter; left time: 988.0641s\n",
      "\titers: 300, epoch: 3 | loss: 0.0437354\n",
      "\tspeed: 0.1447s/iter; left time: 969.8899s\n",
      "Epoch: 3 cost time: 55.84664297103882\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0352386 Vali Loss: 0.6402330 Test Loss: 0.7465704\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0176807\n",
      "\tspeed: 0.3329s/iter; left time: 2168.4471s\n",
      "\titers: 200, epoch: 4 | loss: 0.0280268\n",
      "\tspeed: 0.1393s/iter; left time: 893.2161s\n",
      "\titers: 300, epoch: 4 | loss: 0.0195905\n",
      "\tspeed: 0.1392s/iter; left time: 878.8355s\n",
      "Epoch: 4 cost time: 54.50185966491699\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0242279 Vali Loss: 0.8139097 Test Loss: 0.9793360\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0244614\n",
      "\tspeed: 0.3505s/iter; left time: 2146.7137s\n",
      "\titers: 200, epoch: 5 | loss: 0.0192074\n",
      "\tspeed: 0.1417s/iter; left time: 853.6913s\n",
      "\titers: 300, epoch: 5 | loss: 0.0167077\n",
      "\tspeed: 0.1435s/iter; left time: 850.0667s\n",
      "Epoch: 5 cost time: 55.70100998878479\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0195349 Vali Loss: 0.7812425 Test Loss: 1.0206721\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.46623581647872925, mae:0.5255951285362244\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_additive_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_additive_reversal_ftS_sl168_ll48_pl720_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.2256001\n",
      "\tspeed: 0.1921s/iter; left time: 1429.3089s\n",
      "\titers: 200, epoch: 1 | loss: 0.2640503\n",
      "\tspeed: 0.1915s/iter; left time: 1406.0418s\n",
      "\titers: 300, epoch: 1 | loss: 0.1935900\n",
      "\tspeed: 0.1967s/iter; left time: 1424.3145s\n",
      "Epoch: 1 cost time: 72.92433261871338\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.2419307 Vali Loss: 1.3790305 Test Loss: 0.9916852\n",
      "Validation loss decreased (inf --> 1.379030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1566415\n",
      "\tspeed: 0.4220s/iter; left time: 2981.2476s\n",
      "\titers: 200, epoch: 2 | loss: 0.1265785\n",
      "\tspeed: 0.1991s/iter; left time: 1386.5296s\n",
      "\titers: 300, epoch: 2 | loss: 0.1296778\n",
      "\tspeed: 0.2056s/iter; left time: 1410.9280s\n",
      "Epoch: 2 cost time: 74.96370768547058\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.1436726 Vali Loss: 1.2756332 Test Loss: 0.9610592\n",
      "Validation loss decreased (1.379030 --> 1.275633).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1091172\n",
      "\tspeed: 0.4372s/iter; left time: 2923.2238s\n",
      "\titers: 200, epoch: 3 | loss: 0.0946491\n",
      "\tspeed: 0.1956s/iter; left time: 1288.2163s\n",
      "\titers: 300, epoch: 3 | loss: 0.1212427\n",
      "\tspeed: 0.1952s/iter; left time: 1266.3287s\n",
      "Epoch: 3 cost time: 74.19479084014893\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.1039982 Vali Loss: 1.4226888 Test Loss: 1.1238486\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0854807\n",
      "\tspeed: 0.4321s/iter; left time: 2726.4959s\n",
      "\titers: 200, epoch: 4 | loss: 0.0751833\n",
      "\tspeed: 0.1988s/iter; left time: 1234.4328s\n",
      "\titers: 300, epoch: 4 | loss: 0.0648385\n",
      "\tspeed: 0.1971s/iter; left time: 1204.3946s\n",
      "Epoch: 4 cost time: 73.98952341079712\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0746091 Vali Loss: 1.3503852 Test Loss: 0.9901155\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0451959\n",
      "\tspeed: 0.4126s/iter; left time: 2447.7779s\n",
      "\titers: 200, epoch: 5 | loss: 0.0488544\n",
      "\tspeed: 0.1988s/iter; left time: 1159.3973s\n",
      "\titers: 300, epoch: 5 | loss: 0.0322976\n",
      "\tspeed: 0.1956s/iter; left time: 1121.0965s\n",
      "Epoch: 5 cost time: 73.003338098526\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0426047 Vali Loss: 1.2561963 Test Loss: 0.9139011\n",
      "Validation loss decreased (1.275633 --> 1.256196).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0256373\n",
      "\tspeed: 0.4210s/iter; left time: 2339.1485s\n",
      "\titers: 200, epoch: 6 | loss: 0.0358973\n",
      "\tspeed: 0.1940s/iter; left time: 1058.4536s\n",
      "\titers: 300, epoch: 6 | loss: 0.0255570\n",
      "\tspeed: 0.1893s/iter; left time: 1013.9743s\n",
      "Epoch: 6 cost time: 72.50760340690613\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0278908 Vali Loss: 1.2750813 Test Loss: 0.9767845\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0265100\n",
      "\tspeed: 0.4250s/iter; left time: 2201.2882s\n",
      "\titers: 200, epoch: 7 | loss: 0.0211442\n",
      "\tspeed: 0.2044s/iter; left time: 1038.2139s\n",
      "\titers: 300, epoch: 7 | loss: 0.0292856\n",
      "\tspeed: 0.1950s/iter; left time: 970.6577s\n",
      "Epoch: 7 cost time: 74.94186615943909\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0232200 Vali Loss: 1.2756679 Test Loss: 0.9516881\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0198302\n",
      "\tspeed: 0.4403s/iter; left time: 2114.1798s\n",
      "\titers: 200, epoch: 8 | loss: 0.0199803\n",
      "\tspeed: 0.1937s/iter; left time: 911.0048s\n",
      "\titers: 300, epoch: 8 | loss: 0.0191672\n",
      "\tspeed: 0.1953s/iter; left time: 898.8108s\n",
      "Epoch: 8 cost time: 74.72577047348022\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.0219108 Vali Loss: 1.2829043 Test Loss: 0.9439352\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.9129319787025452, mae:0.8293773531913757\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_ftS_sl168_ll48_pl24_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.0779084\n",
      "\tspeed: 0.0846s/iter; left time: 666.5903s\n",
      "\titers: 200, epoch: 1 | loss: 0.0504455\n",
      "\tspeed: 0.0833s/iter; left time: 648.2223s\n",
      "\titers: 300, epoch: 1 | loss: 0.0197164\n",
      "\tspeed: 0.0832s/iter; left time: 639.1015s\n",
      "Epoch: 1 cost time: 33.38997936248779\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.0696745 Vali Loss: 0.0601717 Test Loss: 0.5217263\n",
      "Validation loss decreased (inf --> 0.060172).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0079673\n",
      "\tspeed: 0.2016s/iter; left time: 1508.0952s\n",
      "\titers: 200, epoch: 2 | loss: 0.0102275\n",
      "\tspeed: 0.0805s/iter; left time: 594.1296s\n",
      "\titers: 300, epoch: 2 | loss: 0.0069956\n",
      "\tspeed: 0.0804s/iter; left time: 585.2110s\n",
      "Epoch: 2 cost time: 32.192991733551025\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0090346 Vali Loss: 0.0276723 Test Loss: 0.3858981\n",
      "Validation loss decreased (0.060172 --> 0.027672).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0048562\n",
      "\tspeed: 0.1972s/iter; left time: 1396.8358s\n",
      "\titers: 200, epoch: 3 | loss: 0.0049227\n",
      "\tspeed: 0.0809s/iter; left time: 564.6499s\n",
      "\titers: 300, epoch: 3 | loss: 0.0056929\n",
      "\tspeed: 0.0804s/iter; left time: 553.5446s\n",
      "Epoch: 3 cost time: 32.37532949447632\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0052468 Vali Loss: 0.0212731 Test Loss: 0.3428676\n",
      "Validation loss decreased (0.027672 --> 0.021273).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0040443\n",
      "\tspeed: 0.2063s/iter; left time: 1378.8680s\n",
      "\titers: 200, epoch: 4 | loss: 0.0039572\n",
      "\tspeed: 0.0848s/iter; left time: 558.4576s\n",
      "\titers: 300, epoch: 4 | loss: 0.0038637\n",
      "\tspeed: 0.0853s/iter; left time: 553.0084s\n",
      "Epoch: 4 cost time: 33.87544870376587\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0042541 Vali Loss: 0.0194189 Test Loss: 0.3463055\n",
      "Validation loss decreased (0.021273 --> 0.019419).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0032491\n",
      "\tspeed: 0.2102s/iter; left time: 1320.9380s\n",
      "\titers: 200, epoch: 5 | loss: 0.0038645\n",
      "\tspeed: 0.0849s/iter; left time: 524.9105s\n",
      "\titers: 300, epoch: 5 | loss: 0.0035221\n",
      "\tspeed: 0.0788s/iter; left time: 479.4930s\n",
      "Epoch: 5 cost time: 32.614938735961914\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0036985 Vali Loss: 0.0163009 Test Loss: 0.3061759\n",
      "Validation loss decreased (0.019419 --> 0.016301).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0034696\n",
      "\tspeed: 0.1950s/iter; left time: 1148.0220s\n",
      "\titers: 200, epoch: 6 | loss: 0.0032936\n",
      "\tspeed: 0.0802s/iter; left time: 464.0724s\n",
      "\titers: 300, epoch: 6 | loss: 0.0031643\n",
      "\tspeed: 0.0803s/iter; left time: 456.4484s\n",
      "Epoch: 6 cost time: 32.317606687545776\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0035017 Vali Loss: 0.0152810 Test Loss: 0.3346299\n",
      "Validation loss decreased (0.016301 --> 0.015281).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0030755\n",
      "\tspeed: 0.2041s/iter; left time: 1119.7304s\n",
      "\titers: 200, epoch: 7 | loss: 0.0031376\n",
      "\tspeed: 0.0838s/iter; left time: 451.4132s\n",
      "\titers: 300, epoch: 7 | loss: 0.0032829\n",
      "\tspeed: 0.0864s/iter; left time: 456.7746s\n",
      "Epoch: 7 cost time: 33.61713147163391\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0033380 Vali Loss: 0.0149483 Test Loss: 0.3168035\n",
      "Validation loss decreased (0.015281 --> 0.014948).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0026839\n",
      "\tspeed: 0.2093s/iter; left time: 1065.0575s\n",
      "\titers: 200, epoch: 8 | loss: 0.0025155\n",
      "\tspeed: 0.0851s/iter; left time: 424.3150s\n",
      "\titers: 300, epoch: 8 | loss: 0.0033272\n",
      "\tspeed: 0.0855s/iter; left time: 417.7215s\n",
      "Epoch: 8 cost time: 33.902761459350586\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0032509 Vali Loss: 0.0151537 Test Loss: 0.3308768\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0027111\n",
      "\tspeed: 0.2027s/iter; left time: 950.6860s\n",
      "\titers: 200, epoch: 9 | loss: 0.0035031\n",
      "\tspeed: 0.0784s/iter; left time: 359.6093s\n",
      "\titers: 300, epoch: 9 | loss: 0.0032983\n",
      "\tspeed: 0.0783s/iter; left time: 351.4065s\n",
      "Epoch: 9 cost time: 31.610782623291016\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0031914 Vali Loss: 0.0144385 Test Loss: 0.3203412\n",
      "Validation loss decreased (0.014948 --> 0.014439).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0029746\n",
      "\tspeed: 0.1935s/iter; left time: 829.9851s\n",
      "\titers: 200, epoch: 10 | loss: 0.0028210\n",
      "\tspeed: 0.0796s/iter; left time: 333.4257s\n",
      "\titers: 300, epoch: 10 | loss: 0.0032073\n",
      "\tspeed: 0.0816s/iter; left time: 333.8926s\n",
      "Epoch: 10 cost time: 32.33610534667969\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0031786 Vali Loss: 0.0149370 Test Loss: 0.3305275\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0027814\n",
      "\tspeed: 0.2011s/iter; left time: 782.4673s\n",
      "\titers: 200, epoch: 11 | loss: 0.0033206\n",
      "\tspeed: 0.0829s/iter; left time: 314.2008s\n",
      "\titers: 300, epoch: 11 | loss: 0.0034709\n",
      "\tspeed: 0.0845s/iter; left time: 311.8743s\n",
      "Epoch: 11 cost time: 33.29441285133362\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0031726 Vali Loss: 0.0146574 Test Loss: 0.3227674\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0036948\n",
      "\tspeed: 0.2052s/iter; left time: 716.7119s\n",
      "\titers: 200, epoch: 12 | loss: 0.0035954\n",
      "\tspeed: 0.0834s/iter; left time: 282.7936s\n",
      "\titers: 300, epoch: 12 | loss: 0.0033297\n",
      "\tspeed: 0.0825s/iter; left time: 271.5944s\n",
      "Epoch: 12 cost time: 32.609113931655884\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0031747 Vali Loss: 0.0149341 Test Loss: 0.3342784\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.3219229280948639, mae:0.4342956840991974\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_ftS_sl168_ll48_pl48_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.0744592\n",
      "\tspeed: 0.0825s/iter; left time: 648.5997s\n",
      "\titers: 200, epoch: 1 | loss: 0.0740855\n",
      "\tspeed: 0.0818s/iter; left time: 635.1341s\n",
      "\titers: 300, epoch: 1 | loss: 0.0305490\n",
      "\tspeed: 0.0827s/iter; left time: 633.9471s\n",
      "Epoch: 1 cost time: 32.80061221122742\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0835835 Vali Loss: 0.0734950 Test Loss: 0.5488078\n",
      "Validation loss decreased (inf --> 0.073495).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0247262\n",
      "\tspeed: 0.2028s/iter; left time: 1513.2955s\n",
      "\titers: 200, epoch: 2 | loss: 0.0099912\n",
      "\tspeed: 0.0861s/iter; left time: 634.2852s\n",
      "\titers: 300, epoch: 2 | loss: 0.0095032\n",
      "\tspeed: 0.0877s/iter; left time: 636.9005s\n",
      "Epoch: 2 cost time: 34.45688033103943\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0128629 Vali Loss: 0.0778417 Test Loss: 0.5470730\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0065309\n",
      "\tspeed: 0.2147s/iter; left time: 1517.1117s\n",
      "\titers: 200, epoch: 3 | loss: 0.0058142\n",
      "\tspeed: 0.0878s/iter; left time: 611.4745s\n",
      "\titers: 300, epoch: 3 | loss: 0.0066063\n",
      "\tspeed: 0.0880s/iter; left time: 604.4598s\n",
      "Epoch: 3 cost time: 34.80311703681946\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0063635 Vali Loss: 0.0274267 Test Loss: 0.3305943\n",
      "Validation loss decreased (0.073495 --> 0.027427).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0043612\n",
      "\tspeed: 0.2120s/iter; left time: 1413.1876s\n",
      "\titers: 200, epoch: 4 | loss: 0.0050122\n",
      "\tspeed: 0.0875s/iter; left time: 574.9378s\n",
      "\titers: 300, epoch: 4 | loss: 0.0058831\n",
      "\tspeed: 0.0876s/iter; left time: 566.1925s\n",
      "Epoch: 4 cost time: 34.79793882369995\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0050216 Vali Loss: 0.0209626 Test Loss: 0.2998013\n",
      "Validation loss decreased (0.027427 --> 0.020963).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0037641\n",
      "\tspeed: 0.2148s/iter; left time: 1346.8204s\n",
      "\titers: 200, epoch: 5 | loss: 0.0037573\n",
      "\tspeed: 0.0857s/iter; left time: 528.8210s\n",
      "\titers: 300, epoch: 5 | loss: 0.0036383\n",
      "\tspeed: 0.0876s/iter; left time: 531.8092s\n",
      "Epoch: 5 cost time: 34.09448194503784\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0041812 Vali Loss: 0.0213484 Test Loss: 0.3091290\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0041302\n",
      "\tspeed: 0.2058s/iter; left time: 1208.2687s\n",
      "\titers: 200, epoch: 6 | loss: 0.0035588\n",
      "\tspeed: 0.0879s/iter; left time: 507.0429s\n",
      "\titers: 300, epoch: 6 | loss: 0.0040384\n",
      "\tspeed: 0.0874s/iter; left time: 495.6945s\n",
      "Epoch: 6 cost time: 34.39194393157959\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0039038 Vali Loss: 0.0195623 Test Loss: 0.2835295\n",
      "Validation loss decreased (0.020963 --> 0.019562).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0036561\n",
      "\tspeed: 0.2029s/iter; left time: 1110.4059s\n",
      "\titers: 200, epoch: 7 | loss: 0.0036450\n",
      "\tspeed: 0.0827s/iter; left time: 444.3488s\n",
      "\titers: 300, epoch: 7 | loss: 0.0039873\n",
      "\tspeed: 0.0779s/iter; left time: 410.7390s\n",
      "Epoch: 7 cost time: 31.81215000152588\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0037898 Vali Loss: 0.0199298 Test Loss: 0.2960719\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0041612\n",
      "\tspeed: 0.1980s/iter; left time: 1004.7307s\n",
      "\titers: 200, epoch: 8 | loss: 0.0037144\n",
      "\tspeed: 0.0858s/iter; left time: 427.0674s\n",
      "\titers: 300, epoch: 8 | loss: 0.0030589\n",
      "\tspeed: 0.0853s/iter; left time: 415.9230s\n",
      "Epoch: 8 cost time: 33.97630476951599\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0036827 Vali Loss: 0.0209670 Test Loss: 0.3030015\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0035973\n",
      "\tspeed: 0.2086s/iter; left time: 975.6498s\n",
      "\titers: 200, epoch: 9 | loss: 0.0033274\n",
      "\tspeed: 0.0830s/iter; left time: 379.7682s\n",
      "\titers: 300, epoch: 9 | loss: 0.0035738\n",
      "\tspeed: 0.0823s/iter; left time: 368.2712s\n",
      "Epoch: 9 cost time: 33.15336728096008\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0036380 Vali Loss: 0.0215603 Test Loss: 0.3047553\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.28424692153930664, mae:0.4048161804676056\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_ftS_sl168_ll48_pl168_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.0828576\n",
      "\tspeed: 0.1110s/iter; left time: 863.6926s\n",
      "\titers: 200, epoch: 1 | loss: 0.0650811\n",
      "\tspeed: 0.1094s/iter; left time: 840.5654s\n",
      "\titers: 300, epoch: 1 | loss: 0.0409655\n",
      "\tspeed: 0.1130s/iter; left time: 856.9674s\n",
      "Epoch: 1 cost time: 43.764060497283936\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.0919519 Vali Loss: 0.0950279 Test Loss: 0.8123059\n",
      "Validation loss decreased (inf --> 0.095028).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0230251\n",
      "\tspeed: 0.2761s/iter; left time: 2039.4992s\n",
      "\titers: 200, epoch: 2 | loss: 0.0100440\n",
      "\tspeed: 0.1089s/iter; left time: 793.1993s\n",
      "\titers: 300, epoch: 2 | loss: 0.0240540\n",
      "\tspeed: 0.1089s/iter; left time: 782.5369s\n",
      "Epoch: 2 cost time: 43.17492985725403\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0142647 Vali Loss: 0.1126523 Test Loss: 0.9433109\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0062437\n",
      "\tspeed: 0.2763s/iter; left time: 1932.3096s\n",
      "\titers: 200, epoch: 3 | loss: 0.0061811\n",
      "\tspeed: 0.1162s/iter; left time: 801.2696s\n",
      "\titers: 300, epoch: 3 | loss: 0.0049678\n",
      "\tspeed: 0.1149s/iter; left time: 780.7944s\n",
      "Epoch: 3 cost time: 45.007076025009155\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0075610 Vali Loss: 0.0417346 Test Loss: 0.6420203\n",
      "Validation loss decreased (0.095028 --> 0.041735).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0053784\n",
      "\tspeed: 0.2900s/iter; left time: 1913.9212s\n",
      "\titers: 200, epoch: 4 | loss: 0.0049038\n",
      "\tspeed: 0.1212s/iter; left time: 787.6663s\n",
      "\titers: 300, epoch: 4 | loss: 0.0060095\n",
      "\tspeed: 0.1109s/iter; left time: 709.5876s\n",
      "Epoch: 4 cost time: 46.107587575912476\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0058441 Vali Loss: 0.0461507 Test Loss: 0.6694450\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0055292\n",
      "\tspeed: 0.2894s/iter; left time: 1795.8392s\n",
      "\titers: 200, epoch: 5 | loss: 0.0044129\n",
      "\tspeed: 0.1136s/iter; left time: 693.2634s\n",
      "\titers: 300, epoch: 5 | loss: 0.0075295\n",
      "\tspeed: 0.1131s/iter; left time: 679.3463s\n",
      "Epoch: 5 cost time: 44.89494299888611\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0051622 Vali Loss: 0.0454516 Test Loss: 0.6319643\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0052093\n",
      "\tspeed: 0.2849s/iter; left time: 1655.7117s\n",
      "\titers: 200, epoch: 6 | loss: 0.0040394\n",
      "\tspeed: 0.1173s/iter; left time: 669.6609s\n",
      "\titers: 300, epoch: 6 | loss: 0.0049892\n",
      "\tspeed: 0.1144s/iter; left time: 641.7970s\n",
      "Epoch: 6 cost time: 45.29948091506958\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0048266 Vali Loss: 0.0403569 Test Loss: 0.5907426\n",
      "Validation loss decreased (0.041735 --> 0.040357).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0052799\n",
      "\tspeed: 0.2883s/iter; left time: 1561.9788s\n",
      "\titers: 200, epoch: 7 | loss: 0.0039960\n",
      "\tspeed: 0.1164s/iter; left time: 618.9987s\n",
      "\titers: 300, epoch: 7 | loss: 0.0043708\n",
      "\tspeed: 0.1166s/iter; left time: 608.4410s\n",
      "Epoch: 7 cost time: 45.82904076576233\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0047241 Vali Loss: 0.0357907 Test Loss: 0.5692974\n",
      "Validation loss decreased (0.040357 --> 0.035791).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0038597\n",
      "\tspeed: 0.2712s/iter; left time: 1362.1638s\n",
      "\titers: 200, epoch: 8 | loss: 0.0052588\n",
      "\tspeed: 0.1093s/iter; left time: 538.2100s\n",
      "\titers: 300, epoch: 8 | loss: 0.0039796\n",
      "\tspeed: 0.1131s/iter; left time: 545.5834s\n",
      "Epoch: 8 cost time: 43.452457904815674\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0045703 Vali Loss: 0.0319872 Test Loss: 0.5366071\n",
      "Validation loss decreased (0.035791 --> 0.031987).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0046370\n",
      "\tspeed: 0.2865s/iter; left time: 1326.1265s\n",
      "\titers: 200, epoch: 9 | loss: 0.0034995\n",
      "\tspeed: 0.1031s/iter; left time: 466.7738s\n",
      "\titers: 300, epoch: 9 | loss: 0.0048267\n",
      "\tspeed: 0.1094s/iter; left time: 484.3767s\n",
      "Epoch: 9 cost time: 43.105642318725586\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0045386 Vali Loss: 0.0345777 Test Loss: 0.5526967\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0041409\n",
      "\tspeed: 0.2823s/iter; left time: 1195.3473s\n",
      "\titers: 200, epoch: 10 | loss: 0.0050113\n",
      "\tspeed: 0.1134s/iter; left time: 468.8651s\n",
      "\titers: 300, epoch: 10 | loss: 0.0039906\n",
      "\tspeed: 0.1123s/iter; left time: 453.0755s\n",
      "Epoch: 10 cost time: 44.4955997467041\n",
      "Epoch: 10, Steps: 394 | Train Loss: 0.0045056 Vali Loss: 0.0345936 Test Loss: 0.5535972\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0042252\n",
      "\tspeed: 0.2742s/iter; left time: 1053.0502s\n",
      "\titers: 200, epoch: 11 | loss: 0.0039412\n",
      "\tspeed: 0.1084s/iter; left time: 405.3523s\n",
      "\titers: 300, epoch: 11 | loss: 0.0043020\n",
      "\tspeed: 0.1105s/iter; left time: 402.2561s\n",
      "Epoch: 11 cost time: 43.6134934425354\n",
      "Epoch: 11, Steps: 394 | Train Loss: 0.0045006 Vali Loss: 0.0341568 Test Loss: 0.5546558\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.5364759564399719, mae:0.6221221685409546\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_ftS_sl168_ll48_pl336_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.1157532\n",
      "\tspeed: 0.1411s/iter; left time: 1084.0607s\n",
      "\titers: 200, epoch: 1 | loss: 0.0744138\n",
      "\tspeed: 0.1443s/iter; left time: 1094.0339s\n",
      "\titers: 300, epoch: 1 | loss: 0.0664750\n",
      "\tspeed: 0.1427s/iter; left time: 1067.2443s\n",
      "Epoch: 1 cost time: 55.54515480995178\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1082489 Vali Loss: 0.2079974 Test Loss: 1.0766892\n",
      "Validation loss decreased (inf --> 0.207997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0352419\n",
      "\tspeed: 0.3411s/iter; left time: 2487.6075s\n",
      "\titers: 200, epoch: 2 | loss: 0.0162082\n",
      "\tspeed: 0.1388s/iter; left time: 998.2651s\n",
      "\titers: 300, epoch: 2 | loss: 0.0173691\n",
      "\tspeed: 0.1395s/iter; left time: 989.3778s\n",
      "Epoch: 2 cost time: 54.390703439712524\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0253497 Vali Loss: 0.0685579 Test Loss: 0.7414190\n",
      "Validation loss decreased (0.207997 --> 0.068558).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0086278\n",
      "\tspeed: 0.3538s/iter; left time: 2441.9968s\n",
      "\titers: 200, epoch: 3 | loss: 0.0081449\n",
      "\tspeed: 0.1493s/iter; left time: 1015.8140s\n",
      "\titers: 300, epoch: 3 | loss: 0.0069477\n",
      "\tspeed: 0.1447s/iter; left time: 969.6783s\n",
      "Epoch: 3 cost time: 56.712653160095215\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0086852 Vali Loss: 0.0524255 Test Loss: 0.7132481\n",
      "Validation loss decreased (0.068558 --> 0.052425).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0110019\n",
      "\tspeed: 0.3340s/iter; left time: 2175.9315s\n",
      "\titers: 200, epoch: 4 | loss: 0.0055446\n",
      "\tspeed: 0.1445s/iter; left time: 927.0756s\n",
      "\titers: 300, epoch: 4 | loss: 0.0068702\n",
      "\tspeed: 0.1414s/iter; left time: 892.9920s\n",
      "Epoch: 4 cost time: 55.174354553222656\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0070471 Vali Loss: 0.0349838 Test Loss: 0.5983296\n",
      "Validation loss decreased (0.052425 --> 0.034984).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0064040\n",
      "\tspeed: 0.3406s/iter; left time: 2086.2775s\n",
      "\titers: 200, epoch: 5 | loss: 0.0071834\n",
      "\tspeed: 0.1384s/iter; left time: 834.0437s\n",
      "\titers: 300, epoch: 5 | loss: 0.0048887\n",
      "\tspeed: 0.1389s/iter; left time: 823.2598s\n",
      "Epoch: 5 cost time: 54.021079301834106\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0061235 Vali Loss: 0.0364072 Test Loss: 0.5975289\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0068438\n",
      "\tspeed: 0.3431s/iter; left time: 1968.2247s\n",
      "\titers: 200, epoch: 6 | loss: 0.0060191\n",
      "\tspeed: 0.1451s/iter; left time: 817.9841s\n",
      "\titers: 300, epoch: 6 | loss: 0.0053394\n",
      "\tspeed: 0.1450s/iter; left time: 802.9525s\n",
      "Epoch: 6 cost time: 56.31269335746765\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0056614 Vali Loss: 0.0379894 Test Loss: 0.6079928\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0045636\n",
      "\tspeed: 0.3383s/iter; left time: 1808.9253s\n",
      "\titers: 200, epoch: 7 | loss: 0.0043840\n",
      "\tspeed: 0.1389s/iter; left time: 728.9092s\n",
      "\titers: 300, epoch: 7 | loss: 0.0051108\n",
      "\tspeed: 0.1375s/iter; left time: 707.7141s\n",
      "Epoch: 7 cost time: 53.81162357330322\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.0053849 Vali Loss: 0.0383941 Test Loss: 0.6106614\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.5981736779212952, mae:0.6436052322387695\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_ftS_sl168_ll48_pl720_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.1308509\n",
      "\tspeed: 0.2013s/iter; left time: 1498.0169s\n",
      "\titers: 200, epoch: 1 | loss: 0.0813928\n",
      "\tspeed: 0.2018s/iter; left time: 1481.1470s\n",
      "\titers: 300, epoch: 1 | loss: 0.0709465\n",
      "\tspeed: 0.1998s/iter; left time: 1446.8305s\n",
      "Epoch: 1 cost time: 74.60769534111023\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.1112092 Vali Loss: 0.2318984 Test Loss: 1.1677661\n",
      "Validation loss decreased (inf --> 0.231898).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0610685\n",
      "\tspeed: 0.4129s/iter; left time: 2916.6292s\n",
      "\titers: 200, epoch: 2 | loss: 0.0563526\n",
      "\tspeed: 0.1955s/iter; left time: 1361.6860s\n",
      "\titers: 300, epoch: 2 | loss: 0.0611550\n",
      "\tspeed: 0.1980s/iter; left time: 1358.7960s\n",
      "Epoch: 2 cost time: 73.14727926254272\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0610857 Vali Loss: 0.2096490 Test Loss: 1.1295230\n",
      "Validation loss decreased (0.231898 --> 0.209649).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0461105\n",
      "\tspeed: 0.4206s/iter; left time: 2812.3038s\n",
      "\titers: 200, epoch: 3 | loss: 0.0313403\n",
      "\tspeed: 0.1926s/iter; left time: 1268.8384s\n",
      "\titers: 300, epoch: 3 | loss: 0.0139396\n",
      "\tspeed: 0.1898s/iter; left time: 1231.4656s\n",
      "Epoch: 3 cost time: 72.33527421951294\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0345835 Vali Loss: 0.0886704 Test Loss: 0.9118086\n",
      "Validation loss decreased (0.209649 --> 0.088670).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0119366\n",
      "\tspeed: 0.4275s/iter; left time: 2697.2899s\n",
      "\titers: 200, epoch: 4 | loss: 0.0076713\n",
      "\tspeed: 0.2026s/iter; left time: 1258.3488s\n",
      "\titers: 300, epoch: 4 | loss: 0.0073321\n",
      "\tspeed: 0.1958s/iter; left time: 1196.2439s\n",
      "Epoch: 4 cost time: 74.93083691596985\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0086853 Vali Loss: 0.0855148 Test Loss: 0.8862971\n",
      "Validation loss decreased (0.088670 --> 0.085515).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0081749\n",
      "\tspeed: 0.4271s/iter; left time: 2534.1038s\n",
      "\titers: 200, epoch: 5 | loss: 0.0071394\n",
      "\tspeed: 0.1885s/iter; left time: 1099.6363s\n",
      "\titers: 300, epoch: 5 | loss: 0.0068024\n",
      "\tspeed: 0.1934s/iter; left time: 1108.6100s\n",
      "Epoch: 5 cost time: 72.90450644493103\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0071594 Vali Loss: 0.0628892 Test Loss: 0.7588555\n",
      "Validation loss decreased (0.085515 --> 0.062889).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0066277\n",
      "\tspeed: 0.4294s/iter; left time: 2385.7686s\n",
      "\titers: 200, epoch: 6 | loss: 0.0059131\n",
      "\tspeed: 0.2025s/iter; left time: 1105.0025s\n",
      "\titers: 300, epoch: 6 | loss: 0.0108241\n",
      "\tspeed: 0.2017s/iter; left time: 1080.2649s\n",
      "Epoch: 6 cost time: 75.30259132385254\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0064113 Vali Loss: 0.0671418 Test Loss: 0.7749138\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0052263\n",
      "\tspeed: 0.4313s/iter; left time: 2233.7078s\n",
      "\titers: 200, epoch: 7 | loss: 0.0070510\n",
      "\tspeed: 0.1910s/iter; left time: 970.2460s\n",
      "\titers: 300, epoch: 7 | loss: 0.0051429\n",
      "\tspeed: 0.1906s/iter; left time: 948.9203s\n",
      "Epoch: 7 cost time: 72.56966590881348\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0060924 Vali Loss: 0.0646198 Test Loss: 0.7647560\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0052747\n",
      "\tspeed: 0.4246s/iter; left time: 2038.9311s\n",
      "\titers: 200, epoch: 8 | loss: 0.0060983\n",
      "\tspeed: 0.2049s/iter; left time: 963.3895s\n",
      "\titers: 300, epoch: 8 | loss: 0.0077765\n",
      "\tspeed: 0.2004s/iter; left time: 922.0145s\n",
      "Epoch: 8 cost time: 75.40744948387146\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.0059784 Vali Loss: 0.0640088 Test Loss: 0.7583368\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.7576248645782471, mae:0.7355899214744568\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl24_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.0735566\n",
      "\tspeed: 0.0805s/iter; left time: 634.1781s\n",
      "\titers: 200, epoch: 1 | loss: 0.0490224\n",
      "\tspeed: 0.0795s/iter; left time: 618.6556s\n",
      "\titers: 300, epoch: 1 | loss: 0.0196565\n",
      "\tspeed: 0.0810s/iter; left time: 622.3384s\n",
      "Epoch: 1 cost time: 32.185946464538574\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.0745217 Vali Loss: 0.3219751 Test Loss: 1.0593061\n",
      "Validation loss decreased (inf --> 0.321975).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0078416\n",
      "\tspeed: 0.2024s/iter; left time: 1514.7212s\n",
      "\titers: 200, epoch: 2 | loss: 0.0095314\n",
      "\tspeed: 0.0819s/iter; left time: 604.3425s\n",
      "\titers: 300, epoch: 2 | loss: 0.0138543\n",
      "\tspeed: 0.0813s/iter; left time: 591.9832s\n",
      "Epoch: 2 cost time: 32.89688158035278\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0117364 Vali Loss: 0.1277741 Test Loss: 0.6720065\n",
      "Validation loss decreased (0.321975 --> 0.127774).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0074824\n",
      "\tspeed: 0.2078s/iter; left time: 1471.8085s\n",
      "\titers: 200, epoch: 3 | loss: 0.0069895\n",
      "\tspeed: 0.0837s/iter; left time: 584.6971s\n",
      "\titers: 300, epoch: 3 | loss: 0.0052155\n",
      "\tspeed: 0.0846s/iter; left time: 582.5601s\n",
      "Epoch: 3 cost time: 33.59067964553833\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0066017 Vali Loss: 0.0934089 Test Loss: 0.3951533\n",
      "Validation loss decreased (0.127774 --> 0.093409).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0034375\n",
      "\tspeed: 0.2040s/iter; left time: 1363.2293s\n",
      "\titers: 200, epoch: 4 | loss: 0.0033862\n",
      "\tspeed: 0.0769s/iter; left time: 506.5739s\n",
      "\titers: 300, epoch: 4 | loss: 0.0034977\n",
      "\tspeed: 0.0806s/iter; left time: 522.5331s\n",
      "Epoch: 4 cost time: 32.00506901741028\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0050507 Vali Loss: 0.0929655 Test Loss: 0.4066679\n",
      "Validation loss decreased (0.093409 --> 0.092966).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0053790\n",
      "\tspeed: 0.1971s/iter; left time: 1238.9725s\n",
      "\titers: 200, epoch: 5 | loss: 0.0042063\n",
      "\tspeed: 0.0799s/iter; left time: 494.3443s\n",
      "\titers: 300, epoch: 5 | loss: 0.0032159\n",
      "\tspeed: 0.0802s/iter; left time: 488.2464s\n",
      "Epoch: 5 cost time: 32.23964071273804\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0045375 Vali Loss: 0.0876080 Test Loss: 0.3822637\n",
      "Validation loss decreased (0.092966 --> 0.087608).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0030873\n",
      "\tspeed: 0.2019s/iter; left time: 1188.3832s\n",
      "\titers: 200, epoch: 6 | loss: 0.0034530\n",
      "\tspeed: 0.0803s/iter; left time: 464.7099s\n",
      "\titers: 300, epoch: 6 | loss: 0.0031967\n",
      "\tspeed: 0.0803s/iter; left time: 456.8497s\n",
      "Epoch: 6 cost time: 32.15554738044739\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0042812 Vali Loss: 0.0905717 Test Loss: 0.3890480\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0033795\n",
      "\tspeed: 0.1954s/iter; left time: 1072.2901s\n",
      "\titers: 200, epoch: 7 | loss: 0.0037799\n",
      "\tspeed: 0.0809s/iter; left time: 435.8104s\n",
      "\titers: 300, epoch: 7 | loss: 0.0029318\n",
      "\tspeed: 0.0831s/iter; left time: 439.1079s\n",
      "Epoch: 7 cost time: 32.843472957611084\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0041807 Vali Loss: 0.0867750 Test Loss: 0.3842827\n",
      "Validation loss decreased (0.087608 --> 0.086775).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0031256\n",
      "\tspeed: 0.2059s/iter; left time: 1047.6791s\n",
      "\titers: 200, epoch: 8 | loss: 0.0026666\n",
      "\tspeed: 0.0846s/iter; left time: 422.0494s\n",
      "\titers: 300, epoch: 8 | loss: 0.0032649\n",
      "\tspeed: 0.0843s/iter; left time: 412.0219s\n",
      "Epoch: 8 cost time: 33.70157527923584\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0040897 Vali Loss: 0.0856322 Test Loss: 0.3710553\n",
      "Validation loss decreased (0.086775 --> 0.085632).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0026487\n",
      "\tspeed: 0.2081s/iter; left time: 975.9332s\n",
      "\titers: 200, epoch: 9 | loss: 0.0029360\n",
      "\tspeed: 0.0833s/iter; left time: 382.1816s\n",
      "\titers: 300, epoch: 9 | loss: 0.0060751\n",
      "\tspeed: 0.0807s/iter; left time: 362.1269s\n",
      "Epoch: 9 cost time: 32.69600200653076\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0040224 Vali Loss: 0.0855519 Test Loss: 0.3728265\n",
      "Validation loss decreased (0.085632 --> 0.085552).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0034070\n",
      "\tspeed: 0.1961s/iter; left time: 841.2040s\n",
      "\titers: 200, epoch: 10 | loss: 0.0036201\n",
      "\tspeed: 0.0805s/iter; left time: 337.4760s\n",
      "\titers: 300, epoch: 10 | loss: 0.0033521\n",
      "\tspeed: 0.0807s/iter; left time: 330.2479s\n",
      "Epoch: 10 cost time: 32.15168809890747\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0040387 Vali Loss: 0.0857357 Test Loss: 0.3675517\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0031000\n",
      "\tspeed: 0.1992s/iter; left time: 775.1413s\n",
      "\titers: 200, epoch: 11 | loss: 0.0031398\n",
      "\tspeed: 0.0833s/iter; left time: 315.7712s\n",
      "\titers: 300, epoch: 11 | loss: 0.0027494\n",
      "\tspeed: 0.0841s/iter; left time: 310.3253s\n",
      "Epoch: 11 cost time: 33.425756216049194\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0039886 Vali Loss: 0.0865526 Test Loss: 0.3752894\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0027331\n",
      "\tspeed: 0.2047s/iter; left time: 714.6551s\n",
      "\titers: 200, epoch: 12 | loss: 0.0030296\n",
      "\tspeed: 0.0843s/iter; left time: 286.0296s\n",
      "\titers: 300, epoch: 12 | loss: 0.0203052\n",
      "\tspeed: 0.0841s/iter; left time: 276.8142s\n",
      "Epoch: 12 cost time: 33.48258829116821\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0039862 Vali Loss: 0.0843517 Test Loss: 0.3683861\n",
      "Validation loss decreased (0.085552 --> 0.084352).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0073106\n",
      "\tspeed: 0.2027s/iter; left time: 626.9374s\n",
      "\titers: 200, epoch: 13 | loss: 0.0029444\n",
      "\tspeed: 0.0793s/iter; left time: 237.3304s\n",
      "\titers: 300, epoch: 13 | loss: 0.0033795\n",
      "\tspeed: 0.0838s/iter; left time: 242.2990s\n",
      "Epoch: 13 cost time: 32.785839796066284\n",
      "Epoch: 13, Steps: 399 | Train Loss: 0.0040132 Vali Loss: 0.0851502 Test Loss: 0.3723646\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "\titers: 100, epoch: 14 | loss: 0.0069013\n",
      "\tspeed: 0.2060s/iter; left time: 554.9414s\n",
      "\titers: 200, epoch: 14 | loss: 0.0037680\n",
      "\tspeed: 0.0847s/iter; left time: 219.7961s\n",
      "\titers: 300, epoch: 14 | loss: 0.0029033\n",
      "\tspeed: 0.0836s/iter; left time: 208.4166s\n",
      "Epoch: 14 cost time: 33.54311394691467\n",
      "Epoch: 14, Steps: 399 | Train Loss: 0.0039939 Vali Loss: 0.0862709 Test Loss: 0.3696958\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.220703125e-08\n",
      "\titers: 100, epoch: 15 | loss: 0.0076109\n",
      "\tspeed: 0.1969s/iter; left time: 451.9945s\n",
      "\titers: 200, epoch: 15 | loss: 0.0032596\n",
      "\tspeed: 0.0801s/iter; left time: 175.7561s\n",
      "\titers: 300, epoch: 15 | loss: 0.0034938\n",
      "\tspeed: 0.0799s/iter; left time: 167.4579s\n",
      "Epoch: 15 cost time: 31.860544204711914\n",
      "Epoch: 15, Steps: 399 | Train Loss: 0.0039855 Vali Loss: 0.0857062 Test Loss: 0.3657811\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.36713966727256775, mae:0.42004433274269104\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl48_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.0726801\n",
      "\tspeed: 0.0831s/iter; left time: 652.9749s\n",
      "\titers: 200, epoch: 1 | loss: 0.0559685\n",
      "\tspeed: 0.0854s/iter; left time: 662.7033s\n",
      "\titers: 300, epoch: 1 | loss: 0.0451574\n",
      "\tspeed: 0.0847s/iter; left time: 649.1722s\n",
      "Epoch: 1 cost time: 33.74171471595764\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0931495 Vali Loss: 0.2354985 Test Loss: 0.8881950\n",
      "Validation loss decreased (inf --> 0.235498).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0194372\n",
      "\tspeed: 0.2112s/iter; left time: 1576.1962s\n",
      "\titers: 200, epoch: 2 | loss: 0.0103024\n",
      "\tspeed: 0.0862s/iter; left time: 635.0437s\n",
      "\titers: 300, epoch: 2 | loss: 0.0193625\n",
      "\tspeed: 0.0871s/iter; left time: 632.7166s\n",
      "Epoch: 2 cost time: 34.550848960876465\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0151549 Vali Loss: 0.1660305 Test Loss: 0.5803056\n",
      "Validation loss decreased (0.235498 --> 0.166030).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0061361\n",
      "\tspeed: 0.2123s/iter; left time: 1499.7543s\n",
      "\titers: 200, epoch: 3 | loss: 0.0074747\n",
      "\tspeed: 0.0883s/iter; left time: 614.6760s\n",
      "\titers: 300, epoch: 3 | loss: 0.0069867\n",
      "\tspeed: 0.0871s/iter; left time: 597.9387s\n",
      "Epoch: 3 cost time: 34.82059717178345\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0088081 Vali Loss: 0.1702116 Test Loss: 0.6108201\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0061060\n",
      "\tspeed: 0.2123s/iter; left time: 1415.4335s\n",
      "\titers: 200, epoch: 4 | loss: 0.0074816\n",
      "\tspeed: 0.0886s/iter; left time: 581.5242s\n",
      "\titers: 300, epoch: 4 | loss: 0.0057662\n",
      "\tspeed: 0.0863s/iter; left time: 557.8966s\n",
      "Epoch: 4 cost time: 34.37576937675476\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0069305 Vali Loss: 0.1467892 Test Loss: 0.5141405\n",
      "Validation loss decreased (0.166030 --> 0.146789).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0047407\n",
      "\tspeed: 0.1964s/iter; left time: 1231.0315s\n",
      "\titers: 200, epoch: 5 | loss: 0.0080646\n",
      "\tspeed: 0.0768s/iter; left time: 473.5727s\n",
      "\titers: 300, epoch: 5 | loss: 0.0047186\n",
      "\tspeed: 0.0823s/iter; left time: 499.3062s\n",
      "Epoch: 5 cost time: 32.08656930923462\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0060839 Vali Loss: 0.1467608 Test Loss: 0.5059960\n",
      "Validation loss decreased (0.146789 --> 0.146761).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0048329\n",
      "\tspeed: 0.2140s/iter; left time: 1256.1787s\n",
      "\titers: 200, epoch: 6 | loss: 0.0071816\n",
      "\tspeed: 0.0857s/iter; left time: 494.4120s\n",
      "\titers: 300, epoch: 6 | loss: 0.0042479\n",
      "\tspeed: 0.0835s/iter; left time: 473.4017s\n",
      "Epoch: 6 cost time: 33.62144947052002\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0057151 Vali Loss: 0.1459199 Test Loss: 0.4988219\n",
      "Validation loss decreased (0.146761 --> 0.145920).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0128569\n",
      "\tspeed: 0.2090s/iter; left time: 1143.6256s\n",
      "\titers: 200, epoch: 7 | loss: 0.0034870\n",
      "\tspeed: 0.0865s/iter; left time: 464.7899s\n",
      "\titers: 300, epoch: 7 | loss: 0.0036733\n",
      "\tspeed: 0.0872s/iter; left time: 459.8781s\n",
      "Epoch: 7 cost time: 34.49146032333374\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0054000 Vali Loss: 0.1459289 Test Loss: 0.4991278\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0047435\n",
      "\tspeed: 0.2061s/iter; left time: 1046.0917s\n",
      "\titers: 200, epoch: 8 | loss: 0.0049436\n",
      "\tspeed: 0.0850s/iter; left time: 422.7650s\n",
      "\titers: 300, epoch: 8 | loss: 0.0037689\n",
      "\tspeed: 0.0858s/iter; left time: 418.1760s\n",
      "Epoch: 8 cost time: 33.84298038482666\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0052941 Vali Loss: 0.1468251 Test Loss: 0.5048034\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0053766\n",
      "\tspeed: 0.2067s/iter; left time: 966.9438s\n",
      "\titers: 200, epoch: 9 | loss: 0.0048438\n",
      "\tspeed: 0.0869s/iter; left time: 397.6237s\n",
      "\titers: 300, epoch: 9 | loss: 0.0057641\n",
      "\tspeed: 0.0875s/iter; left time: 391.8872s\n",
      "Epoch: 9 cost time: 33.90570783615112\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0052513 Vali Loss: 0.1458339 Test Loss: 0.4918543\n",
      "Validation loss decreased (0.145920 --> 0.145834).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0042821\n",
      "\tspeed: 0.2035s/iter; left time: 870.8364s\n",
      "\titers: 200, epoch: 10 | loss: 0.0042633\n",
      "\tspeed: 0.0848s/iter; left time: 354.2638s\n",
      "\titers: 300, epoch: 10 | loss: 0.0047481\n",
      "\tspeed: 0.0856s/iter; left time: 348.9635s\n",
      "Epoch: 10 cost time: 33.95466995239258\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.0052025 Vali Loss: 0.1439379 Test Loss: 0.4914545\n",
      "Validation loss decreased (0.145834 --> 0.143938).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0044305\n",
      "\tspeed: 0.2086s/iter; left time: 809.7031s\n",
      "\titers: 200, epoch: 11 | loss: 0.0046746\n",
      "\tspeed: 0.0827s/iter; left time: 312.7827s\n",
      "\titers: 300, epoch: 11 | loss: 0.0041317\n",
      "\tspeed: 0.0803s/iter; left time: 295.6108s\n",
      "Epoch: 11 cost time: 32.766135454177856\n",
      "Epoch: 11, Steps: 398 | Train Loss: 0.0051541 Vali Loss: 0.1437968 Test Loss: 0.4880533\n",
      "Validation loss decreased (0.143938 --> 0.143797).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0042824\n",
      "\tspeed: 0.2076s/iter; left time: 723.0089s\n",
      "\titers: 200, epoch: 12 | loss: 0.0040849\n",
      "\tspeed: 0.0871s/iter; left time: 294.5304s\n",
      "\titers: 300, epoch: 12 | loss: 0.0048896\n",
      "\tspeed: 0.0874s/iter; left time: 286.7970s\n",
      "Epoch: 12 cost time: 34.186044692993164\n",
      "Epoch: 12, Steps: 398 | Train Loss: 0.0051414 Vali Loss: 0.1442901 Test Loss: 0.4925311\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0043143\n",
      "\tspeed: 0.2024s/iter; left time: 624.5187s\n",
      "\titers: 200, epoch: 13 | loss: 0.0038028\n",
      "\tspeed: 0.0843s/iter; left time: 251.6689s\n",
      "\titers: 300, epoch: 13 | loss: 0.0155238\n",
      "\tspeed: 0.0795s/iter; left time: 229.3845s\n",
      "Epoch: 13 cost time: 33.212687492370605\n",
      "Epoch: 13, Steps: 398 | Train Loss: 0.0051565 Vali Loss: 0.1444179 Test Loss: 0.4928769\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "\titers: 100, epoch: 14 | loss: 0.0032957\n",
      "\tspeed: 0.2088s/iter; left time: 561.0764s\n",
      "\titers: 200, epoch: 14 | loss: 0.0066926\n",
      "\tspeed: 0.0874s/iter; left time: 226.2042s\n",
      "\titers: 300, epoch: 14 | loss: 0.0053027\n",
      "\tspeed: 0.0889s/iter; left time: 221.1978s\n",
      "Epoch: 14 cost time: 34.755107402801514\n",
      "Epoch: 14, Steps: 398 | Train Loss: 0.0051600 Vali Loss: 0.1445097 Test Loss: 0.4907786\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.48951485753059387, mae:0.49246516823768616\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl168_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.1133294\n",
      "\tspeed: 0.1074s/iter; left time: 835.3313s\n",
      "\titers: 200, epoch: 1 | loss: 0.0840013\n",
      "\tspeed: 0.1147s/iter; left time: 880.7881s\n",
      "\titers: 300, epoch: 1 | loss: 0.0724203\n",
      "\tspeed: 0.1149s/iter; left time: 870.8837s\n",
      "Epoch: 1 cost time: 44.72057747840881\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.1099282 Vali Loss: 0.4575065 Test Loss: 1.1998137\n",
      "Validation loss decreased (inf --> 0.457506).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0303322\n",
      "\tspeed: 0.2898s/iter; left time: 2140.7033s\n",
      "\titers: 200, epoch: 2 | loss: 0.0248626\n",
      "\tspeed: 0.1090s/iter; left time: 794.1694s\n",
      "\titers: 300, epoch: 2 | loss: 0.0278241\n",
      "\tspeed: 0.1049s/iter; left time: 754.2703s\n",
      "Epoch: 2 cost time: 43.17569017410278\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0247108 Vali Loss: 0.3783469 Test Loss: 0.9852462\n",
      "Validation loss decreased (0.457506 --> 0.378347).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0220222\n",
      "\tspeed: 0.2755s/iter; left time: 1926.5301s\n",
      "\titers: 200, epoch: 3 | loss: 0.0092644\n",
      "\tspeed: 0.1097s/iter; left time: 756.1158s\n",
      "\titers: 300, epoch: 3 | loss: 0.0072963\n",
      "\tspeed: 0.1099s/iter; left time: 746.3372s\n",
      "Epoch: 3 cost time: 43.324885845184326\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0115100 Vali Loss: 0.3614122 Test Loss: 0.8271785\n",
      "Validation loss decreased (0.378347 --> 0.361412).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0064843\n",
      "\tspeed: 0.2843s/iter; left time: 1876.1798s\n",
      "\titers: 200, epoch: 4 | loss: 0.0110862\n",
      "\tspeed: 0.1162s/iter; left time: 755.3882s\n",
      "\titers: 300, epoch: 4 | loss: 0.0081442\n",
      "\tspeed: 0.1154s/iter; left time: 738.4156s\n",
      "Epoch: 4 cost time: 45.381492376327515\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0088631 Vali Loss: 0.3518466 Test Loss: 0.8168318\n",
      "Validation loss decreased (0.361412 --> 0.351847).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0074335\n",
      "\tspeed: 0.2783s/iter; left time: 1727.0091s\n",
      "\titers: 200, epoch: 5 | loss: 0.0061597\n",
      "\tspeed: 0.1093s/iter; left time: 667.2813s\n",
      "\titers: 300, epoch: 5 | loss: 0.0091825\n",
      "\tspeed: 0.1114s/iter; left time: 668.9434s\n",
      "Epoch: 5 cost time: 43.3469762802124\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0075789 Vali Loss: 0.3406353 Test Loss: 0.8223637\n",
      "Validation loss decreased (0.351847 --> 0.340635).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0082643\n",
      "\tspeed: 0.2740s/iter; left time: 1592.3712s\n",
      "\titers: 200, epoch: 6 | loss: 0.0045196\n",
      "\tspeed: 0.1238s/iter; left time: 706.9115s\n",
      "\titers: 300, epoch: 6 | loss: 0.0061945\n",
      "\tspeed: 0.1177s/iter; left time: 660.4291s\n",
      "Epoch: 6 cost time: 45.782034158706665\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0069962 Vali Loss: 0.3373766 Test Loss: 0.8057047\n",
      "Validation loss decreased (0.340635 --> 0.337377).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0047711\n",
      "\tspeed: 0.2863s/iter; left time: 1550.8821s\n",
      "\titers: 200, epoch: 7 | loss: 0.0055067\n",
      "\tspeed: 0.1178s/iter; left time: 626.5056s\n",
      "\titers: 300, epoch: 7 | loss: 0.0076325\n",
      "\tspeed: 0.1089s/iter; left time: 568.0880s\n",
      "Epoch: 7 cost time: 45.00421214103699\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0065931 Vali Loss: 0.3399976 Test Loss: 0.8257586\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0049938\n",
      "\tspeed: 0.2875s/iter; left time: 1443.9330s\n",
      "\titers: 200, epoch: 8 | loss: 0.0059280\n",
      "\tspeed: 0.1156s/iter; left time: 569.0176s\n",
      "\titers: 300, epoch: 8 | loss: 0.0062486\n",
      "\tspeed: 0.1086s/iter; left time: 523.6080s\n",
      "Epoch: 8 cost time: 44.281010150909424\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0064034 Vali Loss: 0.3384177 Test Loss: 0.8124413\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0096439\n",
      "\tspeed: 0.2768s/iter; left time: 1281.2790s\n",
      "\titers: 200, epoch: 9 | loss: 0.0045965\n",
      "\tspeed: 0.1102s/iter; left time: 499.2933s\n",
      "\titers: 300, epoch: 9 | loss: 0.0048334\n",
      "\tspeed: 0.1106s/iter; left time: 489.8773s\n",
      "Epoch: 9 cost time: 43.85010480880737\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0064120 Vali Loss: 0.3369175 Test Loss: 0.8045102\n",
      "Validation loss decreased (0.337377 --> 0.336918).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0073722\n",
      "\tspeed: 0.2756s/iter; left time: 1167.3344s\n",
      "\titers: 200, epoch: 10 | loss: 0.0069862\n",
      "\tspeed: 0.1080s/iter; left time: 446.4047s\n",
      "\titers: 300, epoch: 10 | loss: 0.0088628\n",
      "\tspeed: 0.1098s/iter; left time: 443.2387s\n",
      "Epoch: 10 cost time: 43.11660933494568\n",
      "Epoch: 10, Steps: 394 | Train Loss: 0.0062952 Vali Loss: 0.3349578 Test Loss: 0.8055313\n",
      "Validation loss decreased (0.336918 --> 0.334958).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0052758\n",
      "\tspeed: 0.2766s/iter; left time: 1062.5206s\n",
      "\titers: 200, epoch: 11 | loss: 0.0070513\n",
      "\tspeed: 0.1115s/iter; left time: 416.9443s\n",
      "\titers: 300, epoch: 11 | loss: 0.0050442\n",
      "\tspeed: 0.1088s/iter; left time: 396.0572s\n",
      "Epoch: 11 cost time: 43.68335008621216\n",
      "Epoch: 11, Steps: 394 | Train Loss: 0.0062899 Vali Loss: 0.3378400 Test Loss: 0.8132362\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.0048568\n",
      "\tspeed: 0.2818s/iter; left time: 971.4184s\n",
      "\titers: 200, epoch: 12 | loss: 0.0057319\n",
      "\tspeed: 0.1135s/iter; left time: 380.0295s\n",
      "\titers: 300, epoch: 12 | loss: 0.0044540\n",
      "\tspeed: 0.1161s/iter; left time: 376.8320s\n",
      "Epoch: 12 cost time: 45.30895805358887\n",
      "Epoch: 12, Steps: 394 | Train Loss: 0.0062875 Vali Loss: 0.3385205 Test Loss: 0.8033431\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "\titers: 100, epoch: 13 | loss: 0.0048991\n",
      "\tspeed: 0.2875s/iter; left time: 877.7458s\n",
      "\titers: 200, epoch: 13 | loss: 0.0071141\n",
      "\tspeed: 0.1137s/iter; left time: 335.6381s\n",
      "\titers: 300, epoch: 13 | loss: 0.0075428\n",
      "\tspeed: 0.1136s/iter; left time: 324.1965s\n",
      "Epoch: 13 cost time: 45.114020109176636\n",
      "Epoch: 13, Steps: 394 | Train Loss: 0.0062189 Vali Loss: 0.3353103 Test Loss: 0.8045512\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.8068361282348633, mae:0.684577226638794\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl336_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.1368954\n",
      "\tspeed: 0.1531s/iter; left time: 1175.6379s\n",
      "\titers: 200, epoch: 1 | loss: 0.0924869\n",
      "\tspeed: 0.1373s/iter; left time: 1040.9173s\n",
      "\titers: 300, epoch: 1 | loss: 0.1062616\n",
      "\tspeed: 0.1387s/iter; left time: 1037.6759s\n",
      "Epoch: 1 cost time: 56.15120840072632\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1193231 Vali Loss: 0.6608498 Test Loss: 1.4531633\n",
      "Validation loss decreased (inf --> 0.660850).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0367328\n",
      "\tspeed: 0.3651s/iter; left time: 2662.1252s\n",
      "\titers: 200, epoch: 2 | loss: 0.0391454\n",
      "\tspeed: 0.1417s/iter; left time: 1019.4044s\n",
      "\titers: 300, epoch: 2 | loss: 0.0178114\n",
      "\tspeed: 0.1406s/iter; left time: 996.8100s\n",
      "Epoch: 2 cost time: 54.73977327346802\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0349257 Vali Loss: 0.5740300 Test Loss: 1.0914432\n",
      "Validation loss decreased (0.660850 --> 0.574030).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0113408\n",
      "\tspeed: 0.3298s/iter; left time: 2276.3174s\n",
      "\titers: 200, epoch: 3 | loss: 0.0117889\n",
      "\tspeed: 0.1359s/iter; left time: 924.6211s\n",
      "\titers: 300, epoch: 3 | loss: 0.0114527\n",
      "\tspeed: 0.1376s/iter; left time: 922.3767s\n",
      "Epoch: 3 cost time: 53.777278661727905\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0120800 Vali Loss: 0.5148547 Test Loss: 1.1268739\n",
      "Validation loss decreased (0.574030 --> 0.514855).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0086671\n",
      "\tspeed: 0.3517s/iter; left time: 2290.7376s\n",
      "\titers: 200, epoch: 4 | loss: 0.0086945\n",
      "\tspeed: 0.1463s/iter; left time: 938.1805s\n",
      "\titers: 300, epoch: 4 | loss: 0.0077993\n",
      "\tspeed: 0.1453s/iter; left time: 917.4257s\n",
      "Epoch: 4 cost time: 56.55338096618652\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0087641 Vali Loss: 0.4856200 Test Loss: 1.0318339\n",
      "Validation loss decreased (0.514855 --> 0.485620).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0085554\n",
      "\tspeed: 0.3408s/iter; left time: 2087.4276s\n",
      "\titers: 200, epoch: 5 | loss: 0.0075607\n",
      "\tspeed: 0.1382s/iter; left time: 832.9355s\n",
      "\titers: 300, epoch: 5 | loss: 0.0056293\n",
      "\tspeed: 0.1389s/iter; left time: 822.7926s\n",
      "Epoch: 5 cost time: 53.825549840927124\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0076497 Vali Loss: 0.4991560 Test Loss: 1.0117855\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0064151\n",
      "\tspeed: 0.3425s/iter; left time: 1964.5838s\n",
      "\titers: 200, epoch: 6 | loss: 0.0071792\n",
      "\tspeed: 0.1476s/iter; left time: 831.6335s\n",
      "\titers: 300, epoch: 6 | loss: 0.0065458\n",
      "\tspeed: 0.1465s/iter; left time: 810.9637s\n",
      "Epoch: 6 cost time: 56.81598234176636\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0070609 Vali Loss: 0.5069171 Test Loss: 1.0425471\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0113205\n",
      "\tspeed: 0.3428s/iter; left time: 1832.7951s\n",
      "\titers: 200, epoch: 7 | loss: 0.0057724\n",
      "\tspeed: 0.1469s/iter; left time: 770.9302s\n",
      "\titers: 300, epoch: 7 | loss: 0.0075336\n",
      "\tspeed: 0.1465s/iter; left time: 753.8247s\n",
      "Epoch: 7 cost time: 56.10996127128601\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.0067773 Vali Loss: 0.4822100 Test Loss: 0.9947153\n",
      "Validation loss decreased (0.485620 --> 0.482210).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0061505\n",
      "\tspeed: 0.3377s/iter; left time: 1674.1019s\n",
      "\titers: 200, epoch: 8 | loss: 0.0062745\n",
      "\tspeed: 0.1401s/iter; left time: 680.5617s\n",
      "\titers: 300, epoch: 8 | loss: 0.0064927\n",
      "\tspeed: 0.1433s/iter; left time: 681.7982s\n",
      "Epoch: 8 cost time: 54.32980036735535\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.0065668 Vali Loss: 0.4965782 Test Loss: 1.0264930\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0065447\n",
      "\tspeed: 0.3325s/iter; left time: 1519.1559s\n",
      "\titers: 200, epoch: 9 | loss: 0.0096259\n",
      "\tspeed: 0.1370s/iter; left time: 612.3052s\n",
      "\titers: 300, epoch: 9 | loss: 0.0058828\n",
      "\tspeed: 0.1394s/iter; left time: 608.9747s\n",
      "Epoch: 9 cost time: 53.73307919502258\n",
      "Epoch: 9, Steps: 389 | Train Loss: 0.0065102 Vali Loss: 0.4955465 Test Loss: 1.0263386\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0101501\n",
      "\tspeed: 0.3460s/iter; left time: 1446.4668s\n",
      "\titers: 200, epoch: 10 | loss: 0.0066934\n",
      "\tspeed: 0.1477s/iter; left time: 602.7207s\n",
      "\titers: 300, epoch: 10 | loss: 0.0057949\n",
      "\tspeed: 0.1451s/iter; left time: 577.6896s\n",
      "Epoch: 10 cost time: 56.71289396286011\n",
      "Epoch: 10, Steps: 389 | Train Loss: 0.0064090 Vali Loss: 0.4958148 Test Loss: 1.0147630\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.993188202381134, mae:0.7993416786193848\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training InformerTS on SYNTH_multiplicative_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'informerstack', 'features': 'S', 'target': 'TARGET', 'freq': 'h', 'checkpoints': './checkpoints', 'seq_len': 168, 'label_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'factor': 5, 'd_model': 512, 'n_heads': 8, 's_layers': [3, 2, 1], 'd_layers': 2, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 3, 'detail_freq': 'h'}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informerstack_SYNTH_multiplicative_reversal_ftS_sl168_ll48_pl720_dm512_nh8_el[3, 2, 1]_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.1293841\n",
      "\tspeed: 0.1889s/iter; left time: 1405.7885s\n",
      "\titers: 200, epoch: 1 | loss: 0.1068931\n",
      "\tspeed: 0.1887s/iter; left time: 1384.9153s\n",
      "\titers: 300, epoch: 1 | loss: 0.1001240\n",
      "\tspeed: 0.1898s/iter; left time: 1374.4209s\n",
      "Epoch: 1 cost time: 72.07550311088562\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.1347610 Vali Loss: 1.1588840 Test Loss: 1.9608668\n",
      "Validation loss decreased (inf --> 1.158884).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0705754\n",
      "\tspeed: 0.4243s/iter; left time: 2997.3521s\n",
      "\titers: 200, epoch: 2 | loss: 0.0616856\n",
      "\tspeed: 0.1910s/iter; left time: 1329.8582s\n",
      "\titers: 300, epoch: 2 | loss: 0.0739858\n",
      "\tspeed: 0.2012s/iter; left time: 1381.0427s\n",
      "Epoch: 2 cost time: 73.71822619438171\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0725808 Vali Loss: 1.0491017 Test Loss: 1.5344478\n",
      "Validation loss decreased (1.158884 --> 1.049102).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0637132\n",
      "\tspeed: 0.4365s/iter; left time: 2919.0802s\n",
      "\titers: 200, epoch: 3 | loss: 0.0561362\n",
      "\tspeed: 0.1980s/iter; left time: 1304.3266s\n",
      "\titers: 300, epoch: 3 | loss: 0.0622933\n",
      "\tspeed: 0.2040s/iter; left time: 1323.3821s\n",
      "Epoch: 3 cost time: 75.48663926124573\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0598800 Vali Loss: 1.1432735 Test Loss: 1.6758161\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0559440\n",
      "\tspeed: 0.4298s/iter; left time: 2711.8774s\n",
      "\titers: 200, epoch: 4 | loss: 0.0483776\n",
      "\tspeed: 0.1927s/iter; left time: 1196.6117s\n",
      "\titers: 300, epoch: 4 | loss: 0.0381324\n",
      "\tspeed: 0.1899s/iter; left time: 1160.1930s\n",
      "Epoch: 4 cost time: 72.20203113555908\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0472942 Vali Loss: 1.1759372 Test Loss: 1.7708070\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0344097\n",
      "\tspeed: 0.4303s/iter; left time: 2553.2058s\n",
      "\titers: 200, epoch: 5 | loss: 0.0269001\n",
      "\tspeed: 0.2003s/iter; left time: 1168.2893s\n",
      "\titers: 300, epoch: 5 | loss: 0.0312904\n",
      "\tspeed: 0.1982s/iter; left time: 1136.4917s\n",
      "Epoch: 5 cost time: 74.98653888702393\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0298013 Vali Loss: 1.0929655 Test Loss: 1.7066438\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:1.533491849899292, mae:1.0204545259475708\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "CPU times: user 1d 15h 43min 17s, sys: 1h 39min 27s, total: 1d 17h 22min 45s\n",
      "Wall time: 9h 20min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Simple loop\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "    for iter in range(model.args.itr):\n",
    "        for dataset_name, dataset_params in datasets.items():\n",
    "            for pred_len in pred_lens:\n",
    "                print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "                # High amount of epochs to accomodate all models\n",
    "                # Early stopping should kick in anyways\n",
    "                model.fit(\n",
    "                    iter = iter + 1 ,\n",
    "                    data=dataset_name,\n",
    "                    data_root_path=dataset_params[0],\n",
    "                    batch_size=32,\n",
    "                    epochs=20, # very high\n",
    "                    pred_len=pred_len,\n",
    "                    features = dataset_params[1],\n",
    "                )\n",
    "\n",
    "                predictions = model.predict()\n",
    "\n",
    "                print(f'\\nMoving to next...\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'ETTh1': './ETTDataset/' ,\n",
    "    'DEWINDh_small': './WINDataset/' ,\n",
    "    'SYNTHh1': './SYNTHDataset/' ,\n",
    "    'SYNTH_additive' : './SYNTHDataset/' ,\n",
    "    'SYNTH_additive_reversal' : './SYNTHDataset/' ,\n",
    "    'SYNTH_multiplicative' : './SYNTHDataset/' ,\n",
    "    'SYNTH_multiplicative_reversal' : './SYNTHDataset/'\n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "\n",
    "models = [CrossformerTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: CrossformerTS\n",
      "Training CrossformerTS on ETTh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 7, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 2, 'data_split': [8640, 2880, 2880]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_ETTh1_il168_pl24_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8449\n",
      "val 2857\n",
      "test 2857\n",
      "\titers: 100, epoch: 1 | loss: 0.5214266\n",
      "\tspeed: 0.0956s/iter; left time: 495.3283s\n",
      "\titers: 200, epoch: 1 | loss: 0.3553054\n",
      "\tspeed: 0.0835s/iter; left time: 424.1230s\n",
      "Epoch: 1 cost time: 23.423332929611206\n",
      "Epoch: 1, Steps: 264 | Train Loss: 0.4547774 Vali Loss: 0.4934796 Test Loss: 0.3461723\n",
      "Validation loss decreased (inf --> 0.493480).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.2587012\n",
      "\tspeed: 0.0828s/iter; left time: 407.0281s\n",
      "\titers: 200, epoch: 2 | loss: 0.2291630\n",
      "\tspeed: 0.0775s/iter; left time: 373.2074s\n",
      "Epoch: 2 cost time: 21.287189483642578\n",
      "Epoch: 2, Steps: 264 | Train Loss: 0.2906402 Vali Loss: 0.4753442 Test Loss: 0.3265434\n",
      "Validation loss decreased (0.493480 --> 0.475344).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2554791\n",
      "\tspeed: 0.0801s/iter; left time: 372.7384s\n",
      "\titers: 200, epoch: 3 | loss: 0.2409281\n",
      "\tspeed: 0.0848s/iter; left time: 386.1251s\n",
      "Epoch: 3 cost time: 21.46168828010559\n",
      "Epoch: 3, Steps: 264 | Train Loss: 0.2625151 Vali Loss: 0.4314120 Test Loss: 0.3109634\n",
      "Validation loss decreased (0.475344 --> 0.431412).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.2673541\n",
      "\tspeed: 0.0845s/iter; left time: 371.0179s\n",
      "\titers: 200, epoch: 4 | loss: 0.2568263\n",
      "\tspeed: 0.0710s/iter; left time: 304.3976s\n",
      "Epoch: 4 cost time: 20.210761547088623\n",
      "Epoch: 4, Steps: 264 | Train Loss: 0.2518725 Vali Loss: 0.4334546 Test Loss: 0.2978264\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2058302\n",
      "\tspeed: 0.0748s/iter; left time: 308.4072s\n",
      "\titers: 200, epoch: 5 | loss: 0.2973945\n",
      "\tspeed: 0.0754s/iter; left time: 303.3834s\n",
      "Epoch: 5 cost time: 19.70811414718628\n",
      "Epoch: 5, Steps: 264 | Train Loss: 0.2425827 Vali Loss: 0.4337481 Test Loss: 0.3014042\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.1939798\n",
      "\tspeed: 0.0775s/iter; left time: 299.2503s\n",
      "\titers: 200, epoch: 6 | loss: 0.2212548\n",
      "\tspeed: 0.0777s/iter; left time: 292.0703s\n",
      "Epoch: 6 cost time: 20.218011379241943\n",
      "Epoch: 6, Steps: 264 | Train Loss: 0.2377041 Vali Loss: 0.4490628 Test Loss: 0.3099064\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "mse:0.31096336245536804, mae:0.36664414405822754\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on ETTh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 7, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 2, 'data_split': [8640, 2880, 2880]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_ETTh1_il168_pl48_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8425\n",
      "val 2833\n",
      "test 2833\n",
      "\titers: 100, epoch: 1 | loss: 0.5027531\n",
      "\tspeed: 0.0780s/iter; left time: 402.3969s\n",
      "\titers: 200, epoch: 1 | loss: 0.4890745\n",
      "\tspeed: 0.0754s/iter; left time: 381.4771s\n",
      "Epoch: 1 cost time: 20.057071208953857\n",
      "Epoch: 1, Steps: 263 | Train Loss: 0.4887847 Vali Loss: 0.5901678 Test Loss: 0.3686840\n",
      "Validation loss decreased (inf --> 0.590168).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.2954859\n",
      "\tspeed: 0.0781s/iter; left time: 382.3672s\n",
      "\titers: 200, epoch: 2 | loss: 0.2758901\n",
      "\tspeed: 0.0829s/iter; left time: 397.5676s\n",
      "Epoch: 2 cost time: 21.43630599975586\n",
      "Epoch: 2, Steps: 263 | Train Loss: 0.3259807 Vali Loss: 0.5651427 Test Loss: 0.3490591\n",
      "Validation loss decreased (0.590168 --> 0.565143).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3048420\n",
      "\tspeed: 0.0768s/iter; left time: 356.0187s\n",
      "\titers: 200, epoch: 3 | loss: 0.3100431\n",
      "\tspeed: 0.0760s/iter; left time: 344.7932s\n",
      "Epoch: 3 cost time: 19.964985370635986\n",
      "Epoch: 3, Steps: 263 | Train Loss: 0.2939564 Vali Loss: 0.5389722 Test Loss: 0.3429969\n",
      "Validation loss decreased (0.565143 --> 0.538972).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.3055387\n",
      "\tspeed: 0.0781s/iter; left time: 341.2944s\n",
      "\titers: 200, epoch: 4 | loss: 0.2642635\n",
      "\tspeed: 0.0774s/iter; left time: 330.4877s\n",
      "Epoch: 4 cost time: 20.551555156707764\n",
      "Epoch: 4, Steps: 263 | Train Loss: 0.2817803 Vali Loss: 0.5867009 Test Loss: 0.3540785\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2843186\n",
      "\tspeed: 0.0825s/iter; left time: 338.9343s\n",
      "\titers: 200, epoch: 5 | loss: 0.2570885\n",
      "\tspeed: 0.0815s/iter; left time: 326.6579s\n",
      "Epoch: 5 cost time: 21.757582187652588\n",
      "Epoch: 5, Steps: 263 | Train Loss: 0.2720722 Vali Loss: 0.5600471 Test Loss: 0.3404703\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.2632669\n",
      "\tspeed: 0.0719s/iter; left time: 276.5801s\n",
      "\titers: 200, epoch: 6 | loss: 0.2429004\n",
      "\tspeed: 0.0792s/iter; left time: 296.7487s\n",
      "Epoch: 6 cost time: 20.20850658416748\n",
      "Epoch: 6, Steps: 263 | Train Loss: 0.2676227 Vali Loss: 0.5793161 Test Loss: 0.3449828\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 7) (88, 32, 48, 7)\n",
      "test shape: (2816, 48, 7) (2816, 48, 7)\n",
      "mse:0.3429969251155853, mae:0.38079026341438293\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on ETTh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 7, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 2, 'data_split': [8640, 2880, 2880]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_ETTh1_il168_pl168_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8305\n",
      "val 2713\n",
      "test 2713\n",
      "\titers: 100, epoch: 1 | loss: 0.5861427\n",
      "\tspeed: 0.0910s/iter; left time: 462.5576s\n",
      "\titers: 200, epoch: 1 | loss: 0.4926127\n",
      "\tspeed: 0.0895s/iter; left time: 445.8177s\n",
      "Epoch: 1 cost time: 23.587937831878662\n",
      "Epoch: 1, Steps: 259 | Train Loss: 0.5739096 Vali Loss: 0.9503108 Test Loss: 0.4590224\n",
      "Validation loss decreased (inf --> 0.950311).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.4112213\n",
      "\tspeed: 0.0904s/iter; left time: 435.9183s\n",
      "\titers: 200, epoch: 2 | loss: 0.3802201\n",
      "\tspeed: 0.0895s/iter; left time: 422.8000s\n",
      "Epoch: 2 cost time: 22.774425506591797\n",
      "Epoch: 2, Steps: 259 | Train Loss: 0.3916861 Vali Loss: 0.9276070 Test Loss: 0.5039399\n",
      "Validation loss decreased (0.950311 --> 0.927607).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3385667\n",
      "\tspeed: 0.0839s/iter; left time: 382.6299s\n",
      "\titers: 200, epoch: 3 | loss: 0.3352483\n",
      "\tspeed: 0.0911s/iter; left time: 406.5946s\n",
      "Epoch: 3 cost time: 22.92314100265503\n",
      "Epoch: 3, Steps: 259 | Train Loss: 0.3507350 Vali Loss: 0.9146111 Test Loss: 0.5274204\n",
      "Validation loss decreased (0.927607 --> 0.914611).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.3493203\n",
      "\tspeed: 0.0886s/iter; left time: 381.3151s\n",
      "\titers: 200, epoch: 4 | loss: 0.3330209\n",
      "\tspeed: 0.0948s/iter; left time: 398.4560s\n",
      "Epoch: 4 cost time: 23.862897157669067\n",
      "Epoch: 4, Steps: 259 | Train Loss: 0.3337637 Vali Loss: 0.9284233 Test Loss: 0.5439101\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3053652\n",
      "\tspeed: 0.0811s/iter; left time: 327.8621s\n",
      "\titers: 200, epoch: 5 | loss: 0.2862138\n",
      "\tspeed: 0.0866s/iter; left time: 341.6957s\n",
      "Epoch: 5 cost time: 22.353447437286377\n",
      "Epoch: 5, Steps: 259 | Train Loss: 0.3189913 Vali Loss: 0.9114560 Test Loss: 0.5652700\n",
      "Validation loss decreased (0.914611 --> 0.911456).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.3083532\n",
      "\tspeed: 0.0918s/iter; left time: 347.6313s\n",
      "\titers: 200, epoch: 6 | loss: 0.3101443\n",
      "\tspeed: 0.0807s/iter; left time: 297.3528s\n",
      "Epoch: 6 cost time: 22.708872079849243\n",
      "Epoch: 6, Steps: 259 | Train Loss: 0.3112794 Vali Loss: 0.9123719 Test Loss: 0.5748707\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3101891\n",
      "\tspeed: 0.0865s/iter; left time: 305.0702s\n",
      "\titers: 200, epoch: 7 | loss: 0.3002844\n",
      "\tspeed: 0.0927s/iter; left time: 317.5881s\n",
      "Epoch: 7 cost time: 23.548161268234253\n",
      "Epoch: 7, Steps: 259 | Train Loss: 0.3045538 Vali Loss: 0.9547570 Test Loss: 0.6176646\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.3110821\n",
      "\tspeed: 0.0939s/iter; left time: 306.7030s\n",
      "\titers: 200, epoch: 8 | loss: 0.2927206\n",
      "\tspeed: 0.0858s/iter; left time: 271.6581s\n",
      "Epoch: 8 cost time: 22.89398431777954\n",
      "Epoch: 8, Steps: 259 | Train Loss: 0.3015661 Vali Loss: 0.9504428 Test Loss: 0.6206670\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 7) (84, 32, 168, 7)\n",
      "test shape: (2688, 168, 7) (2688, 168, 7)\n",
      "mse:0.5652700662612915, mae:0.5486369132995605\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on ETTh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 7, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 2, 'data_split': [8640, 2880, 2880]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_ETTh1_il168_pl336_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8137\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.6794069\n",
      "\tspeed: 0.1202s/iter; left time: 598.9130s\n",
      "\titers: 200, epoch: 1 | loss: 0.5863515\n",
      "\tspeed: 0.1149s/iter; left time: 561.0051s\n",
      "Epoch: 1 cost time: 29.885456323623657\n",
      "Epoch: 1, Steps: 254 | Train Loss: 0.6467308 Vali Loss: 1.1653371 Test Loss: 0.6637748\n",
      "Validation loss decreased (inf --> 1.165337).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.4410754\n",
      "\tspeed: 0.1111s/iter; left time: 525.1432s\n",
      "\titers: 200, epoch: 2 | loss: 0.4063741\n",
      "\tspeed: 0.1097s/iter; left time: 507.6400s\n",
      "Epoch: 2 cost time: 28.17136263847351\n",
      "Epoch: 2, Steps: 254 | Train Loss: 0.4364215 Vali Loss: 1.0995999 Test Loss: 0.7063411\n",
      "Validation loss decreased (1.165337 --> 1.099600).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3628084\n",
      "\tspeed: 0.1166s/iter; left time: 521.5524s\n",
      "\titers: 200, epoch: 3 | loss: 0.3840256\n",
      "\tspeed: 0.1168s/iter; left time: 510.5528s\n",
      "Epoch: 3 cost time: 29.742775678634644\n",
      "Epoch: 3, Steps: 254 | Train Loss: 0.3777067 Vali Loss: 1.1141289 Test Loss: 0.7292963\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.3474818\n",
      "\tspeed: 0.1139s/iter; left time: 480.6471s\n",
      "\titers: 200, epoch: 4 | loss: 0.3662953\n",
      "\tspeed: 0.1043s/iter; left time: 429.4333s\n",
      "Epoch: 4 cost time: 28.067143201828003\n",
      "Epoch: 4, Steps: 254 | Train Loss: 0.3575582 Vali Loss: 1.1284799 Test Loss: 0.7214191\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3439942\n",
      "\tspeed: 0.1159s/iter; left time: 459.6215s\n",
      "\titers: 200, epoch: 5 | loss: 0.3230183\n",
      "\tspeed: 0.2085s/iter; left time: 806.0392s\n",
      "Epoch: 5 cost time: 43.16285252571106\n",
      "Epoch: 5, Steps: 254 | Train Loss: 0.3428949 Vali Loss: 1.1256932 Test Loss: 0.6840545\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 7) (79, 32, 336, 7)\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "mse:0.7063410878181458, mae:0.6263859272003174\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on ETTh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 7, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 2, 'data_split': [8640, 2880, 2880]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_ETTh1_il168_pl720_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7753\n",
      "val 2161\n",
      "test 2161\n",
      "\titers: 100, epoch: 1 | loss: 0.7165520\n",
      "\tspeed: 0.1979s/iter; left time: 938.1633s\n",
      "\titers: 200, epoch: 1 | loss: 0.6205276\n",
      "\tspeed: 0.1889s/iter; left time: 876.9065s\n",
      "Epoch: 1 cost time: 47.03451418876648\n",
      "Epoch: 1, Steps: 242 | Train Loss: 0.7208269 Vali Loss: 1.4274423 Test Loss: 0.9796459\n",
      "Validation loss decreased (inf --> 1.427442).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.4726839\n",
      "\tspeed: 0.2054s/iter; left time: 924.0525s\n",
      "\titers: 200, epoch: 2 | loss: 0.4620941\n",
      "\tspeed: 0.1890s/iter; left time: 831.4061s\n",
      "Epoch: 2 cost time: 47.91112661361694\n",
      "Epoch: 2, Steps: 242 | Train Loss: 0.4843126 Vali Loss: 1.3226649 Test Loss: 0.8490975\n",
      "Validation loss decreased (1.427442 --> 1.322665).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4306442\n",
      "\tspeed: 0.2029s/iter; left time: 863.7415s\n",
      "\titers: 200, epoch: 3 | loss: 0.3994093\n",
      "\tspeed: 0.1914s/iter; left time: 795.6782s\n",
      "Epoch: 3 cost time: 47.92977166175842\n",
      "Epoch: 3, Steps: 242 | Train Loss: 0.4071014 Vali Loss: 1.3594229 Test Loss: 0.9312634\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.3746471\n",
      "\tspeed: 0.2042s/iter; left time: 819.7526s\n",
      "\titers: 200, epoch: 4 | loss: 0.3792653\n",
      "\tspeed: 0.1980s/iter; left time: 775.1820s\n",
      "Epoch: 4 cost time: 48.47176718711853\n",
      "Epoch: 4, Steps: 242 | Train Loss: 0.3824202 Vali Loss: 1.3526093 Test Loss: 0.8516666\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3733685\n",
      "\tspeed: 0.2017s/iter; left time: 761.1521s\n",
      "\titers: 200, epoch: 5 | loss: 0.3631865\n",
      "\tspeed: 0.2008s/iter; left time: 737.5161s\n",
      "Epoch: 5 cost time: 47.90604090690613\n",
      "Epoch: 5, Steps: 242 | Train Loss: 0.3661199 Vali Loss: 1.3666545 Test Loss: 0.9802203\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 7) (67, 32, 720, 7)\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "mse:0.8490975499153137, mae:0.7255786061286926\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on DEWINDh_small with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_DEWINDh_small_il168_pl24_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.2425127\n",
      "\tspeed: 0.0747s/iter; left time: 588.9836s\n",
      "\titers: 200, epoch: 1 | loss: 0.2013348\n",
      "\tspeed: 0.0744s/iter; left time: 578.5933s\n",
      "\titers: 300, epoch: 1 | loss: 0.2937763\n",
      "\tspeed: 0.0738s/iter; left time: 566.9267s\n",
      "Epoch: 1 cost time: 29.64738655090332\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.2961224 Vali Loss: 0.1742905 Test Loss: 0.1397953\n",
      "Validation loss decreased (inf --> 0.174290).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.1672308\n",
      "\tspeed: 0.0729s/iter; left time: 545.6291s\n",
      "\titers: 200, epoch: 2 | loss: 0.1536226\n",
      "\tspeed: 0.0730s/iter; left time: 539.1627s\n",
      "\titers: 300, epoch: 2 | loss: 0.1591199\n",
      "\tspeed: 0.0761s/iter; left time: 554.4326s\n",
      "Epoch: 2 cost time: 29.02888512611389\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.1666490 Vali Loss: 0.1494045 Test Loss: 0.1282292\n",
      "Validation loss decreased (0.174290 --> 0.149405).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1904308\n",
      "\tspeed: 0.0727s/iter; left time: 514.7563s\n",
      "\titers: 200, epoch: 3 | loss: 0.1199476\n",
      "\tspeed: 0.0744s/iter; left time: 519.3115s\n",
      "\titers: 300, epoch: 3 | loss: 0.0969843\n",
      "\tspeed: 0.0756s/iter; left time: 520.6245s\n",
      "Epoch: 3 cost time: 29.893064260482788\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.1443719 Vali Loss: 0.1310158 Test Loss: 0.1102462\n",
      "Validation loss decreased (0.149405 --> 0.131016).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.1642780\n",
      "\tspeed: 0.0776s/iter; left time: 518.6051s\n",
      "\titers: 200, epoch: 4 | loss: 0.1075062\n",
      "\tspeed: 0.0797s/iter; left time: 524.6544s\n",
      "\titers: 300, epoch: 4 | loss: 0.1600467\n",
      "\tspeed: 0.0750s/iter; left time: 486.1121s\n",
      "Epoch: 4 cost time: 29.919283866882324\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.1384346 Vali Loss: 0.1332414 Test Loss: 0.1072354\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1340098\n",
      "\tspeed: 0.0665s/iter; left time: 417.6977s\n",
      "\titers: 200, epoch: 5 | loss: 0.1148514\n",
      "\tspeed: 0.0765s/iter; left time: 472.8502s\n",
      "\titers: 300, epoch: 5 | loss: 0.1111022\n",
      "\tspeed: 0.0710s/iter; left time: 431.9988s\n",
      "Epoch: 5 cost time: 28.738748788833618\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.1306547 Vali Loss: 0.1211727 Test Loss: 0.1054844\n",
      "Validation loss decreased (0.131016 --> 0.121173).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.1101906\n",
      "\tspeed: 0.0715s/iter; left time: 421.0324s\n",
      "\titers: 200, epoch: 6 | loss: 0.1178118\n",
      "\tspeed: 0.0672s/iter; left time: 388.5374s\n",
      "\titers: 300, epoch: 6 | loss: 0.1095689\n",
      "\tspeed: 0.0686s/iter; left time: 390.2444s\n",
      "Epoch: 6 cost time: 27.955284118652344\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.1281894 Vali Loss: 0.1199515 Test Loss: 0.1069715\n",
      "Validation loss decreased (0.121173 --> 0.119952).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1588243\n",
      "\tspeed: 0.0717s/iter; left time: 393.3245s\n",
      "\titers: 200, epoch: 7 | loss: 0.1135286\n",
      "\tspeed: 0.0737s/iter; left time: 396.8817s\n",
      "\titers: 300, epoch: 7 | loss: 0.1241658\n",
      "\tspeed: 0.0704s/iter; left time: 372.1121s\n",
      "Epoch: 7 cost time: 29.073678493499756\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.1256663 Vali Loss: 0.1172335 Test Loss: 0.1022160\n",
      "Validation loss decreased (0.119952 --> 0.117233).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.1504687\n",
      "\tspeed: 0.0700s/iter; left time: 355.9818s\n",
      "\titers: 200, epoch: 8 | loss: 0.1116681\n",
      "\tspeed: 0.0712s/iter; left time: 354.9717s\n",
      "\titers: 300, epoch: 8 | loss: 0.2232320\n",
      "\tspeed: 0.0722s/iter; left time: 353.1431s\n",
      "Epoch: 8 cost time: 28.487411975860596\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.1235967 Vali Loss: 0.1172388 Test Loss: 0.1028800\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0795724\n",
      "\tspeed: 0.0714s/iter; left time: 334.5842s\n",
      "\titers: 200, epoch: 9 | loss: 0.1528533\n",
      "\tspeed: 0.0722s/iter; left time: 331.3765s\n",
      "\titers: 300, epoch: 9 | loss: 0.1096511\n",
      "\tspeed: 0.0767s/iter; left time: 344.4883s\n",
      "Epoch: 9 cost time: 29.55657696723938\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.1220023 Vali Loss: 0.1147172 Test Loss: 0.1007036\n",
      "Validation loss decreased (0.117233 --> 0.114717).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.1292175\n",
      "\tspeed: 0.0777s/iter; left time: 333.4088s\n",
      "\titers: 200, epoch: 10 | loss: 0.1084576\n",
      "\tspeed: 0.0741s/iter; left time: 310.6515s\n",
      "\titers: 300, epoch: 10 | loss: 0.1222250\n",
      "\tspeed: 0.0728s/iter; left time: 297.6152s\n",
      "Epoch: 10 cost time: 29.7900812625885\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.1212045 Vali Loss: 0.1141602 Test Loss: 0.1015793\n",
      "Validation loss decreased (0.114717 --> 0.114160).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1284777\n",
      "\tspeed: 0.0720s/iter; left time: 280.0796s\n",
      "\titers: 200, epoch: 11 | loss: 0.1303377\n",
      "\tspeed: 0.0726s/iter; left time: 275.1701s\n",
      "\titers: 300, epoch: 11 | loss: 0.1403428\n",
      "\tspeed: 0.0851s/iter; left time: 313.9525s\n",
      "Epoch: 11 cost time: 31.212291479110718\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.1193932 Vali Loss: 0.1141564 Test Loss: 0.0997181\n",
      "Validation loss decreased (0.114160 --> 0.114156).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.1167905\n",
      "\tspeed: 0.0791s/iter; left time: 276.3052s\n",
      "\titers: 200, epoch: 12 | loss: 0.1335533\n",
      "\tspeed: 0.0727s/iter; left time: 246.6929s\n",
      "\titers: 300, epoch: 12 | loss: 0.0982116\n",
      "\tspeed: 0.0700s/iter; left time: 230.4212s\n",
      "Epoch: 12 cost time: 29.510270595550537\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.1194730 Vali Loss: 0.1123876 Test Loss: 0.0993424\n",
      "Validation loss decreased (0.114156 --> 0.112388).  Saving model ...\n",
      "\titers: 100, epoch: 13 | loss: 0.1241681\n",
      "\tspeed: 0.0757s/iter; left time: 233.9980s\n",
      "\titers: 200, epoch: 13 | loss: 0.0928982\n",
      "\tspeed: 0.0725s/iter; left time: 216.9387s\n",
      "\titers: 300, epoch: 13 | loss: 0.1223862\n",
      "\tspeed: 0.0788s/iter; left time: 227.8409s\n",
      "Epoch: 13 cost time: 30.357344150543213\n",
      "Epoch: 13, Steps: 399 | Train Loss: 0.1192012 Vali Loss: 0.1121149 Test Loss: 0.0991038\n",
      "Validation loss decreased (0.112388 --> 0.112115).  Saving model ...\n",
      "\titers: 100, epoch: 14 | loss: 0.0923569\n",
      "\tspeed: 0.0764s/iter; left time: 205.8156s\n",
      "\titers: 200, epoch: 14 | loss: 0.1264537\n",
      "\tspeed: 0.0777s/iter; left time: 201.5187s\n",
      "\titers: 300, epoch: 14 | loss: 0.1102223\n",
      "\tspeed: 0.0786s/iter; left time: 195.9560s\n",
      "Epoch: 14 cost time: 31.262927770614624\n",
      "Epoch: 14, Steps: 399 | Train Loss: 0.1186304 Vali Loss: 0.1120053 Test Loss: 0.1002042\n",
      "Validation loss decreased (0.112115 --> 0.112005).  Saving model ...\n",
      "\titers: 100, epoch: 15 | loss: 0.1135688\n",
      "\tspeed: 0.0794s/iter; left time: 182.2695s\n",
      "\titers: 200, epoch: 15 | loss: 0.1727232\n",
      "\tspeed: 0.0756s/iter; left time: 166.0251s\n",
      "\titers: 300, epoch: 15 | loss: 0.1131305\n",
      "\tspeed: 0.0753s/iter; left time: 157.8199s\n",
      "Epoch: 15 cost time: 30.637017965316772\n",
      "Epoch: 15, Steps: 399 | Train Loss: 0.1184030 Vali Loss: 0.1116761 Test Loss: 0.0989717\n",
      "Validation loss decreased (0.112005 --> 0.111676).  Saving model ...\n",
      "\titers: 100, epoch: 16 | loss: 0.1053818\n",
      "\tspeed: 0.0853s/iter; left time: 161.6623s\n",
      "\titers: 200, epoch: 16 | loss: 0.1284082\n",
      "\tspeed: 0.0756s/iter; left time: 135.8216s\n",
      "\titers: 300, epoch: 16 | loss: 0.1247897\n",
      "\tspeed: 0.0756s/iter; left time: 128.2434s\n",
      "Epoch: 16 cost time: 32.01871919631958\n",
      "Epoch: 16, Steps: 399 | Train Loss: 0.1179162 Vali Loss: 0.1118409 Test Loss: 0.0993477\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 17 | loss: 0.1126275\n",
      "\tspeed: 0.0779s/iter; left time: 116.6590s\n",
      "\titers: 200, epoch: 17 | loss: 0.1164138\n",
      "\tspeed: 0.0817s/iter; left time: 114.1624s\n",
      "\titers: 300, epoch: 17 | loss: 0.1468708\n",
      "\tspeed: 0.0835s/iter; left time: 108.2768s\n",
      "Epoch: 17 cost time: 32.35120415687561\n",
      "Epoch: 17, Steps: 399 | Train Loss: 0.1177785 Vali Loss: 0.1117008 Test Loss: 0.0976969\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 18 | loss: 0.0776801\n",
      "\tspeed: 0.0763s/iter; left time: 83.8232s\n",
      "\titers: 200, epoch: 18 | loss: 0.1083349\n",
      "\tspeed: 0.0765s/iter; left time: 76.3849s\n",
      "\titers: 300, epoch: 18 | loss: 0.1676659\n",
      "\tspeed: 0.0738s/iter; left time: 66.2453s\n",
      "Epoch: 18 cost time: 29.992288827896118\n",
      "Epoch: 18, Steps: 399 | Train Loss: 0.1171188 Vali Loss: 0.1117589 Test Loss: 0.0981172\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.0989716500043869, mae:0.15939834713935852\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on DEWINDh_small with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_DEWINDh_small_il168_pl48_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.3006506\n",
      "\tspeed: 0.0794s/iter; left time: 624.0925s\n",
      "\titers: 200, epoch: 1 | loss: 0.2279169\n",
      "\tspeed: 0.0756s/iter; left time: 586.4261s\n",
      "\titers: 300, epoch: 1 | loss: 0.2325549\n",
      "\tspeed: 0.0773s/iter; left time: 592.0341s\n",
      "Epoch: 1 cost time: 30.95104670524597\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.2969285 Vali Loss: 0.1974367 Test Loss: 0.1645838\n",
      "Validation loss decreased (inf --> 0.197437).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.1602157\n",
      "\tspeed: 0.0696s/iter; left time: 519.1184s\n",
      "\titers: 200, epoch: 2 | loss: 0.1562714\n",
      "\tspeed: 0.0672s/iter; left time: 494.4484s\n",
      "\titers: 300, epoch: 2 | loss: 0.1570684\n",
      "\tspeed: 0.0711s/iter; left time: 516.1238s\n",
      "Epoch: 2 cost time: 27.861615657806396\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.1792480 Vali Loss: 0.1777007 Test Loss: 0.1437389\n",
      "Validation loss decreased (0.197437 --> 0.177701).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1751660\n",
      "\tspeed: 0.0730s/iter; left time: 515.9299s\n",
      "\titers: 200, epoch: 3 | loss: 0.1862124\n",
      "\tspeed: 0.0739s/iter; left time: 514.5794s\n",
      "\titers: 300, epoch: 3 | loss: 0.1454418\n",
      "\tspeed: 0.0740s/iter; left time: 507.9649s\n",
      "Epoch: 3 cost time: 29.837661504745483\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.1617017 Vali Loss: 0.1653003 Test Loss: 0.1372682\n",
      "Validation loss decreased (0.177701 --> 0.165300).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.1466971\n",
      "\tspeed: 0.0733s/iter; left time: 488.8599s\n",
      "\titers: 200, epoch: 4 | loss: 0.1360015\n",
      "\tspeed: 0.0734s/iter; left time: 482.0105s\n",
      "\titers: 300, epoch: 4 | loss: 0.1703978\n",
      "\tspeed: 0.0745s/iter; left time: 481.8335s\n",
      "Epoch: 4 cost time: 29.375041723251343\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.1564806 Vali Loss: 0.1632891 Test Loss: 0.1524064\n",
      "Validation loss decreased (0.165300 --> 0.163289).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1272794\n",
      "\tspeed: 0.0654s/iter; left time: 410.1450s\n",
      "\titers: 200, epoch: 5 | loss: 0.1450224\n",
      "\tspeed: 0.0729s/iter; left time: 449.8988s\n",
      "\titers: 300, epoch: 5 | loss: 0.1510842\n",
      "\tspeed: 0.0743s/iter; left time: 450.9425s\n",
      "Epoch: 5 cost time: 28.682260513305664\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.1502811 Vali Loss: 0.1539645 Test Loss: 0.1320159\n",
      "Validation loss decreased (0.163289 --> 0.153964).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.1504505\n",
      "\tspeed: 0.0713s/iter; left time: 418.4730s\n",
      "\titers: 200, epoch: 6 | loss: 0.1464532\n",
      "\tspeed: 0.0639s/iter; left time: 368.4995s\n",
      "\titers: 300, epoch: 6 | loss: 0.1987200\n",
      "\tspeed: 0.0693s/iter; left time: 393.2518s\n",
      "Epoch: 6 cost time: 27.857320547103882\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.1489478 Vali Loss: 0.1528078 Test Loss: 0.1300317\n",
      "Validation loss decreased (0.153964 --> 0.152808).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1278522\n",
      "\tspeed: 0.0737s/iter; left time: 403.6022s\n",
      "\titers: 200, epoch: 7 | loss: 0.1050679\n",
      "\tspeed: 0.0708s/iter; left time: 380.5763s\n",
      "\titers: 300, epoch: 7 | loss: 0.1821333\n",
      "\tspeed: 0.0763s/iter; left time: 402.5060s\n",
      "Epoch: 7 cost time: 29.59127449989319\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.1452110 Vali Loss: 0.1506950 Test Loss: 0.1287564\n",
      "Validation loss decreased (0.152808 --> 0.150695).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.1547177\n",
      "\tspeed: 0.0740s/iter; left time: 375.6110s\n",
      "\titers: 200, epoch: 8 | loss: 0.1095062\n",
      "\tspeed: 0.0639s/iter; left time: 317.9738s\n",
      "\titers: 300, epoch: 8 | loss: 0.1149829\n",
      "\tspeed: 0.0727s/iter; left time: 354.2435s\n",
      "Epoch: 8 cost time: 28.1548011302948\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.1449345 Vali Loss: 0.1488905 Test Loss: 0.1277611\n",
      "Validation loss decreased (0.150695 --> 0.148890).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1306590\n",
      "\tspeed: 0.0713s/iter; left time: 333.3222s\n",
      "\titers: 200, epoch: 9 | loss: 0.1312790\n",
      "\tspeed: 0.0697s/iter; left time: 319.1288s\n",
      "\titers: 300, epoch: 9 | loss: 0.1171665\n",
      "\tspeed: 0.0721s/iter; left time: 322.7366s\n",
      "Epoch: 9 cost time: 28.626525163650513\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.1432487 Vali Loss: 0.1497922 Test Loss: 0.1253626\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.1275654\n",
      "\tspeed: 0.0736s/iter; left time: 314.9466s\n",
      "\titers: 200, epoch: 10 | loss: 0.1309335\n",
      "\tspeed: 0.0739s/iter; left time: 308.6549s\n",
      "\titers: 300, epoch: 10 | loss: 0.1186200\n",
      "\tspeed: 0.0746s/iter; left time: 304.3237s\n",
      "Epoch: 10 cost time: 29.393076419830322\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.1422333 Vali Loss: 0.1491857 Test Loss: 0.1255487\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1897801\n",
      "\tspeed: 0.0708s/iter; left time: 274.6568s\n",
      "\titers: 200, epoch: 11 | loss: 0.1136530\n",
      "\tspeed: 0.0732s/iter; left time: 276.6795s\n",
      "\titers: 300, epoch: 11 | loss: 0.1463847\n",
      "\tspeed: 0.0709s/iter; left time: 261.0918s\n",
      "Epoch: 11 cost time: 29.343151092529297\n",
      "Epoch: 11, Steps: 398 | Train Loss: 0.1412547 Vali Loss: 0.1486659 Test Loss: 0.1261645\n",
      "Validation loss decreased (0.148890 --> 0.148666).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.1392798\n",
      "\tspeed: 0.0765s/iter; left time: 266.5859s\n",
      "\titers: 200, epoch: 12 | loss: 0.1440726\n",
      "\tspeed: 0.0726s/iter; left time: 245.4698s\n",
      "\titers: 300, epoch: 12 | loss: 0.1405647\n",
      "\tspeed: 0.0698s/iter; left time: 229.1251s\n",
      "Epoch: 12 cost time: 28.840702056884766\n",
      "Epoch: 12, Steps: 398 | Train Loss: 0.1407478 Vali Loss: 0.1477265 Test Loss: 0.1247104\n",
      "Validation loss decreased (0.148666 --> 0.147727).  Saving model ...\n",
      "\titers: 100, epoch: 13 | loss: 0.1398873\n",
      "\tspeed: 0.0710s/iter; left time: 219.0504s\n",
      "\titers: 200, epoch: 13 | loss: 0.1508505\n",
      "\tspeed: 0.0716s/iter; left time: 213.7535s\n",
      "\titers: 300, epoch: 13 | loss: 0.1453025\n",
      "\tspeed: 0.0747s/iter; left time: 215.4862s\n",
      "Epoch: 13 cost time: 28.99013590812683\n",
      "Epoch: 13, Steps: 398 | Train Loss: 0.1405678 Vali Loss: 0.1476956 Test Loss: 0.1256280\n",
      "Validation loss decreased (0.147727 --> 0.147696).  Saving model ...\n",
      "\titers: 100, epoch: 14 | loss: 0.1263764\n",
      "\tspeed: 0.0738s/iter; left time: 198.1801s\n",
      "\titers: 200, epoch: 14 | loss: 0.1324616\n",
      "\tspeed: 0.0738s/iter; left time: 190.9058s\n",
      "\titers: 300, epoch: 14 | loss: 0.1533390\n",
      "\tspeed: 0.0768s/iter; left time: 191.1232s\n",
      "Epoch: 14 cost time: 29.792865991592407\n",
      "Epoch: 14, Steps: 398 | Train Loss: 0.1408906 Vali Loss: 0.1472774 Test Loss: 0.1255340\n",
      "Validation loss decreased (0.147696 --> 0.147277).  Saving model ...\n",
      "\titers: 100, epoch: 15 | loss: 0.1141523\n",
      "\tspeed: 0.0698s/iter; left time: 159.7582s\n",
      "\titers: 200, epoch: 15 | loss: 0.1696910\n",
      "\tspeed: 0.0683s/iter; left time: 149.5446s\n",
      "\titers: 300, epoch: 15 | loss: 0.1276187\n",
      "\tspeed: 0.0716s/iter; left time: 149.6586s\n",
      "Epoch: 15 cost time: 28.1636803150177\n",
      "Epoch: 15, Steps: 398 | Train Loss: 0.1401552 Vali Loss: 0.1469501 Test Loss: 0.1243409\n",
      "Validation loss decreased (0.147277 --> 0.146950).  Saving model ...\n",
      "\titers: 100, epoch: 16 | loss: 0.1652438\n",
      "\tspeed: 0.0726s/iter; left time: 137.2004s\n",
      "\titers: 200, epoch: 16 | loss: 0.1258525\n",
      "\tspeed: 0.0747s/iter; left time: 133.7588s\n",
      "\titers: 300, epoch: 16 | loss: 0.1352462\n",
      "\tspeed: 0.0703s/iter; left time: 118.9487s\n",
      "Epoch: 16 cost time: 29.117854118347168\n",
      "Epoch: 16, Steps: 398 | Train Loss: 0.1406289 Vali Loss: 0.1467720 Test Loss: 0.1236953\n",
      "Validation loss decreased (0.146950 --> 0.146772).  Saving model ...\n",
      "\titers: 100, epoch: 17 | loss: 0.1308996\n",
      "\tspeed: 0.0718s/iter; left time: 107.2208s\n",
      "\titers: 200, epoch: 17 | loss: 0.1387502\n",
      "\tspeed: 0.0700s/iter; left time: 97.4787s\n",
      "\titers: 300, epoch: 17 | loss: 0.1245789\n",
      "\tspeed: 0.0715s/iter; left time: 92.4506s\n",
      "Epoch: 17 cost time: 29.158548593521118\n",
      "Epoch: 17, Steps: 398 | Train Loss: 0.1399928 Vali Loss: 0.1468300 Test Loss: 0.1230678\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 18 | loss: 0.1612804\n",
      "\tspeed: 0.0766s/iter; left time: 83.8952s\n",
      "\titers: 200, epoch: 18 | loss: 0.1337716\n",
      "\tspeed: 0.0755s/iter; left time: 75.1272s\n",
      "\titers: 300, epoch: 18 | loss: 0.1363659\n",
      "\tspeed: 0.0735s/iter; left time: 65.8197s\n",
      "Epoch: 18 cost time: 29.42353630065918\n",
      "Epoch: 18, Steps: 398 | Train Loss: 0.1397900 Vali Loss: 0.1467571 Test Loss: 0.1234018\n",
      "Validation loss decreased (0.146772 --> 0.146757).  Saving model ...\n",
      "\titers: 100, epoch: 19 | loss: 0.1291057\n",
      "\tspeed: 0.0707s/iter; left time: 49.2853s\n",
      "\titers: 200, epoch: 19 | loss: 0.1818147\n",
      "\tspeed: 0.0714s/iter; left time: 42.6444s\n",
      "\titers: 300, epoch: 19 | loss: 0.1451017\n",
      "\tspeed: 0.0708s/iter; left time: 35.1955s\n",
      "Epoch: 19 cost time: 28.406525373458862\n",
      "Epoch: 19, Steps: 398 | Train Loss: 0.1394301 Vali Loss: 0.1467490 Test Loss: 0.1247654\n",
      "Validation loss decreased (0.146757 --> 0.146749).  Saving model ...\n",
      "\titers: 100, epoch: 20 | loss: 0.1617741\n",
      "\tspeed: 0.0717s/iter; left time: 21.4251s\n",
      "\titers: 200, epoch: 20 | loss: 0.1022462\n",
      "\tspeed: 0.0718s/iter; left time: 14.2981s\n",
      "\titers: 300, epoch: 20 | loss: 0.1106175\n",
      "\tspeed: 0.0753s/iter; left time: 7.4559s\n",
      "Epoch: 20 cost time: 29.033186674118042\n",
      "Epoch: 20, Steps: 398 | Train Loss: 0.1389430 Vali Loss: 0.1470089 Test Loss: 0.1244802\n",
      "EarlyStopping counter: 1 out of 3\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.12476538121700287, mae:0.17651182413101196\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on DEWINDh_small with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_DEWINDh_small_il168_pl168_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.2919922\n",
      "\tspeed: 0.0780s/iter; left time: 607.0580s\n",
      "\titers: 200, epoch: 1 | loss: 0.2121470\n",
      "\tspeed: 0.0769s/iter; left time: 590.9249s\n",
      "\titers: 300, epoch: 1 | loss: 0.1939276\n",
      "\tspeed: 0.0729s/iter; left time: 552.6123s\n",
      "Epoch: 1 cost time: 29.933212280273438\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.3189897 Vali Loss: 0.2169733 Test Loss: 0.1966010\n",
      "Validation loss decreased (inf --> 0.216973).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.1838764\n",
      "\tspeed: 0.0794s/iter; left time: 586.2646s\n",
      "\titers: 200, epoch: 2 | loss: 0.2209148\n",
      "\tspeed: 0.0763s/iter; left time: 555.9334s\n",
      "\titers: 300, epoch: 2 | loss: 0.1988584\n",
      "\tspeed: 0.0712s/iter; left time: 511.6855s\n",
      "Epoch: 2 cost time: 28.92862319946289\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.1942652 Vali Loss: 0.2028581 Test Loss: 0.1938663\n",
      "Validation loss decreased (0.216973 --> 0.202858).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2017738\n",
      "\tspeed: 0.0733s/iter; left time: 512.3471s\n",
      "\titers: 200, epoch: 3 | loss: 0.1880993\n",
      "\tspeed: 0.0753s/iter; left time: 518.9656s\n",
      "\titers: 300, epoch: 3 | loss: 0.1901653\n",
      "\tspeed: 0.0736s/iter; left time: 499.7130s\n",
      "Epoch: 3 cost time: 29.954369068145752\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.1794772 Vali Loss: 0.1959272 Test Loss: 0.1811677\n",
      "Validation loss decreased (0.202858 --> 0.195927).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.1568065\n",
      "\tspeed: 0.0761s/iter; left time: 502.1439s\n",
      "\titers: 200, epoch: 4 | loss: 0.1716998\n",
      "\tspeed: 0.0766s/iter; left time: 497.5866s\n",
      "\titers: 300, epoch: 4 | loss: 0.1705288\n",
      "\tspeed: 0.0744s/iter; left time: 475.9340s\n",
      "Epoch: 4 cost time: 29.033979654312134\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.1743193 Vali Loss: 0.1959131 Test Loss: 0.1827473\n",
      "Validation loss decreased (0.195927 --> 0.195913).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1992245\n",
      "\tspeed: 0.0731s/iter; left time: 453.7259s\n",
      "\titers: 200, epoch: 5 | loss: 0.1772182\n",
      "\tspeed: 0.0736s/iter; left time: 449.0652s\n",
      "\titers: 300, epoch: 5 | loss: 0.1507689\n",
      "\tspeed: 0.0735s/iter; left time: 441.4839s\n",
      "Epoch: 5 cost time: 28.92751908302307\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.1694585 Vali Loss: 0.1906722 Test Loss: 0.1710462\n",
      "Validation loss decreased (0.195913 --> 0.190672).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.1558651\n",
      "\tspeed: 0.0756s/iter; left time: 439.3702s\n",
      "\titers: 200, epoch: 6 | loss: 0.1697822\n",
      "\tspeed: 0.0761s/iter; left time: 434.3233s\n",
      "\titers: 300, epoch: 6 | loss: 0.1640486\n",
      "\tspeed: 0.0758s/iter; left time: 425.4105s\n",
      "Epoch: 6 cost time: 29.33419966697693\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.1675943 Vali Loss: 0.1902225 Test Loss: 0.1758702\n",
      "Validation loss decreased (0.190672 --> 0.190223).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1643039\n",
      "\tspeed: 0.0705s/iter; left time: 381.9702s\n",
      "\titers: 200, epoch: 7 | loss: 0.1597380\n",
      "\tspeed: 0.0767s/iter; left time: 407.6743s\n",
      "\titers: 300, epoch: 7 | loss: 0.1599884\n",
      "\tspeed: 0.0735s/iter; left time: 383.5489s\n",
      "Epoch: 7 cost time: 28.95988392829895\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.1648337 Vali Loss: 0.1882053 Test Loss: 0.1713777\n",
      "Validation loss decreased (0.190223 --> 0.188205).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.1792213\n",
      "\tspeed: 0.0798s/iter; left time: 400.5910s\n",
      "\titers: 200, epoch: 8 | loss: 0.1660530\n",
      "\tspeed: 0.0756s/iter; left time: 372.3003s\n",
      "\titers: 300, epoch: 8 | loss: 0.1412752\n",
      "\tspeed: 0.0756s/iter; left time: 364.4402s\n",
      "Epoch: 8 cost time: 30.42929196357727\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.1646320 Vali Loss: 0.1870828 Test Loss: 0.1650324\n",
      "Validation loss decreased (0.188205 --> 0.187083).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1807309\n",
      "\tspeed: 0.0859s/iter; left time: 397.4458s\n",
      "\titers: 200, epoch: 9 | loss: 0.1331132\n",
      "\tspeed: 0.0784s/iter; left time: 354.9385s\n",
      "\titers: 300, epoch: 9 | loss: 0.2041686\n",
      "\tspeed: 0.0740s/iter; left time: 327.9018s\n",
      "Epoch: 9 cost time: 30.025158643722534\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.1629310 Vali Loss: 0.1872386 Test Loss: 0.1695851\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.1641964\n",
      "\tspeed: 0.0736s/iter; left time: 311.7177s\n",
      "\titers: 200, epoch: 10 | loss: 0.1681272\n",
      "\tspeed: 0.0724s/iter; left time: 299.5631s\n",
      "\titers: 300, epoch: 10 | loss: 0.1752480\n",
      "\tspeed: 0.0737s/iter; left time: 297.1923s\n",
      "Epoch: 10 cost time: 28.664034128189087\n",
      "Epoch: 10, Steps: 394 | Train Loss: 0.1624446 Vali Loss: 0.1859666 Test Loss: 0.1653754\n",
      "Validation loss decreased (0.187083 --> 0.185967).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1777689\n",
      "\tspeed: 0.0689s/iter; left time: 264.6507s\n",
      "\titers: 200, epoch: 11 | loss: 0.1746068\n",
      "\tspeed: 0.0788s/iter; left time: 294.7404s\n",
      "\titers: 300, epoch: 11 | loss: 0.1581040\n",
      "\tspeed: 0.0757s/iter; left time: 275.5379s\n",
      "Epoch: 11 cost time: 29.274200677871704\n",
      "Epoch: 11, Steps: 394 | Train Loss: 0.1616891 Vali Loss: 0.1864877 Test Loss: 0.1653292\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.1531117\n",
      "\tspeed: 0.0715s/iter; left time: 246.3632s\n",
      "\titers: 200, epoch: 12 | loss: 0.1791397\n",
      "\tspeed: 0.0761s/iter; left time: 254.7355s\n",
      "\titers: 300, epoch: 12 | loss: 0.1814703\n",
      "\tspeed: 0.0767s/iter; left time: 249.1145s\n",
      "Epoch: 12 cost time: 29.51383399963379\n",
      "Epoch: 12, Steps: 394 | Train Loss: 0.1613353 Vali Loss: 0.1866650 Test Loss: 0.1686865\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.1583493\n",
      "\tspeed: 0.0738s/iter; left time: 225.1866s\n",
      "\titers: 200, epoch: 13 | loss: 0.1476016\n",
      "\tspeed: 0.0731s/iter; left time: 215.8855s\n",
      "\titers: 300, epoch: 13 | loss: 0.1465482\n",
      "\tspeed: 0.0723s/iter; left time: 206.2611s\n",
      "Epoch: 13 cost time: 28.869789123535156\n",
      "Epoch: 13, Steps: 394 | Train Loss: 0.1612530 Vali Loss: 0.1863596 Test Loss: 0.1662508\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.16537538170814514, mae:0.21100205183029175\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on DEWINDh_small with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_DEWINDh_small_il168_pl336_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.2888548\n",
      "\tspeed: 0.0786s/iter; left time: 603.6595s\n",
      "\titers: 200, epoch: 1 | loss: 0.2050162\n",
      "\tspeed: 0.0761s/iter; left time: 577.1707s\n",
      "\titers: 300, epoch: 1 | loss: 0.2070069\n",
      "\tspeed: 0.0799s/iter; left time: 597.5736s\n",
      "Epoch: 1 cost time: 30.23176860809326\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.3416480 Vali Loss: 0.2111290 Test Loss: 0.2322071\n",
      "Validation loss decreased (inf --> 0.211129).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.2216659\n",
      "\tspeed: 0.0694s/iter; left time: 506.1555s\n",
      "\titers: 200, epoch: 2 | loss: 0.1891621\n",
      "\tspeed: 0.0711s/iter; left time: 511.3095s\n",
      "\titers: 300, epoch: 2 | loss: 0.2093925\n",
      "\tspeed: 0.0709s/iter; left time: 503.0124s\n",
      "Epoch: 2 cost time: 27.589577198028564\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.1997753 Vali Loss: 0.2138817 Test Loss: 0.2284019\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2046957\n",
      "\tspeed: 0.0732s/iter; left time: 505.1058s\n",
      "\titers: 200, epoch: 3 | loss: 0.1757908\n",
      "\tspeed: 0.0778s/iter; left time: 529.2425s\n",
      "\titers: 300, epoch: 3 | loss: 0.1911266\n",
      "\tspeed: 0.0751s/iter; left time: 503.0635s\n",
      "Epoch: 3 cost time: 29.412392616271973\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.1865556 Vali Loss: 0.1990698 Test Loss: 0.2247228\n",
      "Validation loss decreased (0.211129 --> 0.199070).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.1747946\n",
      "\tspeed: 0.0704s/iter; left time: 458.6469s\n",
      "\titers: 200, epoch: 4 | loss: 0.1864552\n",
      "\tspeed: 0.0708s/iter; left time: 454.0213s\n",
      "\titers: 300, epoch: 4 | loss: 0.1890485\n",
      "\tspeed: 0.0724s/iter; left time: 457.1798s\n",
      "Epoch: 4 cost time: 28.432186365127563\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.1823649 Vali Loss: 0.1979576 Test Loss: 0.2384457\n",
      "Validation loss decreased (0.199070 --> 0.197958).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1607056\n",
      "\tspeed: 0.0744s/iter; left time: 455.9791s\n",
      "\titers: 200, epoch: 5 | loss: 0.1907942\n",
      "\tspeed: 0.0832s/iter; left time: 501.2081s\n",
      "\titers: 300, epoch: 5 | loss: 0.1371334\n",
      "\tspeed: 0.0758s/iter; left time: 449.1333s\n",
      "Epoch: 5 cost time: 30.43278932571411\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.1770878 Vali Loss: 0.1953454 Test Loss: 0.2202525\n",
      "Validation loss decreased (0.197958 --> 0.195345).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.1693689\n",
      "\tspeed: 0.0735s/iter; left time: 421.3793s\n",
      "\titers: 200, epoch: 6 | loss: 0.1678030\n",
      "\tspeed: 0.0727s/iter; left time: 409.9899s\n",
      "\titers: 300, epoch: 6 | loss: 0.1658013\n",
      "\tspeed: 0.0739s/iter; left time: 409.2742s\n",
      "Epoch: 6 cost time: 29.48595356941223\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.1757080 Vali Loss: 0.1935915 Test Loss: 0.2058722\n",
      "Validation loss decreased (0.195345 --> 0.193591).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1724736\n",
      "\tspeed: 0.0733s/iter; left time: 391.8745s\n",
      "\titers: 200, epoch: 7 | loss: 0.1453297\n",
      "\tspeed: 0.0784s/iter; left time: 411.2649s\n",
      "\titers: 300, epoch: 7 | loss: 0.1570688\n",
      "\tspeed: 0.0775s/iter; left time: 399.0964s\n",
      "Epoch: 7 cost time: 29.74552011489868\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.1728981 Vali Loss: 0.1922558 Test Loss: 0.2115311\n",
      "Validation loss decreased (0.193591 --> 0.192256).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.2164452\n",
      "\tspeed: 0.0729s/iter; left time: 361.6800s\n",
      "\titers: 200, epoch: 8 | loss: 0.1880616\n",
      "\tspeed: 0.0764s/iter; left time: 370.9402s\n",
      "\titers: 300, epoch: 8 | loss: 0.1656789\n",
      "\tspeed: 0.0725s/iter; left time: 345.0871s\n",
      "Epoch: 8 cost time: 28.296961307525635\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.1720737 Vali Loss: 0.1915911 Test Loss: 0.2071494\n",
      "Validation loss decreased (0.192256 --> 0.191591).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1751853\n",
      "\tspeed: 0.0743s/iter; left time: 339.3365s\n",
      "\titers: 200, epoch: 9 | loss: 0.1538768\n",
      "\tspeed: 0.0735s/iter; left time: 328.4651s\n",
      "\titers: 300, epoch: 9 | loss: 0.1667277\n",
      "\tspeed: 0.0782s/iter; left time: 341.8210s\n",
      "Epoch: 9 cost time: 29.62987732887268\n",
      "Epoch: 9, Steps: 389 | Train Loss: 0.1706654 Vali Loss: 0.1912502 Test Loss: 0.2058425\n",
      "Validation loss decreased (0.191591 --> 0.191250).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.1795690\n",
      "\tspeed: 0.0751s/iter; left time: 313.7681s\n",
      "\titers: 200, epoch: 10 | loss: 0.1727410\n",
      "\tspeed: 0.0743s/iter; left time: 302.9887s\n",
      "\titers: 300, epoch: 10 | loss: 0.1779250\n",
      "\tspeed: 0.0756s/iter; left time: 301.0721s\n",
      "Epoch: 10 cost time: 29.177488327026367\n",
      "Epoch: 10, Steps: 389 | Train Loss: 0.1701975 Vali Loss: 0.1917179 Test Loss: 0.2093047\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1758234\n",
      "\tspeed: 0.0726s/iter; left time: 275.1313s\n",
      "\titers: 200, epoch: 11 | loss: 0.1841525\n",
      "\tspeed: 0.0682s/iter; left time: 251.8364s\n",
      "\titers: 300, epoch: 11 | loss: 0.1899317\n",
      "\tspeed: 0.0813s/iter; left time: 291.8861s\n",
      "Epoch: 11 cost time: 29.457061529159546\n",
      "Epoch: 11, Steps: 389 | Train Loss: 0.1693128 Vali Loss: 0.1914046 Test Loss: 0.2078565\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.1923562\n",
      "\tspeed: 0.0748s/iter; left time: 254.4989s\n",
      "\titers: 200, epoch: 12 | loss: 0.1629328\n",
      "\tspeed: 0.0720s/iter; left time: 237.5996s\n",
      "\titers: 300, epoch: 12 | loss: 0.1545016\n",
      "\tspeed: 0.0688s/iter; left time: 220.3577s\n",
      "Epoch: 12 cost time: 27.96314787864685\n",
      "Epoch: 12, Steps: 389 | Train Loss: 0.1690893 Vali Loss: 0.1910677 Test Loss: 0.2083513\n",
      "Validation loss decreased (0.191250 --> 0.191068).  Saving model ...\n",
      "\titers: 100, epoch: 13 | loss: 0.1622642\n",
      "\tspeed: 0.0738s/iter; left time: 222.2788s\n",
      "\titers: 200, epoch: 13 | loss: 0.1580951\n",
      "\tspeed: 0.0826s/iter; left time: 240.5776s\n",
      "\titers: 300, epoch: 13 | loss: 0.1344286\n",
      "\tspeed: 0.0770s/iter; left time: 216.6255s\n",
      "Epoch: 13 cost time: 30.398479461669922\n",
      "Epoch: 13, Steps: 389 | Train Loss: 0.1687602 Vali Loss: 0.1915445 Test Loss: 0.2082555\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 14 | loss: 0.1829555\n",
      "\tspeed: 0.0765s/iter; left time: 200.6970s\n",
      "\titers: 200, epoch: 14 | loss: 0.1707666\n",
      "\tspeed: 0.0749s/iter; left time: 189.0005s\n",
      "\titers: 300, epoch: 14 | loss: 0.1522823\n",
      "\tspeed: 0.0761s/iter; left time: 184.5498s\n",
      "Epoch: 14 cost time: 29.922020196914673\n",
      "Epoch: 14, Steps: 389 | Train Loss: 0.1684507 Vali Loss: 0.1916523 Test Loss: 0.2095674\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 15 | loss: 0.1605266\n",
      "\tspeed: 0.0783s/iter; left time: 175.0181s\n",
      "\titers: 200, epoch: 15 | loss: 0.1722920\n",
      "\tspeed: 0.0678s/iter; left time: 144.6853s\n",
      "\titers: 300, epoch: 15 | loss: 0.1615416\n",
      "\tspeed: 0.0711s/iter; left time: 144.7641s\n",
      "Epoch: 15 cost time: 28.537497997283936\n",
      "Epoch: 15, Steps: 389 | Train Loss: 0.1684297 Vali Loss: 0.1914147 Test Loss: 0.2086201\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.20835131406784058, mae:0.23385827243328094\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on DEWINDh_small with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_DEWINDh_small_il168_pl720_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.3261081\n",
      "\tspeed: 0.0771s/iter; left time: 573.4370s\n",
      "\titers: 200, epoch: 1 | loss: 0.2699929\n",
      "\tspeed: 0.0774s/iter; left time: 567.9437s\n",
      "\titers: 300, epoch: 1 | loss: 0.2245009\n",
      "\tspeed: 0.0738s/iter; left time: 534.5051s\n",
      "Epoch: 1 cost time: 28.779840230941772\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.4071162 Vali Loss: 0.2114421 Test Loss: 0.2948433\n",
      "Validation loss decreased (inf --> 0.211442).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.2760970\n",
      "\tspeed: 0.0797s/iter; left time: 562.6871s\n",
      "\titers: 200, epoch: 2 | loss: 0.2588166\n",
      "\tspeed: 0.0795s/iter; left time: 553.9774s\n",
      "\titers: 300, epoch: 2 | loss: 0.2317124\n",
      "\tspeed: 0.0784s/iter; left time: 538.3339s\n",
      "Epoch: 2 cost time: 29.931047439575195\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.2227518 Vali Loss: 0.2052212 Test Loss: 0.3058800\n",
      "Validation loss decreased (0.211442 --> 0.205221).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1886464\n",
      "\tspeed: 0.0822s/iter; left time: 549.9692s\n",
      "\titers: 200, epoch: 3 | loss: 0.2066133\n",
      "\tspeed: 0.0798s/iter; left time: 525.5073s\n",
      "\titers: 300, epoch: 3 | loss: 0.2361291\n",
      "\tspeed: 0.0755s/iter; left time: 489.9055s\n",
      "Epoch: 3 cost time: 29.7808997631073\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.2102538 Vali Loss: 0.2029650 Test Loss: 0.2975541\n",
      "Validation loss decreased (0.205221 --> 0.202965).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.1831477\n",
      "\tspeed: 0.0778s/iter; left time: 490.7518s\n",
      "\titers: 200, epoch: 4 | loss: 0.2102692\n",
      "\tspeed: 0.0808s/iter; left time: 501.7019s\n",
      "\titers: 300, epoch: 4 | loss: 0.2229582\n",
      "\tspeed: 0.0760s/iter; left time: 464.4250s\n",
      "Epoch: 4 cost time: 29.722572326660156\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.2063815 Vali Loss: 0.1995385 Test Loss: 0.2732672\n",
      "Validation loss decreased (0.202965 --> 0.199539).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2162319\n",
      "\tspeed: 0.0829s/iter; left time: 492.0838s\n",
      "\titers: 200, epoch: 5 | loss: 0.1907513\n",
      "\tspeed: 0.0814s/iter; left time: 474.5770s\n",
      "\titers: 300, epoch: 5 | loss: 0.2076745\n",
      "\tspeed: 0.0784s/iter; left time: 449.2621s\n",
      "Epoch: 5 cost time: 30.470277070999146\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.2010572 Vali Loss: 0.1989022 Test Loss: 0.2724388\n",
      "Validation loss decreased (0.199539 --> 0.198902).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.2123514\n",
      "\tspeed: 0.0787s/iter; left time: 437.2611s\n",
      "\titers: 200, epoch: 6 | loss: 0.1959559\n",
      "\tspeed: 0.0770s/iter; left time: 419.8549s\n",
      "\titers: 300, epoch: 6 | loss: 0.2027006\n",
      "\tspeed: 0.0828s/iter; left time: 443.5342s\n",
      "Epoch: 6 cost time: 30.25727367401123\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.1995208 Vali Loss: 0.1984822 Test Loss: 0.2765580\n",
      "Validation loss decreased (0.198902 --> 0.198482).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1902436\n",
      "\tspeed: 0.0790s/iter; left time: 409.3149s\n",
      "\titers: 200, epoch: 7 | loss: 0.2132372\n",
      "\tspeed: 0.0779s/iter; left time: 395.6827s\n",
      "\titers: 300, epoch: 7 | loss: 0.1977117\n",
      "\tspeed: 0.0732s/iter; left time: 364.3247s\n",
      "Epoch: 7 cost time: 28.766824960708618\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.1969779 Vali Loss: 0.1963569 Test Loss: 0.2763585\n",
      "Validation loss decreased (0.198482 --> 0.196357).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.2009371\n",
      "\tspeed: 0.0775s/iter; left time: 372.1123s\n",
      "\titers: 200, epoch: 8 | loss: 0.1865053\n",
      "\tspeed: 0.0772s/iter; left time: 363.1006s\n",
      "\titers: 300, epoch: 8 | loss: 0.1982141\n",
      "\tspeed: 0.0804s/iter; left time: 369.9033s\n",
      "Epoch: 8 cost time: 29.76606559753418\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.1956283 Vali Loss: 0.1962012 Test Loss: 0.2619037\n",
      "Validation loss decreased (0.196357 --> 0.196201).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1958758\n",
      "\tspeed: 0.0818s/iter; left time: 361.8571s\n",
      "\titers: 200, epoch: 9 | loss: 0.2047001\n",
      "\tspeed: 0.0791s/iter; left time: 342.2592s\n",
      "\titers: 300, epoch: 9 | loss: 0.1974300\n",
      "\tspeed: 0.0776s/iter; left time: 327.8382s\n",
      "Epoch: 9 cost time: 29.72291922569275\n",
      "Epoch: 9, Steps: 377 | Train Loss: 0.1944604 Vali Loss: 0.1958132 Test Loss: 0.2732424\n",
      "Validation loss decreased (0.196201 --> 0.195813).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.1864034\n",
      "\tspeed: 0.0800s/iter; left time: 323.8471s\n",
      "\titers: 200, epoch: 10 | loss: 0.1923334\n",
      "\tspeed: 0.0764s/iter; left time: 301.6998s\n",
      "\titers: 300, epoch: 10 | loss: 0.1925887\n",
      "\tspeed: 0.0800s/iter; left time: 307.8370s\n",
      "Epoch: 10 cost time: 30.069046020507812\n",
      "Epoch: 10, Steps: 377 | Train Loss: 0.1938133 Vali Loss: 0.1961413 Test Loss: 0.2685804\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1988624\n",
      "\tspeed: 0.0814s/iter; left time: 298.6975s\n",
      "\titers: 200, epoch: 11 | loss: 0.1736206\n",
      "\tspeed: 0.0813s/iter; left time: 290.1521s\n",
      "\titers: 300, epoch: 11 | loss: 0.1856032\n",
      "\tspeed: 0.0803s/iter; left time: 278.5632s\n",
      "Epoch: 11 cost time: 30.923513889312744\n",
      "Epoch: 11, Steps: 377 | Train Loss: 0.1931207 Vali Loss: 0.1954403 Test Loss: 0.2666979\n",
      "Validation loss decreased (0.195813 --> 0.195440).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.1758547\n",
      "\tspeed: 0.0791s/iter; left time: 260.6223s\n",
      "\titers: 200, epoch: 12 | loss: 0.1796307\n",
      "\tspeed: 0.0746s/iter; left time: 238.3811s\n",
      "\titers: 300, epoch: 12 | loss: 0.1700000\n",
      "\tspeed: 0.0749s/iter; left time: 231.8757s\n",
      "Epoch: 12 cost time: 29.201557159423828\n",
      "Epoch: 12, Steps: 377 | Train Loss: 0.1929528 Vali Loss: 0.1954504 Test Loss: 0.2712663\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.1783972\n",
      "\tspeed: 0.0791s/iter; left time: 230.7717s\n",
      "\titers: 200, epoch: 13 | loss: 0.1961612\n",
      "\tspeed: 0.0786s/iter; left time: 221.2961s\n",
      "\titers: 300, epoch: 13 | loss: 0.1700233\n",
      "\tspeed: 0.0745s/iter; left time: 202.5326s\n",
      "Epoch: 13 cost time: 28.89913535118103\n",
      "Epoch: 13, Steps: 377 | Train Loss: 0.1926059 Vali Loss: 0.1962699 Test Loss: 0.2785317\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 14 | loss: 0.1769871\n",
      "\tspeed: 0.0742s/iter; left time: 188.5741s\n",
      "\titers: 200, epoch: 14 | loss: 0.1908891\n",
      "\tspeed: 0.0786s/iter; left time: 191.8883s\n",
      "\titers: 300, epoch: 14 | loss: 0.1980182\n",
      "\tspeed: 0.0812s/iter; left time: 190.0788s\n",
      "Epoch: 14 cost time: 29.505244255065918\n",
      "Epoch: 14, Steps: 377 | Train Loss: 0.1924480 Vali Loss: 0.1958156 Test Loss: 0.2739785\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.26669782400131226, mae:0.28928041458129883\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTHh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTHh1_il168_pl24_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.1566515\n",
      "\tspeed: 0.0772s/iter; left time: 608.3129s\n",
      "\titers: 200, epoch: 1 | loss: 0.1266271\n",
      "\tspeed: 0.0707s/iter; left time: 550.1533s\n",
      "\titers: 300, epoch: 1 | loss: 0.0687663\n",
      "\tspeed: 0.0745s/iter; left time: 572.2861s\n",
      "Epoch: 1 cost time: 30.038143396377563\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.2178646 Vali Loss: 0.0236653 Test Loss: 0.0247108\n",
      "Validation loss decreased (inf --> 0.023665).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0560641\n",
      "\tspeed: 0.0768s/iter; left time: 574.6125s\n",
      "\titers: 200, epoch: 2 | loss: 0.0523020\n",
      "\tspeed: 0.0752s/iter; left time: 555.3723s\n",
      "\titers: 300, epoch: 2 | loss: 0.0534135\n",
      "\tspeed: 0.0718s/iter; left time: 523.1831s\n",
      "Epoch: 2 cost time: 29.964045763015747\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0563395 Vali Loss: 0.0215656 Test Loss: 0.0225256\n",
      "Validation loss decreased (0.023665 --> 0.021566).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0434218\n",
      "\tspeed: 0.0743s/iter; left time: 526.0343s\n",
      "\titers: 200, epoch: 3 | loss: 0.0397644\n",
      "\tspeed: 0.0742s/iter; left time: 518.3383s\n",
      "\titers: 300, epoch: 3 | loss: 0.0356334\n",
      "\tspeed: 0.0685s/iter; left time: 471.6115s\n",
      "Epoch: 3 cost time: 28.55646586418152\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0410257 Vali Loss: 0.0187433 Test Loss: 0.0191030\n",
      "Validation loss decreased (0.021566 --> 0.018743).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0372538\n",
      "\tspeed: 0.0716s/iter; left time: 478.4523s\n",
      "\titers: 200, epoch: 4 | loss: 0.0394155\n",
      "\tspeed: 0.0748s/iter; left time: 492.6773s\n",
      "\titers: 300, epoch: 4 | loss: 0.0360301\n",
      "\tspeed: 0.0740s/iter; left time: 479.6061s\n",
      "Epoch: 4 cost time: 29.704112768173218\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0367211 Vali Loss: 0.0187418 Test Loss: 0.0191455\n",
      "Validation loss decreased (0.018743 --> 0.018742).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0313712\n",
      "\tspeed: 0.0765s/iter; left time: 480.7813s\n",
      "\titers: 200, epoch: 5 | loss: 0.0299647\n",
      "\tspeed: 0.0768s/iter; left time: 475.1796s\n",
      "\titers: 300, epoch: 5 | loss: 0.0334333\n",
      "\tspeed: 0.0702s/iter; left time: 427.1702s\n",
      "Epoch: 5 cost time: 29.603968858718872\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0326671 Vali Loss: 0.0181704 Test Loss: 0.0187284\n",
      "Validation loss decreased (0.018742 --> 0.018170).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0289711\n",
      "\tspeed: 0.0753s/iter; left time: 443.2686s\n",
      "\titers: 200, epoch: 6 | loss: 0.0293772\n",
      "\tspeed: 0.0731s/iter; left time: 423.0241s\n",
      "\titers: 300, epoch: 6 | loss: 0.0274134\n",
      "\tspeed: 0.0755s/iter; left time: 429.5395s\n",
      "Epoch: 6 cost time: 29.634103298187256\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0315566 Vali Loss: 0.0185596 Test Loss: 0.0188892\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0264585\n",
      "\tspeed: 0.0747s/iter; left time: 409.7088s\n",
      "\titers: 200, epoch: 7 | loss: 0.0286717\n",
      "\tspeed: 0.0766s/iter; left time: 412.6971s\n",
      "\titers: 300, epoch: 7 | loss: 0.0352736\n",
      "\tspeed: 0.0728s/iter; left time: 385.0484s\n",
      "Epoch: 7 cost time: 29.729108095169067\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0295769 Vali Loss: 0.0169521 Test Loss: 0.0174610\n",
      "Validation loss decreased (0.018170 --> 0.016952).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0272343\n",
      "\tspeed: 0.0764s/iter; left time: 388.8705s\n",
      "\titers: 200, epoch: 8 | loss: 0.0251269\n",
      "\tspeed: 0.0749s/iter; left time: 373.4273s\n",
      "\titers: 300, epoch: 8 | loss: 0.0300391\n",
      "\tspeed: 0.0751s/iter; left time: 366.9202s\n",
      "Epoch: 8 cost time: 30.278387784957886\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0292960 Vali Loss: 0.0176009 Test Loss: 0.0181712\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0260588\n",
      "\tspeed: 0.0736s/iter; left time: 345.3021s\n",
      "\titers: 200, epoch: 9 | loss: 0.0264586\n",
      "\tspeed: 0.0799s/iter; left time: 366.5598s\n",
      "\titers: 300, epoch: 9 | loss: 0.0277806\n",
      "\tspeed: 0.0791s/iter; left time: 354.9576s\n",
      "Epoch: 9 cost time: 30.637904167175293\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0280810 Vali Loss: 0.0168330 Test Loss: 0.0172933\n",
      "Validation loss decreased (0.016952 --> 0.016833).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0252041\n",
      "\tspeed: 0.0729s/iter; left time: 312.5460s\n",
      "\titers: 200, epoch: 10 | loss: 0.0272027\n",
      "\tspeed: 0.0720s/iter; left time: 301.6142s\n",
      "\titers: 300, epoch: 10 | loss: 0.0311872\n",
      "\tspeed: 0.0729s/iter; left time: 298.2063s\n",
      "Epoch: 10 cost time: 29.47518301010132\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0279030 Vali Loss: 0.0165041 Test Loss: 0.0169711\n",
      "Validation loss decreased (0.016833 --> 0.016504).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0303371\n",
      "\tspeed: 0.0775s/iter; left time: 301.5023s\n",
      "\titers: 200, epoch: 11 | loss: 0.0267450\n",
      "\tspeed: 0.0808s/iter; left time: 306.3528s\n",
      "\titers: 300, epoch: 11 | loss: 0.0269060\n",
      "\tspeed: 0.0706s/iter; left time: 260.4221s\n",
      "Epoch: 11 cost time: 29.7845401763916\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0272650 Vali Loss: 0.0162671 Test Loss: 0.0167152\n",
      "Validation loss decreased (0.016504 --> 0.016267).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.0259039\n",
      "\tspeed: 0.0724s/iter; left time: 252.8386s\n",
      "\titers: 200, epoch: 12 | loss: 0.0273013\n",
      "\tspeed: 0.0735s/iter; left time: 249.2236s\n",
      "\titers: 300, epoch: 12 | loss: 0.0279138\n",
      "\tspeed: 0.0747s/iter; left time: 245.8092s\n",
      "Epoch: 12 cost time: 29.90600562095642\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0269927 Vali Loss: 0.0160216 Test Loss: 0.0165948\n",
      "Validation loss decreased (0.016267 --> 0.016022).  Saving model ...\n",
      "\titers: 100, epoch: 13 | loss: 0.0258069\n",
      "\tspeed: 0.0783s/iter; left time: 242.2777s\n",
      "\titers: 200, epoch: 13 | loss: 0.0210583\n",
      "\tspeed: 0.0802s/iter; left time: 240.0314s\n",
      "\titers: 300, epoch: 13 | loss: 0.0265347\n",
      "\tspeed: 0.0810s/iter; left time: 234.2661s\n",
      "Epoch: 13 cost time: 31.7359561920166\n",
      "Epoch: 13, Steps: 399 | Train Loss: 0.0266613 Vali Loss: 0.0162755 Test Loss: 0.0166586\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 14 | loss: 0.0259161\n",
      "\tspeed: 0.0752s/iter; left time: 202.6877s\n",
      "\titers: 200, epoch: 14 | loss: 0.0241375\n",
      "\tspeed: 0.0711s/iter; left time: 184.3487s\n",
      "\titers: 300, epoch: 14 | loss: 0.0240110\n",
      "\tspeed: 0.0687s/iter; left time: 171.3429s\n",
      "Epoch: 14 cost time: 28.71908664703369\n",
      "Epoch: 14, Steps: 399 | Train Loss: 0.0268698 Vali Loss: 0.0164420 Test Loss: 0.0169018\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 15 | loss: 0.0280972\n",
      "\tspeed: 0.0745s/iter; left time: 171.0774s\n",
      "\titers: 200, epoch: 15 | loss: 0.0252998\n",
      "\tspeed: 0.0706s/iter; left time: 154.8648s\n",
      "\titers: 300, epoch: 15 | loss: 0.0298691\n",
      "\tspeed: 0.0662s/iter; left time: 138.5860s\n",
      "Epoch: 15 cost time: 28.317153215408325\n",
      "Epoch: 15, Steps: 399 | Train Loss: 0.0266723 Vali Loss: 0.0162397 Test Loss: 0.0167131\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.016594810411334038, mae:0.10283403843641281\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTHh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTHh1_il168_pl48_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.2201959\n",
      "\tspeed: 0.0749s/iter; left time: 589.1800s\n",
      "\titers: 200, epoch: 1 | loss: 0.1136051\n",
      "\tspeed: 0.0710s/iter; left time: 551.1553s\n",
      "\titers: 300, epoch: 1 | loss: 0.0820507\n",
      "\tspeed: 0.0741s/iter; left time: 567.8243s\n",
      "Epoch: 1 cost time: 29.525603771209717\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.2261263 Vali Loss: 0.0313848 Test Loss: 0.0321024\n",
      "Validation loss decreased (inf --> 0.031385).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0694758\n",
      "\tspeed: 0.0711s/iter; left time: 530.4106s\n",
      "\titers: 200, epoch: 2 | loss: 0.0574487\n",
      "\tspeed: 0.0722s/iter; left time: 531.8382s\n",
      "\titers: 300, epoch: 2 | loss: 0.0534206\n",
      "\tspeed: 0.0710s/iter; left time: 515.9283s\n",
      "Epoch: 2 cost time: 28.334055185317993\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0611285 Vali Loss: 0.0266889 Test Loss: 0.0267740\n",
      "Validation loss decreased (0.031385 --> 0.026689).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0450149\n",
      "\tspeed: 0.0696s/iter; left time: 491.7727s\n",
      "\titers: 200, epoch: 3 | loss: 0.0475500\n",
      "\tspeed: 0.0732s/iter; left time: 510.0132s\n",
      "\titers: 300, epoch: 3 | loss: 0.0447099\n",
      "\tspeed: 0.0728s/iter; left time: 500.0349s\n",
      "Epoch: 3 cost time: 29.29896593093872\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0449983 Vali Loss: 0.0200541 Test Loss: 0.0199870\n",
      "Validation loss decreased (0.026689 --> 0.020054).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0372540\n",
      "\tspeed: 0.0727s/iter; left time: 484.6926s\n",
      "\titers: 200, epoch: 4 | loss: 0.0384370\n",
      "\tspeed: 0.0721s/iter; left time: 473.4431s\n",
      "\titers: 300, epoch: 4 | loss: 0.0355455\n",
      "\tspeed: 0.0746s/iter; left time: 482.6205s\n",
      "Epoch: 4 cost time: 28.948698043823242\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0389052 Vali Loss: 0.0205267 Test Loss: 0.0198320\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0333894\n",
      "\tspeed: 0.0679s/iter; left time: 425.8179s\n",
      "\titers: 200, epoch: 5 | loss: 0.0316859\n",
      "\tspeed: 0.0674s/iter; left time: 415.9494s\n",
      "\titers: 300, epoch: 5 | loss: 0.0346127\n",
      "\tspeed: 0.0693s/iter; left time: 420.6407s\n",
      "Epoch: 5 cost time: 27.625036001205444\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0348838 Vali Loss: 0.0189575 Test Loss: 0.0191871\n",
      "Validation loss decreased (0.020054 --> 0.018958).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0335210\n",
      "\tspeed: 0.0730s/iter; left time: 428.5829s\n",
      "\titers: 200, epoch: 6 | loss: 0.0361834\n",
      "\tspeed: 0.0723s/iter; left time: 417.3762s\n",
      "\titers: 300, epoch: 6 | loss: 0.0421574\n",
      "\tspeed: 0.0729s/iter; left time: 413.6061s\n",
      "Epoch: 6 cost time: 29.174105167388916\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0338950 Vali Loss: 0.0174675 Test Loss: 0.0174792\n",
      "Validation loss decreased (0.018958 --> 0.017468).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0297507\n",
      "\tspeed: 0.0800s/iter; left time: 437.7411s\n",
      "\titers: 200, epoch: 7 | loss: 0.0317074\n",
      "\tspeed: 0.0775s/iter; left time: 416.4891s\n",
      "\titers: 300, epoch: 7 | loss: 0.0308337\n",
      "\tspeed: 0.0737s/iter; left time: 388.7129s\n",
      "Epoch: 7 cost time: 29.854392766952515\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0319218 Vali Loss: 0.0176314 Test Loss: 0.0176865\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0333703\n",
      "\tspeed: 0.0664s/iter; left time: 336.7292s\n",
      "\titers: 200, epoch: 8 | loss: 0.0291487\n",
      "\tspeed: 0.0674s/iter; left time: 335.3098s\n",
      "\titers: 300, epoch: 8 | loss: 0.0305643\n",
      "\tspeed: 0.0715s/iter; left time: 348.5304s\n",
      "Epoch: 8 cost time: 27.55591368675232\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0312550 Vali Loss: 0.0177799 Test Loss: 0.0176158\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0271199\n",
      "\tspeed: 0.0684s/iter; left time: 320.0864s\n",
      "\titers: 200, epoch: 9 | loss: 0.0288455\n",
      "\tspeed: 0.0694s/iter; left time: 317.5399s\n",
      "\titers: 300, epoch: 9 | loss: 0.0292279\n",
      "\tspeed: 0.0711s/iter; left time: 318.4181s\n",
      "Epoch: 9 cost time: 27.9433434009552\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0307169 Vali Loss: 0.0174239 Test Loss: 0.0168520\n",
      "Validation loss decreased (0.017468 --> 0.017424).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0293012\n",
      "\tspeed: 0.0719s/iter; left time: 307.5678s\n",
      "\titers: 200, epoch: 10 | loss: 0.0302151\n",
      "\tspeed: 0.0772s/iter; left time: 322.4468s\n",
      "\titers: 300, epoch: 10 | loss: 0.0266944\n",
      "\tspeed: 0.0758s/iter; left time: 309.2918s\n",
      "Epoch: 10 cost time: 29.863743543624878\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.0299074 Vali Loss: 0.0172753 Test Loss: 0.0170742\n",
      "Validation loss decreased (0.017424 --> 0.017275).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0297608\n",
      "\tspeed: 0.0679s/iter; left time: 263.4991s\n",
      "\titers: 200, epoch: 11 | loss: 0.0262898\n",
      "\tspeed: 0.0719s/iter; left time: 271.8178s\n",
      "\titers: 300, epoch: 11 | loss: 0.0309628\n",
      "\tspeed: 0.0742s/iter; left time: 272.9626s\n",
      "Epoch: 11 cost time: 28.68311905860901\n",
      "Epoch: 11, Steps: 398 | Train Loss: 0.0296101 Vali Loss: 0.0174638 Test Loss: 0.0169815\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.0291419\n",
      "\tspeed: 0.0760s/iter; left time: 264.7290s\n",
      "\titers: 200, epoch: 12 | loss: 0.0282246\n",
      "\tspeed: 0.0736s/iter; left time: 249.1064s\n",
      "\titers: 300, epoch: 12 | loss: 0.0291059\n",
      "\tspeed: 0.0732s/iter; left time: 240.4207s\n",
      "Epoch: 12 cost time: 29.66591167449951\n",
      "Epoch: 12, Steps: 398 | Train Loss: 0.0293599 Vali Loss: 0.0172703 Test Loss: 0.0168532\n",
      "Validation loss decreased (0.017275 --> 0.017270).  Saving model ...\n",
      "\titers: 100, epoch: 13 | loss: 0.0300463\n",
      "\tspeed: 0.0723s/iter; left time: 222.9366s\n",
      "\titers: 200, epoch: 13 | loss: 0.0324103\n",
      "\tspeed: 0.0748s/iter; left time: 223.3624s\n",
      "\titers: 300, epoch: 13 | loss: 0.0284237\n",
      "\tspeed: 0.0733s/iter; left time: 211.5243s\n",
      "Epoch: 13 cost time: 29.286927223205566\n",
      "Epoch: 13, Steps: 398 | Train Loss: 0.0291360 Vali Loss: 0.0171736 Test Loss: 0.0169553\n",
      "Validation loss decreased (0.017270 --> 0.017174).  Saving model ...\n",
      "\titers: 100, epoch: 14 | loss: 0.0294829\n",
      "\tspeed: 0.0730s/iter; left time: 196.0571s\n",
      "\titers: 200, epoch: 14 | loss: 0.0286826\n",
      "\tspeed: 0.0742s/iter; left time: 191.9253s\n",
      "\titers: 300, epoch: 14 | loss: 0.0262843\n",
      "\tspeed: 0.0719s/iter; left time: 178.7901s\n",
      "Epoch: 14 cost time: 28.69400978088379\n",
      "Epoch: 14, Steps: 398 | Train Loss: 0.0289284 Vali Loss: 0.0172642 Test Loss: 0.0168365\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 15 | loss: 0.0267118\n",
      "\tspeed: 0.0695s/iter; left time: 158.9794s\n",
      "\titers: 200, epoch: 15 | loss: 0.0286536\n",
      "\tspeed: 0.0704s/iter; left time: 154.1819s\n",
      "\titers: 300, epoch: 15 | loss: 0.0299221\n",
      "\tspeed: 0.0727s/iter; left time: 151.9487s\n",
      "Epoch: 15 cost time: 28.220099687576294\n",
      "Epoch: 15, Steps: 398 | Train Loss: 0.0286306 Vali Loss: 0.0170456 Test Loss: 0.0166737\n",
      "Validation loss decreased (0.017174 --> 0.017046).  Saving model ...\n",
      "\titers: 100, epoch: 16 | loss: 0.0335929\n",
      "\tspeed: 0.0698s/iter; left time: 131.9956s\n",
      "\titers: 200, epoch: 16 | loss: 0.0289270\n",
      "\tspeed: 0.0734s/iter; left time: 131.4959s\n",
      "\titers: 300, epoch: 16 | loss: 0.0271652\n",
      "\tspeed: 0.0746s/iter; left time: 126.2042s\n",
      "Epoch: 16 cost time: 29.158501148223877\n",
      "Epoch: 16, Steps: 398 | Train Loss: 0.0287828 Vali Loss: 0.0170615 Test Loss: 0.0167731\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 17 | loss: 0.0283886\n",
      "\tspeed: 0.0732s/iter; left time: 109.3106s\n",
      "\titers: 200, epoch: 17 | loss: 0.0299501\n",
      "\tspeed: 0.0733s/iter; left time: 102.1177s\n",
      "\titers: 300, epoch: 17 | loss: 0.0255376\n",
      "\tspeed: 0.0723s/iter; left time: 93.4213s\n",
      "Epoch: 17 cost time: 29.01862621307373\n",
      "Epoch: 17, Steps: 398 | Train Loss: 0.0284489 Vali Loss: 0.0172965 Test Loss: 0.0168908\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 18 | loss: 0.0300808\n",
      "\tspeed: 0.0651s/iter; left time: 71.2455s\n",
      "\titers: 200, epoch: 18 | loss: 0.0280825\n",
      "\tspeed: 0.0712s/iter; left time: 70.8671s\n",
      "\titers: 300, epoch: 18 | loss: 0.0325823\n",
      "\tspeed: 0.0702s/iter; left time: 62.8044s\n",
      "Epoch: 18 cost time: 27.872585773468018\n",
      "Epoch: 18, Steps: 398 | Train Loss: 0.0282486 Vali Loss: 0.0170195 Test Loss: 0.0166878\n",
      "Validation loss decreased (0.017046 --> 0.017019).  Saving model ...\n",
      "\titers: 100, epoch: 19 | loss: 0.0262282\n",
      "\tspeed: 0.0743s/iter; left time: 51.7753s\n",
      "\titers: 200, epoch: 19 | loss: 0.0293252\n",
      "\tspeed: 0.0761s/iter; left time: 45.4444s\n",
      "\titers: 300, epoch: 19 | loss: 0.0302689\n",
      "\tspeed: 0.0771s/iter; left time: 38.2966s\n",
      "Epoch: 19 cost time: 30.340042114257812\n",
      "Epoch: 19, Steps: 398 | Train Loss: 0.0280675 Vali Loss: 0.0176232 Test Loss: 0.0171477\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 20 | loss: 0.0310445\n",
      "\tspeed: 0.0772s/iter; left time: 23.0840s\n",
      "\titers: 200, epoch: 20 | loss: 0.0244834\n",
      "\tspeed: 0.0771s/iter; left time: 15.3372s\n",
      "\titers: 300, epoch: 20 | loss: 0.0295111\n",
      "\tspeed: 0.0693s/iter; left time: 6.8580s\n",
      "Epoch: 20 cost time: 29.984609127044678\n",
      "Epoch: 20, Steps: 398 | Train Loss: 0.0279446 Vali Loss: 0.0169174 Test Loss: 0.0164427\n",
      "Validation loss decreased (0.017019 --> 0.016917).  Saving model ...\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.01644264906644821, mae:0.10230854153633118\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTHh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTHh1_il168_pl168_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.2117818\n",
      "\tspeed: 0.0754s/iter; left time: 586.8832s\n",
      "\titers: 200, epoch: 1 | loss: 0.1096819\n",
      "\tspeed: 0.0664s/iter; left time: 510.3691s\n",
      "\titers: 300, epoch: 1 | loss: 0.0783761\n",
      "\tspeed: 0.0672s/iter; left time: 509.5508s\n",
      "Epoch: 1 cost time: 27.08069634437561\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.2587114 Vali Loss: 0.0450551 Test Loss: 0.0433791\n",
      "Validation loss decreased (inf --> 0.045055).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0601102\n",
      "\tspeed: 0.0727s/iter; left time: 537.3946s\n",
      "\titers: 200, epoch: 2 | loss: 0.0549229\n",
      "\tspeed: 0.0698s/iter; left time: 508.8537s\n",
      "\titers: 300, epoch: 2 | loss: 0.0539542\n",
      "\tspeed: 0.0712s/iter; left time: 511.3703s\n",
      "Epoch: 2 cost time: 28.49619746208191\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0603760 Vali Loss: 0.0218948 Test Loss: 0.0234001\n",
      "Validation loss decreased (0.045055 --> 0.021895).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0417998\n",
      "\tspeed: 0.0783s/iter; left time: 547.8575s\n",
      "\titers: 200, epoch: 3 | loss: 0.0450436\n",
      "\tspeed: 0.0869s/iter; left time: 599.3056s\n",
      "\titers: 300, epoch: 3 | loss: 0.0402743\n",
      "\tspeed: 0.0798s/iter; left time: 541.8715s\n",
      "Epoch: 3 cost time: 32.07178568840027\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0452645 Vali Loss: 0.0219086 Test Loss: 0.0221650\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.0411803\n",
      "\tspeed: 0.0749s/iter; left time: 494.0826s\n",
      "\titers: 200, epoch: 4 | loss: 0.0412019\n",
      "\tspeed: 0.0773s/iter; left time: 502.4080s\n",
      "\titers: 300, epoch: 4 | loss: 0.0362356\n",
      "\tspeed: 0.0758s/iter; left time: 485.1513s\n",
      "Epoch: 4 cost time: 30.655054807662964\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0403623 Vali Loss: 0.0194693 Test Loss: 0.0204489\n",
      "Validation loss decreased (0.021895 --> 0.019469).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0358140\n",
      "\tspeed: 0.0805s/iter; left time: 499.4738s\n",
      "\titers: 200, epoch: 5 | loss: 0.0373529\n",
      "\tspeed: 0.0772s/iter; left time: 471.5727s\n",
      "\titers: 300, epoch: 5 | loss: 0.0352457\n",
      "\tspeed: 0.0766s/iter; left time: 460.1902s\n",
      "Epoch: 5 cost time: 30.50171399116516\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0365233 Vali Loss: 0.0181764 Test Loss: 0.0198792\n",
      "Validation loss decreased (0.019469 --> 0.018176).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0331372\n",
      "\tspeed: 0.0729s/iter; left time: 423.7000s\n",
      "\titers: 200, epoch: 6 | loss: 0.0324851\n",
      "\tspeed: 0.0763s/iter; left time: 435.6702s\n",
      "\titers: 300, epoch: 6 | loss: 0.0342127\n",
      "\tspeed: 0.0793s/iter; left time: 444.7232s\n",
      "Epoch: 6 cost time: 30.19671130180359\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0351276 Vali Loss: 0.0174539 Test Loss: 0.0186144\n",
      "Validation loss decreased (0.018176 --> 0.017454).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0339684\n",
      "\tspeed: 0.0809s/iter; left time: 438.4962s\n",
      "\titers: 200, epoch: 7 | loss: 0.0337617\n",
      "\tspeed: 0.0809s/iter; left time: 430.2559s\n",
      "\titers: 300, epoch: 7 | loss: 0.0307419\n",
      "\tspeed: 0.0734s/iter; left time: 383.1635s\n",
      "Epoch: 7 cost time: 29.88001036643982\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0331671 Vali Loss: 0.0174477 Test Loss: 0.0186590\n",
      "Validation loss decreased (0.017454 --> 0.017448).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0315027\n",
      "\tspeed: 0.0715s/iter; left time: 359.3679s\n",
      "\titers: 200, epoch: 8 | loss: 0.0324665\n",
      "\tspeed: 0.0723s/iter; left time: 355.9408s\n",
      "\titers: 300, epoch: 8 | loss: 0.0321665\n",
      "\tspeed: 0.0753s/iter; left time: 362.9502s\n",
      "Epoch: 8 cost time: 28.867762088775635\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0324891 Vali Loss: 0.0173416 Test Loss: 0.0182857\n",
      "Validation loss decreased (0.017448 --> 0.017342).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0321130\n",
      "\tspeed: 0.0736s/iter; left time: 340.7321s\n",
      "\titers: 200, epoch: 9 | loss: 0.0342330\n",
      "\tspeed: 0.0780s/iter; left time: 353.1158s\n",
      "\titers: 300, epoch: 9 | loss: 0.0307879\n",
      "\tspeed: 0.0736s/iter; left time: 326.1032s\n",
      "Epoch: 9 cost time: 29.193039894104004\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0317465 Vali Loss: 0.0169955 Test Loss: 0.0181066\n",
      "Validation loss decreased (0.017342 --> 0.016995).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0296537\n",
      "\tspeed: 0.0738s/iter; left time: 312.6558s\n",
      "\titers: 200, epoch: 10 | loss: 0.0312143\n",
      "\tspeed: 0.0716s/iter; left time: 296.0939s\n",
      "\titers: 300, epoch: 10 | loss: 0.0316095\n",
      "\tspeed: 0.0741s/iter; left time: 299.0920s\n",
      "Epoch: 10 cost time: 28.896623134613037\n",
      "Epoch: 10, Steps: 394 | Train Loss: 0.0313230 Vali Loss: 0.0169719 Test Loss: 0.0177540\n",
      "Validation loss decreased (0.016995 --> 0.016972).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0310926\n",
      "\tspeed: 0.0736s/iter; left time: 282.5146s\n",
      "\titers: 200, epoch: 11 | loss: 0.0325346\n",
      "\tspeed: 0.0721s/iter; left time: 269.6433s\n",
      "\titers: 300, epoch: 11 | loss: 0.0281345\n",
      "\tspeed: 0.0759s/iter; left time: 276.2920s\n",
      "Epoch: 11 cost time: 29.029005765914917\n",
      "Epoch: 11, Steps: 394 | Train Loss: 0.0307699 Vali Loss: 0.0168401 Test Loss: 0.0179719\n",
      "Validation loss decreased (0.016972 --> 0.016840).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.0322688\n",
      "\tspeed: 0.0703s/iter; left time: 242.4541s\n",
      "\titers: 200, epoch: 12 | loss: 0.0306078\n",
      "\tspeed: 0.0727s/iter; left time: 243.1795s\n",
      "\titers: 300, epoch: 12 | loss: 0.0306154\n",
      "\tspeed: 0.0761s/iter; left time: 247.1939s\n",
      "Epoch: 12 cost time: 29.056038856506348\n",
      "Epoch: 12, Steps: 394 | Train Loss: 0.0305665 Vali Loss: 0.0169005 Test Loss: 0.0176909\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.0296988\n",
      "\tspeed: 0.0801s/iter; left time: 244.5293s\n",
      "\titers: 200, epoch: 13 | loss: 0.0292794\n",
      "\tspeed: 0.0813s/iter; left time: 239.9647s\n",
      "\titers: 300, epoch: 13 | loss: 0.0282683\n",
      "\tspeed: 0.0767s/iter; left time: 218.7787s\n",
      "Epoch: 13 cost time: 30.198663473129272\n",
      "Epoch: 13, Steps: 394 | Train Loss: 0.0303254 Vali Loss: 0.0168321 Test Loss: 0.0177243\n",
      "Validation loss decreased (0.016840 --> 0.016832).  Saving model ...\n",
      "\titers: 100, epoch: 14 | loss: 0.0316094\n",
      "\tspeed: 0.0706s/iter; left time: 187.8305s\n",
      "\titers: 200, epoch: 14 | loss: 0.0294327\n",
      "\tspeed: 0.0719s/iter; left time: 183.8934s\n",
      "\titers: 300, epoch: 14 | loss: 0.0320976\n",
      "\tspeed: 0.0736s/iter; left time: 180.9304s\n",
      "Epoch: 14 cost time: 28.55256223678589\n",
      "Epoch: 14, Steps: 394 | Train Loss: 0.0301551 Vali Loss: 0.0170088 Test Loss: 0.0178902\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 15 | loss: 0.0289818\n",
      "\tspeed: 0.0729s/iter; left time: 165.0624s\n",
      "\titers: 200, epoch: 15 | loss: 0.0309098\n",
      "\tspeed: 0.0796s/iter; left time: 172.4159s\n",
      "\titers: 300, epoch: 15 | loss: 0.0286927\n",
      "\tspeed: 0.0777s/iter; left time: 160.4562s\n",
      "Epoch: 15 cost time: 30.015992879867554\n",
      "Epoch: 15, Steps: 394 | Train Loss: 0.0298904 Vali Loss: 0.0173623 Test Loss: 0.0175738\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 16 | loss: 0.0289145\n",
      "\tspeed: 0.0726s/iter; left time: 135.7477s\n",
      "\titers: 200, epoch: 16 | loss: 0.0292054\n",
      "\tspeed: 0.0707s/iter; left time: 125.2764s\n",
      "\titers: 300, epoch: 16 | loss: 0.0326464\n",
      "\tspeed: 0.0715s/iter; left time: 119.5134s\n",
      "Epoch: 16 cost time: 28.50711989402771\n",
      "Epoch: 16, Steps: 394 | Train Loss: 0.0298245 Vali Loss: 0.0166631 Test Loss: 0.0177396\n",
      "Validation loss decreased (0.016832 --> 0.016663).  Saving model ...\n",
      "\titers: 100, epoch: 17 | loss: 0.0295151\n",
      "\tspeed: 0.0730s/iter; left time: 107.8422s\n",
      "\titers: 200, epoch: 17 | loss: 0.0278350\n",
      "\tspeed: 0.0710s/iter; left time: 97.7274s\n",
      "\titers: 300, epoch: 17 | loss: 0.0333125\n",
      "\tspeed: 0.0728s/iter; left time: 92.9330s\n",
      "Epoch: 17 cost time: 28.30724310874939\n",
      "Epoch: 17, Steps: 394 | Train Loss: 0.0295472 Vali Loss: 0.0165387 Test Loss: 0.0173428\n",
      "Validation loss decreased (0.016663 --> 0.016539).  Saving model ...\n",
      "\titers: 100, epoch: 18 | loss: 0.0307739\n",
      "\tspeed: 0.0629s/iter; left time: 68.1543s\n",
      "\titers: 200, epoch: 18 | loss: 0.0302896\n",
      "\tspeed: 0.0646s/iter; left time: 63.5126s\n",
      "\titers: 300, epoch: 18 | loss: 0.0280761\n",
      "\tspeed: 0.0665s/iter; left time: 58.7120s\n",
      "Epoch: 18 cost time: 26.123437643051147\n",
      "Epoch: 18, Steps: 394 | Train Loss: 0.0293219 Vali Loss: 0.0166911 Test Loss: 0.0176104\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 19 | loss: 0.0288501\n",
      "\tspeed: 0.0739s/iter; left time: 50.8976s\n",
      "\titers: 200, epoch: 19 | loss: 0.0285144\n",
      "\tspeed: 0.0714s/iter; left time: 42.0314s\n",
      "\titers: 300, epoch: 19 | loss: 0.0273117\n",
      "\tspeed: 0.0693s/iter; left time: 33.9025s\n",
      "Epoch: 19 cost time: 27.47500467300415\n",
      "Epoch: 19, Steps: 394 | Train Loss: 0.0291340 Vali Loss: 0.0166548 Test Loss: 0.0174644\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 20 | loss: 0.0304441\n",
      "\tspeed: 0.0722s/iter; left time: 21.3015s\n",
      "\titers: 200, epoch: 20 | loss: 0.0282631\n",
      "\tspeed: 0.0695s/iter; left time: 13.5447s\n",
      "\titers: 300, epoch: 20 | loss: 0.0277566\n",
      "\tspeed: 0.0719s/iter; left time: 6.8269s\n",
      "Epoch: 20 cost time: 28.218973398208618\n",
      "Epoch: 20, Steps: 394 | Train Loss: 0.0289658 Vali Loss: 0.0169078 Test Loss: 0.0173883\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.017342790961265564, mae:0.10515831410884857\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTHh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTHh1_il168_pl336_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.2986894\n",
      "\tspeed: 0.0850s/iter; left time: 652.8352s\n",
      "\titers: 200, epoch: 1 | loss: 0.1133294\n",
      "\tspeed: 0.0738s/iter; left time: 559.1795s\n",
      "\titers: 300, epoch: 1 | loss: 0.0839279\n",
      "\tspeed: 0.0740s/iter; left time: 553.5894s\n",
      "Epoch: 1 cost time: 29.581531763076782\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.2904716 Vali Loss: 0.0250509 Test Loss: 0.0254743\n",
      "Validation loss decreased (inf --> 0.025051).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0602538\n",
      "\tspeed: 0.0721s/iter; left time: 525.9073s\n",
      "\titers: 200, epoch: 2 | loss: 0.0533339\n",
      "\tspeed: 0.0740s/iter; left time: 531.9308s\n",
      "\titers: 300, epoch: 2 | loss: 0.0518300\n",
      "\tspeed: 0.0739s/iter; left time: 524.2273s\n",
      "Epoch: 2 cost time: 28.538797855377197\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0578876 Vali Loss: 0.0202415 Test Loss: 0.0210236\n",
      "Validation loss decreased (0.025051 --> 0.020242).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0455632\n",
      "\tspeed: 0.0785s/iter; left time: 542.1410s\n",
      "\titers: 200, epoch: 3 | loss: 0.0453180\n",
      "\tspeed: 0.0752s/iter; left time: 511.8746s\n",
      "\titers: 300, epoch: 3 | loss: 0.0437837\n",
      "\tspeed: 0.0697s/iter; left time: 467.1381s\n",
      "Epoch: 3 cost time: 28.967177629470825\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0448848 Vali Loss: 0.0181905 Test Loss: 0.0193695\n",
      "Validation loss decreased (0.020242 --> 0.018191).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0420834\n",
      "\tspeed: 0.0686s/iter; left time: 446.9899s\n",
      "\titers: 200, epoch: 4 | loss: 0.0389768\n",
      "\tspeed: 0.0731s/iter; left time: 469.1134s\n",
      "\titers: 300, epoch: 4 | loss: 0.0390975\n",
      "\tspeed: 0.0743s/iter; left time: 468.8537s\n",
      "Epoch: 4 cost time: 28.25726842880249\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0399125 Vali Loss: 0.0183995 Test Loss: 0.0195097\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0362399\n",
      "\tspeed: 0.0768s/iter; left time: 470.4920s\n",
      "\titers: 200, epoch: 5 | loss: 0.0359694\n",
      "\tspeed: 0.0757s/iter; left time: 456.3269s\n",
      "\titers: 300, epoch: 5 | loss: 0.0344221\n",
      "\tspeed: 0.0760s/iter; left time: 450.3410s\n",
      "Epoch: 5 cost time: 29.88062310218811\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0361414 Vali Loss: 0.0172720 Test Loss: 0.0180966\n",
      "Validation loss decreased (0.018191 --> 0.017272).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0345812\n",
      "\tspeed: 0.0736s/iter; left time: 422.2245s\n",
      "\titers: 200, epoch: 6 | loss: 0.0347407\n",
      "\tspeed: 0.0711s/iter; left time: 400.7588s\n",
      "\titers: 300, epoch: 6 | loss: 0.0347952\n",
      "\tspeed: 0.0778s/iter; left time: 430.6745s\n",
      "Epoch: 6 cost time: 28.999374389648438\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0345546 Vali Loss: 0.0179277 Test Loss: 0.0184803\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0322827\n",
      "\tspeed: 0.0763s/iter; left time: 407.7538s\n",
      "\titers: 200, epoch: 7 | loss: 0.0308043\n",
      "\tspeed: 0.0764s/iter; left time: 401.0393s\n",
      "\titers: 300, epoch: 7 | loss: 0.0305426\n",
      "\tspeed: 0.0774s/iter; left time: 398.6107s\n",
      "Epoch: 7 cost time: 29.88751792907715\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.0329037 Vali Loss: 0.0168494 Test Loss: 0.0187859\n",
      "Validation loss decreased (0.017272 --> 0.016849).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0323036\n",
      "\tspeed: 0.0784s/iter; left time: 388.7540s\n",
      "\titers: 200, epoch: 8 | loss: 0.0317894\n",
      "\tspeed: 0.0758s/iter; left time: 368.0365s\n",
      "\titers: 300, epoch: 8 | loss: 0.0332188\n",
      "\tspeed: 0.0729s/iter; left time: 346.6768s\n",
      "Epoch: 8 cost time: 29.24373483657837\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.0321437 Vali Loss: 0.0168707 Test Loss: 0.0188561\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0307089\n",
      "\tspeed: 0.0751s/iter; left time: 343.2719s\n",
      "\titers: 200, epoch: 9 | loss: 0.0299144\n",
      "\tspeed: 0.0787s/iter; left time: 351.6522s\n",
      "\titers: 300, epoch: 9 | loss: 0.0328722\n",
      "\tspeed: 0.0772s/iter; left time: 337.4266s\n",
      "Epoch: 9 cost time: 30.232221841812134\n",
      "Epoch: 9, Steps: 389 | Train Loss: 0.0312670 Vali Loss: 0.0169373 Test Loss: 0.0177095\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.0320396\n",
      "\tspeed: 0.0693s/iter; left time: 289.8155s\n",
      "\titers: 200, epoch: 10 | loss: 0.0326630\n",
      "\tspeed: 0.0710s/iter; left time: 289.6744s\n",
      "\titers: 300, epoch: 10 | loss: 0.0303982\n",
      "\tspeed: 0.0762s/iter; left time: 303.4656s\n",
      "Epoch: 10 cost time: 28.23157835006714\n",
      "Epoch: 10, Steps: 389 | Train Loss: 0.0309148 Vali Loss: 0.0162254 Test Loss: 0.0180590\n",
      "Validation loss decreased (0.016849 --> 0.016225).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0301329\n",
      "\tspeed: 0.0744s/iter; left time: 282.1958s\n",
      "\titers: 200, epoch: 11 | loss: 0.0300003\n",
      "\tspeed: 0.0768s/iter; left time: 283.4879s\n",
      "\titers: 300, epoch: 11 | loss: 0.0301073\n",
      "\tspeed: 0.0794s/iter; left time: 285.1749s\n",
      "Epoch: 11 cost time: 30.048160552978516\n",
      "Epoch: 11, Steps: 389 | Train Loss: 0.0304712 Vali Loss: 0.0164249 Test Loss: 0.0178700\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.0305357\n",
      "\tspeed: 0.0785s/iter; left time: 267.0111s\n",
      "\titers: 200, epoch: 12 | loss: 0.0309167\n",
      "\tspeed: 0.0777s/iter; left time: 256.4190s\n",
      "\titers: 300, epoch: 12 | loss: 0.0305239\n",
      "\tspeed: 0.0772s/iter; left time: 247.3236s\n",
      "Epoch: 12 cost time: 30.16099262237549\n",
      "Epoch: 12, Steps: 389 | Train Loss: 0.0302290 Vali Loss: 0.0164081 Test Loss: 0.0177034\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.0303352\n",
      "\tspeed: 0.0741s/iter; left time: 223.1511s\n",
      "\titers: 200, epoch: 13 | loss: 0.0289882\n",
      "\tspeed: 0.0774s/iter; left time: 225.5270s\n",
      "\titers: 300, epoch: 13 | loss: 0.0281268\n",
      "\tspeed: 0.0775s/iter; left time: 217.9518s\n",
      "Epoch: 13 cost time: 29.872440576553345\n",
      "Epoch: 13, Steps: 389 | Train Loss: 0.0299481 Vali Loss: 0.0161751 Test Loss: 0.0177470\n",
      "Validation loss decreased (0.016225 --> 0.016175).  Saving model ...\n",
      "\titers: 100, epoch: 14 | loss: 0.0312044\n",
      "\tspeed: 0.0723s/iter; left time: 189.6427s\n",
      "\titers: 200, epoch: 14 | loss: 0.0291596\n",
      "\tspeed: 0.0723s/iter; left time: 182.3844s\n",
      "\titers: 300, epoch: 14 | loss: 0.0290448\n",
      "\tspeed: 0.0755s/iter; left time: 183.0276s\n",
      "Epoch: 14 cost time: 29.101978302001953\n",
      "Epoch: 14, Steps: 389 | Train Loss: 0.0297479 Vali Loss: 0.0163786 Test Loss: 0.0174338\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 15 | loss: 0.0299752\n",
      "\tspeed: 0.0757s/iter; left time: 169.0857s\n",
      "\titers: 200, epoch: 15 | loss: 0.0281541\n",
      "\tspeed: 0.0724s/iter; left time: 154.6346s\n",
      "\titers: 300, epoch: 15 | loss: 0.0300299\n",
      "\tspeed: 0.0766s/iter; left time: 155.8195s\n",
      "Epoch: 15 cost time: 29.21464991569519\n",
      "Epoch: 15, Steps: 389 | Train Loss: 0.0294965 Vali Loss: 0.0163936 Test Loss: 0.0180949\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 16 | loss: 0.0296245\n",
      "\tspeed: 0.0731s/iter; left time: 134.8543s\n",
      "\titers: 200, epoch: 16 | loss: 0.0294275\n",
      "\tspeed: 0.0718s/iter; left time: 125.3501s\n",
      "\titers: 300, epoch: 16 | loss: 0.0276554\n",
      "\tspeed: 0.0759s/iter; left time: 124.8932s\n",
      "Epoch: 16 cost time: 28.78096079826355\n",
      "Epoch: 16, Steps: 389 | Train Loss: 0.0292550 Vali Loss: 0.0162323 Test Loss: 0.0175024\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.017747005447745323, mae:0.10646801441907883\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTHh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTHh1_il168_pl720_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.3846466\n",
      "\tspeed: 0.0807s/iter; left time: 600.3680s\n",
      "\titers: 200, epoch: 1 | loss: 0.1073221\n",
      "\tspeed: 0.0809s/iter; left time: 593.5411s\n",
      "\titers: 300, epoch: 1 | loss: 0.0834502\n",
      "\tspeed: 0.0811s/iter; left time: 587.2925s\n",
      "Epoch: 1 cost time: 30.51243233680725\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.3122610 Vali Loss: 0.0238339 Test Loss: 0.0263485\n",
      "Validation loss decreased (inf --> 0.023834).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0594663\n",
      "\tspeed: 0.0729s/iter; left time: 514.8072s\n",
      "\titers: 200, epoch: 2 | loss: 0.0529925\n",
      "\tspeed: 0.0750s/iter; left time: 522.0010s\n",
      "\titers: 300, epoch: 2 | loss: 0.0474293\n",
      "\tspeed: 0.0777s/iter; left time: 533.3454s\n",
      "Epoch: 2 cost time: 28.49406671524048\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0555168 Vali Loss: 0.0271490 Test Loss: 0.0291263\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0419280\n",
      "\tspeed: 0.0772s/iter; left time: 516.2009s\n",
      "\titers: 200, epoch: 3 | loss: 0.0386278\n",
      "\tspeed: 0.0782s/iter; left time: 515.2259s\n",
      "\titers: 300, epoch: 3 | loss: 0.0404287\n",
      "\tspeed: 0.0813s/iter; left time: 527.5501s\n",
      "Epoch: 3 cost time: 30.1772301197052\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0404442 Vali Loss: 0.0192938 Test Loss: 0.0207192\n",
      "Validation loss decreased (0.023834 --> 0.019294).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0373022\n",
      "\tspeed: 0.0808s/iter; left time: 510.1561s\n",
      "\titers: 200, epoch: 4 | loss: 0.0357872\n",
      "\tspeed: 0.0775s/iter; left time: 480.9693s\n",
      "\titers: 300, epoch: 4 | loss: 0.0343487\n",
      "\tspeed: 0.0785s/iter; left time: 479.4460s\n",
      "Epoch: 4 cost time: 29.605422735214233\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0360991 Vali Loss: 0.0192342 Test Loss: 0.0195702\n",
      "Validation loss decreased (0.019294 --> 0.019234).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0333421\n",
      "\tspeed: 0.0778s/iter; left time: 461.4581s\n",
      "\titers: 200, epoch: 5 | loss: 0.0326479\n",
      "\tspeed: 0.0809s/iter; left time: 472.0101s\n",
      "\titers: 300, epoch: 5 | loss: 0.0327069\n",
      "\tspeed: 0.0820s/iter; left time: 470.0217s\n",
      "Epoch: 5 cost time: 30.371502161026\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0330485 Vali Loss: 0.0178868 Test Loss: 0.0187844\n",
      "Validation loss decreased (0.019234 --> 0.017887).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0325286\n",
      "\tspeed: 0.0793s/iter; left time: 440.8328s\n",
      "\titers: 200, epoch: 6 | loss: 0.0329030\n",
      "\tspeed: 0.0781s/iter; left time: 425.8908s\n",
      "\titers: 300, epoch: 6 | loss: 0.0292120\n",
      "\tspeed: 0.0782s/iter; left time: 419.0218s\n",
      "Epoch: 6 cost time: 29.574011087417603\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0315677 Vali Loss: 0.0181605 Test Loss: 0.0196654\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0314848\n",
      "\tspeed: 0.0791s/iter; left time: 409.4265s\n",
      "\titers: 200, epoch: 7 | loss: 0.0292166\n",
      "\tspeed: 0.0825s/iter; left time: 419.2376s\n",
      "\titers: 300, epoch: 7 | loss: 0.0310816\n",
      "\tspeed: 0.0826s/iter; left time: 411.0342s\n",
      "Epoch: 7 cost time: 30.751770973205566\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0303181 Vali Loss: 0.0169106 Test Loss: 0.0179043\n",
      "Validation loss decreased (0.017887 --> 0.016911).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0303852\n",
      "\tspeed: 0.0797s/iter; left time: 382.7456s\n",
      "\titers: 200, epoch: 8 | loss: 0.0294573\n",
      "\tspeed: 0.0774s/iter; left time: 363.8925s\n",
      "\titers: 300, epoch: 8 | loss: 0.0302906\n",
      "\tspeed: 0.0749s/iter; left time: 344.6590s\n",
      "Epoch: 8 cost time: 29.224583387374878\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.0297840 Vali Loss: 0.0173626 Test Loss: 0.0179485\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0314239\n",
      "\tspeed: 0.0770s/iter; left time: 340.8347s\n",
      "\titers: 200, epoch: 9 | loss: 0.0290799\n",
      "\tspeed: 0.0786s/iter; left time: 339.8682s\n",
      "\titers: 300, epoch: 9 | loss: 0.0302525\n",
      "\tspeed: 0.0814s/iter; left time: 343.7524s\n",
      "Epoch: 9 cost time: 30.02639126777649\n",
      "Epoch: 9, Steps: 377 | Train Loss: 0.0290611 Vali Loss: 0.0164908 Test Loss: 0.0172331\n",
      "Validation loss decreased (0.016911 --> 0.016491).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0284727\n",
      "\tspeed: 0.0794s/iter; left time: 321.2968s\n",
      "\titers: 200, epoch: 10 | loss: 0.0279728\n",
      "\tspeed: 0.0812s/iter; left time: 320.7073s\n",
      "\titers: 300, epoch: 10 | loss: 0.0291081\n",
      "\tspeed: 0.0793s/iter; left time: 305.0895s\n",
      "Epoch: 10 cost time: 30.164292097091675\n",
      "Epoch: 10, Steps: 377 | Train Loss: 0.0287420 Vali Loss: 0.0165509 Test Loss: 0.0174911\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0284236\n",
      "\tspeed: 0.0770s/iter; left time: 282.6833s\n",
      "\titers: 200, epoch: 11 | loss: 0.0276285\n",
      "\tspeed: 0.0811s/iter; left time: 289.4382s\n",
      "\titers: 300, epoch: 11 | loss: 0.0303054\n",
      "\tspeed: 0.0804s/iter; left time: 279.0808s\n",
      "Epoch: 11 cost time: 30.072187185287476\n",
      "Epoch: 11, Steps: 377 | Train Loss: 0.0284160 Vali Loss: 0.0165162 Test Loss: 0.0174609\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.0282878\n",
      "\tspeed: 0.0776s/iter; left time: 255.7690s\n",
      "\titers: 200, epoch: 12 | loss: 0.0281564\n",
      "\tspeed: 0.0777s/iter; left time: 248.2129s\n",
      "\titers: 300, epoch: 12 | loss: 0.0292795\n",
      "\tspeed: 0.0777s/iter; left time: 240.2977s\n",
      "Epoch: 12 cost time: 29.37538743019104\n",
      "Epoch: 12, Steps: 377 | Train Loss: 0.0281922 Vali Loss: 0.0165622 Test Loss: 0.0172294\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.017233099788427353, mae:0.10472988337278366\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_il168_pl24_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.1176126\n",
      "\tspeed: 0.0754s/iter; left time: 594.5472s\n",
      "\titers: 200, epoch: 1 | loss: 0.0619905\n",
      "\tspeed: 0.0730s/iter; left time: 568.3291s\n",
      "\titers: 300, epoch: 1 | loss: 0.0387343\n",
      "\tspeed: 0.0767s/iter; left time: 589.3545s\n",
      "Epoch: 1 cost time: 30.362586975097656\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.0897954 Vali Loss: 0.0198644 Test Loss: 0.0600213\n",
      "Validation loss decreased (inf --> 0.019864).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0248918\n",
      "\tspeed: 0.0721s/iter; left time: 539.1428s\n",
      "\titers: 200, epoch: 2 | loss: 0.0201516\n",
      "\tspeed: 0.0721s/iter; left time: 532.2943s\n",
      "\titers: 300, epoch: 2 | loss: 0.0182170\n",
      "\tspeed: 0.0742s/iter; left time: 540.1106s\n",
      "Epoch: 2 cost time: 29.203381061553955\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0224233 Vali Loss: 0.0117419 Test Loss: 0.0482056\n",
      "Validation loss decreased (0.019864 --> 0.011742).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0150358\n",
      "\tspeed: 0.0741s/iter; left time: 524.4996s\n",
      "\titers: 200, epoch: 3 | loss: 0.0166294\n",
      "\tspeed: 0.0720s/iter; left time: 502.8532s\n",
      "\titers: 300, epoch: 3 | loss: 0.0149394\n",
      "\tspeed: 0.0748s/iter; left time: 515.0290s\n",
      "Epoch: 3 cost time: 29.557448387145996\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0141449 Vali Loss: 0.0097235 Test Loss: 0.0412148\n",
      "Validation loss decreased (0.011742 --> 0.009724).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0120547\n",
      "\tspeed: 0.0744s/iter; left time: 497.0371s\n",
      "\titers: 200, epoch: 4 | loss: 0.0162132\n",
      "\tspeed: 0.0746s/iter; left time: 491.3158s\n",
      "\titers: 300, epoch: 4 | loss: 0.0099693\n",
      "\tspeed: 0.0761s/iter; left time: 493.5055s\n",
      "Epoch: 4 cost time: 30.090157747268677\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0119604 Vali Loss: 0.0064699 Test Loss: 0.0256038\n",
      "Validation loss decreased (0.009724 --> 0.006470).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0097120\n",
      "\tspeed: 0.0774s/iter; left time: 486.5543s\n",
      "\titers: 200, epoch: 5 | loss: 0.0101477\n",
      "\tspeed: 0.0677s/iter; left time: 418.7085s\n",
      "\titers: 300, epoch: 5 | loss: 0.0082934\n",
      "\tspeed: 0.0703s/iter; left time: 427.6983s\n",
      "Epoch: 5 cost time: 29.02220344543457\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0099618 Vali Loss: 0.0082581 Test Loss: 0.0354250\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0084071\n",
      "\tspeed: 0.0701s/iter; left time: 412.8465s\n",
      "\titers: 200, epoch: 6 | loss: 0.0077310\n",
      "\tspeed: 0.0712s/iter; left time: 411.6852s\n",
      "\titers: 300, epoch: 6 | loss: 0.0108692\n",
      "\tspeed: 0.0674s/iter; left time: 383.3376s\n",
      "Epoch: 6 cost time: 27.912567853927612\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0091906 Vali Loss: 0.0065009 Test Loss: 0.0271833\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0098976\n",
      "\tspeed: 0.0727s/iter; left time: 398.6676s\n",
      "\titers: 200, epoch: 7 | loss: 0.0081012\n",
      "\tspeed: 0.0721s/iter; left time: 388.5836s\n",
      "\titers: 300, epoch: 7 | loss: 0.0084774\n",
      "\tspeed: 0.0747s/iter; left time: 394.6928s\n",
      "Epoch: 7 cost time: 29.46854853630066\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0084740 Vali Loss: 0.0053648 Test Loss: 0.0243647\n",
      "Validation loss decreased (0.006470 --> 0.005365).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0082682\n",
      "\tspeed: 0.0735s/iter; left time: 374.1645s\n",
      "\titers: 200, epoch: 8 | loss: 0.0094058\n",
      "\tspeed: 0.0765s/iter; left time: 381.7381s\n",
      "\titers: 300, epoch: 8 | loss: 0.0088881\n",
      "\tspeed: 0.0743s/iter; left time: 363.2583s\n",
      "Epoch: 8 cost time: 29.373791217803955\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0081614 Vali Loss: 0.0045299 Test Loss: 0.0199218\n",
      "Validation loss decreased (0.005365 --> 0.004530).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0068939\n",
      "\tspeed: 0.0709s/iter; left time: 332.3804s\n",
      "\titers: 200, epoch: 9 | loss: 0.0091359\n",
      "\tspeed: 0.0738s/iter; left time: 338.4724s\n",
      "\titers: 300, epoch: 9 | loss: 0.0070681\n",
      "\tspeed: 0.0747s/iter; left time: 335.2336s\n",
      "Epoch: 9 cost time: 29.404968976974487\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0076774 Vali Loss: 0.0042719 Test Loss: 0.0176504\n",
      "Validation loss decreased (0.004530 --> 0.004272).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0070036\n",
      "\tspeed: 0.0762s/iter; left time: 326.7341s\n",
      "\titers: 200, epoch: 10 | loss: 0.0074357\n",
      "\tspeed: 0.0740s/iter; left time: 309.9829s\n",
      "\titers: 300, epoch: 10 | loss: 0.0074593\n",
      "\tspeed: 0.0719s/iter; left time: 294.2124s\n",
      "Epoch: 10 cost time: 28.999688386917114\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0075600 Vali Loss: 0.0045628 Test Loss: 0.0152340\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0071217\n",
      "\tspeed: 0.0715s/iter; left time: 278.0908s\n",
      "\titers: 200, epoch: 11 | loss: 0.0062140\n",
      "\tspeed: 0.0713s/iter; left time: 270.4471s\n",
      "\titers: 300, epoch: 11 | loss: 0.0093187\n",
      "\tspeed: 0.0743s/iter; left time: 274.3566s\n",
      "Epoch: 11 cost time: 29.434781551361084\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0072814 Vali Loss: 0.0043914 Test Loss: 0.0208240\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.0073250\n",
      "\tspeed: 0.0738s/iter; left time: 257.8540s\n",
      "\titers: 200, epoch: 12 | loss: 0.0064191\n",
      "\tspeed: 0.0734s/iter; left time: 249.1172s\n",
      "\titers: 300, epoch: 12 | loss: 0.0061739\n",
      "\tspeed: 0.0724s/iter; left time: 238.2272s\n",
      "Epoch: 12 cost time: 29.328155517578125\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0072097 Vali Loss: 0.0050302 Test Loss: 0.0239390\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.01765039935708046, mae:0.10391996800899506\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_il168_pl48_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.1197041\n",
      "\tspeed: 0.0732s/iter; left time: 575.6470s\n",
      "\titers: 200, epoch: 1 | loss: 0.0700769\n",
      "\tspeed: 0.0723s/iter; left time: 561.1986s\n",
      "\titers: 300, epoch: 1 | loss: 0.0465283\n",
      "\tspeed: 0.0711s/iter; left time: 544.5344s\n",
      "Epoch: 1 cost time: 29.229195594787598\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0981501 Vali Loss: 0.0507776 Test Loss: 0.0438259\n",
      "Validation loss decreased (inf --> 0.050778).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0306651\n",
      "\tspeed: 0.0746s/iter; left time: 556.9774s\n",
      "\titers: 200, epoch: 2 | loss: 0.0224269\n",
      "\tspeed: 0.0748s/iter; left time: 550.5142s\n",
      "\titers: 300, epoch: 2 | loss: 0.0235649\n",
      "\tspeed: 0.0744s/iter; left time: 540.0041s\n",
      "Epoch: 2 cost time: 29.945837020874023\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0262092 Vali Loss: 0.0128914 Test Loss: 0.0387143\n",
      "Validation loss decreased (0.050778 --> 0.012891).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0155342\n",
      "\tspeed: 0.0771s/iter; left time: 544.3993s\n",
      "\titers: 200, epoch: 3 | loss: 0.0166672\n",
      "\tspeed: 0.0712s/iter; left time: 496.0850s\n",
      "\titers: 300, epoch: 3 | loss: 0.0154257\n",
      "\tspeed: 0.0733s/iter; left time: 503.4624s\n",
      "Epoch: 3 cost time: 29.503596782684326\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0164069 Vali Loss: 0.0113294 Test Loss: 0.0375193\n",
      "Validation loss decreased (0.012891 --> 0.011329).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0142923\n",
      "\tspeed: 0.0729s/iter; left time: 485.6968s\n",
      "\titers: 200, epoch: 4 | loss: 0.0154599\n",
      "\tspeed: 0.0715s/iter; left time: 469.4836s\n",
      "\titers: 300, epoch: 4 | loss: 0.0126998\n",
      "\tspeed: 0.0670s/iter; left time: 433.0051s\n",
      "Epoch: 4 cost time: 27.432916164398193\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0139580 Vali Loss: 0.0107201 Test Loss: 0.0391744\n",
      "Validation loss decreased (0.011329 --> 0.010720).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0120666\n",
      "\tspeed: 0.0696s/iter; left time: 436.0492s\n",
      "\titers: 200, epoch: 5 | loss: 0.0104722\n",
      "\tspeed: 0.0700s/iter; left time: 431.6099s\n",
      "\titers: 300, epoch: 5 | loss: 0.0123846\n",
      "\tspeed: 0.0705s/iter; left time: 427.9551s\n",
      "Epoch: 5 cost time: 28.282661199569702\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0116835 Vali Loss: 0.0077064 Test Loss: 0.0194671\n",
      "Validation loss decreased (0.010720 --> 0.007706).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0113264\n",
      "\tspeed: 0.0756s/iter; left time: 443.9103s\n",
      "\titers: 200, epoch: 6 | loss: 0.0126287\n",
      "\tspeed: 0.0796s/iter; left time: 459.3395s\n",
      "\titers: 300, epoch: 6 | loss: 0.0105193\n",
      "\tspeed: 0.0751s/iter; left time: 426.1518s\n",
      "Epoch: 6 cost time: 30.16141176223755\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0110121 Vali Loss: 0.0063850 Test Loss: 0.0196683\n",
      "Validation loss decreased (0.007706 --> 0.006385).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0110679\n",
      "\tspeed: 0.0744s/iter; left time: 407.2557s\n",
      "\titers: 200, epoch: 7 | loss: 0.0102042\n",
      "\tspeed: 0.0743s/iter; left time: 399.2683s\n",
      "\titers: 300, epoch: 7 | loss: 0.0103150\n",
      "\tspeed: 0.0728s/iter; left time: 384.0957s\n",
      "Epoch: 7 cost time: 29.593939781188965\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0098712 Vali Loss: 0.0071316 Test Loss: 0.0162463\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0082720\n",
      "\tspeed: 0.0766s/iter; left time: 388.9331s\n",
      "\titers: 200, epoch: 8 | loss: 0.0105956\n",
      "\tspeed: 0.0768s/iter; left time: 382.3106s\n",
      "\titers: 300, epoch: 8 | loss: 0.0083451\n",
      "\tspeed: 0.0742s/iter; left time: 361.4981s\n",
      "Epoch: 8 cost time: 29.718714714050293\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0093926 Vali Loss: 0.0058710 Test Loss: 0.0207658\n",
      "Validation loss decreased (0.006385 --> 0.005871).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0095233\n",
      "\tspeed: 0.0688s/iter; left time: 321.7738s\n",
      "\titers: 200, epoch: 9 | loss: 0.0101941\n",
      "\tspeed: 0.0727s/iter; left time: 332.8361s\n",
      "\titers: 300, epoch: 9 | loss: 0.0075069\n",
      "\tspeed: 0.0723s/iter; left time: 323.5169s\n",
      "Epoch: 9 cost time: 28.771923303604126\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0090288 Vali Loss: 0.0053909 Test Loss: 0.0198848\n",
      "Validation loss decreased (0.005871 --> 0.005391).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0097119\n",
      "\tspeed: 0.0796s/iter; left time: 340.5364s\n",
      "\titers: 200, epoch: 10 | loss: 0.0103787\n",
      "\tspeed: 0.0778s/iter; left time: 325.1397s\n",
      "\titers: 300, epoch: 10 | loss: 0.0087596\n",
      "\tspeed: 0.0698s/iter; left time: 284.7563s\n",
      "Epoch: 10 cost time: 30.096296787261963\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.0088030 Vali Loss: 0.0053292 Test Loss: 0.0187640\n",
      "Validation loss decreased (0.005391 --> 0.005329).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0081509\n",
      "\tspeed: 0.0776s/iter; left time: 301.0323s\n",
      "\titers: 200, epoch: 11 | loss: 0.0074516\n",
      "\tspeed: 0.0752s/iter; left time: 284.3527s\n",
      "\titers: 300, epoch: 11 | loss: 0.0083908\n",
      "\tspeed: 0.0722s/iter; left time: 265.7489s\n",
      "Epoch: 11 cost time: 30.34198570251465\n",
      "Epoch: 11, Steps: 398 | Train Loss: 0.0085989 Vali Loss: 0.0056916 Test Loss: 0.0230551\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.0090958\n",
      "\tspeed: 0.0785s/iter; left time: 273.5010s\n",
      "\titers: 200, epoch: 12 | loss: 0.0078575\n",
      "\tspeed: 0.0766s/iter; left time: 259.0472s\n",
      "\titers: 300, epoch: 12 | loss: 0.0076841\n",
      "\tspeed: 0.0728s/iter; left time: 239.0598s\n",
      "Epoch: 12 cost time: 30.242746114730835\n",
      "Epoch: 12, Steps: 398 | Train Loss: 0.0083969 Vali Loss: 0.0050605 Test Loss: 0.0192127\n",
      "Validation loss decreased (0.005329 --> 0.005061).  Saving model ...\n",
      "\titers: 100, epoch: 13 | loss: 0.0085625\n",
      "\tspeed: 0.0712s/iter; left time: 219.7912s\n",
      "\titers: 200, epoch: 13 | loss: 0.0079802\n",
      "\tspeed: 0.0697s/iter; left time: 207.9419s\n",
      "\titers: 300, epoch: 13 | loss: 0.0094552\n",
      "\tspeed: 0.0710s/iter; left time: 204.8776s\n",
      "Epoch: 13 cost time: 28.62302255630493\n",
      "Epoch: 13, Steps: 398 | Train Loss: 0.0083667 Vali Loss: 0.0049195 Test Loss: 0.0162570\n",
      "Validation loss decreased (0.005061 --> 0.004920).  Saving model ...\n",
      "\titers: 100, epoch: 14 | loss: 0.0084110\n",
      "\tspeed: 0.0735s/iter; left time: 197.5489s\n",
      "\titers: 200, epoch: 14 | loss: 0.0098776\n",
      "\tspeed: 0.0721s/iter; left time: 186.5671s\n",
      "\titers: 300, epoch: 14 | loss: 0.0077348\n",
      "\tspeed: 0.0712s/iter; left time: 176.9756s\n",
      "Epoch: 14 cost time: 28.891422748565674\n",
      "Epoch: 14, Steps: 398 | Train Loss: 0.0082584 Vali Loss: 0.0053802 Test Loss: 0.0215414\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 15 | loss: 0.0082929\n",
      "\tspeed: 0.0717s/iter; left time: 164.2346s\n",
      "\titers: 200, epoch: 15 | loss: 0.0089309\n",
      "\tspeed: 0.0730s/iter; left time: 159.7358s\n",
      "\titers: 300, epoch: 15 | loss: 0.0071610\n",
      "\tspeed: 0.0712s/iter; left time: 148.7064s\n",
      "Epoch: 15 cost time: 28.979478120803833\n",
      "Epoch: 15, Steps: 398 | Train Loss: 0.0081274 Vali Loss: 0.0056368 Test Loss: 0.0222799\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 16 | loss: 0.0076111\n",
      "\tspeed: 0.0788s/iter; left time: 149.0504s\n",
      "\titers: 200, epoch: 16 | loss: 0.0084603\n",
      "\tspeed: 0.0759s/iter; left time: 136.0213s\n",
      "\titers: 300, epoch: 16 | loss: 0.0084986\n",
      "\tspeed: 0.0732s/iter; left time: 123.8021s\n",
      "Epoch: 16 cost time: 29.918282508850098\n",
      "Epoch: 16, Steps: 398 | Train Loss: 0.0080739 Vali Loss: 0.0053222 Test Loss: 0.0208879\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.01625696010887623, mae:0.1000460758805275\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_il168_pl168_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.1275591\n",
      "\tspeed: 0.0771s/iter; left time: 600.1023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1058484\n",
      "\tspeed: 0.0741s/iter; left time: 569.2222s\n",
      "\titers: 300, epoch: 1 | loss: 0.0576933\n",
      "\tspeed: 0.0735s/iter; left time: 557.4147s\n",
      "Epoch: 1 cost time: 29.70195722579956\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.1143476 Vali Loss: 0.0449808 Test Loss: 0.1393903\n",
      "Validation loss decreased (inf --> 0.044981).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0337306\n",
      "\tspeed: 0.0762s/iter; left time: 562.9573s\n",
      "\titers: 200, epoch: 2 | loss: 0.0289061\n",
      "\tspeed: 0.0763s/iter; left time: 555.9149s\n",
      "\titers: 300, epoch: 2 | loss: 0.0327998\n",
      "\tspeed: 0.0754s/iter; left time: 541.6390s\n",
      "Epoch: 2 cost time: 30.11699151992798\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0363320 Vali Loss: 0.0264348 Test Loss: 0.0743629\n",
      "Validation loss decreased (0.044981 --> 0.026435).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0268615\n",
      "\tspeed: 0.0780s/iter; left time: 545.1096s\n",
      "\titers: 200, epoch: 3 | loss: 0.0255199\n",
      "\tspeed: 0.0763s/iter; left time: 526.1041s\n",
      "\titers: 300, epoch: 3 | loss: 0.0290556\n",
      "\tspeed: 0.0718s/iter; left time: 487.8665s\n",
      "Epoch: 3 cost time: 29.39812159538269\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0272181 Vali Loss: 0.0244289 Test Loss: 0.0323203\n",
      "Validation loss decreased (0.026435 --> 0.024429).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0270680\n",
      "\tspeed: 0.0738s/iter; left time: 487.2890s\n",
      "\titers: 200, epoch: 4 | loss: 0.0350587\n",
      "\tspeed: 0.0717s/iter; left time: 465.8358s\n",
      "\titers: 300, epoch: 4 | loss: 0.0287624\n",
      "\tspeed: 0.0715s/iter; left time: 457.4565s\n",
      "Epoch: 4 cost time: 28.398346424102783\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0252955 Vali Loss: 0.0268926 Test Loss: 0.0919590\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0230248\n",
      "\tspeed: 0.0728s/iter; left time: 451.8058s\n",
      "\titers: 200, epoch: 5 | loss: 0.0230931\n",
      "\tspeed: 0.0729s/iter; left time: 445.0815s\n",
      "\titers: 300, epoch: 5 | loss: 0.0264101\n",
      "\tspeed: 0.0743s/iter; left time: 445.9351s\n",
      "Epoch: 5 cost time: 28.8934109210968\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0221753 Vali Loss: 0.0187192 Test Loss: 0.0579768\n",
      "Validation loss decreased (0.024429 --> 0.018719).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0280888\n",
      "\tspeed: 0.0772s/iter; left time: 448.6816s\n",
      "\titers: 200, epoch: 6 | loss: 0.0171176\n",
      "\tspeed: 0.0793s/iter; left time: 452.9205s\n",
      "\titers: 300, epoch: 6 | loss: 0.0169652\n",
      "\tspeed: 0.0759s/iter; left time: 425.7217s\n",
      "Epoch: 6 cost time: 30.100464344024658\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0211704 Vali Loss: 0.0175431 Test Loss: 0.0605220\n",
      "Validation loss decreased (0.018719 --> 0.017543).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0207464\n",
      "\tspeed: 0.0734s/iter; left time: 397.5548s\n",
      "\titers: 200, epoch: 7 | loss: 0.0187233\n",
      "\tspeed: 0.0719s/iter; left time: 382.0302s\n",
      "\titers: 300, epoch: 7 | loss: 0.0194875\n",
      "\tspeed: 0.0727s/iter; left time: 379.4910s\n",
      "Epoch: 7 cost time: 29.101242542266846\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0201159 Vali Loss: 0.0223854 Test Loss: 0.0806615\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0189995\n",
      "\tspeed: 0.0774s/iter; left time: 388.5867s\n",
      "\titers: 200, epoch: 8 | loss: 0.0225767\n",
      "\tspeed: 0.0812s/iter; left time: 399.7304s\n",
      "\titers: 300, epoch: 8 | loss: 0.0205470\n",
      "\tspeed: 0.0765s/iter; left time: 368.7917s\n",
      "Epoch: 8 cost time: 30.874006748199463\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0197039 Vali Loss: 0.0178897 Test Loss: 0.0642299\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0205802\n",
      "\tspeed: 0.0720s/iter; left time: 333.3663s\n",
      "\titers: 200, epoch: 9 | loss: 0.0194867\n",
      "\tspeed: 0.0724s/iter; left time: 327.8777s\n",
      "\titers: 300, epoch: 9 | loss: 0.0168951\n",
      "\tspeed: 0.0749s/iter; left time: 331.6047s\n",
      "Epoch: 9 cost time: 29.12768816947937\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0189909 Vali Loss: 0.0169324 Test Loss: 0.0614921\n",
      "Validation loss decreased (0.017543 --> 0.016932).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0174944\n",
      "\tspeed: 0.0745s/iter; left time: 315.5001s\n",
      "\titers: 200, epoch: 10 | loss: 0.0189596\n",
      "\tspeed: 0.0787s/iter; left time: 325.6162s\n",
      "\titers: 300, epoch: 10 | loss: 0.0200685\n",
      "\tspeed: 0.0783s/iter; left time: 315.8501s\n",
      "Epoch: 10 cost time: 30.141016721725464\n",
      "Epoch: 10, Steps: 394 | Train Loss: 0.0187512 Vali Loss: 0.0201326 Test Loss: 0.0706696\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0168941\n",
      "\tspeed: 0.0734s/iter; left time: 281.7769s\n",
      "\titers: 200, epoch: 11 | loss: 0.0157443\n",
      "\tspeed: 0.0747s/iter; left time: 279.2956s\n",
      "\titers: 300, epoch: 11 | loss: 0.0166062\n",
      "\tspeed: 0.0734s/iter; left time: 267.3955s\n",
      "Epoch: 11 cost time: 29.058077812194824\n",
      "Epoch: 11, Steps: 394 | Train Loss: 0.0183811 Vali Loss: 0.0209662 Test Loss: 0.0763867\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.0207703\n",
      "\tspeed: 0.0767s/iter; left time: 264.4504s\n",
      "\titers: 200, epoch: 12 | loss: 0.0159233\n",
      "\tspeed: 0.0747s/iter; left time: 250.1260s\n",
      "\titers: 300, epoch: 12 | loss: 0.0166218\n",
      "\tspeed: 0.0777s/iter; left time: 252.3494s\n",
      "Epoch: 12 cost time: 29.88577675819397\n",
      "Epoch: 12, Steps: 394 | Train Loss: 0.0183849 Vali Loss: 0.0199569 Test Loss: 0.0724221\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.06149214133620262, mae:0.20823781192302704\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_il168_pl336_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.1366402\n",
      "\tspeed: 0.0805s/iter; left time: 618.0912s\n",
      "\titers: 200, epoch: 1 | loss: 0.1178341\n",
      "\tspeed: 0.0735s/iter; left time: 557.3498s\n",
      "\titers: 300, epoch: 1 | loss: 0.1029047\n",
      "\tspeed: 0.0761s/iter; left time: 569.5530s\n",
      "Epoch: 1 cost time: 29.61690330505371\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1346445 Vali Loss: 0.0843201 Test Loss: 0.2543579\n",
      "Validation loss decreased (inf --> 0.084320).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0632442\n",
      "\tspeed: 0.0761s/iter; left time: 554.7729s\n",
      "\titers: 200, epoch: 2 | loss: 0.0580763\n",
      "\tspeed: 0.0729s/iter; left time: 524.6205s\n",
      "\titers: 300, epoch: 2 | loss: 0.0673871\n",
      "\tspeed: 0.0716s/iter; left time: 507.7945s\n",
      "Epoch: 2 cost time: 28.526081800460815\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0575269 Vali Loss: 0.0620637 Test Loss: 0.1730694\n",
      "Validation loss decreased (0.084320 --> 0.062064).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0440888\n",
      "\tspeed: 0.0771s/iter; left time: 531.8815s\n",
      "\titers: 200, epoch: 3 | loss: 0.0539361\n",
      "\tspeed: 0.0730s/iter; left time: 496.4222s\n",
      "\titers: 300, epoch: 3 | loss: 0.0370817\n",
      "\tspeed: 0.0750s/iter; left time: 502.4743s\n",
      "Epoch: 3 cost time: 29.19987988471985\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0460470 Vali Loss: 0.0491184 Test Loss: 0.1538200\n",
      "Validation loss decreased (0.062064 --> 0.049118).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0397523\n",
      "\tspeed: 0.0759s/iter; left time: 494.5688s\n",
      "\titers: 200, epoch: 4 | loss: 0.0385961\n",
      "\tspeed: 0.0781s/iter; left time: 500.6931s\n",
      "\titers: 300, epoch: 4 | loss: 0.0434962\n",
      "\tspeed: 0.0744s/iter; left time: 469.7025s\n",
      "Epoch: 4 cost time: 29.567604303359985\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0423380 Vali Loss: 0.0711897 Test Loss: 0.2313786\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0448205\n",
      "\tspeed: 0.0743s/iter; left time: 455.0329s\n",
      "\titers: 200, epoch: 5 | loss: 0.0327166\n",
      "\tspeed: 0.0725s/iter; left time: 436.9089s\n",
      "\titers: 300, epoch: 5 | loss: 0.0339790\n",
      "\tspeed: 0.0734s/iter; left time: 434.7600s\n",
      "Epoch: 5 cost time: 28.488932132720947\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0396034 Vali Loss: 0.0552960 Test Loss: 0.2034938\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0365788\n",
      "\tspeed: 0.0725s/iter; left time: 415.8056s\n",
      "\titers: 200, epoch: 6 | loss: 0.0441552\n",
      "\tspeed: 0.0782s/iter; left time: 440.8670s\n",
      "\titers: 300, epoch: 6 | loss: 0.0325345\n",
      "\tspeed: 0.0789s/iter; left time: 436.8225s\n",
      "Epoch: 6 cost time: 29.8295578956604\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0381748 Vali Loss: 0.0476648 Test Loss: 0.1766764\n",
      "Validation loss decreased (0.049118 --> 0.047665).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0430479\n",
      "\tspeed: 0.0754s/iter; left time: 403.0589s\n",
      "\titers: 200, epoch: 7 | loss: 0.0294096\n",
      "\tspeed: 0.0734s/iter; left time: 385.1749s\n",
      "\titers: 300, epoch: 7 | loss: 0.0378905\n",
      "\tspeed: 0.0752s/iter; left time: 386.8485s\n",
      "Epoch: 7 cost time: 28.858075857162476\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.0371605 Vali Loss: 0.0431797 Test Loss: 0.1652493\n",
      "Validation loss decreased (0.047665 --> 0.043180).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0392306\n",
      "\tspeed: 0.0734s/iter; left time: 363.6918s\n",
      "\titers: 200, epoch: 8 | loss: 0.0396688\n",
      "\tspeed: 0.0765s/iter; left time: 371.5062s\n",
      "\titers: 300, epoch: 8 | loss: 0.0350419\n",
      "\tspeed: 0.0784s/iter; left time: 372.9301s\n",
      "Epoch: 8 cost time: 29.618701696395874\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.0365615 Vali Loss: 0.0591930 Test Loss: 0.2223749\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0331802\n",
      "\tspeed: 0.0765s/iter; left time: 349.5322s\n",
      "\titers: 200, epoch: 9 | loss: 0.0341362\n",
      "\tspeed: 0.0770s/iter; left time: 344.0370s\n",
      "\titers: 300, epoch: 9 | loss: 0.0410483\n",
      "\tspeed: 0.0772s/iter; left time: 337.2150s\n",
      "Epoch: 9 cost time: 29.970695972442627\n",
      "Epoch: 9, Steps: 389 | Train Loss: 0.0356966 Vali Loss: 0.0531323 Test Loss: 0.2082342\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.0318879\n",
      "\tspeed: 0.0739s/iter; left time: 308.8835s\n",
      "\titers: 200, epoch: 10 | loss: 0.0331277\n",
      "\tspeed: 0.0737s/iter; left time: 300.7631s\n",
      "\titers: 300, epoch: 10 | loss: 0.0332841\n",
      "\tspeed: 0.0770s/iter; left time: 306.2869s\n",
      "Epoch: 10 cost time: 29.441967725753784\n",
      "Epoch: 10, Steps: 389 | Train Loss: 0.0354468 Vali Loss: 0.0546748 Test Loss: 0.2085372\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.16524925827980042, mae:0.35950005054473877\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_il168_pl720_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.1249231\n",
      "\tspeed: 0.0772s/iter; left time: 574.7418s\n",
      "\titers: 200, epoch: 1 | loss: 0.1116732\n",
      "\tspeed: 0.0744s/iter; left time: 546.0032s\n",
      "\titers: 300, epoch: 1 | loss: 0.0953755\n",
      "\tspeed: 0.0780s/iter; left time: 565.1289s\n",
      "Epoch: 1 cost time: 29.04622530937195\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.1358536 Vali Loss: 0.0672959 Test Loss: 0.1250256\n",
      "Validation loss decreased (inf --> 0.067296).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0563296\n",
      "\tspeed: 0.0803s/iter; left time: 567.2015s\n",
      "\titers: 200, epoch: 2 | loss: 0.0451128\n",
      "\tspeed: 0.0802s/iter; left time: 558.7619s\n",
      "\titers: 300, epoch: 2 | loss: 0.0462797\n",
      "\tspeed: 0.0808s/iter; left time: 554.8653s\n",
      "Epoch: 2 cost time: 30.79971933364868\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0508291 Vali Loss: 0.0339138 Test Loss: 0.0676349\n",
      "Validation loss decreased (0.067296 --> 0.033914).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0371368\n",
      "\tspeed: 0.0843s/iter; left time: 563.5343s\n",
      "\titers: 200, epoch: 3 | loss: 0.0389325\n",
      "\tspeed: 0.0838s/iter; left time: 552.0241s\n",
      "\titers: 300, epoch: 3 | loss: 0.0363676\n",
      "\tspeed: 0.0834s/iter; left time: 541.1241s\n",
      "Epoch: 3 cost time: 31.60538387298584\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0380823 Vali Loss: 0.0300103 Test Loss: 0.0571927\n",
      "Validation loss decreased (0.033914 --> 0.030010).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0370088\n",
      "\tspeed: 0.0803s/iter; left time: 506.8167s\n",
      "\titers: 200, epoch: 4 | loss: 0.0368180\n",
      "\tspeed: 0.0812s/iter; left time: 504.3015s\n",
      "\titers: 300, epoch: 4 | loss: 0.0306429\n",
      "\tspeed: 0.0800s/iter; left time: 489.0876s\n",
      "Epoch: 4 cost time: 30.257579803466797\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0346471 Vali Loss: 0.0360019 Test Loss: 0.0790063\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0289369\n",
      "\tspeed: 0.0764s/iter; left time: 453.4381s\n",
      "\titers: 200, epoch: 5 | loss: 0.0290099\n",
      "\tspeed: 0.0798s/iter; left time: 465.4282s\n",
      "\titers: 300, epoch: 5 | loss: 0.0347401\n",
      "\tspeed: 0.0834s/iter; left time: 478.0679s\n",
      "Epoch: 5 cost time: 30.300211906433105\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0311944 Vali Loss: 0.0254409 Test Loss: 0.0406752\n",
      "Validation loss decreased (0.030010 --> 0.025441).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0305151\n",
      "\tspeed: 0.0803s/iter; left time: 446.0096s\n",
      "\titers: 200, epoch: 6 | loss: 0.0285397\n",
      "\tspeed: 0.0785s/iter; left time: 428.5482s\n",
      "\titers: 300, epoch: 6 | loss: 0.0328258\n",
      "\tspeed: 0.0800s/iter; left time: 428.6721s\n",
      "Epoch: 6 cost time: 30.00359272956848\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0294628 Vali Loss: 0.0266557 Test Loss: 0.0536753\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0320090\n",
      "\tspeed: 0.0814s/iter; left time: 421.3738s\n",
      "\titers: 200, epoch: 7 | loss: 0.0287176\n",
      "\tspeed: 0.0833s/iter; left time: 423.1898s\n",
      "\titers: 300, epoch: 7 | loss: 0.0294786\n",
      "\tspeed: 0.0853s/iter; left time: 424.6766s\n",
      "Epoch: 7 cost time: 31.350613117218018\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0281756 Vali Loss: 0.0300822 Test Loss: 0.0645643\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0307192\n",
      "\tspeed: 0.0767s/iter; left time: 368.1229s\n",
      "\titers: 200, epoch: 8 | loss: 0.0284996\n",
      "\tspeed: 0.0789s/iter; left time: 370.7856s\n",
      "\titers: 300, epoch: 8 | loss: 0.0315191\n",
      "\tspeed: 0.0813s/iter; left time: 374.0343s\n",
      "Epoch: 8 cost time: 30.223114013671875\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.0278025 Vali Loss: 0.0241347 Test Loss: 0.0461603\n",
      "Validation loss decreased (0.025441 --> 0.024135).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0234831\n",
      "\tspeed: 0.0826s/iter; left time: 365.5362s\n",
      "\titers: 200, epoch: 9 | loss: 0.0292773\n",
      "\tspeed: 0.0829s/iter; left time: 358.5231s\n",
      "\titers: 300, epoch: 9 | loss: 0.0228415\n",
      "\tspeed: 0.0828s/iter; left time: 349.9087s\n",
      "Epoch: 9 cost time: 31.052708387374878\n",
      "Epoch: 9, Steps: 377 | Train Loss: 0.0270787 Vali Loss: 0.0252073 Test Loss: 0.0541159\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.0266751\n",
      "\tspeed: 0.0786s/iter; left time: 317.9820s\n",
      "\titers: 200, epoch: 10 | loss: 0.0314134\n",
      "\tspeed: 0.0786s/iter; left time: 310.2917s\n",
      "\titers: 300, epoch: 10 | loss: 0.0253747\n",
      "\tspeed: 0.0780s/iter; left time: 300.2341s\n",
      "Epoch: 10 cost time: 29.90623188018799\n",
      "Epoch: 10, Steps: 377 | Train Loss: 0.0268671 Vali Loss: 0.0260422 Test Loss: 0.0517761\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0291856\n",
      "\tspeed: 0.0827s/iter; left time: 303.5089s\n",
      "\titers: 200, epoch: 11 | loss: 0.0266232\n",
      "\tspeed: 0.0835s/iter; left time: 298.0235s\n",
      "\titers: 300, epoch: 11 | loss: 0.0244825\n",
      "\tspeed: 0.0820s/iter; left time: 284.4641s\n",
      "Epoch: 11 cost time: 30.751803159713745\n",
      "Epoch: 11, Steps: 377 | Train Loss: 0.0265379 Vali Loss: 0.0296221 Test Loss: 0.0612946\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.04616033658385277, mae:0.17070917785167694\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_reversal_il168_pl24_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.1306798\n",
      "\tspeed: 0.0726s/iter; left time: 572.0654s\n",
      "\titers: 200, epoch: 1 | loss: 0.0580857\n",
      "\tspeed: 0.0730s/iter; left time: 568.1036s\n",
      "\titers: 300, epoch: 1 | loss: 0.0716058\n",
      "\tspeed: 0.0721s/iter; left time: 554.1202s\n",
      "Epoch: 1 cost time: 29.418641805648804\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.1175867 Vali Loss: 0.0472454 Test Loss: 0.0538576\n",
      "Validation loss decreased (inf --> 0.047245).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0288671\n",
      "\tspeed: 0.0783s/iter; left time: 585.5361s\n",
      "\titers: 200, epoch: 2 | loss: 0.0360008\n",
      "\tspeed: 0.0772s/iter; left time: 570.1659s\n",
      "\titers: 300, epoch: 2 | loss: 0.0205206\n",
      "\tspeed: 0.0771s/iter; left time: 561.1731s\n",
      "Epoch: 2 cost time: 30.307631731033325\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0294249 Vali Loss: 0.0221301 Test Loss: 0.0234822\n",
      "Validation loss decreased (0.047245 --> 0.022130).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0157332\n",
      "\tspeed: 0.0759s/iter; left time: 537.7396s\n",
      "\titers: 200, epoch: 3 | loss: 0.0239928\n",
      "\tspeed: 0.0718s/iter; left time: 501.6421s\n",
      "\titers: 300, epoch: 3 | loss: 0.0181749\n",
      "\tspeed: 0.0749s/iter; left time: 515.5857s\n",
      "Epoch: 3 cost time: 29.1836895942688\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0193943 Vali Loss: 0.0183862 Test Loss: 0.0202715\n",
      "Validation loss decreased (0.022130 --> 0.018386).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0185251\n",
      "\tspeed: 0.0701s/iter; left time: 468.6439s\n",
      "\titers: 200, epoch: 4 | loss: 0.0207700\n",
      "\tspeed: 0.0690s/iter; left time: 454.5396s\n",
      "\titers: 300, epoch: 4 | loss: 0.0166900\n",
      "\tspeed: 0.0731s/iter; left time: 473.7465s\n",
      "Epoch: 4 cost time: 28.536664962768555\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0164816 Vali Loss: 0.0173101 Test Loss: 0.0312051\n",
      "Validation loss decreased (0.018386 --> 0.017310).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0130923\n",
      "\tspeed: 0.0708s/iter; left time: 445.1104s\n",
      "\titers: 200, epoch: 5 | loss: 0.0149223\n",
      "\tspeed: 0.0693s/iter; left time: 428.5586s\n",
      "\titers: 300, epoch: 5 | loss: 0.0131449\n",
      "\tspeed: 0.0717s/iter; left time: 436.2121s\n",
      "Epoch: 5 cost time: 28.491304397583008\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0143014 Vali Loss: 0.0122348 Test Loss: 0.0196826\n",
      "Validation loss decreased (0.017310 --> 0.012235).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0131655\n",
      "\tspeed: 0.0735s/iter; left time: 432.6713s\n",
      "\titers: 200, epoch: 6 | loss: 0.0153919\n",
      "\tspeed: 0.0752s/iter; left time: 434.8487s\n",
      "\titers: 300, epoch: 6 | loss: 0.0123974\n",
      "\tspeed: 0.0728s/iter; left time: 414.1948s\n",
      "Epoch: 6 cost time: 29.739840030670166\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0133186 Vali Loss: 0.0121712 Test Loss: 0.0186953\n",
      "Validation loss decreased (0.012235 --> 0.012171).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0124627\n",
      "\tspeed: 0.0775s/iter; left time: 425.0123s\n",
      "\titers: 200, epoch: 7 | loss: 0.0137933\n",
      "\tspeed: 0.0778s/iter; left time: 419.2492s\n",
      "\titers: 300, epoch: 7 | loss: 0.0135620\n",
      "\tspeed: 0.0782s/iter; left time: 413.4619s\n",
      "Epoch: 7 cost time: 30.707123041152954\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0123719 Vali Loss: 0.0174405 Test Loss: 0.0388560\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0115289\n",
      "\tspeed: 0.0773s/iter; left time: 393.2026s\n",
      "\titers: 200, epoch: 8 | loss: 0.0163228\n",
      "\tspeed: 0.0764s/iter; left time: 381.0255s\n",
      "\titers: 300, epoch: 8 | loss: 0.0174323\n",
      "\tspeed: 0.0755s/iter; left time: 369.1806s\n",
      "Epoch: 8 cost time: 30.31738591194153\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0119898 Vali Loss: 0.0136575 Test Loss: 0.0312847\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0104963\n",
      "\tspeed: 0.0763s/iter; left time: 357.9368s\n",
      "\titers: 200, epoch: 9 | loss: 0.0103059\n",
      "\tspeed: 0.0834s/iter; left time: 382.6153s\n",
      "\titers: 300, epoch: 9 | loss: 0.0100317\n",
      "\tspeed: 0.0821s/iter; left time: 368.5655s\n",
      "Epoch: 9 cost time: 32.198747396469116\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0113807 Vali Loss: 0.0120828 Test Loss: 0.0274885\n",
      "Validation loss decreased (0.012171 --> 0.012083).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0108147\n",
      "\tspeed: 0.0749s/iter; left time: 321.1279s\n",
      "\titers: 200, epoch: 10 | loss: 0.0118928\n",
      "\tspeed: 0.0755s/iter; left time: 316.2860s\n",
      "\titers: 300, epoch: 10 | loss: 0.0141356\n",
      "\tspeed: 0.0793s/iter; left time: 324.4548s\n",
      "Epoch: 10 cost time: 30.62182641029358\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0111431 Vali Loss: 0.0150286 Test Loss: 0.0355200\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0108180\n",
      "\tspeed: 0.0774s/iter; left time: 301.0400s\n",
      "\titers: 200, epoch: 11 | loss: 0.0108093\n",
      "\tspeed: 0.0768s/iter; left time: 291.2714s\n",
      "\titers: 300, epoch: 11 | loss: 0.0095839\n",
      "\tspeed: 0.0758s/iter; left time: 279.6461s\n",
      "Epoch: 11 cost time: 30.872672080993652\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0108636 Vali Loss: 0.0218975 Test Loss: 0.0474142\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.0123143\n",
      "\tspeed: 0.0733s/iter; left time: 255.8722s\n",
      "\titers: 200, epoch: 12 | loss: 0.0119039\n",
      "\tspeed: 0.0730s/iter; left time: 247.6745s\n",
      "\titers: 300, epoch: 12 | loss: 0.0110971\n",
      "\tspeed: 0.0755s/iter; left time: 248.5645s\n",
      "Epoch: 12 cost time: 29.33632516860962\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0106936 Vali Loss: 0.0182538 Test Loss: 0.0409455\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.02748849429190159, mae:0.12139219045639038\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_reversal_il168_pl48_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.1680437\n",
      "\tspeed: 0.0789s/iter; left time: 620.5900s\n",
      "\titers: 200, epoch: 1 | loss: 0.0853185\n",
      "\tspeed: 0.0770s/iter; left time: 597.3030s\n",
      "\titers: 300, epoch: 1 | loss: 0.0432862\n",
      "\tspeed: 0.0727s/iter; left time: 556.7264s\n",
      "Epoch: 1 cost time: 29.946809768676758\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.1285105 Vali Loss: 0.0546684 Test Loss: 0.0526023\n",
      "Validation loss decreased (inf --> 0.054668).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0376862\n",
      "\tspeed: 0.0709s/iter; left time: 528.8804s\n",
      "\titers: 200, epoch: 2 | loss: 0.0307899\n",
      "\tspeed: 0.0711s/iter; left time: 523.3233s\n",
      "\titers: 300, epoch: 2 | loss: 0.0258960\n",
      "\tspeed: 0.0712s/iter; left time: 516.9278s\n",
      "Epoch: 2 cost time: 27.948630571365356\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0354210 Vali Loss: 0.0884477 Test Loss: 0.1389402\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0264804\n",
      "\tspeed: 0.0737s/iter; left time: 520.7371s\n",
      "\titers: 200, epoch: 3 | loss: 0.0197013\n",
      "\tspeed: 0.0732s/iter; left time: 509.5688s\n",
      "\titers: 300, epoch: 3 | loss: 0.0199942\n",
      "\tspeed: 0.0725s/iter; left time: 498.0253s\n",
      "Epoch: 3 cost time: 29.08461618423462\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0235081 Vali Loss: 0.0284649 Test Loss: 0.0553440\n",
      "Validation loss decreased (0.054668 --> 0.028465).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0219388\n",
      "\tspeed: 0.0770s/iter; left time: 513.3339s\n",
      "\titers: 200, epoch: 4 | loss: 0.0178381\n",
      "\tspeed: 0.0727s/iter; left time: 477.2584s\n",
      "\titers: 300, epoch: 4 | loss: 0.0159144\n",
      "\tspeed: 0.0722s/iter; left time: 466.7569s\n",
      "Epoch: 4 cost time: 29.309946537017822\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0202465 Vali Loss: 0.0265842 Test Loss: 0.0551072\n",
      "Validation loss decreased (0.028465 --> 0.026584).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0188032\n",
      "\tspeed: 0.0769s/iter; left time: 482.3696s\n",
      "\titers: 200, epoch: 5 | loss: 0.0160675\n",
      "\tspeed: 0.0755s/iter; left time: 465.4629s\n",
      "\titers: 300, epoch: 5 | loss: 0.0184464\n",
      "\tspeed: 0.0738s/iter; left time: 448.1742s\n",
      "Epoch: 5 cost time: 30.148757934570312\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0175660 Vali Loss: 0.0269469 Test Loss: 0.0613852\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0174314\n",
      "\tspeed: 0.0712s/iter; left time: 418.0826s\n",
      "\titers: 200, epoch: 6 | loss: 0.0170098\n",
      "\tspeed: 0.0726s/iter; left time: 419.0823s\n",
      "\titers: 300, epoch: 6 | loss: 0.0161384\n",
      "\tspeed: 0.0714s/iter; left time: 405.1329s\n",
      "Epoch: 6 cost time: 28.61389684677124\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0164282 Vali Loss: 0.0290680 Test Loss: 0.0665902\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0180956\n",
      "\tspeed: 0.0733s/iter; left time: 401.4250s\n",
      "\titers: 200, epoch: 7 | loss: 0.0157581\n",
      "\tspeed: 0.0755s/iter; left time: 405.8022s\n",
      "\titers: 300, epoch: 7 | loss: 0.0186988\n",
      "\tspeed: 0.0776s/iter; left time: 409.3556s\n",
      "Epoch: 7 cost time: 30.336167573928833\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0154810 Vali Loss: 0.0316770 Test Loss: 0.0751642\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.0551072396337986, mae:0.16586995124816895\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_reversal_il168_pl168_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.2578308\n",
      "\tspeed: 0.0751s/iter; left time: 584.5902s\n",
      "\titers: 200, epoch: 1 | loss: 0.0982442\n",
      "\tspeed: 0.0749s/iter; left time: 575.0269s\n",
      "\titers: 300, epoch: 1 | loss: 0.0960420\n",
      "\tspeed: 0.0752s/iter; left time: 569.9094s\n",
      "Epoch: 1 cost time: 29.304255962371826\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.1818036 Vali Loss: 0.1775288 Test Loss: 0.1145776\n",
      "Validation loss decreased (inf --> 0.177529).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0609431\n",
      "\tspeed: 0.0786s/iter; left time: 580.4364s\n",
      "\titers: 200, epoch: 2 | loss: 0.0565290\n",
      "\tspeed: 0.0749s/iter; left time: 545.6707s\n",
      "\titers: 300, epoch: 2 | loss: 0.0648442\n",
      "\tspeed: 0.0756s/iter; left time: 543.2947s\n",
      "Epoch: 2 cost time: 30.48227286338806\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0708033 Vali Loss: 0.0808840 Test Loss: 0.0628247\n",
      "Validation loss decreased (0.177529 --> 0.080884).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0544487\n",
      "\tspeed: 0.0800s/iter; left time: 559.4981s\n",
      "\titers: 200, epoch: 3 | loss: 0.0551176\n",
      "\tspeed: 0.0763s/iter; left time: 525.5931s\n",
      "\titers: 300, epoch: 3 | loss: 0.0490613\n",
      "\tspeed: 0.0774s/iter; left time: 525.9000s\n",
      "Epoch: 3 cost time: 30.28959035873413\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0576550 Vali Loss: 0.0679629 Test Loss: 0.0735354\n",
      "Validation loss decreased (0.080884 --> 0.067963).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0439238\n",
      "\tspeed: 0.0778s/iter; left time: 513.6025s\n",
      "\titers: 200, epoch: 4 | loss: 0.0583504\n",
      "\tspeed: 0.0763s/iter; left time: 496.0039s\n",
      "\titers: 300, epoch: 4 | loss: 0.0584886\n",
      "\tspeed: 0.0738s/iter; left time: 472.1533s\n",
      "Epoch: 4 cost time: 29.43565082550049\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0539580 Vali Loss: 0.0923983 Test Loss: 0.0658228\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0454243\n",
      "\tspeed: 0.0707s/iter; left time: 438.5325s\n",
      "\titers: 200, epoch: 5 | loss: 0.0507438\n",
      "\tspeed: 0.0735s/iter; left time: 448.9289s\n",
      "\titers: 300, epoch: 5 | loss: 0.0553602\n",
      "\tspeed: 0.0748s/iter; left time: 449.0560s\n",
      "Epoch: 5 cost time: 28.85092067718506\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0497805 Vali Loss: 0.0586245 Test Loss: 0.0893200\n",
      "Validation loss decreased (0.067963 --> 0.058625).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0475207\n",
      "\tspeed: 0.0724s/iter; left time: 420.6687s\n",
      "\titers: 200, epoch: 6 | loss: 0.0551004\n",
      "\tspeed: 0.0748s/iter; left time: 427.4533s\n",
      "\titers: 300, epoch: 6 | loss: 0.0423320\n",
      "\tspeed: 0.0779s/iter; left time: 437.1169s\n",
      "Epoch: 6 cost time: 29.87500309944153\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0481300 Vali Loss: 0.0565432 Test Loss: 0.0809101\n",
      "Validation loss decreased (0.058625 --> 0.056543).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0371414\n",
      "\tspeed: 0.0729s/iter; left time: 394.9768s\n",
      "\titers: 200, epoch: 7 | loss: 0.0442448\n",
      "\tspeed: 0.0740s/iter; left time: 393.2854s\n",
      "\titers: 300, epoch: 7 | loss: 0.0423014\n",
      "\tspeed: 0.0745s/iter; left time: 388.4989s\n",
      "Epoch: 7 cost time: 29.31605100631714\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0452289 Vali Loss: 0.0578869 Test Loss: 0.1007524\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0493786\n",
      "\tspeed: 0.0722s/iter; left time: 362.8594s\n",
      "\titers: 200, epoch: 8 | loss: 0.0405620\n",
      "\tspeed: 0.0765s/iter; left time: 376.4146s\n",
      "\titers: 300, epoch: 8 | loss: 0.0519561\n",
      "\tspeed: 0.0763s/iter; left time: 367.9343s\n",
      "Epoch: 8 cost time: 29.891979932785034\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0449794 Vali Loss: 0.0650212 Test Loss: 0.0748228\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0430418\n",
      "\tspeed: 0.0710s/iter; left time: 328.5474s\n",
      "\titers: 200, epoch: 9 | loss: 0.0409287\n",
      "\tspeed: 0.0724s/iter; left time: 327.7142s\n",
      "\titers: 300, epoch: 9 | loss: 0.0458163\n",
      "\tspeed: 0.0711s/iter; left time: 314.7401s\n",
      "Epoch: 9 cost time: 28.0982666015625\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0431137 Vali Loss: 0.0535840 Test Loss: 0.0804157\n",
      "Validation loss decreased (0.056543 --> 0.053584).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0423317\n",
      "\tspeed: 0.0727s/iter; left time: 308.0378s\n",
      "\titers: 200, epoch: 10 | loss: 0.0348934\n",
      "\tspeed: 0.0786s/iter; left time: 325.0304s\n",
      "\titers: 300, epoch: 10 | loss: 0.0373032\n",
      "\tspeed: 0.0778s/iter; left time: 313.8199s\n",
      "Epoch: 10 cost time: 30.23905658721924\n",
      "Epoch: 10, Steps: 394 | Train Loss: 0.0429132 Vali Loss: 0.0563903 Test Loss: 0.1045248\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0461643\n",
      "\tspeed: 0.0786s/iter; left time: 302.0533s\n",
      "\titers: 200, epoch: 11 | loss: 0.0432979\n",
      "\tspeed: 0.0772s/iter; left time: 288.7238s\n",
      "\titers: 300, epoch: 11 | loss: 0.0349765\n",
      "\tspeed: 0.0721s/iter; left time: 262.3568s\n",
      "Epoch: 11 cost time: 29.600020170211792\n",
      "Epoch: 11, Steps: 394 | Train Loss: 0.0424775 Vali Loss: 0.0536382 Test Loss: 0.0948037\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.0514518\n",
      "\tspeed: 0.0742s/iter; left time: 255.7973s\n",
      "\titers: 200, epoch: 12 | loss: 0.0524946\n",
      "\tspeed: 0.0782s/iter; left time: 261.7828s\n",
      "\titers: 300, epoch: 12 | loss: 0.0603996\n",
      "\tspeed: 0.0762s/iter; left time: 247.3895s\n",
      "Epoch: 12 cost time: 30.12926745414734\n",
      "Epoch: 12, Steps: 394 | Train Loss: 0.0421585 Vali Loss: 0.0545060 Test Loss: 0.0971390\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.0804157555103302, mae:0.21454238891601562\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_reversal_il168_pl336_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.3690712\n",
      "\tspeed: 0.0765s/iter; left time: 587.2146s\n",
      "\titers: 200, epoch: 1 | loss: 0.2149713\n",
      "\tspeed: 0.0725s/iter; left time: 549.3913s\n",
      "\titers: 300, epoch: 1 | loss: 0.1768049\n",
      "\tspeed: 0.0720s/iter; left time: 538.9253s\n",
      "Epoch: 1 cost time: 28.542572498321533\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.2739301 Vali Loss: 0.3315820 Test Loss: 0.1914819\n",
      "Validation loss decreased (inf --> 0.331582).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.1730859\n",
      "\tspeed: 0.0716s/iter; left time: 522.4212s\n",
      "\titers: 200, epoch: 2 | loss: 0.1956303\n",
      "\tspeed: 0.0764s/iter; left time: 549.2451s\n",
      "\titers: 300, epoch: 2 | loss: 0.1551467\n",
      "\tspeed: 0.0774s/iter; left time: 548.9854s\n",
      "Epoch: 2 cost time: 29.416769981384277\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.1549016 Vali Loss: 0.3149453 Test Loss: 0.1780806\n",
      "Validation loss decreased (0.331582 --> 0.314945).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1020675\n",
      "\tspeed: 0.0768s/iter; left time: 530.3221s\n",
      "\titers: 200, epoch: 3 | loss: 0.1296396\n",
      "\tspeed: 0.0751s/iter; left time: 511.0481s\n",
      "\titers: 300, epoch: 3 | loss: 0.1419733\n",
      "\tspeed: 0.0682s/iter; left time: 456.9959s\n",
      "Epoch: 3 cost time: 28.50582265853882\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.1362597 Vali Loss: 0.2931559 Test Loss: 0.1609577\n",
      "Validation loss decreased (0.314945 --> 0.293156).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.1029497\n",
      "\tspeed: 0.0719s/iter; left time: 468.3057s\n",
      "\titers: 200, epoch: 4 | loss: 0.1162688\n",
      "\tspeed: 0.0724s/iter; left time: 464.4061s\n",
      "\titers: 300, epoch: 4 | loss: 0.1328079\n",
      "\tspeed: 0.0761s/iter; left time: 480.7151s\n",
      "Epoch: 4 cost time: 28.79202914237976\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.1317099 Vali Loss: 0.2911842 Test Loss: 0.1513128\n",
      "Validation loss decreased (0.293156 --> 0.291184).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1187946\n",
      "\tspeed: 0.0746s/iter; left time: 456.7184s\n",
      "\titers: 200, epoch: 5 | loss: 0.1185483\n",
      "\tspeed: 0.0739s/iter; left time: 445.2566s\n",
      "\titers: 300, epoch: 5 | loss: 0.1130660\n",
      "\tspeed: 0.0732s/iter; left time: 433.8517s\n",
      "Epoch: 5 cost time: 28.595773935317993\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.1248335 Vali Loss: 0.2775803 Test Loss: 0.1389560\n",
      "Validation loss decreased (0.291184 --> 0.277580).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.1347689\n",
      "\tspeed: 0.0730s/iter; left time: 418.5533s\n",
      "\titers: 200, epoch: 6 | loss: 0.1138541\n",
      "\tspeed: 0.0777s/iter; left time: 438.1635s\n",
      "\titers: 300, epoch: 6 | loss: 0.1170672\n",
      "\tspeed: 0.0777s/iter; left time: 430.4025s\n",
      "Epoch: 6 cost time: 29.70302677154541\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.1227417 Vali Loss: 0.2496030 Test Loss: 0.1224085\n",
      "Validation loss decreased (0.277580 --> 0.249603).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1039769\n",
      "\tspeed: 0.0741s/iter; left time: 396.0580s\n",
      "\titers: 200, epoch: 7 | loss: 0.1369753\n",
      "\tspeed: 0.0733s/iter; left time: 384.6369s\n",
      "\titers: 300, epoch: 7 | loss: 0.1252235\n",
      "\tspeed: 0.0714s/iter; left time: 367.6460s\n",
      "Epoch: 7 cost time: 28.544454097747803\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.1192300 Vali Loss: 0.2809749 Test Loss: 0.1393975\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0937961\n",
      "\tspeed: 0.0734s/iter; left time: 363.8562s\n",
      "\titers: 200, epoch: 8 | loss: 0.1024302\n",
      "\tspeed: 0.0719s/iter; left time: 349.2595s\n",
      "\titers: 300, epoch: 8 | loss: 0.1183627\n",
      "\tspeed: 0.0740s/iter; left time: 352.2791s\n",
      "Epoch: 8 cost time: 28.51272463798523\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.1179109 Vali Loss: 0.2454376 Test Loss: 0.1191279\n",
      "Validation loss decreased (0.249603 --> 0.245438).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1017435\n",
      "\tspeed: 0.0755s/iter; left time: 344.7833s\n",
      "\titers: 200, epoch: 9 | loss: 0.1190502\n",
      "\tspeed: 0.0726s/iter; left time: 324.4536s\n",
      "\titers: 300, epoch: 9 | loss: 0.0977757\n",
      "\tspeed: 0.0719s/iter; left time: 314.0463s\n",
      "Epoch: 9 cost time: 28.294888734817505\n",
      "Epoch: 9, Steps: 389 | Train Loss: 0.1160093 Vali Loss: 0.2769276 Test Loss: 0.1377713\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.0931306\n",
      "\tspeed: 0.0733s/iter; left time: 306.4076s\n",
      "\titers: 200, epoch: 10 | loss: 0.1215437\n",
      "\tspeed: 0.0755s/iter; left time: 308.0442s\n",
      "\titers: 300, epoch: 10 | loss: 0.1139560\n",
      "\tspeed: 0.0789s/iter; left time: 314.1524s\n",
      "Epoch: 10 cost time: 29.682499885559082\n",
      "Epoch: 10, Steps: 389 | Train Loss: 0.1142740 Vali Loss: 0.2279085 Test Loss: 0.1120149\n",
      "Validation loss decreased (0.245438 --> 0.227908).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0945719\n",
      "\tspeed: 0.0752s/iter; left time: 285.1205s\n",
      "\titers: 200, epoch: 11 | loss: 0.1078989\n",
      "\tspeed: 0.0775s/iter; left time: 285.8915s\n",
      "\titers: 300, epoch: 11 | loss: 0.1220491\n",
      "\tspeed: 0.0756s/iter; left time: 271.6398s\n",
      "Epoch: 11 cost time: 29.72703218460083\n",
      "Epoch: 11, Steps: 389 | Train Loss: 0.1128655 Vali Loss: 0.2518377 Test Loss: 0.1244037\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.1412380\n",
      "\tspeed: 0.0740s/iter; left time: 251.9057s\n",
      "\titers: 200, epoch: 12 | loss: 0.1540004\n",
      "\tspeed: 0.0751s/iter; left time: 248.0161s\n",
      "\titers: 300, epoch: 12 | loss: 0.1069571\n",
      "\tspeed: 0.0733s/iter; left time: 234.7652s\n",
      "Epoch: 12 cost time: 28.584604024887085\n",
      "Epoch: 12, Steps: 389 | Train Loss: 0.1125157 Vali Loss: 0.2466175 Test Loss: 0.1260242\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.0791579\n",
      "\tspeed: 0.0745s/iter; left time: 224.6036s\n",
      "\titers: 200, epoch: 13 | loss: 0.1431735\n",
      "\tspeed: 0.0777s/iter; left time: 226.4762s\n",
      "\titers: 300, epoch: 13 | loss: 0.1172808\n",
      "\tspeed: 0.0706s/iter; left time: 198.6450s\n",
      "Epoch: 13 cost time: 28.80678915977478\n",
      "Epoch: 13, Steps: 389 | Train Loss: 0.1124489 Vali Loss: 0.2425877 Test Loss: 0.1216210\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.11201486736536026, mae:0.2475729137659073\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_reversal_il168_pl720_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.4215371\n",
      "\tspeed: 0.0738s/iter; left time: 549.1148s\n",
      "\titers: 200, epoch: 1 | loss: 0.4002006\n",
      "\tspeed: 0.0760s/iter; left time: 558.0681s\n",
      "\titers: 300, epoch: 1 | loss: 0.2460188\n",
      "\tspeed: 0.0796s/iter; left time: 576.5402s\n",
      "Epoch: 1 cost time: 28.95130205154419\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.3882058 Vali Loss: 0.9599454 Test Loss: 0.5963968\n",
      "Validation loss decreased (inf --> 0.959945).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.2540464\n",
      "\tspeed: 0.0792s/iter; left time: 559.4928s\n",
      "\titers: 200, epoch: 2 | loss: 0.2830283\n",
      "\tspeed: 0.0800s/iter; left time: 556.9013s\n",
      "\titers: 300, epoch: 2 | loss: 0.2233936\n",
      "\tspeed: 0.0805s/iter; left time: 552.6403s\n",
      "Epoch: 2 cost time: 30.277282238006592\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.2585672 Vali Loss: 0.9086016 Test Loss: 0.6166057\n",
      "Validation loss decreased (0.959945 --> 0.908602).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2604934\n",
      "\tspeed: 0.0795s/iter; left time: 531.3893s\n",
      "\titers: 200, epoch: 3 | loss: 0.2419358\n",
      "\tspeed: 0.0794s/iter; left time: 523.0195s\n",
      "\titers: 300, epoch: 3 | loss: 0.2229050\n",
      "\tspeed: 0.0768s/iter; left time: 498.4893s\n",
      "Epoch: 3 cost time: 29.522867679595947\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.2416964 Vali Loss: 0.7889710 Test Loss: 0.5066994\n",
      "Validation loss decreased (0.908602 --> 0.788971).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.2026640\n",
      "\tspeed: 0.0795s/iter; left time: 501.7570s\n",
      "\titers: 200, epoch: 4 | loss: 0.2581767\n",
      "\tspeed: 0.0802s/iter; left time: 498.2272s\n",
      "\titers: 300, epoch: 4 | loss: 0.2360277\n",
      "\tspeed: 0.0816s/iter; left time: 498.3455s\n",
      "Epoch: 4 cost time: 30.138394832611084\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.2351366 Vali Loss: 0.7973936 Test Loss: 0.5757333\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2157132\n",
      "\tspeed: 0.0729s/iter; left time: 432.3419s\n",
      "\titers: 200, epoch: 5 | loss: 0.2475430\n",
      "\tspeed: 0.0755s/iter; left time: 440.3496s\n",
      "\titers: 300, epoch: 5 | loss: 0.2576702\n",
      "\tspeed: 0.0778s/iter; left time: 446.3010s\n",
      "Epoch: 5 cost time: 28.51411747932434\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.2297140 Vali Loss: 0.8150653 Test Loss: 0.5055493\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.1942302\n",
      "\tspeed: 0.0810s/iter; left time: 449.9828s\n",
      "\titers: 200, epoch: 6 | loss: 0.2012292\n",
      "\tspeed: 0.0818s/iter; left time: 446.2916s\n",
      "\titers: 300, epoch: 6 | loss: 0.1860531\n",
      "\tspeed: 0.0793s/iter; left time: 424.7894s\n",
      "Epoch: 6 cost time: 30.14216637611389\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.2282704 Vali Loss: 0.8706281 Test Loss: 0.6212353\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.5066994428634644, mae:0.5632137656211853\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_il168_pl24_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.1112969\n",
      "\tspeed: 0.0720s/iter; left time: 567.7214s\n",
      "\titers: 200, epoch: 1 | loss: 0.0707543\n",
      "\tspeed: 0.0734s/iter; left time: 571.0145s\n",
      "\titers: 300, epoch: 1 | loss: 0.0535366\n",
      "\tspeed: 0.0725s/iter; left time: 557.1813s\n",
      "Epoch: 1 cost time: 29.14925479888916\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.1060157 Vali Loss: 0.0635190 Test Loss: 0.3661633\n",
      "Validation loss decreased (inf --> 0.063519).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0318440\n",
      "\tspeed: 0.0755s/iter; left time: 564.9877s\n",
      "\titers: 200, epoch: 2 | loss: 0.0258245\n",
      "\tspeed: 0.0755s/iter; left time: 557.0387s\n",
      "\titers: 300, epoch: 2 | loss: 0.0269632\n",
      "\tspeed: 0.0746s/iter; left time: 543.2421s\n",
      "Epoch: 2 cost time: 29.62783670425415\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0265566 Vali Loss: 0.0351689 Test Loss: 0.2040716\n",
      "Validation loss decreased (0.063519 --> 0.035169).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0154539\n",
      "\tspeed: 0.0710s/iter; left time: 502.9935s\n",
      "\titers: 200, epoch: 3 | loss: 0.0165307\n",
      "\tspeed: 0.0718s/iter; left time: 501.1964s\n",
      "\titers: 300, epoch: 3 | loss: 0.0133167\n",
      "\tspeed: 0.0719s/iter; left time: 495.0771s\n",
      "Epoch: 3 cost time: 28.62982702255249\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0169424 Vali Loss: 0.0459556 Test Loss: 0.1449208\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.0191859\n",
      "\tspeed: 0.0742s/iter; left time: 495.8202s\n",
      "\titers: 200, epoch: 4 | loss: 0.0193187\n",
      "\tspeed: 0.0756s/iter; left time: 497.8198s\n",
      "\titers: 300, epoch: 4 | loss: 0.0132315\n",
      "\tspeed: 0.0748s/iter; left time: 484.9043s\n",
      "Epoch: 4 cost time: 29.614158391952515\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0148194 Vali Loss: 0.0293906 Test Loss: 0.1744723\n",
      "Validation loss decreased (0.035169 --> 0.029391).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0119361\n",
      "\tspeed: 0.0724s/iter; left time: 455.0051s\n",
      "\titers: 200, epoch: 5 | loss: 0.0119885\n",
      "\tspeed: 0.0718s/iter; left time: 444.3286s\n",
      "\titers: 300, epoch: 5 | loss: 0.0099561\n",
      "\tspeed: 0.0719s/iter; left time: 437.3111s\n",
      "Epoch: 5 cost time: 28.966346502304077\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0123716 Vali Loss: 0.0196991 Test Loss: 0.1294013\n",
      "Validation loss decreased (0.029391 --> 0.019699).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0114673\n",
      "\tspeed: 0.0740s/iter; left time: 435.4608s\n",
      "\titers: 200, epoch: 6 | loss: 0.0157558\n",
      "\tspeed: 0.0751s/iter; left time: 434.8097s\n",
      "\titers: 300, epoch: 6 | loss: 0.0128541\n",
      "\tspeed: 0.0758s/iter; left time: 431.2569s\n",
      "Epoch: 6 cost time: 30.291850090026855\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0115265 Vali Loss: 0.0198475 Test Loss: 0.1314290\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0108266\n",
      "\tspeed: 0.0712s/iter; left time: 390.4846s\n",
      "\titers: 200, epoch: 7 | loss: 0.0106392\n",
      "\tspeed: 0.0683s/iter; left time: 368.0048s\n",
      "\titers: 300, epoch: 7 | loss: 0.0108456\n",
      "\tspeed: 0.0710s/iter; left time: 375.2243s\n",
      "Epoch: 7 cost time: 28.401888370513916\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0104614 Vali Loss: 0.0188133 Test Loss: 0.1003759\n",
      "Validation loss decreased (0.019699 --> 0.018813).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0083628\n",
      "\tspeed: 0.0739s/iter; left time: 376.1948s\n",
      "\titers: 200, epoch: 8 | loss: 0.0093670\n",
      "\tspeed: 0.0737s/iter; left time: 367.8216s\n",
      "\titers: 300, epoch: 8 | loss: 0.0097617\n",
      "\tspeed: 0.0755s/iter; left time: 369.2109s\n",
      "Epoch: 8 cost time: 29.87922167778015\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0102516 Vali Loss: 0.0157923 Test Loss: 0.1068584\n",
      "Validation loss decreased (0.018813 --> 0.015792).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0107442\n",
      "\tspeed: 0.0727s/iter; left time: 340.8983s\n",
      "\titers: 200, epoch: 9 | loss: 0.0111018\n",
      "\tspeed: 0.0725s/iter; left time: 332.6757s\n",
      "\titers: 300, epoch: 9 | loss: 0.0097019\n",
      "\tspeed: 0.0717s/iter; left time: 322.0337s\n",
      "Epoch: 9 cost time: 28.95107388496399\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0096382 Vali Loss: 0.0162849 Test Loss: 0.1084872\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.0097988\n",
      "\tspeed: 0.0755s/iter; left time: 323.8006s\n",
      "\titers: 200, epoch: 10 | loss: 0.0080683\n",
      "\tspeed: 0.0764s/iter; left time: 320.2078s\n",
      "\titers: 300, epoch: 10 | loss: 0.0094518\n",
      "\tspeed: 0.0754s/iter; left time: 308.2287s\n",
      "Epoch: 10 cost time: 30.161661624908447\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0093559 Vali Loss: 0.0160968 Test Loss: 0.1097814\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0088704\n",
      "\tspeed: 0.0753s/iter; left time: 293.1288s\n",
      "\titers: 200, epoch: 11 | loss: 0.0093186\n",
      "\tspeed: 0.0756s/iter; left time: 286.7285s\n",
      "\titers: 300, epoch: 11 | loss: 0.0085465\n",
      "\tspeed: 0.0743s/iter; left time: 274.3578s\n",
      "Epoch: 11 cost time: 30.0076904296875\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0090673 Vali Loss: 0.0144772 Test Loss: 0.0982381\n",
      "Validation loss decreased (0.015792 --> 0.014477).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.0088496\n",
      "\tspeed: 0.0761s/iter; left time: 265.7090s\n",
      "\titers: 200, epoch: 12 | loss: 0.0101219\n",
      "\tspeed: 0.0751s/iter; left time: 254.8399s\n",
      "\titers: 300, epoch: 12 | loss: 0.0080580\n",
      "\tspeed: 0.0737s/iter; left time: 242.5204s\n",
      "Epoch: 12 cost time: 29.959295988082886\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0089934 Vali Loss: 0.0159199 Test Loss: 0.1063904\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.0146001\n",
      "\tspeed: 0.0767s/iter; left time: 237.2294s\n",
      "\titers: 200, epoch: 13 | loss: 0.0083869\n",
      "\tspeed: 0.0759s/iter; left time: 227.2055s\n",
      "\titers: 300, epoch: 13 | loss: 0.0083895\n",
      "\tspeed: 0.0743s/iter; left time: 214.9836s\n",
      "Epoch: 13 cost time: 29.456602096557617\n",
      "Epoch: 13, Steps: 399 | Train Loss: 0.0088661 Vali Loss: 0.0145769 Test Loss: 0.0985974\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 14 | loss: 0.0099041\n",
      "\tspeed: 0.0746s/iter; left time: 200.8634s\n",
      "\titers: 200, epoch: 14 | loss: 0.0078486\n",
      "\tspeed: 0.0755s/iter; left time: 195.9054s\n",
      "\titers: 300, epoch: 14 | loss: 0.0104454\n",
      "\tspeed: 0.0734s/iter; left time: 183.0916s\n",
      "Epoch: 14 cost time: 29.597763776779175\n",
      "Epoch: 14, Steps: 399 | Train Loss: 0.0087558 Vali Loss: 0.0168805 Test Loss: 0.1116874\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.09823812544345856, mae:0.23568813502788544\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_il168_pl48_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.1328450\n",
      "\tspeed: 0.0744s/iter; left time: 585.1876s\n",
      "\titers: 200, epoch: 1 | loss: 0.0739274\n",
      "\tspeed: 0.0699s/iter; left time: 542.2948s\n",
      "\titers: 300, epoch: 1 | loss: 0.0438934\n",
      "\tspeed: 0.0696s/iter; left time: 533.5094s\n",
      "Epoch: 1 cost time: 28.1141197681427\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.1124433 Vali Loss: 0.0700408 Test Loss: 0.3319566\n",
      "Validation loss decreased (inf --> 0.070041).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0353558\n",
      "\tspeed: 0.0715s/iter; left time: 533.9144s\n",
      "\titers: 200, epoch: 2 | loss: 0.0316020\n",
      "\tspeed: 0.0709s/iter; left time: 521.8344s\n",
      "\titers: 300, epoch: 2 | loss: 0.0238062\n",
      "\tspeed: 0.0687s/iter; left time: 498.7801s\n",
      "Epoch: 2 cost time: 28.038378953933716\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0291721 Vali Loss: 0.0395755 Test Loss: 0.1694324\n",
      "Validation loss decreased (0.070041 --> 0.039575).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0214035\n",
      "\tspeed: 0.0714s/iter; left time: 504.6682s\n",
      "\titers: 200, epoch: 3 | loss: 0.0178582\n",
      "\tspeed: 0.0675s/iter; left time: 470.2342s\n",
      "\titers: 300, epoch: 3 | loss: 0.0154584\n",
      "\tspeed: 0.0675s/iter; left time: 463.5588s\n",
      "Epoch: 3 cost time: 27.241353750228882\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0188034 Vali Loss: 0.0429191 Test Loss: 0.2132419\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.0195837\n",
      "\tspeed: 0.0707s/iter; left time: 471.2904s\n",
      "\titers: 200, epoch: 4 | loss: 0.0205591\n",
      "\tspeed: 0.0754s/iter; left time: 495.0926s\n",
      "\titers: 300, epoch: 4 | loss: 0.0145106\n",
      "\tspeed: 0.0729s/iter; left time: 471.3669s\n",
      "Epoch: 4 cost time: 29.146589040756226\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0159249 Vali Loss: 0.0355344 Test Loss: 0.2095440\n",
      "Validation loss decreased (0.039575 --> 0.035534).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0135605\n",
      "\tspeed: 0.0704s/iter; left time: 441.4000s\n",
      "\titers: 200, epoch: 5 | loss: 0.0100965\n",
      "\tspeed: 0.0734s/iter; left time: 452.8575s\n",
      "\titers: 300, epoch: 5 | loss: 0.0136888\n",
      "\tspeed: 0.0705s/iter; left time: 427.5623s\n",
      "Epoch: 5 cost time: 28.384679794311523\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0135176 Vali Loss: 0.0320629 Test Loss: 0.1745151\n",
      "Validation loss decreased (0.035534 --> 0.032063).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0103213\n",
      "\tspeed: 0.0709s/iter; left time: 415.9672s\n",
      "\titers: 200, epoch: 6 | loss: 0.0138666\n",
      "\tspeed: 0.0744s/iter; left time: 429.4710s\n",
      "\titers: 300, epoch: 6 | loss: 0.0167966\n",
      "\tspeed: 0.0748s/iter; left time: 423.9077s\n",
      "Epoch: 6 cost time: 29.3955340385437\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0127720 Vali Loss: 0.0312591 Test Loss: 0.1919878\n",
      "Validation loss decreased (0.032063 --> 0.031259).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0118075\n",
      "\tspeed: 0.0726s/iter; left time: 397.3075s\n",
      "\titers: 200, epoch: 7 | loss: 0.0101971\n",
      "\tspeed: 0.0712s/iter; left time: 382.3661s\n",
      "\titers: 300, epoch: 7 | loss: 0.0131607\n",
      "\tspeed: 0.0722s/iter; left time: 380.8218s\n",
      "Epoch: 7 cost time: 28.849363327026367\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0114780 Vali Loss: 0.0166185 Test Loss: 0.1005558\n",
      "Validation loss decreased (0.031259 --> 0.016619).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0142551\n",
      "\tspeed: 0.0714s/iter; left time: 362.5800s\n",
      "\titers: 200, epoch: 8 | loss: 0.0108191\n",
      "\tspeed: 0.0728s/iter; left time: 362.1583s\n",
      "\titers: 300, epoch: 8 | loss: 0.0106080\n",
      "\tspeed: 0.0747s/iter; left time: 364.2230s\n",
      "Epoch: 8 cost time: 29.257927417755127\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0111545 Vali Loss: 0.0169256 Test Loss: 0.1184508\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0098906\n",
      "\tspeed: 0.0704s/iter; left time: 329.4555s\n",
      "\titers: 200, epoch: 9 | loss: 0.0104522\n",
      "\tspeed: 0.0682s/iter; left time: 312.3119s\n",
      "\titers: 300, epoch: 9 | loss: 0.0108477\n",
      "\tspeed: 0.0699s/iter; left time: 313.0812s\n",
      "Epoch: 9 cost time: 27.8098623752594\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0105737 Vali Loss: 0.0299884 Test Loss: 0.1765711\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.0094151\n",
      "\tspeed: 0.0695s/iter; left time: 297.3936s\n",
      "\titers: 200, epoch: 10 | loss: 0.0084347\n",
      "\tspeed: 0.0713s/iter; left time: 297.9586s\n",
      "\titers: 300, epoch: 10 | loss: 0.0106467\n",
      "\tspeed: 0.0737s/iter; left time: 300.5372s\n",
      "Epoch: 10 cost time: 28.648550748825073\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.0104816 Vali Loss: 0.0181281 Test Loss: 0.1278309\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.10055576264858246, mae:0.24045059084892273\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_il168_pl168_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.1555612\n",
      "\tspeed: 0.0751s/iter; left time: 584.2456s\n",
      "\titers: 200, epoch: 1 | loss: 0.1089802\n",
      "\tspeed: 0.0706s/iter; left time: 542.5657s\n",
      "\titers: 300, epoch: 1 | loss: 0.0933125\n",
      "\tspeed: 0.0703s/iter; left time: 533.1938s\n",
      "Epoch: 1 cost time: 28.386855125427246\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.1477105 Vali Loss: 0.2982433 Test Loss: 1.0264199\n",
      "Validation loss decreased (inf --> 0.298243).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0564557\n",
      "\tspeed: 0.0737s/iter; left time: 544.5718s\n",
      "\titers: 200, epoch: 2 | loss: 0.0434064\n",
      "\tspeed: 0.0706s/iter; left time: 514.2142s\n",
      "\titers: 300, epoch: 2 | loss: 0.0414571\n",
      "\tspeed: 0.0714s/iter; left time: 513.4446s\n",
      "Epoch: 2 cost time: 28.83941078186035\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0473532 Vali Loss: 0.1142768 Test Loss: 0.4328703\n",
      "Validation loss decreased (0.298243 --> 0.114277).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0371049\n",
      "\tspeed: 0.0744s/iter; left time: 520.3770s\n",
      "\titers: 200, epoch: 3 | loss: 0.0329878\n",
      "\tspeed: 0.0729s/iter; left time: 502.2210s\n",
      "\titers: 300, epoch: 3 | loss: 0.0254648\n",
      "\tspeed: 0.0714s/iter; left time: 484.7651s\n",
      "Epoch: 3 cost time: 28.608652353286743\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0341863 Vali Loss: 0.0952498 Test Loss: 0.4083554\n",
      "Validation loss decreased (0.114277 --> 0.095250).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0362344\n",
      "\tspeed: 0.0739s/iter; left time: 487.8615s\n",
      "\titers: 200, epoch: 4 | loss: 0.0236270\n",
      "\tspeed: 0.0722s/iter; left time: 469.1683s\n",
      "\titers: 300, epoch: 4 | loss: 0.0323972\n",
      "\tspeed: 0.0743s/iter; left time: 475.2050s\n",
      "Epoch: 4 cost time: 29.20103693008423\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0307656 Vali Loss: 0.0930243 Test Loss: 0.4535389\n",
      "Validation loss decreased (0.095250 --> 0.093024).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0350593\n",
      "\tspeed: 0.0748s/iter; left time: 464.4358s\n",
      "\titers: 200, epoch: 5 | loss: 0.0241181\n",
      "\tspeed: 0.0718s/iter; left time: 438.6000s\n",
      "\titers: 300, epoch: 5 | loss: 0.0243705\n",
      "\tspeed: 0.0717s/iter; left time: 430.7608s\n",
      "Epoch: 5 cost time: 28.63218355178833\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0263850 Vali Loss: 0.0964973 Test Loss: 0.4779645\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0272919\n",
      "\tspeed: 0.0712s/iter; left time: 413.8236s\n",
      "\titers: 200, epoch: 6 | loss: 0.0228394\n",
      "\tspeed: 0.0718s/iter; left time: 410.1176s\n",
      "\titers: 300, epoch: 6 | loss: 0.0220226\n",
      "\tspeed: 0.0732s/iter; left time: 410.7067s\n",
      "Epoch: 6 cost time: 28.74384045600891\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0249522 Vali Loss: 0.0876427 Test Loss: 0.4999666\n",
      "Validation loss decreased (0.093024 --> 0.087643).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0243443\n",
      "\tspeed: 0.0787s/iter; left time: 426.5832s\n",
      "\titers: 200, epoch: 7 | loss: 0.0199626\n",
      "\tspeed: 0.0785s/iter; left time: 417.3094s\n",
      "\titers: 300, epoch: 7 | loss: 0.0187263\n",
      "\tspeed: 0.0773s/iter; left time: 403.3487s\n",
      "Epoch: 7 cost time: 30.54478144645691\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0228604 Vali Loss: 0.0730818 Test Loss: 0.4274611\n",
      "Validation loss decreased (0.087643 --> 0.073082).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0281254\n",
      "\tspeed: 0.0737s/iter; left time: 370.3833s\n",
      "\titers: 200, epoch: 8 | loss: 0.0230504\n",
      "\tspeed: 0.0727s/iter; left time: 358.1314s\n",
      "\titers: 300, epoch: 8 | loss: 0.0213408\n",
      "\tspeed: 0.0684s/iter; left time: 329.7841s\n",
      "Epoch: 8 cost time: 28.43180537223816\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0223548 Vali Loss: 0.0768223 Test Loss: 0.4572923\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0164026\n",
      "\tspeed: 0.0730s/iter; left time: 337.9162s\n",
      "\titers: 200, epoch: 9 | loss: 0.0222946\n",
      "\tspeed: 0.0733s/iter; left time: 331.8272s\n",
      "\titers: 300, epoch: 9 | loss: 0.0224736\n",
      "\tspeed: 0.0724s/iter; left time: 320.7790s\n",
      "Epoch: 9 cost time: 28.73518180847168\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0214509 Vali Loss: 0.0652070 Test Loss: 0.4098935\n",
      "Validation loss decreased (0.073082 --> 0.065207).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0187407\n",
      "\tspeed: 0.0731s/iter; left time: 309.4653s\n",
      "\titers: 200, epoch: 10 | loss: 0.0237160\n",
      "\tspeed: 0.0744s/iter; left time: 307.5325s\n",
      "\titers: 300, epoch: 10 | loss: 0.0228647\n",
      "\tspeed: 0.0744s/iter; left time: 300.0443s\n",
      "Epoch: 10 cost time: 29.440309524536133\n",
      "Epoch: 10, Steps: 394 | Train Loss: 0.0210269 Vali Loss: 0.0649080 Test Loss: 0.3900673\n",
      "Validation loss decreased (0.065207 --> 0.064908).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0179010\n",
      "\tspeed: 0.0774s/iter; left time: 297.3258s\n",
      "\titers: 200, epoch: 11 | loss: 0.0189601\n",
      "\tspeed: 0.0778s/iter; left time: 290.9866s\n",
      "\titers: 300, epoch: 11 | loss: 0.0203516\n",
      "\tspeed: 0.0785s/iter; left time: 285.8710s\n",
      "Epoch: 11 cost time: 30.410674333572388\n",
      "Epoch: 11, Steps: 394 | Train Loss: 0.0205163 Vali Loss: 0.0716047 Test Loss: 0.4457649\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.0231971\n",
      "\tspeed: 0.0731s/iter; left time: 252.1092s\n",
      "\titers: 200, epoch: 12 | loss: 0.0219197\n",
      "\tspeed: 0.0742s/iter; left time: 248.2082s\n",
      "\titers: 300, epoch: 12 | loss: 0.0219642\n",
      "\tspeed: 0.0710s/iter; left time: 230.6218s\n",
      "Epoch: 12 cost time: 28.972702264785767\n",
      "Epoch: 12, Steps: 394 | Train Loss: 0.0203504 Vali Loss: 0.0775348 Test Loss: 0.4770283\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.0224012\n",
      "\tspeed: 0.0753s/iter; left time: 229.9710s\n",
      "\titers: 200, epoch: 13 | loss: 0.0170665\n",
      "\tspeed: 0.0763s/iter; left time: 225.3980s\n",
      "\titers: 300, epoch: 13 | loss: 0.0184122\n",
      "\tspeed: 0.0740s/iter; left time: 211.1911s\n",
      "Epoch: 13 cost time: 29.476627588272095\n",
      "Epoch: 13, Steps: 394 | Train Loss: 0.0201326 Vali Loss: 0.0783014 Test Loss: 0.4720198\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.3900672495365143, mae:0.507689356803894\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_il168_pl336_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.2215290\n",
      "\tspeed: 0.0705s/iter; left time: 541.6879s\n",
      "\titers: 200, epoch: 1 | loss: 0.1446963\n",
      "\tspeed: 0.0737s/iter; left time: 558.9859s\n",
      "\titers: 300, epoch: 1 | loss: 0.1013069\n",
      "\tspeed: 0.0732s/iter; left time: 547.6473s\n",
      "Epoch: 1 cost time: 28.607093811035156\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1732895 Vali Loss: 0.3255825 Test Loss: 1.2381706\n",
      "Validation loss decreased (inf --> 0.325582).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.1049781\n",
      "\tspeed: 0.0760s/iter; left time: 554.4929s\n",
      "\titers: 200, epoch: 2 | loss: 0.0670419\n",
      "\tspeed: 0.0774s/iter; left time: 556.6628s\n",
      "\titers: 300, epoch: 2 | loss: 0.0617847\n",
      "\tspeed: 0.0780s/iter; left time: 553.2093s\n",
      "Epoch: 2 cost time: 29.533250093460083\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0732258 Vali Loss: 0.2426947 Test Loss: 0.7157286\n",
      "Validation loss decreased (0.325582 --> 0.242695).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0492069\n",
      "\tspeed: 0.0729s/iter; left time: 503.4884s\n",
      "\titers: 200, epoch: 3 | loss: 0.0545150\n",
      "\tspeed: 0.0743s/iter; left time: 505.1859s\n",
      "\titers: 300, epoch: 3 | loss: 0.0554284\n",
      "\tspeed: 0.0724s/iter; left time: 485.5375s\n",
      "Epoch: 3 cost time: 28.69692373275757\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0568288 Vali Loss: 0.1287910 Test Loss: 0.4376967\n",
      "Validation loss decreased (0.242695 --> 0.128791).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0520268\n",
      "\tspeed: 0.0771s/iter; left time: 502.4475s\n",
      "\titers: 200, epoch: 4 | loss: 0.0496750\n",
      "\tspeed: 0.0783s/iter; left time: 502.0171s\n",
      "\titers: 300, epoch: 4 | loss: 0.0445591\n",
      "\tspeed: 0.0789s/iter; left time: 497.8637s\n",
      "Epoch: 4 cost time: 30.270485401153564\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0510914 Vali Loss: 0.2267623 Test Loss: 0.7925658\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0507235\n",
      "\tspeed: 0.0765s/iter; left time: 468.5104s\n",
      "\titers: 200, epoch: 5 | loss: 0.0428249\n",
      "\tspeed: 0.0778s/iter; left time: 468.7591s\n",
      "\titers: 300, epoch: 5 | loss: 0.0409280\n",
      "\tspeed: 0.0735s/iter; left time: 435.2929s\n",
      "Epoch: 5 cost time: 29.15634536743164\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0444004 Vali Loss: 0.1933311 Test Loss: 0.6617704\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0428091\n",
      "\tspeed: 0.0759s/iter; left time: 435.5501s\n",
      "\titers: 200, epoch: 6 | loss: 0.0366532\n",
      "\tspeed: 0.0789s/iter; left time: 444.7774s\n",
      "\titers: 300, epoch: 6 | loss: 0.0424175\n",
      "\tspeed: 0.0782s/iter; left time: 432.7912s\n",
      "Epoch: 6 cost time: 29.505720853805542\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0420654 Vali Loss: 0.1932314 Test Loss: 0.7253890\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.4376966953277588, mae:0.5251463651657104\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_il168_pl720_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.1877224\n",
      "\tspeed: 0.0739s/iter; left time: 549.5968s\n",
      "\titers: 200, epoch: 1 | loss: 0.1620519\n",
      "\tspeed: 0.0822s/iter; left time: 603.2536s\n",
      "\titers: 300, epoch: 1 | loss: 0.1015060\n",
      "\tspeed: 0.0810s/iter; left time: 586.7061s\n",
      "Epoch: 1 cost time: 29.95662260055542\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.1653236 Vali Loss: 0.2537379 Test Loss: 0.9858011\n",
      "Validation loss decreased (inf --> 0.253738).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0611173\n",
      "\tspeed: 0.0843s/iter; left time: 595.2152s\n",
      "\titers: 200, epoch: 2 | loss: 0.0678124\n",
      "\tspeed: 0.0827s/iter; left time: 575.9206s\n",
      "\titers: 300, epoch: 2 | loss: 0.0480352\n",
      "\tspeed: 0.0828s/iter; left time: 568.0316s\n",
      "Epoch: 2 cost time: 31.48555898666382\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0627507 Vali Loss: 0.1981001 Test Loss: 0.7110418\n",
      "Validation loss decreased (0.253738 --> 0.198100).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0472913\n",
      "\tspeed: 0.0841s/iter; left time: 562.5513s\n",
      "\titers: 200, epoch: 3 | loss: 0.0400917\n",
      "\tspeed: 0.0777s/iter; left time: 511.7917s\n",
      "\titers: 300, epoch: 3 | loss: 0.0434419\n",
      "\tspeed: 0.0785s/iter; left time: 509.2318s\n",
      "Epoch: 3 cost time: 30.19413995742798\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0467958 Vali Loss: 0.1252849 Test Loss: 0.4793908\n",
      "Validation loss decreased (0.198100 --> 0.125285).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0309284\n",
      "\tspeed: 0.0819s/iter; left time: 516.8624s\n",
      "\titers: 200, epoch: 4 | loss: 0.0405648\n",
      "\tspeed: 0.0819s/iter; left time: 508.6414s\n",
      "\titers: 300, epoch: 4 | loss: 0.0398106\n",
      "\tspeed: 0.0802s/iter; left time: 490.1635s\n",
      "Epoch: 4 cost time: 30.430278062820435\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0411789 Vali Loss: 0.1535993 Test Loss: 0.6447393\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0348514\n",
      "\tspeed: 0.0761s/iter; left time: 451.2384s\n",
      "\titers: 200, epoch: 5 | loss: 0.0331388\n",
      "\tspeed: 0.0769s/iter; left time: 448.7280s\n",
      "\titers: 300, epoch: 5 | loss: 0.0380111\n",
      "\tspeed: 0.0760s/iter; left time: 435.7717s\n",
      "Epoch: 5 cost time: 28.893831968307495\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0359799 Vali Loss: 0.1851865 Test Loss: 0.7517140\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0356588\n",
      "\tspeed: 0.0812s/iter; left time: 451.0221s\n",
      "\titers: 200, epoch: 6 | loss: 0.0313200\n",
      "\tspeed: 0.0815s/iter; left time: 444.8181s\n",
      "\titers: 300, epoch: 6 | loss: 0.0291130\n",
      "\tspeed: 0.0821s/iter; left time: 439.7686s\n",
      "Epoch: 6 cost time: 30.913743495941162\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0338829 Vali Loss: 0.1776791 Test Loss: 0.6946144\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.4793908894062042, mae:0.5598621368408203\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il168_pl24_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.1032530\n",
      "\tspeed: 0.0793s/iter; left time: 624.7028s\n",
      "\titers: 200, epoch: 1 | loss: 0.0614113\n",
      "\tspeed: 0.0718s/iter; left time: 559.0433s\n",
      "\titers: 300, epoch: 1 | loss: 0.0458146\n",
      "\tspeed: 0.0707s/iter; left time: 542.8573s\n",
      "Epoch: 1 cost time: 29.39724111557007\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.1057679 Vali Loss: 0.1415089 Test Loss: 0.3942864\n",
      "Validation loss decreased (inf --> 0.141509).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0281383\n",
      "\tspeed: 0.0729s/iter; left time: 545.1497s\n",
      "\titers: 200, epoch: 2 | loss: 0.0312423\n",
      "\tspeed: 0.0735s/iter; left time: 542.6083s\n",
      "\titers: 300, epoch: 2 | loss: 0.0200936\n",
      "\tspeed: 0.0704s/iter; left time: 512.9205s\n",
      "Epoch: 2 cost time: 28.794069051742554\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0279406 Vali Loss: 0.1089076 Test Loss: 0.3169608\n",
      "Validation loss decreased (0.141509 --> 0.108908).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0148075\n",
      "\tspeed: 0.0723s/iter; left time: 511.9743s\n",
      "\titers: 200, epoch: 3 | loss: 0.0172506\n",
      "\tspeed: 0.0732s/iter; left time: 510.8728s\n",
      "\titers: 300, epoch: 3 | loss: 0.0166157\n",
      "\tspeed: 0.0730s/iter; left time: 502.3664s\n",
      "Epoch: 3 cost time: 29.322663068771362\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0185148 Vali Loss: 0.1009541 Test Loss: 0.2888790\n",
      "Validation loss decreased (0.108908 --> 0.100954).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0163630\n",
      "\tspeed: 0.0766s/iter; left time: 511.9250s\n",
      "\titers: 200, epoch: 4 | loss: 0.0133340\n",
      "\tspeed: 0.0770s/iter; left time: 507.0044s\n",
      "\titers: 300, epoch: 4 | loss: 0.0155530\n",
      "\tspeed: 0.0765s/iter; left time: 495.8026s\n",
      "Epoch: 4 cost time: 30.582682371139526\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0162304 Vali Loss: 0.0922552 Test Loss: 0.2764868\n",
      "Validation loss decreased (0.100954 --> 0.092255).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0156125\n",
      "\tspeed: 0.0768s/iter; left time: 482.4994s\n",
      "\titers: 200, epoch: 5 | loss: 0.0117062\n",
      "\tspeed: 0.0718s/iter; left time: 444.1784s\n",
      "\titers: 300, epoch: 5 | loss: 0.0099637\n",
      "\tspeed: 0.0714s/iter; left time: 434.3038s\n",
      "Epoch: 5 cost time: 29.15445590019226\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0137698 Vali Loss: 0.0890701 Test Loss: 0.2688804\n",
      "Validation loss decreased (0.092255 --> 0.089070).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0162445\n",
      "\tspeed: 0.0728s/iter; left time: 428.6723s\n",
      "\titers: 200, epoch: 6 | loss: 0.0123825\n",
      "\tspeed: 0.0736s/iter; left time: 425.7508s\n",
      "\titers: 300, epoch: 6 | loss: 0.0117450\n",
      "\tspeed: 0.0736s/iter; left time: 418.4034s\n",
      "Epoch: 6 cost time: 29.29044508934021\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0131594 Vali Loss: 0.0910389 Test Loss: 0.2723936\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0107356\n",
      "\tspeed: 0.0727s/iter; left time: 398.9864s\n",
      "\titers: 200, epoch: 7 | loss: 0.0106411\n",
      "\tspeed: 0.0735s/iter; left time: 395.9927s\n",
      "\titers: 300, epoch: 7 | loss: 0.0103243\n",
      "\tspeed: 0.0730s/iter; left time: 386.2068s\n",
      "Epoch: 7 cost time: 29.178393602371216\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0118539 Vali Loss: 0.0864543 Test Loss: 0.2557860\n",
      "Validation loss decreased (0.089070 --> 0.086454).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0116097\n",
      "\tspeed: 0.0753s/iter; left time: 382.9676s\n",
      "\titers: 200, epoch: 8 | loss: 0.0087459\n",
      "\tspeed: 0.0773s/iter; left time: 385.7343s\n",
      "\titers: 300, epoch: 8 | loss: 0.0093113\n",
      "\tspeed: 0.0729s/iter; left time: 356.2667s\n",
      "Epoch: 8 cost time: 29.512552738189697\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0114586 Vali Loss: 0.0911532 Test Loss: 0.2688506\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0100950\n",
      "\tspeed: 0.0766s/iter; left time: 358.9723s\n",
      "\titers: 200, epoch: 9 | loss: 0.0097491\n",
      "\tspeed: 0.0752s/iter; left time: 345.2883s\n",
      "\titers: 300, epoch: 9 | loss: 0.0118251\n",
      "\tspeed: 0.0686s/iter; left time: 308.1131s\n",
      "Epoch: 9 cost time: 28.72717571258545\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0111011 Vali Loss: 0.0829227 Test Loss: 0.2411534\n",
      "Validation loss decreased (0.086454 --> 0.082923).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0105890\n",
      "\tspeed: 0.0758s/iter; left time: 325.0368s\n",
      "\titers: 200, epoch: 10 | loss: 0.0110935\n",
      "\tspeed: 0.0760s/iter; left time: 318.6177s\n",
      "\titers: 300, epoch: 10 | loss: 0.0104972\n",
      "\tspeed: 0.0769s/iter; left time: 314.4529s\n",
      "Epoch: 10 cost time: 30.56349468231201\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0107756 Vali Loss: 0.0852797 Test Loss: 0.2540137\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0087027\n",
      "\tspeed: 0.0762s/iter; left time: 296.4479s\n",
      "\titers: 200, epoch: 11 | loss: 0.0111572\n",
      "\tspeed: 0.0806s/iter; left time: 305.4948s\n",
      "\titers: 300, epoch: 11 | loss: 0.0077595\n",
      "\tspeed: 0.0730s/iter; left time: 269.5021s\n",
      "Epoch: 11 cost time: 30.466728687286377\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0104826 Vali Loss: 0.0827540 Test Loss: 0.2420557\n",
      "Validation loss decreased (0.082923 --> 0.082754).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.0086116\n",
      "\tspeed: 0.0766s/iter; left time: 267.4500s\n",
      "\titers: 200, epoch: 12 | loss: 0.0089972\n",
      "\tspeed: 0.0746s/iter; left time: 253.0186s\n",
      "\titers: 300, epoch: 12 | loss: 0.0081952\n",
      "\tspeed: 0.0765s/iter; left time: 251.7399s\n",
      "Epoch: 12 cost time: 30.479586601257324\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0104214 Vali Loss: 0.0838791 Test Loss: 0.2521182\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.0070574\n",
      "\tspeed: 0.0682s/iter; left time: 210.9074s\n",
      "\titers: 200, epoch: 13 | loss: 0.0096245\n",
      "\tspeed: 0.0714s/iter; left time: 213.6249s\n",
      "\titers: 300, epoch: 13 | loss: 0.0114733\n",
      "\tspeed: 0.0681s/iter; left time: 196.8902s\n",
      "Epoch: 13 cost time: 27.92301344871521\n",
      "Epoch: 13, Steps: 399 | Train Loss: 0.0102941 Vali Loss: 0.0841684 Test Loss: 0.2549941\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 14 | loss: 0.0072988\n",
      "\tspeed: 0.0743s/iter; left time: 200.2304s\n",
      "\titers: 200, epoch: 14 | loss: 0.0080499\n",
      "\tspeed: 0.0718s/iter; left time: 186.2039s\n",
      "\titers: 300, epoch: 14 | loss: 0.0094887\n",
      "\tspeed: 0.0768s/iter; left time: 191.6087s\n",
      "Epoch: 14 cost time: 29.718010663986206\n",
      "Epoch: 14, Steps: 399 | Train Loss: 0.0101813 Vali Loss: 0.0804439 Test Loss: 0.2351311\n",
      "Validation loss decreased (0.082754 --> 0.080444).  Saving model ...\n",
      "\titers: 100, epoch: 15 | loss: 0.0074860\n",
      "\tspeed: 0.0727s/iter; left time: 166.8500s\n",
      "\titers: 200, epoch: 15 | loss: 0.0087886\n",
      "\tspeed: 0.0717s/iter; left time: 157.3552s\n",
      "\titers: 300, epoch: 15 | loss: 0.0094922\n",
      "\tspeed: 0.0721s/iter; left time: 151.1220s\n",
      "Epoch: 15 cost time: 28.905124187469482\n",
      "Epoch: 15, Steps: 399 | Train Loss: 0.0101012 Vali Loss: 0.0813660 Test Loss: 0.2342579\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 16 | loss: 0.0091180\n",
      "\tspeed: 0.0750s/iter; left time: 142.1490s\n",
      "\titers: 200, epoch: 16 | loss: 0.0092579\n",
      "\tspeed: 0.0738s/iter; left time: 132.5697s\n",
      "\titers: 300, epoch: 16 | loss: 0.0077879\n",
      "\tspeed: 0.0729s/iter; left time: 123.5851s\n",
      "Epoch: 16 cost time: 29.38546848297119\n",
      "Epoch: 16, Steps: 399 | Train Loss: 0.0099670 Vali Loss: 0.0806424 Test Loss: 0.2345044\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 17 | loss: 0.0099105\n",
      "\tspeed: 0.0707s/iter; left time: 105.8054s\n",
      "\titers: 200, epoch: 17 | loss: 0.0069601\n",
      "\tspeed: 0.0722s/iter; left time: 100.8124s\n",
      "\titers: 300, epoch: 17 | loss: 0.0128523\n",
      "\tspeed: 0.0727s/iter; left time: 94.3320s\n",
      "Epoch: 17 cost time: 28.829335927963257\n",
      "Epoch: 17, Steps: 399 | Train Loss: 0.0099563 Vali Loss: 0.0833629 Test Loss: 0.2446213\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.23513111472129822, mae:0.31250643730163574\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il168_pl48_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.1759879\n",
      "\tspeed: 0.0807s/iter; left time: 634.5570s\n",
      "\titers: 200, epoch: 1 | loss: 0.0660221\n",
      "\tspeed: 0.0759s/iter; left time: 589.2846s\n",
      "\titers: 300, epoch: 1 | loss: 0.0700714\n",
      "\tspeed: 0.0751s/iter; left time: 575.1024s\n",
      "Epoch: 1 cost time: 30.47341275215149\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.1152585 Vali Loss: 0.2017604 Test Loss: 0.5038751\n",
      "Validation loss decreased (inf --> 0.201760).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0392435\n",
      "\tspeed: 0.0709s/iter; left time: 529.3274s\n",
      "\titers: 200, epoch: 2 | loss: 0.0397932\n",
      "\tspeed: 0.0677s/iter; left time: 498.1996s\n",
      "\titers: 300, epoch: 2 | loss: 0.0226576\n",
      "\tspeed: 0.0725s/iter; left time: 526.7045s\n",
      "Epoch: 2 cost time: 28.343406677246094\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0336316 Vali Loss: 0.1504587 Test Loss: 0.4245456\n",
      "Validation loss decreased (0.201760 --> 0.150459).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0200727\n",
      "\tspeed: 0.0799s/iter; left time: 564.3401s\n",
      "\titers: 200, epoch: 3 | loss: 0.0203413\n",
      "\tspeed: 0.0744s/iter; left time: 518.0352s\n",
      "\titers: 300, epoch: 3 | loss: 0.0218668\n",
      "\tspeed: 0.0763s/iter; left time: 524.1024s\n",
      "Epoch: 3 cost time: 30.324267387390137\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0229544 Vali Loss: 0.1556817 Test Loss: 0.3845871\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.0229700\n",
      "\tspeed: 0.0707s/iter; left time: 471.3093s\n",
      "\titers: 200, epoch: 4 | loss: 0.0204921\n",
      "\tspeed: 0.0725s/iter; left time: 476.1670s\n",
      "\titers: 300, epoch: 4 | loss: 0.0160204\n",
      "\tspeed: 0.0713s/iter; left time: 460.7822s\n",
      "Epoch: 4 cost time: 28.290681838989258\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0201969 Vali Loss: 0.1522805 Test Loss: 0.3974662\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0416225\n",
      "\tspeed: 0.0722s/iter; left time: 452.3890s\n",
      "\titers: 200, epoch: 5 | loss: 0.0107945\n",
      "\tspeed: 0.0749s/iter; left time: 462.3003s\n",
      "\titers: 300, epoch: 5 | loss: 0.0174514\n",
      "\tspeed: 0.0721s/iter; left time: 437.6718s\n",
      "Epoch: 5 cost time: 28.914458990097046\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0170862 Vali Loss: 0.1470919 Test Loss: 0.4252558\n",
      "Validation loss decreased (0.150459 --> 0.147092).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0126077\n",
      "\tspeed: 0.0727s/iter; left time: 426.9107s\n",
      "\titers: 200, epoch: 6 | loss: 0.0107863\n",
      "\tspeed: 0.0735s/iter; left time: 424.3795s\n",
      "\titers: 300, epoch: 6 | loss: 0.0125770\n",
      "\tspeed: 0.0739s/iter; left time: 418.8937s\n",
      "Epoch: 6 cost time: 29.06229043006897\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0160205 Vali Loss: 0.1453845 Test Loss: 0.4055638\n",
      "Validation loss decreased (0.147092 --> 0.145384).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0126265\n",
      "\tspeed: 0.0739s/iter; left time: 404.7092s\n",
      "\titers: 200, epoch: 7 | loss: 0.0178554\n",
      "\tspeed: 0.0757s/iter; left time: 406.8175s\n",
      "\titers: 300, epoch: 7 | loss: 0.0272931\n",
      "\tspeed: 0.0741s/iter; left time: 390.9630s\n",
      "Epoch: 7 cost time: 29.26218271255493\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0150771 Vali Loss: 0.1426413 Test Loss: 0.4025692\n",
      "Validation loss decreased (0.145384 --> 0.142641).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0226893\n",
      "\tspeed: 0.0717s/iter; left time: 363.9630s\n",
      "\titers: 200, epoch: 8 | loss: 0.0119379\n",
      "\tspeed: 0.0705s/iter; left time: 350.8475s\n",
      "\titers: 300, epoch: 8 | loss: 0.0186624\n",
      "\tspeed: 0.0713s/iter; left time: 347.3796s\n",
      "Epoch: 8 cost time: 28.35985517501831\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0146542 Vali Loss: 0.1536088 Test Loss: 0.4200699\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0123770\n",
      "\tspeed: 0.0705s/iter; left time: 329.6313s\n",
      "\titers: 200, epoch: 9 | loss: 0.0132251\n",
      "\tspeed: 0.0752s/iter; left time: 344.2307s\n",
      "\titers: 300, epoch: 9 | loss: 0.0164618\n",
      "\tspeed: 0.0711s/iter; left time: 318.4910s\n",
      "Epoch: 9 cost time: 28.78372359275818\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0139822 Vali Loss: 0.1525507 Test Loss: 0.4353808\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.0169972\n",
      "\tspeed: 0.0708s/iter; left time: 302.8766s\n",
      "\titers: 200, epoch: 10 | loss: 0.0108118\n",
      "\tspeed: 0.0733s/iter; left time: 306.2997s\n",
      "\titers: 300, epoch: 10 | loss: 0.0113071\n",
      "\tspeed: 0.0740s/iter; left time: 302.0436s\n",
      "Epoch: 10 cost time: 28.997793197631836\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.0138048 Vali Loss: 0.1439192 Test Loss: 0.3997292\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.4025692343711853, mae:0.43576738238334656\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il168_pl168_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.2069060\n",
      "\tspeed: 0.0747s/iter; left time: 581.5225s\n",
      "\titers: 200, epoch: 1 | loss: 0.1133528\n",
      "\tspeed: 0.0742s/iter; left time: 569.9027s\n",
      "\titers: 300, epoch: 1 | loss: 0.0818365\n",
      "\tspeed: 0.0769s/iter; left time: 583.1562s\n",
      "Epoch: 1 cost time: 29.82828950881958\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.1542501 Vali Loss: 0.4041195 Test Loss: 0.9247547\n",
      "Validation loss decreased (inf --> 0.404120).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0636618\n",
      "\tspeed: 0.0750s/iter; left time: 553.6792s\n",
      "\titers: 200, epoch: 2 | loss: 0.0644914\n",
      "\tspeed: 0.0742s/iter; left time: 540.5841s\n",
      "\titers: 300, epoch: 2 | loss: 0.0584106\n",
      "\tspeed: 0.0725s/iter; left time: 521.3519s\n",
      "Epoch: 2 cost time: 29.16333246231079\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0571590 Vali Loss: 0.3496130 Test Loss: 0.7400019\n",
      "Validation loss decreased (0.404120 --> 0.349613).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0333648\n",
      "\tspeed: 0.0734s/iter; left time: 513.1914s\n",
      "\titers: 200, epoch: 3 | loss: 0.0344589\n",
      "\tspeed: 0.0750s/iter; left time: 516.8319s\n",
      "\titers: 300, epoch: 3 | loss: 0.0262585\n",
      "\tspeed: 0.0744s/iter; left time: 505.5638s\n",
      "Epoch: 3 cost time: 29.181212425231934\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0433071 Vali Loss: 0.3391235 Test Loss: 0.7297036\n",
      "Validation loss decreased (0.349613 --> 0.339124).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0347913\n",
      "\tspeed: 0.0742s/iter; left time: 489.9612s\n",
      "\titers: 200, epoch: 4 | loss: 0.0463365\n",
      "\tspeed: 0.0715s/iter; left time: 464.4100s\n",
      "\titers: 300, epoch: 4 | loss: 0.0517348\n",
      "\tspeed: 0.0742s/iter; left time: 474.6109s\n",
      "Epoch: 4 cost time: 28.9867742061615\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0401558 Vali Loss: 0.3513729 Test Loss: 0.9543475\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0568945\n",
      "\tspeed: 0.0724s/iter; left time: 449.3287s\n",
      "\titers: 200, epoch: 5 | loss: 0.0229284\n",
      "\tspeed: 0.0731s/iter; left time: 446.1308s\n",
      "\titers: 300, epoch: 5 | loss: 0.0383980\n",
      "\tspeed: 0.0730s/iter; left time: 438.6190s\n",
      "Epoch: 5 cost time: 28.69752526283264\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0354040 Vali Loss: 0.3643104 Test Loss: 1.0257124\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0273770\n",
      "\tspeed: 0.0719s/iter; left time: 417.5781s\n",
      "\titers: 200, epoch: 6 | loss: 0.0276327\n",
      "\tspeed: 0.0725s/iter; left time: 414.1748s\n",
      "\titers: 300, epoch: 6 | loss: 0.0303995\n",
      "\tspeed: 0.0744s/iter; left time: 417.3792s\n",
      "Epoch: 6 cost time: 28.978190183639526\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0339402 Vali Loss: 0.3506313 Test Loss: 1.0248304\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.7297034859657288, mae:0.6445755362510681\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il168_pl336_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.2249907\n",
      "\tspeed: 0.0788s/iter; left time: 605.2089s\n",
      "\titers: 200, epoch: 1 | loss: 0.1779469\n",
      "\tspeed: 0.0751s/iter; left time: 569.0316s\n",
      "\titers: 300, epoch: 1 | loss: 0.1270201\n",
      "\tspeed: 0.0750s/iter; left time: 560.8028s\n",
      "Epoch: 1 cost time: 29.707351446151733\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1993982 Vali Loss: 0.6880810 Test Loss: 1.4301016\n",
      "Validation loss decreased (inf --> 0.688081).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0940535\n",
      "\tspeed: 0.0742s/iter; left time: 541.4122s\n",
      "\titers: 200, epoch: 2 | loss: 0.1040140\n",
      "\tspeed: 0.0752s/iter; left time: 541.1342s\n",
      "\titers: 300, epoch: 2 | loss: 0.0805032\n",
      "\tspeed: 0.0726s/iter; left time: 514.6515s\n",
      "Epoch: 2 cost time: 28.805697679519653\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0952604 Vali Loss: 0.5758578 Test Loss: 1.2165390\n",
      "Validation loss decreased (0.688081 --> 0.575858).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0700169\n",
      "\tspeed: 0.0730s/iter; left time: 504.0152s\n",
      "\titers: 200, epoch: 3 | loss: 0.0523969\n",
      "\tspeed: 0.0736s/iter; left time: 500.8198s\n",
      "\titers: 300, epoch: 3 | loss: 0.0956035\n",
      "\tspeed: 0.0784s/iter; left time: 525.5991s\n",
      "Epoch: 3 cost time: 29.214281797409058\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0759832 Vali Loss: 0.5460669 Test Loss: 1.3610351\n",
      "Validation loss decreased (0.575858 --> 0.546067).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0700067\n",
      "\tspeed: 0.0763s/iter; left time: 496.7824s\n",
      "\titers: 200, epoch: 4 | loss: 0.0482245\n",
      "\tspeed: 0.0783s/iter; left time: 502.1144s\n",
      "\titers: 300, epoch: 4 | loss: 0.0601900\n",
      "\tspeed: 0.0769s/iter; left time: 485.4304s\n",
      "Epoch: 4 cost time: 29.966758251190186\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0707239 Vali Loss: 0.5602898 Test Loss: 1.3617344\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0963781\n",
      "\tspeed: 0.0719s/iter; left time: 440.6576s\n",
      "\titers: 200, epoch: 5 | loss: 0.0833555\n",
      "\tspeed: 0.0740s/iter; left time: 446.0068s\n",
      "\titers: 300, epoch: 5 | loss: 0.0896085\n",
      "\tspeed: 0.0780s/iter; left time: 462.0969s\n",
      "Epoch: 5 cost time: 29.291443347930908\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0640428 Vali Loss: 0.5310873 Test Loss: 1.4754112\n",
      "Validation loss decreased (0.546067 --> 0.531087).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0570694\n",
      "\tspeed: 0.0780s/iter; left time: 447.5836s\n",
      "\titers: 200, epoch: 6 | loss: 0.0368341\n",
      "\tspeed: 0.0740s/iter; left time: 417.1710s\n",
      "\titers: 300, epoch: 6 | loss: 0.0414325\n",
      "\tspeed: 0.0700s/iter; left time: 387.2572s\n",
      "Epoch: 6 cost time: 28.26341414451599\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0610850 Vali Loss: 0.5842949 Test Loss: 1.7426153\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0502005\n",
      "\tspeed: 0.0698s/iter; left time: 373.4387s\n",
      "\titers: 200, epoch: 7 | loss: 0.0446617\n",
      "\tspeed: 0.0727s/iter; left time: 381.3005s\n",
      "\titers: 300, epoch: 7 | loss: 0.0574240\n",
      "\tspeed: 0.0786s/iter; left time: 404.3888s\n",
      "Epoch: 7 cost time: 28.986579418182373\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.0571570 Vali Loss: 0.5403840 Test Loss: 1.6501103\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0657401\n",
      "\tspeed: 0.0761s/iter; left time: 377.2290s\n",
      "\titers: 200, epoch: 8 | loss: 0.0527530\n",
      "\tspeed: 0.0765s/iter; left time: 371.5618s\n",
      "\titers: 300, epoch: 8 | loss: 0.0571786\n",
      "\tspeed: 0.0735s/iter; left time: 349.6420s\n",
      "Epoch: 8 cost time: 29.134706497192383\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.0560692 Vali Loss: 0.5403323 Test Loss: 1.6845558\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:1.4754111766815186, mae:0.9395936727523804\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 2, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il168_pl720_sl6_win2_fa10_dm256_nh4_el3_iter2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.2395852\n",
      "\tspeed: 0.0814s/iter; left time: 605.5618s\n",
      "\titers: 200, epoch: 1 | loss: 0.1841136\n",
      "\tspeed: 0.0786s/iter; left time: 577.2649s\n",
      "\titers: 300, epoch: 1 | loss: 0.1476042\n",
      "\tspeed: 0.0821s/iter; left time: 594.2559s\n",
      "Epoch: 1 cost time: 30.576887607574463\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.2120967 Vali Loss: 1.1630169 Test Loss: 1.7426180\n",
      "Validation loss decreased (inf --> 1.163017).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0689139\n",
      "\tspeed: 0.0812s/iter; left time: 573.5285s\n",
      "\titers: 200, epoch: 2 | loss: 0.1100431\n",
      "\tspeed: 0.0822s/iter; left time: 572.4394s\n",
      "\titers: 300, epoch: 2 | loss: 0.1471447\n",
      "\tspeed: 0.0742s/iter; left time: 509.5297s\n",
      "Epoch: 2 cost time: 29.77274250984192\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.1077593 Vali Loss: 1.1259365 Test Loss: 1.9264957\n",
      "Validation loss decreased (1.163017 --> 1.125936).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0660172\n",
      "\tspeed: 0.0778s/iter; left time: 520.1759s\n",
      "\titers: 200, epoch: 3 | loss: 0.0991583\n",
      "\tspeed: 0.0780s/iter; left time: 514.1053s\n",
      "\titers: 300, epoch: 3 | loss: 0.0786930\n",
      "\tspeed: 0.0810s/iter; left time: 525.4173s\n",
      "Epoch: 3 cost time: 30.015652179718018\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0888276 Vali Loss: 1.1310166 Test Loss: 1.8439764\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.0708244\n",
      "\tspeed: 0.0808s/iter; left time: 509.7190s\n",
      "\titers: 200, epoch: 4 | loss: 0.0733835\n",
      "\tspeed: 0.0814s/iter; left time: 505.3459s\n",
      "\titers: 300, epoch: 4 | loss: 0.0987140\n",
      "\tspeed: 0.0810s/iter; left time: 494.9267s\n",
      "Epoch: 4 cost time: 30.561789989471436\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0803968 Vali Loss: 1.0746967 Test Loss: 1.8854281\n",
      "Validation loss decreased (1.125936 --> 1.074697).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0714490\n",
      "\tspeed: 0.0775s/iter; left time: 459.9115s\n",
      "\titers: 200, epoch: 5 | loss: 0.1052264\n",
      "\tspeed: 0.0738s/iter; left time: 430.2922s\n",
      "\titers: 300, epoch: 5 | loss: 0.0844449\n",
      "\tspeed: 0.0787s/iter; left time: 451.3484s\n",
      "Epoch: 5 cost time: 29.31210947036743\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0747191 Vali Loss: 1.0192445 Test Loss: 1.7672531\n",
      "Validation loss decreased (1.074697 --> 1.019244).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0551099\n",
      "\tspeed: 0.0783s/iter; left time: 435.0650s\n",
      "\titers: 200, epoch: 6 | loss: 0.0428135\n",
      "\tspeed: 0.0795s/iter; left time: 433.6796s\n",
      "\titers: 300, epoch: 6 | loss: 0.0515614\n",
      "\tspeed: 0.0757s/iter; left time: 405.5625s\n",
      "Epoch: 6 cost time: 28.979809284210205\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0713475 Vali Loss: 0.9729716 Test Loss: 1.6152878\n",
      "Validation loss decreased (1.019244 --> 0.972972).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0626659\n",
      "\tspeed: 0.0775s/iter; left time: 401.4146s\n",
      "\titers: 200, epoch: 7 | loss: 0.0665585\n",
      "\tspeed: 0.0740s/iter; left time: 376.0038s\n",
      "\titers: 300, epoch: 7 | loss: 0.0492548\n",
      "\tspeed: 0.0772s/iter; left time: 384.5059s\n",
      "Epoch: 7 cost time: 29.132887840270996\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0677398 Vali Loss: 1.0155871 Test Loss: 1.7555620\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0454311\n",
      "\tspeed: 0.0819s/iter; left time: 393.3623s\n",
      "\titers: 200, epoch: 8 | loss: 0.0430295\n",
      "\tspeed: 0.0828s/iter; left time: 389.3351s\n",
      "\titers: 300, epoch: 8 | loss: 0.0594510\n",
      "\tspeed: 0.0819s/iter; left time: 376.9314s\n",
      "Epoch: 8 cost time: 30.826653718948364\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.0660355 Vali Loss: 1.0332733 Test Loss: 1.8459744\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0664516\n",
      "\tspeed: 0.0780s/iter; left time: 345.1098s\n",
      "\titers: 200, epoch: 9 | loss: 0.0730036\n",
      "\tspeed: 0.0788s/iter; left time: 340.6763s\n",
      "\titers: 300, epoch: 9 | loss: 0.1029416\n",
      "\tspeed: 0.0816s/iter; left time: 344.9528s\n",
      "Epoch: 9 cost time: 30.63245987892151\n",
      "Epoch: 9, Steps: 377 | Train Loss: 0.0643914 Vali Loss: 0.9606379 Test Loss: 1.7720349\n",
      "Validation loss decreased (0.972972 --> 0.960638).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0486781\n",
      "\tspeed: 0.0838s/iter; left time: 339.3714s\n",
      "\titers: 200, epoch: 10 | loss: 0.0319319\n",
      "\tspeed: 0.0845s/iter; left time: 333.4837s\n",
      "\titers: 300, epoch: 10 | loss: 0.0690216\n",
      "\tspeed: 0.0808s/iter; left time: 310.7338s\n",
      "Epoch: 10 cost time: 31.091166019439697\n",
      "Epoch: 10, Steps: 377 | Train Loss: 0.0635101 Vali Loss: 0.9526582 Test Loss: 1.7322005\n",
      "Validation loss decreased (0.960638 --> 0.952658).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0477481\n",
      "\tspeed: 0.0787s/iter; left time: 289.0899s\n",
      "\titers: 200, epoch: 11 | loss: 0.0759336\n",
      "\tspeed: 0.0775s/iter; left time: 276.6177s\n",
      "\titers: 300, epoch: 11 | loss: 0.0746540\n",
      "\tspeed: 0.0836s/iter; left time: 290.2127s\n",
      "Epoch: 11 cost time: 30.5122287273407\n",
      "Epoch: 11, Steps: 377 | Train Loss: 0.0623255 Vali Loss: 0.9970680 Test Loss: 1.7646547\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.1052696\n",
      "\tspeed: 0.0857s/iter; left time: 282.3931s\n",
      "\titers: 200, epoch: 12 | loss: 0.0541462\n",
      "\tspeed: 0.0842s/iter; left time: 268.7820s\n",
      "\titers: 300, epoch: 12 | loss: 0.0441665\n",
      "\tspeed: 0.0845s/iter; left time: 261.5532s\n",
      "Epoch: 12 cost time: 32.043092489242554\n",
      "Epoch: 12, Steps: 377 | Train Loss: 0.0618974 Vali Loss: 0.9694067 Test Loss: 1.7512052\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.0621306\n",
      "\tspeed: 0.0809s/iter; left time: 235.8888s\n",
      "\titers: 200, epoch: 13 | loss: 0.0690343\n",
      "\tspeed: 0.0819s/iter; left time: 230.8319s\n",
      "\titers: 300, epoch: 13 | loss: 0.0383706\n",
      "\tspeed: 0.0834s/iter; left time: 226.7088s\n",
      "Epoch: 13 cost time: 30.866363763809204\n",
      "Epoch: 13, Steps: 377 | Train Loss: 0.0617426 Vali Loss: 0.9658290 Test Loss: 1.7530660\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:1.7322006225585938, mae:1.0654782056808472\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on ETTh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 7, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 3, 'data_split': [8640, 2880, 2880]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_ETTh1_il168_pl24_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8449\n",
      "val 2857\n",
      "test 2857\n",
      "\titers: 100, epoch: 1 | loss: 0.4359798\n",
      "\tspeed: 0.0855s/iter; left time: 443.0421s\n",
      "\titers: 200, epoch: 1 | loss: 0.3268143\n",
      "\tspeed: 0.0822s/iter; left time: 417.6397s\n",
      "Epoch: 1 cost time: 21.98344326019287\n",
      "Epoch: 1, Steps: 264 | Train Loss: 0.4522302 Vali Loss: 0.5033547 Test Loss: 0.3421980\n",
      "Validation loss decreased (inf --> 0.503355).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.2900459\n",
      "\tspeed: 0.0793s/iter; left time: 389.8614s\n",
      "\titers: 200, epoch: 2 | loss: 0.2836223\n",
      "\tspeed: 0.0831s/iter; left time: 400.0556s\n",
      "Epoch: 2 cost time: 21.39884042739868\n",
      "Epoch: 2, Steps: 264 | Train Loss: 0.2889093 Vali Loss: 0.4380511 Test Loss: 0.3226840\n",
      "Validation loss decreased (0.503355 --> 0.438051).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2621304\n",
      "\tspeed: 0.0815s/iter; left time: 379.2523s\n",
      "\titers: 200, epoch: 3 | loss: 0.2527190\n",
      "\tspeed: 0.0841s/iter; left time: 383.0798s\n",
      "Epoch: 3 cost time: 21.98856830596924\n",
      "Epoch: 3, Steps: 264 | Train Loss: 0.2608519 Vali Loss: 0.4398241 Test Loss: 0.3083563\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.2376152\n",
      "\tspeed: 0.0808s/iter; left time: 354.7796s\n",
      "\titers: 200, epoch: 4 | loss: 0.2334855\n",
      "\tspeed: 0.0849s/iter; left time: 364.3398s\n",
      "Epoch: 4 cost time: 22.039124250411987\n",
      "Epoch: 4, Steps: 264 | Train Loss: 0.2514027 Vali Loss: 0.4310442 Test Loss: 0.3064453\n",
      "Validation loss decreased (0.438051 --> 0.431044).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2375517\n",
      "\tspeed: 0.0868s/iter; left time: 357.8835s\n",
      "\titers: 200, epoch: 5 | loss: 0.2266519\n",
      "\tspeed: 0.0863s/iter; left time: 347.4743s\n",
      "Epoch: 5 cost time: 23.018563747406006\n",
      "Epoch: 5, Steps: 264 | Train Loss: 0.2425364 Vali Loss: 0.4263520 Test Loss: 0.2995898\n",
      "Validation loss decreased (0.431044 --> 0.426352).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.2397791\n",
      "\tspeed: 0.0861s/iter; left time: 332.5353s\n",
      "\titers: 200, epoch: 6 | loss: 0.2041470\n",
      "\tspeed: 0.0841s/iter; left time: 316.1923s\n",
      "Epoch: 6 cost time: 22.201738357543945\n",
      "Epoch: 6, Steps: 264 | Train Loss: 0.2372569 Vali Loss: 0.4346724 Test Loss: 0.3000129\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2628523\n",
      "\tspeed: 0.0803s/iter; left time: 288.7972s\n",
      "\titers: 200, epoch: 7 | loss: 0.2508851\n",
      "\tspeed: 0.0842s/iter; left time: 294.2865s\n",
      "Epoch: 7 cost time: 22.16172480583191\n",
      "Epoch: 7, Steps: 264 | Train Loss: 0.2328603 Vali Loss: 0.4459021 Test Loss: 0.2989538\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.2144868\n",
      "\tspeed: 0.0821s/iter; left time: 273.7305s\n",
      "\titers: 200, epoch: 8 | loss: 0.2563981\n",
      "\tspeed: 0.0841s/iter; left time: 271.8313s\n",
      "Epoch: 8 cost time: 22.055034160614014\n",
      "Epoch: 8, Steps: 264 | Train Loss: 0.2308911 Vali Loss: 0.4409103 Test Loss: 0.2981359\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
      "test shape: (2848, 24, 7) (2848, 24, 7)\n",
      "mse:0.2995899021625519, mae:0.35400310158729553\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on ETTh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 7, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 3, 'data_split': [8640, 2880, 2880]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_ETTh1_il168_pl48_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8425\n",
      "val 2833\n",
      "test 2833\n",
      "\titers: 100, epoch: 1 | loss: 0.5006971\n",
      "\tspeed: 0.0873s/iter; left time: 450.6382s\n",
      "\titers: 200, epoch: 1 | loss: 0.3263183\n",
      "\tspeed: 0.0834s/iter; left time: 422.2949s\n",
      "Epoch: 1 cost time: 22.40427589416504\n",
      "Epoch: 1, Steps: 263 | Train Loss: 0.4904265 Vali Loss: 0.5687675 Test Loss: 0.3705392\n",
      "Validation loss decreased (inf --> 0.568767).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.2882743\n",
      "\tspeed: 0.0888s/iter; left time: 435.0548s\n",
      "\titers: 200, epoch: 2 | loss: 0.3003450\n",
      "\tspeed: 0.0856s/iter; left time: 410.4938s\n",
      "Epoch: 2 cost time: 22.626023530960083\n",
      "Epoch: 2, Steps: 263 | Train Loss: 0.3214004 Vali Loss: 0.5665362 Test Loss: 0.3561658\n",
      "Validation loss decreased (0.568767 --> 0.566536).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2860460\n",
      "\tspeed: 0.0835s/iter; left time: 386.8642s\n",
      "\titers: 200, epoch: 3 | loss: 0.2832352\n",
      "\tspeed: 0.0824s/iter; left time: 373.8380s\n",
      "Epoch: 3 cost time: 22.058160543441772\n",
      "Epoch: 3, Steps: 263 | Train Loss: 0.2934566 Vali Loss: 0.5809759 Test Loss: 0.3643158\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.2600237\n",
      "\tspeed: 0.0859s/iter; left time: 375.4360s\n",
      "\titers: 200, epoch: 4 | loss: 0.2999200\n",
      "\tspeed: 0.0870s/iter; left time: 371.6112s\n",
      "Epoch: 4 cost time: 22.64843440055847\n",
      "Epoch: 4, Steps: 263 | Train Loss: 0.2822576 Vali Loss: 0.5602973 Test Loss: 0.3465700\n",
      "Validation loss decreased (0.566536 --> 0.560297).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2487850\n",
      "\tspeed: 0.0847s/iter; left time: 348.2315s\n",
      "\titers: 200, epoch: 5 | loss: 0.3235180\n",
      "\tspeed: 0.0872s/iter; left time: 349.7498s\n",
      "Epoch: 5 cost time: 22.725574254989624\n",
      "Epoch: 5, Steps: 263 | Train Loss: 0.2717720 Vali Loss: 0.5625966 Test Loss: 0.3455267\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.2834162\n",
      "\tspeed: 0.0896s/iter; left time: 344.5531s\n",
      "\titers: 200, epoch: 6 | loss: 0.2956799\n",
      "\tspeed: 0.0845s/iter; left time: 316.4051s\n",
      "Epoch: 6 cost time: 22.766181230545044\n",
      "Epoch: 6, Steps: 263 | Train Loss: 0.2680570 Vali Loss: 0.5692195 Test Loss: 0.3519067\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2565739\n",
      "\tspeed: 0.0874s/iter; left time: 313.1752s\n",
      "\titers: 200, epoch: 7 | loss: 0.2674327\n",
      "\tspeed: 0.0886s/iter; left time: 308.7306s\n",
      "Epoch: 7 cost time: 23.08157968521118\n",
      "Epoch: 7, Steps: 263 | Train Loss: 0.2627621 Vali Loss: 0.5710726 Test Loss: 0.3510904\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 7) (88, 32, 48, 7)\n",
      "test shape: (2816, 48, 7) (2816, 48, 7)\n",
      "mse:0.3465699851512909, mae:0.38547590374946594\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on ETTh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 7, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 3, 'data_split': [8640, 2880, 2880]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_ETTh1_il168_pl168_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8305\n",
      "val 2713\n",
      "test 2713\n",
      "\titers: 100, epoch: 1 | loss: 0.6260944\n",
      "\tspeed: 0.0993s/iter; left time: 504.6501s\n",
      "\titers: 200, epoch: 1 | loss: 0.5005667\n",
      "\tspeed: 0.0899s/iter; left time: 447.5636s\n",
      "Epoch: 1 cost time: 24.217338800430298\n",
      "Epoch: 1, Steps: 259 | Train Loss: 0.5686379 Vali Loss: 0.9015196 Test Loss: 0.4719609\n",
      "Validation loss decreased (inf --> 0.901520).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.4114985\n",
      "\tspeed: 0.0845s/iter; left time: 407.5852s\n",
      "\titers: 200, epoch: 2 | loss: 0.3400915\n",
      "\tspeed: 0.0827s/iter; left time: 390.7140s\n",
      "Epoch: 2 cost time: 22.560821294784546\n",
      "Epoch: 2, Steps: 259 | Train Loss: 0.3939569 Vali Loss: 0.8986334 Test Loss: 0.4631450\n",
      "Validation loss decreased (0.901520 --> 0.898633).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4157582\n",
      "\tspeed: 0.0889s/iter; left time: 405.6841s\n",
      "\titers: 200, epoch: 3 | loss: 0.3687331\n",
      "\tspeed: 0.0910s/iter; left time: 406.2419s\n",
      "Epoch: 3 cost time: 23.451661586761475\n",
      "Epoch: 3, Steps: 259 | Train Loss: 0.3552653 Vali Loss: 0.9385713 Test Loss: 0.5172408\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.3407929\n",
      "\tspeed: 0.0866s/iter; left time: 372.7484s\n",
      "\titers: 200, epoch: 4 | loss: 0.3019759\n",
      "\tspeed: 0.0902s/iter; left time: 379.3828s\n",
      "Epoch: 4 cost time: 23.03810429573059\n",
      "Epoch: 4, Steps: 259 | Train Loss: 0.3396362 Vali Loss: 0.9341278 Test Loss: 0.5759323\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3336057\n",
      "\tspeed: 0.0928s/iter; left time: 375.4834s\n",
      "\titers: 200, epoch: 5 | loss: 0.3262427\n",
      "\tspeed: 0.0923s/iter; left time: 364.2628s\n",
      "Epoch: 5 cost time: 24.058868885040283\n",
      "Epoch: 5, Steps: 259 | Train Loss: 0.3260578 Vali Loss: 0.9601630 Test Loss: 0.6052024\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 7) (84, 32, 168, 7)\n",
      "test shape: (2688, 168, 7) (2688, 168, 7)\n",
      "mse:0.4631449282169342, mae:0.46267563104629517\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on ETTh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 7, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 3, 'data_split': [8640, 2880, 2880]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_ETTh1_il168_pl336_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8137\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.6370671\n",
      "\tspeed: 0.1125s/iter; left time: 560.3241s\n",
      "\titers: 200, epoch: 1 | loss: 0.5326796\n",
      "\tspeed: 0.1097s/iter; left time: 535.6133s\n",
      "Epoch: 1 cost time: 28.261203050613403\n",
      "Epoch: 1, Steps: 254 | Train Loss: 0.6500199 Vali Loss: 1.2094655 Test Loss: 0.6804507\n",
      "Validation loss decreased (inf --> 1.209466).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.4626897\n",
      "\tspeed: 0.1104s/iter; left time: 521.8207s\n",
      "\titers: 200, epoch: 2 | loss: 0.4135780\n",
      "\tspeed: 0.1117s/iter; left time: 517.0565s\n",
      "Epoch: 2 cost time: 28.216683864593506\n",
      "Epoch: 2, Steps: 254 | Train Loss: 0.4330485 Vali Loss: 1.1659153 Test Loss: 0.7136123\n",
      "Validation loss decreased (1.209466 --> 1.165915).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3863311\n",
      "\tspeed: 0.1119s/iter; left time: 500.5688s\n",
      "\titers: 200, epoch: 3 | loss: 0.4010473\n",
      "\tspeed: 0.1149s/iter; left time: 502.5733s\n",
      "Epoch: 3 cost time: 29.210959434509277\n",
      "Epoch: 3, Steps: 254 | Train Loss: 0.3753376 Vali Loss: 1.1717972 Test Loss: 0.7337325\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.3737389\n",
      "\tspeed: 0.1105s/iter; left time: 466.2168s\n",
      "\titers: 200, epoch: 4 | loss: 0.3647022\n",
      "\tspeed: 0.1237s/iter; left time: 509.4890s\n",
      "Epoch: 4 cost time: 30.112292289733887\n",
      "Epoch: 4, Steps: 254 | Train Loss: 0.3565444 Vali Loss: 1.1515782 Test Loss: 0.7161331\n",
      "Validation loss decreased (1.165915 --> 1.151578).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3332777\n",
      "\tspeed: 0.1072s/iter; left time: 425.2053s\n",
      "\titers: 200, epoch: 5 | loss: 0.3471382\n",
      "\tspeed: 0.1011s/iter; left time: 390.6603s\n",
      "Epoch: 5 cost time: 26.75829529762268\n",
      "Epoch: 5, Steps: 254 | Train Loss: 0.3429974 Vali Loss: 1.1333492 Test Loss: 0.7096163\n",
      "Validation loss decreased (1.151578 --> 1.133349).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.3404499\n",
      "\tspeed: 0.1115s/iter; left time: 413.7921s\n",
      "\titers: 200, epoch: 6 | loss: 0.3324481\n",
      "\tspeed: 0.1164s/iter; left time: 420.4552s\n",
      "Epoch: 6 cost time: 29.009478092193604\n",
      "Epoch: 6, Steps: 254 | Train Loss: 0.3361632 Vali Loss: 1.1239272 Test Loss: 0.7224055\n",
      "Validation loss decreased (1.133349 --> 1.123927).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3341471\n",
      "\tspeed: 0.1118s/iter; left time: 386.3849s\n",
      "\titers: 200, epoch: 7 | loss: 0.3284478\n",
      "\tspeed: 0.1112s/iter; left time: 373.4597s\n",
      "Epoch: 7 cost time: 28.381686687469482\n",
      "Epoch: 7, Steps: 254 | Train Loss: 0.3312737 Vali Loss: 1.1394139 Test Loss: 0.7535409\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.3388963\n",
      "\tspeed: 0.1148s/iter; left time: 367.6648s\n",
      "\titers: 200, epoch: 8 | loss: 0.3117730\n",
      "\tspeed: 0.1121s/iter; left time: 347.7941s\n",
      "Epoch: 8 cost time: 28.665746688842773\n",
      "Epoch: 8, Steps: 254 | Train Loss: 0.3282922 Vali Loss: 1.1426835 Test Loss: 0.7673734\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.3312876\n",
      "\tspeed: 0.1099s/iter; left time: 324.2148s\n",
      "\titers: 200, epoch: 9 | loss: 0.3086556\n",
      "\tspeed: 0.1135s/iter; left time: 323.3218s\n",
      "Epoch: 9 cost time: 28.659162759780884\n",
      "Epoch: 9, Steps: 254 | Train Loss: 0.3254266 Vali Loss: 1.1585174 Test Loss: 0.7672176\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 7) (79, 32, 336, 7)\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "mse:0.7224053144454956, mae:0.6227895021438599\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on ETTh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 7, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 3, 'data_split': [8640, 2880, 2880]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_ETTh1_il168_pl720_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7753\n",
      "val 2161\n",
      "test 2161\n",
      "\titers: 100, epoch: 1 | loss: 0.7050180\n",
      "\tspeed: 0.1949s/iter; left time: 924.1528s\n",
      "\titers: 200, epoch: 1 | loss: 0.6216529\n",
      "\tspeed: 0.1963s/iter; left time: 911.1843s\n",
      "Epoch: 1 cost time: 47.816630363464355\n",
      "Epoch: 1, Steps: 242 | Train Loss: 0.7275247 Vali Loss: 1.3699050 Test Loss: 0.8546566\n",
      "Validation loss decreased (inf --> 1.369905).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.4908116\n",
      "\tspeed: 0.1996s/iter; left time: 897.7836s\n",
      "\titers: 200, epoch: 2 | loss: 0.4449148\n",
      "\tspeed: 0.1955s/iter; left time: 859.9402s\n",
      "Epoch: 2 cost time: 48.04868507385254\n",
      "Epoch: 2, Steps: 242 | Train Loss: 0.4887003 Vali Loss: 1.3298123 Test Loss: 0.8663419\n",
      "Validation loss decreased (1.369905 --> 1.329812).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3880305\n",
      "\tspeed: 0.1952s/iter; left time: 831.0409s\n",
      "\titers: 200, epoch: 3 | loss: 0.4120776\n",
      "\tspeed: 0.1931s/iter; left time: 802.7795s\n",
      "Epoch: 3 cost time: 47.17014122009277\n",
      "Epoch: 3, Steps: 242 | Train Loss: 0.4158435 Vali Loss: 1.2919668 Test Loss: 1.0059787\n",
      "Validation loss decreased (1.329812 --> 1.291967).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.3833386\n",
      "\tspeed: 0.1957s/iter; left time: 785.7456s\n",
      "\titers: 200, epoch: 4 | loss: 0.3760547\n",
      "\tspeed: 0.1985s/iter; left time: 777.1086s\n",
      "Epoch: 4 cost time: 47.98063826560974\n",
      "Epoch: 4, Steps: 242 | Train Loss: 0.3924244 Vali Loss: 1.3091470 Test Loss: 1.0337684\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3678845\n",
      "\tspeed: 0.1948s/iter; left time: 734.8021s\n",
      "\titers: 200, epoch: 5 | loss: 0.3616984\n",
      "\tspeed: 0.2034s/iter; left time: 747.0317s\n",
      "Epoch: 5 cost time: 48.068490982055664\n",
      "Epoch: 5, Steps: 242 | Train Loss: 0.3742841 Vali Loss: 1.2687885 Test Loss: 0.9999728\n",
      "Validation loss decreased (1.291967 --> 1.268788).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.3637421\n",
      "\tspeed: 0.2031s/iter; left time: 717.2286s\n",
      "\titers: 200, epoch: 6 | loss: 0.3945895\n",
      "\tspeed: 0.2006s/iter; left time: 688.1137s\n",
      "Epoch: 6 cost time: 48.6354660987854\n",
      "Epoch: 6, Steps: 242 | Train Loss: 0.3660264 Vali Loss: 1.2642691 Test Loss: 1.0230346\n",
      "Validation loss decreased (1.268788 --> 1.264269).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3610753\n",
      "\tspeed: 0.2043s/iter; left time: 671.8049s\n",
      "\titers: 200, epoch: 7 | loss: 0.3641820\n",
      "\tspeed: 0.2063s/iter; left time: 657.8212s\n",
      "Epoch: 7 cost time: 49.789159536361694\n",
      "Epoch: 7, Steps: 242 | Train Loss: 0.3588788 Vali Loss: 1.2728350 Test Loss: 0.9957781\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.3690242\n",
      "\tspeed: 0.1809s/iter; left time: 551.3113s\n",
      "\titers: 200, epoch: 8 | loss: 0.3856726\n",
      "\tspeed: 0.1960s/iter; left time: 577.5992s\n",
      "Epoch: 8 cost time: 45.85397148132324\n",
      "Epoch: 8, Steps: 242 | Train Loss: 0.3553478 Vali Loss: 1.2572789 Test Loss: 0.9630152\n",
      "Validation loss decreased (1.264269 --> 1.257279).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.3673951\n",
      "\tspeed: 0.1970s/iter; left time: 552.6414s\n",
      "\titers: 200, epoch: 9 | loss: 0.3615567\n",
      "\tspeed: 0.2007s/iter; left time: 542.9702s\n",
      "Epoch: 9 cost time: 48.04281187057495\n",
      "Epoch: 9, Steps: 242 | Train Loss: 0.3524448 Vali Loss: 1.2613688 Test Loss: 1.0103310\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.3588955\n",
      "\tspeed: 0.1943s/iter; left time: 497.8873s\n",
      "\titers: 200, epoch: 10 | loss: 0.3584485\n",
      "\tspeed: 0.1931s/iter; left time: 475.5738s\n",
      "Epoch: 10 cost time: 46.912421464920044\n",
      "Epoch: 10, Steps: 242 | Train Loss: 0.3504771 Vali Loss: 1.2594531 Test Loss: 0.9973724\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.3650396\n",
      "\tspeed: 0.1990s/iter; left time: 461.8286s\n",
      "\titers: 200, epoch: 11 | loss: 0.3451880\n",
      "\tspeed: 0.2049s/iter; left time: 455.1645s\n",
      "Epoch: 11 cost time: 49.09414887428284\n",
      "Epoch: 11, Steps: 242 | Train Loss: 0.3488900 Vali Loss: 1.2630745 Test Loss: 0.9926363\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 7) (67, 32, 720, 7)\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "mse:0.9630151987075806, mae:0.7617897987365723\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on DEWINDh_small with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_DEWINDh_small_il168_pl24_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.3531817\n",
      "\tspeed: 0.0771s/iter; left time: 607.9970s\n",
      "\titers: 200, epoch: 1 | loss: 0.1933510\n",
      "\tspeed: 0.0756s/iter; left time: 588.1586s\n",
      "\titers: 300, epoch: 1 | loss: 0.1558162\n",
      "\tspeed: 0.0751s/iter; left time: 576.8497s\n",
      "Epoch: 1 cost time: 30.864954471588135\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.2903091 Vali Loss: 0.1558876 Test Loss: 0.1264814\n",
      "Validation loss decreased (inf --> 0.155888).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.1842827\n",
      "\tspeed: 0.0761s/iter; left time: 569.3977s\n",
      "\titers: 200, epoch: 2 | loss: 0.1357923\n",
      "\tspeed: 0.0743s/iter; left time: 548.2366s\n",
      "\titers: 300, epoch: 2 | loss: 0.1204000\n",
      "\tspeed: 0.0741s/iter; left time: 539.4810s\n",
      "Epoch: 2 cost time: 29.145665645599365\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.1598744 Vali Loss: 0.1473022 Test Loss: 0.1150521\n",
      "Validation loss decreased (0.155888 --> 0.147302).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1462897\n",
      "\tspeed: 0.0732s/iter; left time: 518.6679s\n",
      "\titers: 200, epoch: 3 | loss: 0.0940053\n",
      "\tspeed: 0.0745s/iter; left time: 520.2716s\n",
      "\titers: 300, epoch: 3 | loss: 0.1028419\n",
      "\tspeed: 0.0783s/iter; left time: 539.1140s\n",
      "Epoch: 3 cost time: 30.44178080558777\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.1427302 Vali Loss: 0.1267791 Test Loss: 0.1089031\n",
      "Validation loss decreased (0.147302 --> 0.126779).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.1436144\n",
      "\tspeed: 0.0786s/iter; left time: 525.2220s\n",
      "\titers: 200, epoch: 4 | loss: 0.1188087\n",
      "\tspeed: 0.0777s/iter; left time: 511.3243s\n",
      "\titers: 300, epoch: 4 | loss: 0.1206652\n",
      "\tspeed: 0.0753s/iter; left time: 488.1126s\n",
      "Epoch: 4 cost time: 30.391088724136353\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.1365448 Vali Loss: 0.1265814 Test Loss: 0.1100054\n",
      "Validation loss decreased (0.126779 --> 0.126581).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2538432\n",
      "\tspeed: 0.0732s/iter; left time: 460.0795s\n",
      "\titers: 200, epoch: 5 | loss: 0.1060243\n",
      "\tspeed: 0.0678s/iter; left time: 419.6245s\n",
      "\titers: 300, epoch: 5 | loss: 0.1667269\n",
      "\tspeed: 0.0722s/iter; left time: 439.2447s\n",
      "Epoch: 5 cost time: 28.734646558761597\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.1300954 Vali Loss: 0.1231773 Test Loss: 0.1093403\n",
      "Validation loss decreased (0.126581 --> 0.123177).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.1248719\n",
      "\tspeed: 0.0738s/iter; left time: 434.2331s\n",
      "\titers: 200, epoch: 6 | loss: 0.1659362\n",
      "\tspeed: 0.0696s/iter; left time: 402.9494s\n",
      "\titers: 300, epoch: 6 | loss: 0.1299754\n",
      "\tspeed: 0.0721s/iter; left time: 410.2237s\n",
      "Epoch: 6 cost time: 28.781930923461914\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.1288555 Vali Loss: 0.1182183 Test Loss: 0.1057795\n",
      "Validation loss decreased (0.123177 --> 0.118218).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1498770\n",
      "\tspeed: 0.0712s/iter; left time: 390.8581s\n",
      "\titers: 200, epoch: 7 | loss: 0.1051340\n",
      "\tspeed: 0.0726s/iter; left time: 391.1417s\n",
      "\titers: 300, epoch: 7 | loss: 0.0999520\n",
      "\tspeed: 0.0748s/iter; left time: 395.4273s\n",
      "Epoch: 7 cost time: 29.45435118675232\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.1251644 Vali Loss: 0.1171971 Test Loss: 0.1038321\n",
      "Validation loss decreased (0.118218 --> 0.117197).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.1081711\n",
      "\tspeed: 0.0799s/iter; left time: 406.5415s\n",
      "\titers: 200, epoch: 8 | loss: 0.1324477\n",
      "\tspeed: 0.0791s/iter; left time: 394.3289s\n",
      "\titers: 300, epoch: 8 | loss: 0.0906790\n",
      "\tspeed: 0.0793s/iter; left time: 387.5170s\n",
      "Epoch: 8 cost time: 31.500580310821533\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.1234641 Vali Loss: 0.1149258 Test Loss: 0.1035558\n",
      "Validation loss decreased (0.117197 --> 0.114926).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1520801\n",
      "\tspeed: 0.0774s/iter; left time: 362.7843s\n",
      "\titers: 200, epoch: 9 | loss: 0.0813727\n",
      "\tspeed: 0.0701s/iter; left time: 321.8177s\n",
      "\titers: 300, epoch: 9 | loss: 0.1425620\n",
      "\tspeed: 0.0696s/iter; left time: 312.2351s\n",
      "Epoch: 9 cost time: 29.215759754180908\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.1215352 Vali Loss: 0.1144541 Test Loss: 0.1019374\n",
      "Validation loss decreased (0.114926 --> 0.114454).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0994848\n",
      "\tspeed: 0.0749s/iter; left time: 321.2041s\n",
      "\titers: 200, epoch: 10 | loss: 0.1088356\n",
      "\tspeed: 0.0738s/iter; left time: 309.2058s\n",
      "\titers: 300, epoch: 10 | loss: 0.1136675\n",
      "\tspeed: 0.0746s/iter; left time: 305.1385s\n",
      "Epoch: 10 cost time: 29.773776531219482\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.1216865 Vali Loss: 0.1160762 Test Loss: 0.1012837\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1180257\n",
      "\tspeed: 0.0735s/iter; left time: 285.8785s\n",
      "\titers: 200, epoch: 11 | loss: 0.1353136\n",
      "\tspeed: 0.0741s/iter; left time: 280.8927s\n",
      "\titers: 300, epoch: 11 | loss: 0.1143744\n",
      "\tspeed: 0.0769s/iter; left time: 283.9337s\n",
      "Epoch: 11 cost time: 30.23841404914856\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.1202063 Vali Loss: 0.1140150 Test Loss: 0.1018977\n",
      "Validation loss decreased (0.114454 --> 0.114015).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.1002436\n",
      "\tspeed: 0.0773s/iter; left time: 269.8385s\n",
      "\titers: 200, epoch: 12 | loss: 0.1726182\n",
      "\tspeed: 0.0804s/iter; left time: 272.5872s\n",
      "\titers: 300, epoch: 12 | loss: 0.1134026\n",
      "\tspeed: 0.0777s/iter; left time: 255.6940s\n",
      "Epoch: 12 cost time: 31.297265768051147\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.1200860 Vali Loss: 0.1140710 Test Loss: 0.1009609\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.1241183\n",
      "\tspeed: 0.0773s/iter; left time: 239.1175s\n",
      "\titers: 200, epoch: 13 | loss: 0.1462154\n",
      "\tspeed: 0.0748s/iter; left time: 223.9301s\n",
      "\titers: 300, epoch: 13 | loss: 0.1275976\n",
      "\tspeed: 0.0775s/iter; left time: 224.2250s\n",
      "Epoch: 13 cost time: 30.76191782951355\n",
      "Epoch: 13, Steps: 399 | Train Loss: 0.1197111 Vali Loss: 0.1143213 Test Loss: 0.1001481\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 14 | loss: 0.1128476\n",
      "\tspeed: 0.0755s/iter; left time: 203.3208s\n",
      "\titers: 200, epoch: 14 | loss: 0.1546671\n",
      "\tspeed: 0.0785s/iter; left time: 203.6726s\n",
      "\titers: 300, epoch: 14 | loss: 0.1043905\n",
      "\tspeed: 0.0778s/iter; left time: 194.1185s\n",
      "Epoch: 14 cost time: 30.82796049118042\n",
      "Epoch: 14, Steps: 399 | Train Loss: 0.1197059 Vali Loss: 0.1147561 Test Loss: 0.1017840\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.10189766436815262, mae:0.16441921889781952\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on DEWINDh_small with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_DEWINDh_small_il168_pl48_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.2537548\n",
      "\tspeed: 0.0752s/iter; left time: 590.8421s\n",
      "\titers: 200, epoch: 1 | loss: 0.2230575\n",
      "\tspeed: 0.0738s/iter; left time: 572.4475s\n",
      "\titers: 300, epoch: 1 | loss: 0.1431747\n",
      "\tspeed: 0.0774s/iter; left time: 592.6146s\n",
      "Epoch: 1 cost time: 30.128947257995605\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.3024869 Vali Loss: 0.1876371 Test Loss: 0.1595600\n",
      "Validation loss decreased (inf --> 0.187637).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.1324771\n",
      "\tspeed: 0.0742s/iter; left time: 553.7410s\n",
      "\titers: 200, epoch: 2 | loss: 0.1440937\n",
      "\tspeed: 0.0746s/iter; left time: 549.3266s\n",
      "\titers: 300, epoch: 2 | loss: 0.1920851\n",
      "\tspeed: 0.0737s/iter; left time: 534.9727s\n",
      "Epoch: 2 cost time: 29.526384115219116\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.1777412 Vali Loss: 0.1743769 Test Loss: 0.1427372\n",
      "Validation loss decreased (0.187637 --> 0.174377).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1268647\n",
      "\tspeed: 0.0730s/iter; left time: 515.8772s\n",
      "\titers: 200, epoch: 3 | loss: 0.1594413\n",
      "\tspeed: 0.0714s/iter; left time: 497.3432s\n",
      "\titers: 300, epoch: 3 | loss: 0.1815990\n",
      "\tspeed: 0.0699s/iter; left time: 479.9212s\n",
      "Epoch: 3 cost time: 28.383713006973267\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.1608076 Vali Loss: 0.1660120 Test Loss: 0.1402290\n",
      "Validation loss decreased (0.174377 --> 0.166012).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.1548368\n",
      "\tspeed: 0.0746s/iter; left time: 497.2030s\n",
      "\titers: 200, epoch: 4 | loss: 0.1694912\n",
      "\tspeed: 0.0791s/iter; left time: 519.5521s\n",
      "\titers: 300, epoch: 4 | loss: 0.1711720\n",
      "\tspeed: 0.0766s/iter; left time: 495.4849s\n",
      "Epoch: 4 cost time: 30.276445388793945\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.1569011 Vali Loss: 0.1617148 Test Loss: 0.1376395\n",
      "Validation loss decreased (0.166012 --> 0.161715).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1565208\n",
      "\tspeed: 0.0720s/iter; left time: 451.5991s\n",
      "\titers: 200, epoch: 5 | loss: 0.1248580\n",
      "\tspeed: 0.0729s/iter; left time: 449.4139s\n",
      "\titers: 300, epoch: 5 | loss: 0.1223314\n",
      "\tspeed: 0.0761s/iter; left time: 461.5917s\n",
      "Epoch: 5 cost time: 29.7139949798584\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.1508256 Vali Loss: 0.1540250 Test Loss: 0.1341997\n",
      "Validation loss decreased (0.161715 --> 0.154025).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.1812439\n",
      "\tspeed: 0.0744s/iter; left time: 436.9135s\n",
      "\titers: 200, epoch: 6 | loss: 0.1888389\n",
      "\tspeed: 0.0735s/iter; left time: 424.0408s\n",
      "\titers: 300, epoch: 6 | loss: 0.1468416\n",
      "\tspeed: 0.0735s/iter; left time: 416.6601s\n",
      "Epoch: 6 cost time: 29.37560272216797\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.1486526 Vali Loss: 0.1622337 Test Loss: 0.1275888\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1040735\n",
      "\tspeed: 0.0716s/iter; left time: 391.9669s\n",
      "\titers: 200, epoch: 7 | loss: 0.1327339\n",
      "\tspeed: 0.0734s/iter; left time: 394.5003s\n",
      "\titers: 300, epoch: 7 | loss: 0.1589763\n",
      "\tspeed: 0.0762s/iter; left time: 401.6741s\n",
      "Epoch: 7 cost time: 29.889032125473022\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.1464468 Vali Loss: 0.1527154 Test Loss: 0.1277564\n",
      "Validation loss decreased (0.154025 --> 0.152715).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.1414803\n",
      "\tspeed: 0.0711s/iter; left time: 360.8456s\n",
      "\titers: 200, epoch: 8 | loss: 0.1686430\n",
      "\tspeed: 0.0772s/iter; left time: 383.9388s\n",
      "\titers: 300, epoch: 8 | loss: 0.1386504\n",
      "\tspeed: 0.0743s/iter; left time: 361.9777s\n",
      "Epoch: 8 cost time: 29.330885887145996\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.1448341 Vali Loss: 0.1544081 Test Loss: 0.1252837\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1293161\n",
      "\tspeed: 0.0726s/iter; left time: 339.5878s\n",
      "\titers: 200, epoch: 9 | loss: 0.1599514\n",
      "\tspeed: 0.0748s/iter; left time: 342.1998s\n",
      "\titers: 300, epoch: 9 | loss: 0.1417391\n",
      "\tspeed: 0.0772s/iter; left time: 345.5665s\n",
      "Epoch: 9 cost time: 29.49107313156128\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.1435136 Vali Loss: 0.1507317 Test Loss: 0.1263260\n",
      "Validation loss decreased (0.152715 --> 0.150732).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.1459919\n",
      "\tspeed: 0.0764s/iter; left time: 326.8494s\n",
      "\titers: 200, epoch: 10 | loss: 0.1148216\n",
      "\tspeed: 0.0738s/iter; left time: 308.4486s\n",
      "\titers: 300, epoch: 10 | loss: 0.1372322\n",
      "\tspeed: 0.0731s/iter; left time: 298.2747s\n",
      "Epoch: 10 cost time: 29.530877113342285\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.1426602 Vali Loss: 0.1502888 Test Loss: 0.1250718\n",
      "Validation loss decreased (0.150732 --> 0.150289).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1267701\n",
      "\tspeed: 0.0754s/iter; left time: 292.7488s\n",
      "\titers: 200, epoch: 11 | loss: 0.1087107\n",
      "\tspeed: 0.0727s/iter; left time: 275.0652s\n",
      "\titers: 300, epoch: 11 | loss: 0.1158854\n",
      "\tspeed: 0.0741s/iter; left time: 272.8635s\n",
      "Epoch: 11 cost time: 29.892744302749634\n",
      "Epoch: 11, Steps: 398 | Train Loss: 0.1418525 Vali Loss: 0.1498816 Test Loss: 0.1243793\n",
      "Validation loss decreased (0.150289 --> 0.149882).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.1656965\n",
      "\tspeed: 0.0769s/iter; left time: 267.7687s\n",
      "\titers: 200, epoch: 12 | loss: 0.1108834\n",
      "\tspeed: 0.0747s/iter; left time: 252.7634s\n",
      "\titers: 300, epoch: 12 | loss: 0.1573044\n",
      "\tspeed: 0.0719s/iter; left time: 235.8959s\n",
      "Epoch: 12 cost time: 29.594554901123047\n",
      "Epoch: 12, Steps: 398 | Train Loss: 0.1415419 Vali Loss: 0.1491529 Test Loss: 0.1246771\n",
      "Validation loss decreased (0.149882 --> 0.149153).  Saving model ...\n",
      "\titers: 100, epoch: 13 | loss: 0.1410964\n",
      "\tspeed: 0.0748s/iter; left time: 230.8343s\n",
      "\titers: 200, epoch: 13 | loss: 0.1736037\n",
      "\tspeed: 0.0751s/iter; left time: 224.2105s\n",
      "\titers: 300, epoch: 13 | loss: 0.1509107\n",
      "\tspeed: 0.0716s/iter; left time: 206.4261s\n",
      "Epoch: 13 cost time: 29.778729915618896\n",
      "Epoch: 13, Steps: 398 | Train Loss: 0.1412169 Vali Loss: 0.1491112 Test Loss: 0.1249353\n",
      "Validation loss decreased (0.149153 --> 0.149111).  Saving model ...\n",
      "\titers: 100, epoch: 14 | loss: 0.1361708\n",
      "\tspeed: 0.0728s/iter; left time: 195.5668s\n",
      "\titers: 200, epoch: 14 | loss: 0.1366258\n",
      "\tspeed: 0.0774s/iter; left time: 200.1925s\n",
      "\titers: 300, epoch: 14 | loss: 0.0955821\n",
      "\tspeed: 0.0719s/iter; left time: 178.7756s\n",
      "Epoch: 14 cost time: 29.25092077255249\n",
      "Epoch: 14, Steps: 398 | Train Loss: 0.1410666 Vali Loss: 0.1494645 Test Loss: 0.1226903\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 15 | loss: 0.1566560\n",
      "\tspeed: 0.0734s/iter; left time: 168.0976s\n",
      "\titers: 200, epoch: 15 | loss: 0.1073604\n",
      "\tspeed: 0.0736s/iter; left time: 161.2159s\n",
      "\titers: 300, epoch: 15 | loss: 0.1228732\n",
      "\tspeed: 0.0744s/iter; left time: 155.3273s\n",
      "Epoch: 15 cost time: 29.585001230239868\n",
      "Epoch: 15, Steps: 398 | Train Loss: 0.1408998 Vali Loss: 0.1484452 Test Loss: 0.1235596\n",
      "Validation loss decreased (0.149111 --> 0.148445).  Saving model ...\n",
      "\titers: 100, epoch: 16 | loss: 0.1352992\n",
      "\tspeed: 0.0774s/iter; left time: 146.3077s\n",
      "\titers: 200, epoch: 16 | loss: 0.0829470\n",
      "\tspeed: 0.0775s/iter; left time: 138.7396s\n",
      "\titers: 300, epoch: 16 | loss: 0.1418042\n",
      "\tspeed: 0.0751s/iter; left time: 126.9509s\n",
      "Epoch: 16 cost time: 30.34024429321289\n",
      "Epoch: 16, Steps: 398 | Train Loss: 0.1405819 Vali Loss: 0.1492100 Test Loss: 0.1233945\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 17 | loss: 0.1348408\n",
      "\tspeed: 0.0742s/iter; left time: 110.8425s\n",
      "\titers: 200, epoch: 17 | loss: 0.1170949\n",
      "\tspeed: 0.0742s/iter; left time: 103.4135s\n",
      "\titers: 300, epoch: 17 | loss: 0.1279996\n",
      "\tspeed: 0.0775s/iter; left time: 100.1830s\n",
      "Epoch: 17 cost time: 30.366485118865967\n",
      "Epoch: 17, Steps: 398 | Train Loss: 0.1406695 Vali Loss: 0.1496685 Test Loss: 0.1226523\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 18 | loss: 0.2035314\n",
      "\tspeed: 0.0777s/iter; left time: 85.0981s\n",
      "\titers: 200, epoch: 18 | loss: 0.1205648\n",
      "\tspeed: 0.0767s/iter; left time: 76.2748s\n",
      "\titers: 300, epoch: 18 | loss: 0.1147074\n",
      "\tspeed: 0.0748s/iter; left time: 66.9695s\n",
      "Epoch: 18 cost time: 30.182876110076904\n",
      "Epoch: 18, Steps: 398 | Train Loss: 0.1399318 Vali Loss: 0.1493994 Test Loss: 0.1227517\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.12355956435203552, mae:0.17530761659145355\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on DEWINDh_small with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_DEWINDh_small_il168_pl168_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.2531253\n",
      "\tspeed: 0.0782s/iter; left time: 608.1304s\n",
      "\titers: 200, epoch: 1 | loss: 0.2441927\n",
      "\tspeed: 0.0756s/iter; left time: 580.4857s\n",
      "\titers: 300, epoch: 1 | loss: 0.2256001\n",
      "\tspeed: 0.0789s/iter; left time: 598.4085s\n",
      "Epoch: 1 cost time: 30.93938899040222\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.3265607 Vali Loss: 0.2077003 Test Loss: 0.2073114\n",
      "Validation loss decreased (inf --> 0.207700).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.1671338\n",
      "\tspeed: 0.0779s/iter; left time: 575.8147s\n",
      "\titers: 200, epoch: 2 | loss: 0.1759053\n",
      "\tspeed: 0.0790s/iter; left time: 575.7209s\n",
      "\titers: 300, epoch: 2 | loss: 0.1983624\n",
      "\tspeed: 0.0799s/iter; left time: 574.3685s\n",
      "Epoch: 2 cost time: 30.655497550964355\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.1947123 Vali Loss: 0.2028463 Test Loss: 0.1863151\n",
      "Validation loss decreased (0.207700 --> 0.202846).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1669643\n",
      "\tspeed: 0.0755s/iter; left time: 528.2036s\n",
      "\titers: 200, epoch: 3 | loss: 0.1582653\n",
      "\tspeed: 0.0720s/iter; left time: 496.0020s\n",
      "\titers: 300, epoch: 3 | loss: 0.1765635\n",
      "\tspeed: 0.0769s/iter; left time: 522.2882s\n",
      "Epoch: 3 cost time: 29.90630793571472\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.1802180 Vali Loss: 0.1972288 Test Loss: 0.1860033\n",
      "Validation loss decreased (0.202846 --> 0.197229).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.2226020\n",
      "\tspeed: 0.0764s/iter; left time: 503.9313s\n",
      "\titers: 200, epoch: 4 | loss: 0.1368843\n",
      "\tspeed: 0.0772s/iter; left time: 501.4254s\n",
      "\titers: 300, epoch: 4 | loss: 0.1798556\n",
      "\tspeed: 0.0772s/iter; left time: 494.2970s\n",
      "Epoch: 4 cost time: 30.20103430747986\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.1749655 Vali Loss: 0.1957066 Test Loss: 0.1812293\n",
      "Validation loss decreased (0.197229 --> 0.195707).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1695017\n",
      "\tspeed: 0.0753s/iter; left time: 467.1188s\n",
      "\titers: 200, epoch: 5 | loss: 0.1423173\n",
      "\tspeed: 0.0715s/iter; left time: 436.6012s\n",
      "\titers: 300, epoch: 5 | loss: 0.1349889\n",
      "\tspeed: 0.0757s/iter; left time: 454.4797s\n",
      "Epoch: 5 cost time: 29.75413227081299\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.1695662 Vali Loss: 0.1895586 Test Loss: 0.1690440\n",
      "Validation loss decreased (0.195707 --> 0.189559).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.1416980\n",
      "\tspeed: 0.0749s/iter; left time: 435.3024s\n",
      "\titers: 200, epoch: 6 | loss: 0.1607366\n",
      "\tspeed: 0.0743s/iter; left time: 424.3909s\n",
      "\titers: 300, epoch: 6 | loss: 0.1786595\n",
      "\tspeed: 0.0730s/iter; left time: 409.8018s\n",
      "Epoch: 6 cost time: 28.982641220092773\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.1675262 Vali Loss: 0.1904025 Test Loss: 0.1706934\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1500578\n",
      "\tspeed: 0.0742s/iter; left time: 401.7536s\n",
      "\titers: 200, epoch: 7 | loss: 0.1610824\n",
      "\tspeed: 0.0749s/iter; left time: 398.2470s\n",
      "\titers: 300, epoch: 7 | loss: 0.1680074\n",
      "\tspeed: 0.0738s/iter; left time: 384.9154s\n",
      "Epoch: 7 cost time: 29.366079092025757\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.1650507 Vali Loss: 0.1896988 Test Loss: 0.1696493\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.1388414\n",
      "\tspeed: 0.0736s/iter; left time: 369.7713s\n",
      "\titers: 200, epoch: 8 | loss: 0.1480400\n",
      "\tspeed: 0.0753s/iter; left time: 370.5727s\n",
      "\titers: 300, epoch: 8 | loss: 0.1574476\n",
      "\tspeed: 0.0749s/iter; left time: 361.1869s\n",
      "Epoch: 8 cost time: 29.59547185897827\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.1641485 Vali Loss: 0.1878532 Test Loss: 0.1668904\n",
      "Validation loss decreased (0.189559 --> 0.187853).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1411774\n",
      "\tspeed: 0.0776s/iter; left time: 359.0783s\n",
      "\titers: 200, epoch: 9 | loss: 0.1713996\n",
      "\tspeed: 0.0757s/iter; left time: 342.6553s\n",
      "\titers: 300, epoch: 9 | loss: 0.1720767\n",
      "\tspeed: 0.0772s/iter; left time: 342.0751s\n",
      "Epoch: 9 cost time: 30.48186206817627\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.1626561 Vali Loss: 0.1878836 Test Loss: 0.1690954\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.1695123\n",
      "\tspeed: 0.0778s/iter; left time: 329.5167s\n",
      "\titers: 200, epoch: 10 | loss: 0.1307252\n",
      "\tspeed: 0.0774s/iter; left time: 320.0925s\n",
      "\titers: 300, epoch: 10 | loss: 0.1600216\n",
      "\tspeed: 0.0749s/iter; left time: 302.3107s\n",
      "Epoch: 10 cost time: 30.030670642852783\n",
      "Epoch: 10, Steps: 394 | Train Loss: 0.1620850 Vali Loss: 0.1869077 Test Loss: 0.1653643\n",
      "Validation loss decreased (0.187853 --> 0.186908).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1584302\n",
      "\tspeed: 0.0740s/iter; left time: 284.2738s\n",
      "\titers: 200, epoch: 11 | loss: 0.1465812\n",
      "\tspeed: 0.0727s/iter; left time: 272.0302s\n",
      "\titers: 300, epoch: 11 | loss: 0.1638003\n",
      "\tspeed: 0.0753s/iter; left time: 274.2979s\n",
      "Epoch: 11 cost time: 29.710777282714844\n",
      "Epoch: 11, Steps: 394 | Train Loss: 0.1614545 Vali Loss: 0.1862973 Test Loss: 0.1661908\n",
      "Validation loss decreased (0.186908 --> 0.186297).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.1812198\n",
      "\tspeed: 0.0785s/iter; left time: 270.4745s\n",
      "\titers: 200, epoch: 12 | loss: 0.1518902\n",
      "\tspeed: 0.0767s/iter; left time: 256.7761s\n",
      "\titers: 300, epoch: 12 | loss: 0.1440954\n",
      "\tspeed: 0.0756s/iter; left time: 245.6094s\n",
      "Epoch: 12 cost time: 30.105901956558228\n",
      "Epoch: 12, Steps: 394 | Train Loss: 0.1611474 Vali Loss: 0.1858270 Test Loss: 0.1628177\n",
      "Validation loss decreased (0.186297 --> 0.185827).  Saving model ...\n",
      "\titers: 100, epoch: 13 | loss: 0.1633466\n",
      "\tspeed: 0.0743s/iter; left time: 226.8031s\n",
      "\titers: 200, epoch: 13 | loss: 0.1464046\n",
      "\tspeed: 0.0756s/iter; left time: 223.2338s\n",
      "\titers: 300, epoch: 13 | loss: 0.1627931\n",
      "\tspeed: 0.0773s/iter; left time: 220.4969s\n",
      "Epoch: 13 cost time: 30.103548049926758\n",
      "Epoch: 13, Steps: 394 | Train Loss: 0.1608465 Vali Loss: 0.1856407 Test Loss: 0.1644692\n",
      "Validation loss decreased (0.185827 --> 0.185641).  Saving model ...\n",
      "\titers: 100, epoch: 14 | loss: 0.1398947\n",
      "\tspeed: 0.0737s/iter; left time: 195.9067s\n",
      "\titers: 200, epoch: 14 | loss: 0.1765853\n",
      "\tspeed: 0.0716s/iter; left time: 183.1448s\n",
      "\titers: 300, epoch: 14 | loss: 0.1759423\n",
      "\tspeed: 0.0711s/iter; left time: 174.7785s\n",
      "Epoch: 14 cost time: 28.53831124305725\n",
      "Epoch: 14, Steps: 394 | Train Loss: 0.1605600 Vali Loss: 0.1844877 Test Loss: 0.1610051\n",
      "Validation loss decreased (0.185641 --> 0.184488).  Saving model ...\n",
      "\titers: 100, epoch: 15 | loss: 0.1337958\n",
      "\tspeed: 0.0743s/iter; left time: 168.3509s\n",
      "\titers: 200, epoch: 15 | loss: 0.1415984\n",
      "\tspeed: 0.0751s/iter; left time: 162.6398s\n",
      "\titers: 300, epoch: 15 | loss: 0.1677892\n",
      "\tspeed: 0.0775s/iter; left time: 159.9919s\n",
      "Epoch: 15 cost time: 30.065003395080566\n",
      "Epoch: 15, Steps: 394 | Train Loss: 0.1601449 Vali Loss: 0.1859169 Test Loss: 0.1657272\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 16 | loss: 0.1394436\n",
      "\tspeed: 0.0805s/iter; left time: 150.6257s\n",
      "\titers: 200, epoch: 16 | loss: 0.1767854\n",
      "\tspeed: 0.0776s/iter; left time: 137.3576s\n",
      "\titers: 300, epoch: 16 | loss: 0.1723968\n",
      "\tspeed: 0.0768s/iter; left time: 128.3762s\n",
      "Epoch: 16 cost time: 30.57214331626892\n",
      "Epoch: 16, Steps: 394 | Train Loss: 0.1598634 Vali Loss: 0.1849635 Test Loss: 0.1621425\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 17 | loss: 0.1582435\n",
      "\tspeed: 0.0740s/iter; left time: 109.2737s\n",
      "\titers: 200, epoch: 17 | loss: 0.1744539\n",
      "\tspeed: 0.0709s/iter; left time: 97.6269s\n",
      "\titers: 300, epoch: 17 | loss: 0.1687208\n",
      "\tspeed: 0.0767s/iter; left time: 98.0009s\n",
      "Epoch: 17 cost time: 29.60562300682068\n",
      "Epoch: 17, Steps: 394 | Train Loss: 0.1598240 Vali Loss: 0.1840785 Test Loss: 0.1601448\n",
      "Validation loss decreased (0.184488 --> 0.184078).  Saving model ...\n",
      "\titers: 100, epoch: 18 | loss: 0.1799743\n",
      "\tspeed: 0.0796s/iter; left time: 86.1889s\n",
      "\titers: 200, epoch: 18 | loss: 0.1728431\n",
      "\tspeed: 0.0779s/iter; left time: 76.6176s\n",
      "\titers: 300, epoch: 18 | loss: 0.1623224\n",
      "\tspeed: 0.0789s/iter; left time: 69.6901s\n",
      "Epoch: 18 cost time: 31.12893772125244\n",
      "Epoch: 18, Steps: 394 | Train Loss: 0.1596381 Vali Loss: 0.1842079 Test Loss: 0.1602769\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 19 | loss: 0.1667848\n",
      "\tspeed: 0.0780s/iter; left time: 53.7433s\n",
      "\titers: 200, epoch: 19 | loss: 0.1517913\n",
      "\tspeed: 0.0762s/iter; left time: 44.8979s\n",
      "\titers: 300, epoch: 19 | loss: 0.1690041\n",
      "\tspeed: 0.0698s/iter; left time: 34.1225s\n",
      "Epoch: 19 cost time: 28.51310157775879\n",
      "Epoch: 19, Steps: 394 | Train Loss: 0.1590661 Vali Loss: 0.1848747 Test Loss: 0.1631720\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 20 | loss: 0.1399102\n",
      "\tspeed: 0.0756s/iter; left time: 22.3032s\n",
      "\titers: 200, epoch: 20 | loss: 0.1746336\n",
      "\tspeed: 0.0761s/iter; left time: 14.8380s\n",
      "\titers: 300, epoch: 20 | loss: 0.1558561\n",
      "\tspeed: 0.0766s/iter; left time: 7.2796s\n",
      "Epoch: 20 cost time: 29.957200527191162\n",
      "Epoch: 20, Steps: 394 | Train Loss: 0.1589400 Vali Loss: 0.1835168 Test Loss: 0.1596920\n",
      "Validation loss decreased (0.184078 --> 0.183517).  Saving model ...\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.1596919298171997, mae:0.2043636292219162\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on DEWINDh_small with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_DEWINDh_small_il168_pl336_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.3089052\n",
      "\tspeed: 0.0798s/iter; left time: 612.7047s\n",
      "\titers: 200, epoch: 1 | loss: 0.2449039\n",
      "\tspeed: 0.0755s/iter; left time: 572.0203s\n",
      "\titers: 300, epoch: 1 | loss: 0.2180312\n",
      "\tspeed: 0.0762s/iter; left time: 570.3040s\n",
      "Epoch: 1 cost time: 30.1840500831604\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.3405002 Vali Loss: 0.2122200 Test Loss: 0.2389717\n",
      "Validation loss decreased (inf --> 0.212220).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.1971092\n",
      "\tspeed: 0.0784s/iter; left time: 571.4593s\n",
      "\titers: 200, epoch: 2 | loss: 0.2023050\n",
      "\tspeed: 0.0793s/iter; left time: 570.0242s\n",
      "\titers: 300, epoch: 2 | loss: 0.2043447\n",
      "\tspeed: 0.0777s/iter; left time: 551.3581s\n",
      "Epoch: 2 cost time: 30.693729877471924\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.1995224 Vali Loss: 0.2043797 Test Loss: 0.2441888\n",
      "Validation loss decreased (0.212220 --> 0.204380).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1701892\n",
      "\tspeed: 0.0805s/iter; left time: 555.8790s\n",
      "\titers: 200, epoch: 3 | loss: 0.1865168\n",
      "\tspeed: 0.0763s/iter; left time: 519.1060s\n",
      "\titers: 300, epoch: 3 | loss: 0.1814975\n",
      "\tspeed: 0.0744s/iter; left time: 498.8167s\n",
      "Epoch: 3 cost time: 29.702519178390503\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.1862601 Vali Loss: 0.1988582 Test Loss: 0.2183375\n",
      "Validation loss decreased (0.204380 --> 0.198858).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.1989189\n",
      "\tspeed: 0.0745s/iter; left time: 485.2125s\n",
      "\titers: 200, epoch: 4 | loss: 0.1916326\n",
      "\tspeed: 0.0727s/iter; left time: 466.5957s\n",
      "\titers: 300, epoch: 4 | loss: 0.1769612\n",
      "\tspeed: 0.0752s/iter; left time: 474.6483s\n",
      "Epoch: 4 cost time: 28.896849393844604\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.1820296 Vali Loss: 0.1989884 Test Loss: 0.2368640\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1784596\n",
      "\tspeed: 0.0738s/iter; left time: 452.0711s\n",
      "\titers: 200, epoch: 5 | loss: 0.1704213\n",
      "\tspeed: 0.0727s/iter; left time: 438.0227s\n",
      "\titers: 300, epoch: 5 | loss: 0.1659487\n",
      "\tspeed: 0.0742s/iter; left time: 439.3917s\n",
      "Epoch: 5 cost time: 29.307000398635864\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.1771438 Vali Loss: 0.1956012 Test Loss: 0.2258228\n",
      "Validation loss decreased (0.198858 --> 0.195601).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.1843170\n",
      "\tspeed: 0.0755s/iter; left time: 433.1170s\n",
      "\titers: 200, epoch: 6 | loss: 0.1884287\n",
      "\tspeed: 0.0764s/iter; left time: 430.4899s\n",
      "\titers: 300, epoch: 6 | loss: 0.1779829\n",
      "\tspeed: 0.0781s/iter; left time: 432.3240s\n",
      "Epoch: 6 cost time: 29.885653734207153\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.1751732 Vali Loss: 0.1940534 Test Loss: 0.2175993\n",
      "Validation loss decreased (0.195601 --> 0.194053).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1669609\n",
      "\tspeed: 0.0746s/iter; left time: 399.1400s\n",
      "\titers: 200, epoch: 7 | loss: 0.1783348\n",
      "\tspeed: 0.0770s/iter; left time: 403.7708s\n",
      "\titers: 300, epoch: 7 | loss: 0.1895222\n",
      "\tspeed: 0.0769s/iter; left time: 395.6462s\n",
      "Epoch: 7 cost time: 29.74129819869995\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.1728891 Vali Loss: 0.1922521 Test Loss: 0.2098337\n",
      "Validation loss decreased (0.194053 --> 0.192252).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.1756118\n",
      "\tspeed: 0.0767s/iter; left time: 380.1700s\n",
      "\titers: 200, epoch: 8 | loss: 0.2161881\n",
      "\tspeed: 0.0755s/iter; left time: 366.7257s\n",
      "\titers: 300, epoch: 8 | loss: 0.1821270\n",
      "\tspeed: 0.0733s/iter; left time: 348.9156s\n",
      "Epoch: 8 cost time: 28.868770599365234\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.1718809 Vali Loss: 0.1935395 Test Loss: 0.2146996\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1849502\n",
      "\tspeed: 0.0736s/iter; left time: 336.2685s\n",
      "\titers: 200, epoch: 9 | loss: 0.1606214\n",
      "\tspeed: 0.0737s/iter; left time: 329.2710s\n",
      "\titers: 300, epoch: 9 | loss: 0.1407036\n",
      "\tspeed: 0.0743s/iter; left time: 324.5110s\n",
      "Epoch: 9 cost time: 28.852532863616943\n",
      "Epoch: 9, Steps: 389 | Train Loss: 0.1707478 Vali Loss: 0.1918205 Test Loss: 0.2071518\n",
      "Validation loss decreased (0.192252 --> 0.191820).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.1762407\n",
      "\tspeed: 0.0783s/iter; left time: 327.3276s\n",
      "\titers: 200, epoch: 10 | loss: 0.1675891\n",
      "\tspeed: 0.0778s/iter; left time: 317.6159s\n",
      "\titers: 300, epoch: 10 | loss: 0.1774089\n",
      "\tspeed: 0.0808s/iter; left time: 321.5154s\n",
      "Epoch: 10 cost time: 30.558494091033936\n",
      "Epoch: 10, Steps: 389 | Train Loss: 0.1703252 Vali Loss: 0.1911758 Test Loss: 0.2020186\n",
      "Validation loss decreased (0.191820 --> 0.191176).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1920739\n",
      "\tspeed: 0.0784s/iter; left time: 297.3095s\n",
      "\titers: 200, epoch: 11 | loss: 0.1781030\n",
      "\tspeed: 0.0772s/iter; left time: 284.9731s\n",
      "\titers: 300, epoch: 11 | loss: 0.1728748\n",
      "\tspeed: 0.0785s/iter; left time: 281.7912s\n",
      "Epoch: 11 cost time: 30.12713313102722\n",
      "Epoch: 11, Steps: 389 | Train Loss: 0.1694754 Vali Loss: 0.1919729 Test Loss: 0.2102083\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.1714095\n",
      "\tspeed: 0.0757s/iter; left time: 257.6949s\n",
      "\titers: 200, epoch: 12 | loss: 0.1819821\n",
      "\tspeed: 0.0757s/iter; left time: 249.9401s\n",
      "\titers: 300, epoch: 12 | loss: 0.1549750\n",
      "\tspeed: 0.0794s/iter; left time: 254.1327s\n",
      "Epoch: 12 cost time: 29.77595829963684\n",
      "Epoch: 12, Steps: 389 | Train Loss: 0.1691015 Vali Loss: 0.1910069 Test Loss: 0.2042454\n",
      "Validation loss decreased (0.191176 --> 0.191007).  Saving model ...\n",
      "\titers: 100, epoch: 13 | loss: 0.1633630\n",
      "\tspeed: 0.0750s/iter; left time: 225.9962s\n",
      "\titers: 200, epoch: 13 | loss: 0.1793603\n",
      "\tspeed: 0.0738s/iter; left time: 214.9603s\n",
      "\titers: 300, epoch: 13 | loss: 0.1329528\n",
      "\tspeed: 0.0762s/iter; left time: 214.3092s\n",
      "Epoch: 13 cost time: 29.0005202293396\n",
      "Epoch: 13, Steps: 389 | Train Loss: 0.1689753 Vali Loss: 0.1910753 Test Loss: 0.2053822\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 14 | loss: 0.1681648\n",
      "\tspeed: 0.0759s/iter; left time: 199.2360s\n",
      "\titers: 200, epoch: 14 | loss: 0.1601659\n",
      "\tspeed: 0.0757s/iter; left time: 190.9758s\n",
      "\titers: 300, epoch: 14 | loss: 0.1697524\n",
      "\tspeed: 0.0753s/iter; left time: 182.5051s\n",
      "Epoch: 14 cost time: 29.370519876480103\n",
      "Epoch: 14, Steps: 389 | Train Loss: 0.1684838 Vali Loss: 0.1908086 Test Loss: 0.2031945\n",
      "Validation loss decreased (0.191007 --> 0.190809).  Saving model ...\n",
      "\titers: 100, epoch: 15 | loss: 0.1669336\n",
      "\tspeed: 0.0735s/iter; left time: 164.1985s\n",
      "\titers: 200, epoch: 15 | loss: 0.1948712\n",
      "\tspeed: 0.0756s/iter; left time: 161.4256s\n",
      "\titers: 300, epoch: 15 | loss: 0.1487166\n",
      "\tspeed: 0.0741s/iter; left time: 150.8323s\n",
      "Epoch: 15 cost time: 28.90963625907898\n",
      "Epoch: 15, Steps: 389 | Train Loss: 0.1683818 Vali Loss: 0.1916436 Test Loss: 0.2058382\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 16 | loss: 0.1411319\n",
      "\tspeed: 0.0739s/iter; left time: 136.4801s\n",
      "\titers: 200, epoch: 16 | loss: 0.1631022\n",
      "\tspeed: 0.0758s/iter; left time: 132.3120s\n",
      "\titers: 300, epoch: 16 | loss: 0.1603058\n",
      "\tspeed: 0.0740s/iter; left time: 121.8039s\n",
      "Epoch: 16 cost time: 28.954631567001343\n",
      "Epoch: 16, Steps: 389 | Train Loss: 0.1679950 Vali Loss: 0.1905985 Test Loss: 0.2039151\n",
      "Validation loss decreased (0.190809 --> 0.190598).  Saving model ...\n",
      "\titers: 100, epoch: 17 | loss: 0.1616268\n",
      "\tspeed: 0.0714s/iter; left time: 104.0821s\n",
      "\titers: 200, epoch: 17 | loss: 0.1436342\n",
      "\tspeed: 0.0704s/iter; left time: 95.4947s\n",
      "\titers: 300, epoch: 17 | loss: 0.1674689\n",
      "\tspeed: 0.0733s/iter; left time: 92.1185s\n",
      "Epoch: 17 cost time: 28.1983425617218\n",
      "Epoch: 17, Steps: 389 | Train Loss: 0.1677895 Vali Loss: 0.1911520 Test Loss: 0.2062658\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 18 | loss: 0.1760904\n",
      "\tspeed: 0.0776s/iter; left time: 82.8257s\n",
      "\titers: 200, epoch: 18 | loss: 0.1525475\n",
      "\tspeed: 0.0795s/iter; left time: 76.9093s\n",
      "\titers: 300, epoch: 18 | loss: 0.1754203\n",
      "\tspeed: 0.0796s/iter; left time: 69.1224s\n",
      "Epoch: 18 cost time: 30.72171688079834\n",
      "Epoch: 18, Steps: 389 | Train Loss: 0.1674474 Vali Loss: 0.1904949 Test Loss: 0.2030128\n",
      "Validation loss decreased (0.190598 --> 0.190495).  Saving model ...\n",
      "\titers: 100, epoch: 19 | loss: 0.1821263\n",
      "\tspeed: 0.0725s/iter; left time: 49.2447s\n",
      "\titers: 200, epoch: 19 | loss: 0.1540752\n",
      "\tspeed: 0.0761s/iter; left time: 44.0550s\n",
      "\titers: 300, epoch: 19 | loss: 0.1466377\n",
      "\tspeed: 0.0764s/iter; left time: 36.5720s\n",
      "Epoch: 19 cost time: 29.318702936172485\n",
      "Epoch: 19, Steps: 389 | Train Loss: 0.1672393 Vali Loss: 0.1899398 Test Loss: 0.1974106\n",
      "Validation loss decreased (0.190495 --> 0.189940).  Saving model ...\n",
      "\titers: 100, epoch: 20 | loss: 0.1473804\n",
      "\tspeed: 0.0787s/iter; left time: 22.8279s\n",
      "\titers: 200, epoch: 20 | loss: 0.1694173\n",
      "\tspeed: 0.0796s/iter; left time: 15.1195s\n",
      "\titers: 300, epoch: 20 | loss: 0.1598329\n",
      "\tspeed: 0.0790s/iter; left time: 7.1120s\n",
      "Epoch: 20 cost time: 30.735726356506348\n",
      "Epoch: 20, Steps: 389 | Train Loss: 0.1670104 Vali Loss: 0.1905455 Test Loss: 0.2014823\n",
      "EarlyStopping counter: 1 out of 3\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.19741059839725494, mae:0.2280973196029663\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on DEWINDh_small with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_DEWINDh_small_il168_pl720_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.3235501\n",
      "\tspeed: 0.0779s/iter; left time: 579.8224s\n",
      "\titers: 200, epoch: 1 | loss: 0.2648822\n",
      "\tspeed: 0.0743s/iter; left time: 545.3850s\n",
      "\titers: 300, epoch: 1 | loss: 0.2323041\n",
      "\tspeed: 0.0777s/iter; left time: 562.6037s\n",
      "Epoch: 1 cost time: 29.132827281951904\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.3913172 Vali Loss: 0.2133706 Test Loss: 0.2998368\n",
      "Validation loss decreased (inf --> 0.213371).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.2221394\n",
      "\tspeed: 0.0814s/iter; left time: 574.7584s\n",
      "\titers: 200, epoch: 2 | loss: 0.2123696\n",
      "\tspeed: 0.0841s/iter; left time: 585.9912s\n",
      "\titers: 300, epoch: 2 | loss: 0.2254831\n",
      "\tspeed: 0.0830s/iter; left time: 569.6089s\n",
      "Epoch: 2 cost time: 31.1952645778656\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.2212811 Vali Loss: 0.2066567 Test Loss: 0.2723224\n",
      "Validation loss decreased (0.213371 --> 0.206657).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2022787\n",
      "\tspeed: 0.0768s/iter; left time: 513.4261s\n",
      "\titers: 200, epoch: 3 | loss: 0.2138183\n",
      "\tspeed: 0.0770s/iter; left time: 507.1004s\n",
      "\titers: 300, epoch: 3 | loss: 0.2231981\n",
      "\tspeed: 0.0799s/iter; left time: 518.3955s\n",
      "Epoch: 3 cost time: 29.562582969665527\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.2092318 Vali Loss: 0.2026598 Test Loss: 0.3049836\n",
      "Validation loss decreased (0.206657 --> 0.202660).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.2098389\n",
      "\tspeed: 0.0832s/iter; left time: 524.8930s\n",
      "\titers: 200, epoch: 4 | loss: 0.1943580\n",
      "\tspeed: 0.0829s/iter; left time: 514.7155s\n",
      "\titers: 300, epoch: 4 | loss: 0.2257080\n",
      "\tspeed: 0.0813s/iter; left time: 496.8715s\n",
      "Epoch: 4 cost time: 31.03621244430542\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.2049911 Vali Loss: 0.1998113 Test Loss: 0.2894856\n",
      "Validation loss decreased (0.202660 --> 0.199811).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1842321\n",
      "\tspeed: 0.0774s/iter; left time: 459.2608s\n",
      "\titers: 200, epoch: 5 | loss: 0.2201308\n",
      "\tspeed: 0.0783s/iter; left time: 456.4542s\n",
      "\titers: 300, epoch: 5 | loss: 0.1663116\n",
      "\tspeed: 0.0776s/iter; left time: 444.9396s\n",
      "Epoch: 5 cost time: 29.649234771728516\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.1999159 Vali Loss: 0.1969206 Test Loss: 0.2680311\n",
      "Validation loss decreased (0.199811 --> 0.196921).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.2128072\n",
      "\tspeed: 0.0791s/iter; left time: 439.6833s\n",
      "\titers: 200, epoch: 6 | loss: 0.1767525\n",
      "\tspeed: 0.0815s/iter; left time: 444.6044s\n",
      "\titers: 300, epoch: 6 | loss: 0.2031664\n",
      "\tspeed: 0.0811s/iter; left time: 434.4752s\n",
      "Epoch: 6 cost time: 30.217668056488037\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.1980478 Vali Loss: 0.1969830 Test Loss: 0.2682118\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2006702\n",
      "\tspeed: 0.0772s/iter; left time: 399.6549s\n",
      "\titers: 200, epoch: 7 | loss: 0.2301098\n",
      "\tspeed: 0.0758s/iter; left time: 384.9299s\n",
      "\titers: 300, epoch: 7 | loss: 0.1679405\n",
      "\tspeed: 0.0771s/iter; left time: 384.1109s\n",
      "Epoch: 7 cost time: 29.236342906951904\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.1956183 Vali Loss: 0.1977811 Test Loss: 0.2772325\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.1832284\n",
      "\tspeed: 0.0806s/iter; left time: 387.1439s\n",
      "\titers: 200, epoch: 8 | loss: 0.2081524\n",
      "\tspeed: 0.0783s/iter; left time: 368.3125s\n",
      "\titers: 300, epoch: 8 | loss: 0.2043418\n",
      "\tspeed: 0.0769s/iter; left time: 353.6847s\n",
      "Epoch: 8 cost time: 29.307720184326172\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.1946416 Vali Loss: 0.1957692 Test Loss: 0.2640577\n",
      "Validation loss decreased (0.196921 --> 0.195769).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1640617\n",
      "\tspeed: 0.0830s/iter; left time: 367.3748s\n",
      "\titers: 200, epoch: 9 | loss: 0.1844905\n",
      "\tspeed: 0.0808s/iter; left time: 349.2595s\n",
      "\titers: 300, epoch: 9 | loss: 0.2033575\n",
      "\tspeed: 0.0773s/iter; left time: 326.5899s\n",
      "Epoch: 9 cost time: 30.23826313018799\n",
      "Epoch: 9, Steps: 377 | Train Loss: 0.1933247 Vali Loss: 0.1947239 Test Loss: 0.2589608\n",
      "Validation loss decreased (0.195769 --> 0.194724).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.2071355\n",
      "\tspeed: 0.0776s/iter; left time: 314.2437s\n",
      "\titers: 200, epoch: 10 | loss: 0.2087751\n",
      "\tspeed: 0.0795s/iter; left time: 313.7736s\n",
      "\titers: 300, epoch: 10 | loss: 0.1729166\n",
      "\tspeed: 0.0783s/iter; left time: 301.2474s\n",
      "Epoch: 10 cost time: 29.590468645095825\n",
      "Epoch: 10, Steps: 377 | Train Loss: 0.1926593 Vali Loss: 0.1942657 Test Loss: 0.2477294\n",
      "Validation loss decreased (0.194724 --> 0.194266).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.2194545\n",
      "\tspeed: 0.0780s/iter; left time: 286.4688s\n",
      "\titers: 200, epoch: 11 | loss: 0.1932855\n",
      "\tspeed: 0.0808s/iter; left time: 288.3875s\n",
      "\titers: 300, epoch: 11 | loss: 0.2018244\n",
      "\tspeed: 0.0801s/iter; left time: 278.0255s\n",
      "Epoch: 11 cost time: 29.950905323028564\n",
      "Epoch: 11, Steps: 377 | Train Loss: 0.1922144 Vali Loss: 0.1948200 Test Loss: 0.2625062\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.2130330\n",
      "\tspeed: 0.0775s/iter; left time: 255.1221s\n",
      "\titers: 200, epoch: 12 | loss: 0.1919490\n",
      "\tspeed: 0.0808s/iter; left time: 258.1724s\n",
      "\titers: 300, epoch: 12 | loss: 0.2044085\n",
      "\tspeed: 0.0778s/iter; left time: 240.8613s\n",
      "Epoch: 12 cost time: 29.7271671295166\n",
      "Epoch: 12, Steps: 377 | Train Loss: 0.1916047 Vali Loss: 0.1943975 Test Loss: 0.2552732\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.1898448\n",
      "\tspeed: 0.0790s/iter; left time: 230.3400s\n",
      "\titers: 200, epoch: 13 | loss: 0.1773221\n",
      "\tspeed: 0.0784s/iter; left time: 220.9193s\n",
      "\titers: 300, epoch: 13 | loss: 0.1990347\n",
      "\tspeed: 0.0766s/iter; left time: 208.2515s\n",
      "Epoch: 13 cost time: 29.537351369857788\n",
      "Epoch: 13, Steps: 377 | Train Loss: 0.1914568 Vali Loss: 0.1957366 Test Loss: 0.2727609\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.2477293610572815, mae:0.2758016884326935\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTHh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTHh1_il168_pl24_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.1489368\n",
      "\tspeed: 0.0774s/iter; left time: 610.1300s\n",
      "\titers: 200, epoch: 1 | loss: 0.0885228\n",
      "\tspeed: 0.0751s/iter; left time: 584.6239s\n",
      "\titers: 300, epoch: 1 | loss: 0.0751145\n",
      "\tspeed: 0.0725s/iter; left time: 557.0661s\n",
      "Epoch: 1 cost time: 29.815667629241943\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.1805945 Vali Loss: 0.0273327 Test Loss: 0.0281784\n",
      "Validation loss decreased (inf --> 0.027333).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0585177\n",
      "\tspeed: 0.0734s/iter; left time: 549.4168s\n",
      "\titers: 200, epoch: 2 | loss: 0.0520144\n",
      "\tspeed: 0.0721s/iter; left time: 532.0657s\n",
      "\titers: 300, epoch: 2 | loss: 0.0466560\n",
      "\tspeed: 0.0729s/iter; left time: 531.2042s\n",
      "Epoch: 2 cost time: 29.602127075195312\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0531827 Vali Loss: 0.0281360 Test Loss: 0.0286566\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0322356\n",
      "\tspeed: 0.0773s/iter; left time: 547.4056s\n",
      "\titers: 200, epoch: 3 | loss: 0.0393360\n",
      "\tspeed: 0.0777s/iter; left time: 542.5032s\n",
      "\titers: 300, epoch: 3 | loss: 0.0404675\n",
      "\tspeed: 0.0758s/iter; left time: 521.8882s\n",
      "Epoch: 3 cost time: 30.595942497253418\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0387130 Vali Loss: 0.0196359 Test Loss: 0.0199955\n",
      "Validation loss decreased (0.027333 --> 0.019636).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0339426\n",
      "\tspeed: 0.0759s/iter; left time: 507.4023s\n",
      "\titers: 200, epoch: 4 | loss: 0.0330963\n",
      "\tspeed: 0.0755s/iter; left time: 496.8718s\n",
      "\titers: 300, epoch: 4 | loss: 0.0446535\n",
      "\tspeed: 0.0736s/iter; left time: 477.2354s\n",
      "Epoch: 4 cost time: 29.761049509048462\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0350078 Vali Loss: 0.0197159 Test Loss: 0.0201144\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0302076\n",
      "\tspeed: 0.0795s/iter; left time: 499.3656s\n",
      "\titers: 200, epoch: 5 | loss: 0.0300402\n",
      "\tspeed: 0.0795s/iter; left time: 491.5253s\n",
      "\titers: 300, epoch: 5 | loss: 0.0304756\n",
      "\tspeed: 0.0752s/iter; left time: 457.5047s\n",
      "Epoch: 5 cost time: 30.893176078796387\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0313149 Vali Loss: 0.0168417 Test Loss: 0.0170967\n",
      "Validation loss decreased (0.019636 --> 0.016842).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0318843\n",
      "\tspeed: 0.0790s/iter; left time: 464.7333s\n",
      "\titers: 200, epoch: 6 | loss: 0.0358781\n",
      "\tspeed: 0.0813s/iter; left time: 470.5942s\n",
      "\titers: 300, epoch: 6 | loss: 0.0337669\n",
      "\tspeed: 0.0774s/iter; left time: 440.3030s\n",
      "Epoch: 6 cost time: 31.106218338012695\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0304823 Vali Loss: 0.0193089 Test Loss: 0.0194647\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0290234\n",
      "\tspeed: 0.0749s/iter; left time: 411.0799s\n",
      "\titers: 200, epoch: 7 | loss: 0.0253387\n",
      "\tspeed: 0.0732s/iter; left time: 394.5293s\n",
      "\titers: 300, epoch: 7 | loss: 0.0264543\n",
      "\tspeed: 0.0751s/iter; left time: 396.8695s\n",
      "Epoch: 7 cost time: 29.713486194610596\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0283958 Vali Loss: 0.0166862 Test Loss: 0.0170902\n",
      "Validation loss decreased (0.016842 --> 0.016686).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0250031\n",
      "\tspeed: 0.0731s/iter; left time: 371.9873s\n",
      "\titers: 200, epoch: 8 | loss: 0.0287198\n",
      "\tspeed: 0.0745s/iter; left time: 371.7144s\n",
      "\titers: 300, epoch: 8 | loss: 0.0323795\n",
      "\tspeed: 0.0739s/iter; left time: 361.4324s\n",
      "Epoch: 8 cost time: 29.474294185638428\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0278000 Vali Loss: 0.0171151 Test Loss: 0.0174113\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0316611\n",
      "\tspeed: 0.0795s/iter; left time: 372.7873s\n",
      "\titers: 200, epoch: 9 | loss: 0.0222336\n",
      "\tspeed: 0.0756s/iter; left time: 346.9641s\n",
      "\titers: 300, epoch: 9 | loss: 0.0294640\n",
      "\tspeed: 0.0785s/iter; left time: 352.4904s\n",
      "Epoch: 9 cost time: 30.62826657295227\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0272357 Vali Loss: 0.0165558 Test Loss: 0.0169899\n",
      "Validation loss decreased (0.016686 --> 0.016556).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0244313\n",
      "\tspeed: 0.0734s/iter; left time: 314.8428s\n",
      "\titers: 200, epoch: 10 | loss: 0.0266693\n",
      "\tspeed: 0.0761s/iter; left time: 318.7655s\n",
      "\titers: 300, epoch: 10 | loss: 0.0253471\n",
      "\tspeed: 0.0750s/iter; left time: 306.6211s\n",
      "Epoch: 10 cost time: 29.121085166931152\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0267103 Vali Loss: 0.0165108 Test Loss: 0.0169759\n",
      "Validation loss decreased (0.016556 --> 0.016511).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0261905\n",
      "\tspeed: 0.0726s/iter; left time: 282.3438s\n",
      "\titers: 200, epoch: 11 | loss: 0.0255063\n",
      "\tspeed: 0.0736s/iter; left time: 279.0581s\n",
      "\titers: 300, epoch: 11 | loss: 0.0236521\n",
      "\tspeed: 0.0720s/iter; left time: 265.7038s\n",
      "Epoch: 11 cost time: 28.97366952896118\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0264121 Vali Loss: 0.0162322 Test Loss: 0.0165294\n",
      "Validation loss decreased (0.016511 --> 0.016232).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.0276231\n",
      "\tspeed: 0.0712s/iter; left time: 248.6130s\n",
      "\titers: 200, epoch: 12 | loss: 0.0275747\n",
      "\tspeed: 0.0730s/iter; left time: 247.4940s\n",
      "\titers: 300, epoch: 12 | loss: 0.0293928\n",
      "\tspeed: 0.0745s/iter; left time: 245.3176s\n",
      "Epoch: 12 cost time: 29.65352201461792\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0261659 Vali Loss: 0.0166722 Test Loss: 0.0169044\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.0251598\n",
      "\tspeed: 0.0745s/iter; left time: 230.5627s\n",
      "\titers: 200, epoch: 13 | loss: 0.0249021\n",
      "\tspeed: 0.0731s/iter; left time: 218.8623s\n",
      "\titers: 300, epoch: 13 | loss: 0.0228404\n",
      "\tspeed: 0.0733s/iter; left time: 212.0907s\n",
      "Epoch: 13 cost time: 29.35710597038269\n",
      "Epoch: 13, Steps: 399 | Train Loss: 0.0262006 Vali Loss: 0.0164409 Test Loss: 0.0167019\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 14 | loss: 0.0226136\n",
      "\tspeed: 0.0736s/iter; left time: 198.1449s\n",
      "\titers: 200, epoch: 14 | loss: 0.0251848\n",
      "\tspeed: 0.0745s/iter; left time: 193.2101s\n",
      "\titers: 300, epoch: 14 | loss: 0.0224757\n",
      "\tspeed: 0.0730s/iter; left time: 182.0548s\n",
      "Epoch: 14 cost time: 29.748730421066284\n",
      "Epoch: 14, Steps: 399 | Train Loss: 0.0258112 Vali Loss: 0.0162043 Test Loss: 0.0165244\n",
      "Validation loss decreased (0.016232 --> 0.016204).  Saving model ...\n",
      "\titers: 100, epoch: 15 | loss: 0.0277817\n",
      "\tspeed: 0.0769s/iter; left time: 176.5297s\n",
      "\titers: 200, epoch: 15 | loss: 0.0296372\n",
      "\tspeed: 0.0804s/iter; left time: 176.4948s\n",
      "\titers: 300, epoch: 15 | loss: 0.0265428\n",
      "\tspeed: 0.0784s/iter; left time: 164.3047s\n",
      "Epoch: 15 cost time: 31.432372093200684\n",
      "Epoch: 15, Steps: 399 | Train Loss: 0.0257860 Vali Loss: 0.0162071 Test Loss: 0.0164153\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 16 | loss: 0.0245809\n",
      "\tspeed: 0.0741s/iter; left time: 140.5855s\n",
      "\titers: 200, epoch: 16 | loss: 0.0309494\n",
      "\tspeed: 0.0757s/iter; left time: 136.0242s\n",
      "\titers: 300, epoch: 16 | loss: 0.0249287\n",
      "\tspeed: 0.0739s/iter; left time: 125.4049s\n",
      "Epoch: 16 cost time: 29.834770679473877\n",
      "Epoch: 16, Steps: 399 | Train Loss: 0.0254637 Vali Loss: 0.0163076 Test Loss: 0.0165852\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 17 | loss: 0.0265741\n",
      "\tspeed: 0.0758s/iter; left time: 113.4292s\n",
      "\titers: 200, epoch: 17 | loss: 0.0241227\n",
      "\tspeed: 0.0737s/iter; left time: 103.0049s\n",
      "\titers: 300, epoch: 17 | loss: 0.0241825\n",
      "\tspeed: 0.0750s/iter; left time: 97.2940s\n",
      "Epoch: 17 cost time: 30.150392293930054\n",
      "Epoch: 17, Steps: 399 | Train Loss: 0.0254972 Vali Loss: 0.0168013 Test Loss: 0.0170367\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.0165244210511446, mae:0.10238488018512726\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTHh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTHh1_il168_pl48_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.1927081\n",
      "\tspeed: 0.0730s/iter; left time: 573.5735s\n",
      "\titers: 200, epoch: 1 | loss: 0.1138895\n",
      "\tspeed: 0.0725s/iter; left time: 562.3800s\n",
      "\titers: 300, epoch: 1 | loss: 0.0816822\n",
      "\tspeed: 0.0720s/iter; left time: 551.8065s\n",
      "Epoch: 1 cost time: 29.093668937683105\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.2447481 Vali Loss: 0.0265775 Test Loss: 0.0283495\n",
      "Validation loss decreased (inf --> 0.026578).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0675287\n",
      "\tspeed: 0.0762s/iter; left time: 568.4706s\n",
      "\titers: 200, epoch: 2 | loss: 0.0536730\n",
      "\tspeed: 0.0787s/iter; left time: 579.4884s\n",
      "\titers: 300, epoch: 2 | loss: 0.0434159\n",
      "\tspeed: 0.0746s/iter; left time: 541.8877s\n",
      "Epoch: 2 cost time: 30.09683108329773\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0600929 Vali Loss: 0.0231852 Test Loss: 0.0237996\n",
      "Validation loss decreased (0.026578 --> 0.023185).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0390785\n",
      "\tspeed: 0.0722s/iter; left time: 510.2162s\n",
      "\titers: 200, epoch: 3 | loss: 0.0455152\n",
      "\tspeed: 0.0728s/iter; left time: 507.1093s\n",
      "\titers: 300, epoch: 3 | loss: 0.0392153\n",
      "\tspeed: 0.0744s/iter; left time: 510.5840s\n",
      "Epoch: 3 cost time: 29.183476209640503\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0439679 Vali Loss: 0.0235342 Test Loss: 0.0234499\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.0545021\n",
      "\tspeed: 0.0765s/iter; left time: 509.8349s\n",
      "\titers: 200, epoch: 4 | loss: 0.0432289\n",
      "\tspeed: 0.0774s/iter; left time: 508.0886s\n",
      "\titers: 300, epoch: 4 | loss: 0.0457662\n",
      "\tspeed: 0.0770s/iter; left time: 498.1300s\n",
      "Epoch: 4 cost time: 30.74368977546692\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0399136 Vali Loss: 0.0204405 Test Loss: 0.0205507\n",
      "Validation loss decreased (0.023185 --> 0.020440).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0375664\n",
      "\tspeed: 0.0716s/iter; left time: 449.1374s\n",
      "\titers: 200, epoch: 5 | loss: 0.0331056\n",
      "\tspeed: 0.0724s/iter; left time: 446.8369s\n",
      "\titers: 300, epoch: 5 | loss: 0.0336904\n",
      "\tspeed: 0.0740s/iter; left time: 449.0990s\n",
      "Epoch: 5 cost time: 28.57427167892456\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0355178 Vali Loss: 0.0186007 Test Loss: 0.0186926\n",
      "Validation loss decreased (0.020440 --> 0.018601).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0316716\n",
      "\tspeed: 0.0765s/iter; left time: 449.4227s\n",
      "\titers: 200, epoch: 6 | loss: 0.0321152\n",
      "\tspeed: 0.0774s/iter; left time: 446.4899s\n",
      "\titers: 300, epoch: 6 | loss: 0.0410584\n",
      "\tspeed: 0.0767s/iter; left time: 435.0329s\n",
      "Epoch: 6 cost time: 30.13738989830017\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0339525 Vali Loss: 0.0185641 Test Loss: 0.0182999\n",
      "Validation loss decreased (0.018601 --> 0.018564).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0317649\n",
      "\tspeed: 0.0705s/iter; left time: 386.0796s\n",
      "\titers: 200, epoch: 7 | loss: 0.0306073\n",
      "\tspeed: 0.0740s/iter; left time: 397.7519s\n",
      "\titers: 300, epoch: 7 | loss: 0.0318913\n",
      "\tspeed: 0.0751s/iter; left time: 395.9851s\n",
      "Epoch: 7 cost time: 29.341387033462524\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0319683 Vali Loss: 0.0174227 Test Loss: 0.0174138\n",
      "Validation loss decreased (0.018564 --> 0.017423).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0352760\n",
      "\tspeed: 0.0761s/iter; left time: 386.2304s\n",
      "\titers: 200, epoch: 8 | loss: 0.0351221\n",
      "\tspeed: 0.0760s/iter; left time: 378.0933s\n",
      "\titers: 300, epoch: 8 | loss: 0.0299064\n",
      "\tspeed: 0.0751s/iter; left time: 365.9655s\n",
      "Epoch: 8 cost time: 30.46656370162964\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0315512 Vali Loss: 0.0177813 Test Loss: 0.0177024\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0329300\n",
      "\tspeed: 0.0687s/iter; left time: 321.3512s\n",
      "\titers: 200, epoch: 9 | loss: 0.0298602\n",
      "\tspeed: 0.0729s/iter; left time: 333.6367s\n",
      "\titers: 300, epoch: 9 | loss: 0.0332063\n",
      "\tspeed: 0.0719s/iter; left time: 321.7199s\n",
      "Epoch: 9 cost time: 28.396281957626343\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0307582 Vali Loss: 0.0180440 Test Loss: 0.0177416\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.0295993\n",
      "\tspeed: 0.0754s/iter; left time: 322.4699s\n",
      "\titers: 200, epoch: 10 | loss: 0.0282826\n",
      "\tspeed: 0.0749s/iter; left time: 313.1125s\n",
      "\titers: 300, epoch: 10 | loss: 0.0281586\n",
      "\tspeed: 0.0766s/iter; left time: 312.4911s\n",
      "Epoch: 10 cost time: 30.359238147735596\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.0302704 Vali Loss: 0.0173670 Test Loss: 0.0173206\n",
      "Validation loss decreased (0.017423 --> 0.017367).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0274439\n",
      "\tspeed: 0.0759s/iter; left time: 294.4308s\n",
      "\titers: 200, epoch: 11 | loss: 0.0281774\n",
      "\tspeed: 0.0754s/iter; left time: 285.2602s\n",
      "\titers: 300, epoch: 11 | loss: 0.0322486\n",
      "\tspeed: 0.0744s/iter; left time: 273.7489s\n",
      "Epoch: 11 cost time: 29.703425884246826\n",
      "Epoch: 11, Steps: 398 | Train Loss: 0.0294654 Vali Loss: 0.0171732 Test Loss: 0.0169977\n",
      "Validation loss decreased (0.017367 --> 0.017173).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.0300629\n",
      "\tspeed: 0.0774s/iter; left time: 269.6662s\n",
      "\titers: 200, epoch: 12 | loss: 0.0255531\n",
      "\tspeed: 0.0787s/iter; left time: 266.2447s\n",
      "\titers: 300, epoch: 12 | loss: 0.0287065\n",
      "\tspeed: 0.0758s/iter; left time: 248.9223s\n",
      "Epoch: 12 cost time: 30.93438744544983\n",
      "Epoch: 12, Steps: 398 | Train Loss: 0.0294747 Vali Loss: 0.0170164 Test Loss: 0.0168949\n",
      "Validation loss decreased (0.017173 --> 0.017016).  Saving model ...\n",
      "\titers: 100, epoch: 13 | loss: 0.0262346\n",
      "\tspeed: 0.0775s/iter; left time: 239.1351s\n",
      "\titers: 200, epoch: 13 | loss: 0.0264282\n",
      "\tspeed: 0.0778s/iter; left time: 232.2649s\n",
      "\titers: 300, epoch: 13 | loss: 0.0321957\n",
      "\tspeed: 0.0738s/iter; left time: 212.7744s\n",
      "Epoch: 13 cost time: 29.956655025482178\n",
      "Epoch: 13, Steps: 398 | Train Loss: 0.0292521 Vali Loss: 0.0168265 Test Loss: 0.0167062\n",
      "Validation loss decreased (0.017016 --> 0.016827).  Saving model ...\n",
      "\titers: 100, epoch: 14 | loss: 0.0306535\n",
      "\tspeed: 0.0715s/iter; left time: 192.0437s\n",
      "\titers: 200, epoch: 14 | loss: 0.0264040\n",
      "\tspeed: 0.0757s/iter; left time: 195.8980s\n",
      "\titers: 300, epoch: 14 | loss: 0.0233838\n",
      "\tspeed: 0.0735s/iter; left time: 182.8037s\n",
      "Epoch: 14 cost time: 29.20202875137329\n",
      "Epoch: 14, Steps: 398 | Train Loss: 0.0290857 Vali Loss: 0.0174407 Test Loss: 0.0171790\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 15 | loss: 0.0296180\n",
      "\tspeed: 0.0701s/iter; left time: 160.3991s\n",
      "\titers: 200, epoch: 15 | loss: 0.0266401\n",
      "\tspeed: 0.0731s/iter; left time: 159.9319s\n",
      "\titers: 300, epoch: 15 | loss: 0.0285930\n",
      "\tspeed: 0.0730s/iter; left time: 152.5653s\n",
      "Epoch: 15 cost time: 28.924180030822754\n",
      "Epoch: 15, Steps: 398 | Train Loss: 0.0289327 Vali Loss: 0.0169945 Test Loss: 0.0169134\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 16 | loss: 0.0284180\n",
      "\tspeed: 0.0728s/iter; left time: 137.6105s\n",
      "\titers: 200, epoch: 16 | loss: 0.0290597\n",
      "\tspeed: 0.0759s/iter; left time: 135.9117s\n",
      "\titers: 300, epoch: 16 | loss: 0.0285102\n",
      "\tspeed: 0.0749s/iter; left time: 126.6348s\n",
      "Epoch: 16 cost time: 29.609121084213257\n",
      "Epoch: 16, Steps: 398 | Train Loss: 0.0288168 Vali Loss: 0.0169447 Test Loss: 0.0167835\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.016706209629774094, mae:0.10307476669549942\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTHh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTHh1_il168_pl168_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.2317281\n",
      "\tspeed: 0.0761s/iter; left time: 592.4174s\n",
      "\titers: 200, epoch: 1 | loss: 0.1169130\n",
      "\tspeed: 0.0753s/iter; left time: 578.1234s\n",
      "\titers: 300, epoch: 1 | loss: 0.0893645\n",
      "\tspeed: 0.0772s/iter; left time: 584.9386s\n",
      "Epoch: 1 cost time: 30.134603261947632\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.2757620 Vali Loss: 0.0250435 Test Loss: 0.0258739\n",
      "Validation loss decreased (inf --> 0.025043).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0611678\n",
      "\tspeed: 0.0791s/iter; left time: 584.2426s\n",
      "\titers: 200, epoch: 2 | loss: 0.0597702\n",
      "\tspeed: 0.0828s/iter; left time: 603.2563s\n",
      "\titers: 300, epoch: 2 | loss: 0.0565965\n",
      "\tspeed: 0.0801s/iter; left time: 575.6330s\n",
      "Epoch: 2 cost time: 31.698254108428955\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0601722 Vali Loss: 0.0249944 Test Loss: 0.0240325\n",
      "Validation loss decreased (0.025043 --> 0.024994).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0562376\n",
      "\tspeed: 0.0725s/iter; left time: 506.8388s\n",
      "\titers: 200, epoch: 3 | loss: 0.0421125\n",
      "\tspeed: 0.0718s/iter; left time: 494.6349s\n",
      "\titers: 300, epoch: 3 | loss: 0.0401026\n",
      "\tspeed: 0.0727s/iter; left time: 493.7245s\n",
      "Epoch: 3 cost time: 28.71079134941101\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0452715 Vali Loss: 0.0192721 Test Loss: 0.0201386\n",
      "Validation loss decreased (0.024994 --> 0.019272).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0402316\n",
      "\tspeed: 0.0786s/iter; left time: 518.5787s\n",
      "\titers: 200, epoch: 4 | loss: 0.0399234\n",
      "\tspeed: 0.0747s/iter; left time: 485.2761s\n",
      "\titers: 300, epoch: 4 | loss: 0.0379409\n",
      "\tspeed: 0.0742s/iter; left time: 474.7216s\n",
      "Epoch: 4 cost time: 30.283217430114746\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0410623 Vali Loss: 0.0199838 Test Loss: 0.0207052\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0346940\n",
      "\tspeed: 0.0718s/iter; left time: 445.3963s\n",
      "\titers: 200, epoch: 5 | loss: 0.0379506\n",
      "\tspeed: 0.0724s/iter; left time: 442.1140s\n",
      "\titers: 300, epoch: 5 | loss: 0.0357631\n",
      "\tspeed: 0.0736s/iter; left time: 442.0974s\n",
      "Epoch: 5 cost time: 28.986396074295044\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0365221 Vali Loss: 0.0185240 Test Loss: 0.0194056\n",
      "Validation loss decreased (0.019272 --> 0.018524).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0319145\n",
      "\tspeed: 0.0768s/iter; left time: 446.0985s\n",
      "\titers: 200, epoch: 6 | loss: 0.0342873\n",
      "\tspeed: 0.0753s/iter; left time: 429.9762s\n",
      "\titers: 300, epoch: 6 | loss: 0.0329264\n",
      "\tspeed: 0.0748s/iter; left time: 419.9068s\n",
      "Epoch: 6 cost time: 29.880302667617798\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0349491 Vali Loss: 0.0193730 Test Loss: 0.0194842\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0352387\n",
      "\tspeed: 0.0741s/iter; left time: 401.5073s\n",
      "\titers: 200, epoch: 7 | loss: 0.0312436\n",
      "\tspeed: 0.0815s/iter; left time: 433.1289s\n",
      "\titers: 300, epoch: 7 | loss: 0.0333634\n",
      "\tspeed: 0.0774s/iter; left time: 403.5951s\n",
      "Epoch: 7 cost time: 30.660826444625854\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0329892 Vali Loss: 0.0182560 Test Loss: 0.0188362\n",
      "Validation loss decreased (0.018524 --> 0.018256).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0355096\n",
      "\tspeed: 0.0771s/iter; left time: 387.4731s\n",
      "\titers: 200, epoch: 8 | loss: 0.0324223\n",
      "\tspeed: 0.0744s/iter; left time: 366.0787s\n",
      "\titers: 300, epoch: 8 | loss: 0.0337435\n",
      "\tspeed: 0.0743s/iter; left time: 358.4282s\n",
      "Epoch: 8 cost time: 29.784773588180542\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0324179 Vali Loss: 0.0173447 Test Loss: 0.0183825\n",
      "Validation loss decreased (0.018256 --> 0.017345).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0314660\n",
      "\tspeed: 0.0767s/iter; left time: 355.2105s\n",
      "\titers: 200, epoch: 9 | loss: 0.0305580\n",
      "\tspeed: 0.0742s/iter; left time: 335.9260s\n",
      "\titers: 300, epoch: 9 | loss: 0.0316134\n",
      "\tspeed: 0.0749s/iter; left time: 331.6414s\n",
      "Epoch: 9 cost time: 29.67261576652527\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0314247 Vali Loss: 0.0171465 Test Loss: 0.0176189\n",
      "Validation loss decreased (0.017345 --> 0.017147).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0313262\n",
      "\tspeed: 0.0794s/iter; left time: 336.1887s\n",
      "\titers: 200, epoch: 10 | loss: 0.0319317\n",
      "\tspeed: 0.0799s/iter; left time: 330.3552s\n",
      "\titers: 300, epoch: 10 | loss: 0.0341465\n",
      "\tspeed: 0.0826s/iter; left time: 333.2558s\n",
      "Epoch: 10 cost time: 31.22931146621704\n",
      "Epoch: 10, Steps: 394 | Train Loss: 0.0311775 Vali Loss: 0.0169087 Test Loss: 0.0176234\n",
      "Validation loss decreased (0.017147 --> 0.016909).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0302647\n",
      "\tspeed: 0.0783s/iter; left time: 300.7186s\n",
      "\titers: 200, epoch: 11 | loss: 0.0307147\n",
      "\tspeed: 0.0782s/iter; left time: 292.5329s\n",
      "\titers: 300, epoch: 11 | loss: 0.0314736\n",
      "\tspeed: 0.0783s/iter; left time: 285.0494s\n",
      "Epoch: 11 cost time: 30.828320503234863\n",
      "Epoch: 11, Steps: 394 | Train Loss: 0.0306930 Vali Loss: 0.0167284 Test Loss: 0.0176007\n",
      "Validation loss decreased (0.016909 --> 0.016728).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.0299630\n",
      "\tspeed: 0.0790s/iter; left time: 272.2536s\n",
      "\titers: 200, epoch: 12 | loss: 0.0314947\n",
      "\tspeed: 0.0810s/iter; left time: 271.0159s\n",
      "\titers: 300, epoch: 12 | loss: 0.0298403\n",
      "\tspeed: 0.0797s/iter; left time: 258.7463s\n",
      "Epoch: 12 cost time: 31.452655792236328\n",
      "Epoch: 12, Steps: 394 | Train Loss: 0.0304083 Vali Loss: 0.0169967 Test Loss: 0.0175815\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.0325601\n",
      "\tspeed: 0.0737s/iter; left time: 224.9641s\n",
      "\titers: 200, epoch: 13 | loss: 0.0274242\n",
      "\tspeed: 0.0743s/iter; left time: 219.4662s\n",
      "\titers: 300, epoch: 13 | loss: 0.0316494\n",
      "\tspeed: 0.0748s/iter; left time: 213.3514s\n",
      "Epoch: 13 cost time: 29.405563592910767\n",
      "Epoch: 13, Steps: 394 | Train Loss: 0.0302266 Vali Loss: 0.0169605 Test Loss: 0.0177056\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 14 | loss: 0.0323819\n",
      "\tspeed: 0.0729s/iter; left time: 193.7247s\n",
      "\titers: 200, epoch: 14 | loss: 0.0289403\n",
      "\tspeed: 0.0765s/iter; left time: 195.7720s\n",
      "\titers: 300, epoch: 14 | loss: 0.0291941\n",
      "\tspeed: 0.0764s/iter; left time: 187.9874s\n",
      "Epoch: 14 cost time: 30.061942100524902\n",
      "Epoch: 14, Steps: 394 | Train Loss: 0.0299755 Vali Loss: 0.0169783 Test Loss: 0.0175094\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.017600733786821365, mae:0.10610012710094452\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTHh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTHh1_il168_pl336_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.2093265\n",
      "\tspeed: 0.0761s/iter; left time: 584.5730s\n",
      "\titers: 200, epoch: 1 | loss: 0.1072883\n",
      "\tspeed: 0.0735s/iter; left time: 557.4853s\n",
      "\titers: 300, epoch: 1 | loss: 0.0851278\n",
      "\tspeed: 0.0737s/iter; left time: 551.6377s\n",
      "Epoch: 1 cost time: 29.165016651153564\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.2657099 Vali Loss: 0.0244703 Test Loss: 0.0279034\n",
      "Validation loss decreased (inf --> 0.024470).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0639625\n",
      "\tspeed: 0.0776s/iter; left time: 565.7015s\n",
      "\titers: 200, epoch: 2 | loss: 0.0559256\n",
      "\tspeed: 0.0774s/iter; left time: 556.4418s\n",
      "\titers: 300, epoch: 2 | loss: 0.0518185\n",
      "\tspeed: 0.0777s/iter; left time: 550.7512s\n",
      "Epoch: 2 cost time: 30.225577116012573\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0577475 Vali Loss: 0.0207637 Test Loss: 0.0240134\n",
      "Validation loss decreased (0.024470 --> 0.020764).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0441770\n",
      "\tspeed: 0.0749s/iter; left time: 516.7069s\n",
      "\titers: 200, epoch: 3 | loss: 0.0424523\n",
      "\tspeed: 0.0773s/iter; left time: 525.6056s\n",
      "\titers: 300, epoch: 3 | loss: 0.0432183\n",
      "\tspeed: 0.0762s/iter; left time: 510.9576s\n",
      "Epoch: 3 cost time: 29.59484362602234\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0446809 Vali Loss: 0.0181700 Test Loss: 0.0209426\n",
      "Validation loss decreased (0.020764 --> 0.018170).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0384859\n",
      "\tspeed: 0.0798s/iter; left time: 519.7727s\n",
      "\titers: 200, epoch: 4 | loss: 0.0389293\n",
      "\tspeed: 0.0771s/iter; left time: 494.7293s\n",
      "\titers: 300, epoch: 4 | loss: 0.0378669\n",
      "\tspeed: 0.0773s/iter; left time: 487.9101s\n",
      "Epoch: 4 cost time: 30.499202013015747\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0400022 Vali Loss: 0.0179964 Test Loss: 0.0189773\n",
      "Validation loss decreased (0.018170 --> 0.017996).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0369958\n",
      "\tspeed: 0.0757s/iter; left time: 463.6167s\n",
      "\titers: 200, epoch: 5 | loss: 0.0342381\n",
      "\tspeed: 0.0749s/iter; left time: 451.0624s\n",
      "\titers: 300, epoch: 5 | loss: 0.0349600\n",
      "\tspeed: 0.0775s/iter; left time: 459.0361s\n",
      "Epoch: 5 cost time: 29.65464496612549\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0359352 Vali Loss: 0.0174410 Test Loss: 0.0192227\n",
      "Validation loss decreased (0.017996 --> 0.017441).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0339711\n",
      "\tspeed: 0.0797s/iter; left time: 456.9660s\n",
      "\titers: 200, epoch: 6 | loss: 0.0346009\n",
      "\tspeed: 0.0769s/iter; left time: 433.2565s\n",
      "\titers: 300, epoch: 6 | loss: 0.0328376\n",
      "\tspeed: 0.0743s/iter; left time: 411.0564s\n",
      "Epoch: 6 cost time: 29.797005891799927\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0342841 Vali Loss: 0.0178789 Test Loss: 0.0181865\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0328732\n",
      "\tspeed: 0.0755s/iter; left time: 403.4430s\n",
      "\titers: 200, epoch: 7 | loss: 0.0328628\n",
      "\tspeed: 0.0744s/iter; left time: 390.5310s\n",
      "\titers: 300, epoch: 7 | loss: 0.0332096\n",
      "\tspeed: 0.0737s/iter; left time: 379.1376s\n",
      "Epoch: 7 cost time: 29.09337830543518\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.0324305 Vali Loss: 0.0168879 Test Loss: 0.0178308\n",
      "Validation loss decreased (0.017441 --> 0.016888).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0313274\n",
      "\tspeed: 0.0830s/iter; left time: 411.5940s\n",
      "\titers: 200, epoch: 8 | loss: 0.0320772\n",
      "\tspeed: 0.0813s/iter; left time: 394.8997s\n",
      "\titers: 300, epoch: 8 | loss: 0.0310116\n",
      "\tspeed: 0.0781s/iter; left time: 371.5823s\n",
      "Epoch: 8 cost time: 31.296912908554077\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.0316789 Vali Loss: 0.0164201 Test Loss: 0.0184037\n",
      "Validation loss decreased (0.016888 --> 0.016420).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0302718\n",
      "\tspeed: 0.0804s/iter; left time: 367.4843s\n",
      "\titers: 200, epoch: 9 | loss: 0.0313474\n",
      "\tspeed: 0.0791s/iter; left time: 353.3913s\n",
      "\titers: 300, epoch: 9 | loss: 0.0318568\n",
      "\tspeed: 0.0796s/iter; left time: 347.6925s\n",
      "Epoch: 9 cost time: 30.836323738098145\n",
      "Epoch: 9, Steps: 389 | Train Loss: 0.0307523 Vali Loss: 0.0164563 Test Loss: 0.0178564\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.0307124\n",
      "\tspeed: 0.0689s/iter; left time: 288.1692s\n",
      "\titers: 200, epoch: 10 | loss: 0.0305660\n",
      "\tspeed: 0.0741s/iter; left time: 302.3136s\n",
      "\titers: 300, epoch: 10 | loss: 0.0296519\n",
      "\tspeed: 0.0771s/iter; left time: 307.0295s\n",
      "Epoch: 10 cost time: 28.754151821136475\n",
      "Epoch: 10, Steps: 389 | Train Loss: 0.0302795 Vali Loss: 0.0165237 Test Loss: 0.0176303\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0288455\n",
      "\tspeed: 0.0754s/iter; left time: 285.9292s\n",
      "\titers: 200, epoch: 11 | loss: 0.0312615\n",
      "\tspeed: 0.0759s/iter; left time: 280.1065s\n",
      "\titers: 300, epoch: 11 | loss: 0.0304815\n",
      "\tspeed: 0.0764s/iter; left time: 274.4603s\n",
      "Epoch: 11 cost time: 29.54864001274109\n",
      "Epoch: 11, Steps: 389 | Train Loss: 0.0298539 Vali Loss: 0.0163866 Test Loss: 0.0174969\n",
      "Validation loss decreased (0.016420 --> 0.016387).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.0286576\n",
      "\tspeed: 0.0818s/iter; left time: 278.3834s\n",
      "\titers: 200, epoch: 12 | loss: 0.0305399\n",
      "\tspeed: 0.0809s/iter; left time: 267.0768s\n",
      "\titers: 300, epoch: 12 | loss: 0.0308840\n",
      "\tspeed: 0.0765s/iter; left time: 244.8698s\n",
      "Epoch: 12 cost time: 30.445821523666382\n",
      "Epoch: 12, Steps: 389 | Train Loss: 0.0296151 Vali Loss: 0.0162367 Test Loss: 0.0175944\n",
      "Validation loss decreased (0.016387 --> 0.016237).  Saving model ...\n",
      "\titers: 100, epoch: 13 | loss: 0.0286674\n",
      "\tspeed: 0.0753s/iter; left time: 226.7765s\n",
      "\titers: 200, epoch: 13 | loss: 0.0289948\n",
      "\tspeed: 0.0764s/iter; left time: 222.5363s\n",
      "\titers: 300, epoch: 13 | loss: 0.0309679\n",
      "\tspeed: 0.0765s/iter; left time: 215.0605s\n",
      "Epoch: 13 cost time: 29.504229307174683\n",
      "Epoch: 13, Steps: 389 | Train Loss: 0.0294618 Vali Loss: 0.0164096 Test Loss: 0.0176660\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 14 | loss: 0.0297379\n",
      "\tspeed: 0.0769s/iter; left time: 201.8257s\n",
      "\titers: 200, epoch: 14 | loss: 0.0283812\n",
      "\tspeed: 0.0770s/iter; left time: 194.4664s\n",
      "\titers: 300, epoch: 14 | loss: 0.0310591\n",
      "\tspeed: 0.0807s/iter; left time: 195.5729s\n",
      "Epoch: 14 cost time: 30.895511150360107\n",
      "Epoch: 14, Steps: 389 | Train Loss: 0.0291690 Vali Loss: 0.0162618 Test Loss: 0.0177185\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 15 | loss: 0.0277982\n",
      "\tspeed: 0.0753s/iter; left time: 168.3752s\n",
      "\titers: 200, epoch: 15 | loss: 0.0284346\n",
      "\tspeed: 0.0747s/iter; left time: 159.5006s\n",
      "\titers: 300, epoch: 15 | loss: 0.0276397\n",
      "\tspeed: 0.0749s/iter; left time: 152.4381s\n",
      "Epoch: 15 cost time: 29.589182376861572\n",
      "Epoch: 15, Steps: 389 | Train Loss: 0.0289436 Vali Loss: 0.0165247 Test Loss: 0.0174390\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.017594434320926666, mae:0.10587264597415924\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTHh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTHh1_il168_pl720_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.3744476\n",
      "\tspeed: 0.0874s/iter; left time: 650.5422s\n",
      "\titers: 200, epoch: 1 | loss: 0.1076050\n",
      "\tspeed: 0.0816s/iter; left time: 598.7076s\n",
      "\titers: 300, epoch: 1 | loss: 0.0764018\n",
      "\tspeed: 0.0810s/iter; left time: 586.7019s\n",
      "Epoch: 1 cost time: 31.11896061897278\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.3271042 Vali Loss: 0.0329715 Test Loss: 0.0333167\n",
      "Validation loss decreased (inf --> 0.032972).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0583175\n",
      "\tspeed: 0.0795s/iter; left time: 561.4828s\n",
      "\titers: 200, epoch: 2 | loss: 0.0536586\n",
      "\tspeed: 0.0857s/iter; left time: 596.8453s\n",
      "\titers: 300, epoch: 2 | loss: 0.0457675\n",
      "\tspeed: 0.0851s/iter; left time: 584.4615s\n",
      "Epoch: 2 cost time: 31.613541841506958\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0552426 Vali Loss: 0.0216577 Test Loss: 0.0228603\n",
      "Validation loss decreased (0.032972 --> 0.021658).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0443924\n",
      "\tspeed: 0.0824s/iter; left time: 551.2858s\n",
      "\titers: 200, epoch: 3 | loss: 0.0407712\n",
      "\tspeed: 0.0810s/iter; left time: 533.4422s\n",
      "\titers: 300, epoch: 3 | loss: 0.0391080\n",
      "\tspeed: 0.0826s/iter; left time: 536.0140s\n",
      "Epoch: 3 cost time: 31.16236686706543\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0411164 Vali Loss: 0.0193727 Test Loss: 0.0199786\n",
      "Validation loss decreased (0.021658 --> 0.019373).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0377811\n",
      "\tspeed: 0.0838s/iter; left time: 529.0350s\n",
      "\titers: 200, epoch: 4 | loss: 0.0386707\n",
      "\tspeed: 0.0855s/iter; left time: 530.8214s\n",
      "\titers: 300, epoch: 4 | loss: 0.0358290\n",
      "\tspeed: 0.0847s/iter; left time: 517.3950s\n",
      "Epoch: 4 cost time: 31.480357885360718\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0369619 Vali Loss: 0.0205344 Test Loss: 0.0212408\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0353041\n",
      "\tspeed: 0.0733s/iter; left time: 435.0574s\n",
      "\titers: 200, epoch: 5 | loss: 0.0327038\n",
      "\tspeed: 0.0749s/iter; left time: 436.8522s\n",
      "\titers: 300, epoch: 5 | loss: 0.0343026\n",
      "\tspeed: 0.0806s/iter; left time: 462.2593s\n",
      "Epoch: 5 cost time: 29.200201511383057\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0337973 Vali Loss: 0.0179660 Test Loss: 0.0189403\n",
      "Validation loss decreased (0.019373 --> 0.017966).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0347316\n",
      "\tspeed: 0.0789s/iter; left time: 438.3066s\n",
      "\titers: 200, epoch: 6 | loss: 0.0315232\n",
      "\tspeed: 0.0821s/iter; left time: 447.8382s\n",
      "\titers: 300, epoch: 6 | loss: 0.0320169\n",
      "\tspeed: 0.0801s/iter; left time: 429.0396s\n",
      "Epoch: 6 cost time: 30.50867772102356\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0323986 Vali Loss: 0.0180992 Test Loss: 0.0188598\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0323312\n",
      "\tspeed: 0.0786s/iter; left time: 407.3006s\n",
      "\titers: 200, epoch: 7 | loss: 0.0322770\n",
      "\tspeed: 0.0825s/iter; left time: 418.9516s\n",
      "\titers: 300, epoch: 7 | loss: 0.0324624\n",
      "\tspeed: 0.0844s/iter; left time: 420.1360s\n",
      "Epoch: 7 cost time: 31.049407958984375\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0309913 Vali Loss: 0.0169625 Test Loss: 0.0179579\n",
      "Validation loss decreased (0.017966 --> 0.016963).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0295243\n",
      "\tspeed: 0.0835s/iter; left time: 401.1595s\n",
      "\titers: 200, epoch: 8 | loss: 0.0310399\n",
      "\tspeed: 0.0847s/iter; left time: 398.1118s\n",
      "\titers: 300, epoch: 8 | loss: 0.0288360\n",
      "\tspeed: 0.0823s/iter; left time: 378.7998s\n",
      "Epoch: 8 cost time: 31.344297885894775\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.0302942 Vali Loss: 0.0179213 Test Loss: 0.0189342\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0290505\n",
      "\tspeed: 0.0830s/iter; left time: 367.1313s\n",
      "\titers: 200, epoch: 9 | loss: 0.0292858\n",
      "\tspeed: 0.0827s/iter; left time: 357.5911s\n",
      "\titers: 300, epoch: 9 | loss: 0.0280533\n",
      "\tspeed: 0.0848s/iter; left time: 358.2563s\n",
      "Epoch: 9 cost time: 31.710285663604736\n",
      "Epoch: 9, Steps: 377 | Train Loss: 0.0295821 Vali Loss: 0.0169192 Test Loss: 0.0180075\n",
      "Validation loss decreased (0.016963 --> 0.016919).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0285590\n",
      "\tspeed: 0.0816s/iter; left time: 330.2432s\n",
      "\titers: 200, epoch: 10 | loss: 0.0286789\n",
      "\tspeed: 0.0803s/iter; left time: 317.0709s\n",
      "\titers: 300, epoch: 10 | loss: 0.0295760\n",
      "\tspeed: 0.0780s/iter; left time: 300.1413s\n",
      "Epoch: 10 cost time: 30.27130675315857\n",
      "Epoch: 10, Steps: 377 | Train Loss: 0.0292925 Vali Loss: 0.0166190 Test Loss: 0.0173891\n",
      "Validation loss decreased (0.016919 --> 0.016619).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0301150\n",
      "\tspeed: 0.0798s/iter; left time: 292.9786s\n",
      "\titers: 200, epoch: 11 | loss: 0.0284060\n",
      "\tspeed: 0.0815s/iter; left time: 291.0113s\n",
      "\titers: 300, epoch: 11 | loss: 0.0282866\n",
      "\tspeed: 0.0799s/iter; left time: 277.4925s\n",
      "Epoch: 11 cost time: 30.234747171401978\n",
      "Epoch: 11, Steps: 377 | Train Loss: 0.0289501 Vali Loss: 0.0166873 Test Loss: 0.0176971\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.0294254\n",
      "\tspeed: 0.0808s/iter; left time: 266.0718s\n",
      "\titers: 200, epoch: 12 | loss: 0.0282750\n",
      "\tspeed: 0.0799s/iter; left time: 255.1630s\n",
      "\titers: 300, epoch: 12 | loss: 0.0284998\n",
      "\tspeed: 0.0819s/iter; left time: 253.5403s\n",
      "Epoch: 12 cost time: 30.738806009292603\n",
      "Epoch: 12, Steps: 377 | Train Loss: 0.0287266 Vali Loss: 0.0170015 Test Loss: 0.0177115\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.0287617\n",
      "\tspeed: 0.0851s/iter; left time: 248.2316s\n",
      "\titers: 200, epoch: 13 | loss: 0.0308613\n",
      "\tspeed: 0.0865s/iter; left time: 243.5707s\n",
      "\titers: 300, epoch: 13 | loss: 0.0283237\n",
      "\tspeed: 0.0817s/iter; left time: 222.0132s\n",
      "Epoch: 13 cost time: 31.190797805786133\n",
      "Epoch: 13, Steps: 377 | Train Loss: 0.0286102 Vali Loss: 0.0166552 Test Loss: 0.0176627\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.017389047890901566, mae:0.10529797524213791\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_il168_pl24_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.1083963\n",
      "\tspeed: 0.0698s/iter; left time: 549.9821s\n",
      "\titers: 200, epoch: 1 | loss: 0.0645142\n",
      "\tspeed: 0.0730s/iter; left time: 568.2412s\n",
      "\titers: 300, epoch: 1 | loss: 0.0387240\n",
      "\tspeed: 0.0701s/iter; left time: 538.5137s\n",
      "Epoch: 1 cost time: 28.356958627700806\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.0928534 Vali Loss: 0.0210049 Test Loss: 0.0716559\n",
      "Validation loss decreased (inf --> 0.021005).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0240600\n",
      "\tspeed: 0.0750s/iter; left time: 560.7808s\n",
      "\titers: 200, epoch: 2 | loss: 0.0203071\n",
      "\tspeed: 0.0741s/iter; left time: 546.8239s\n",
      "\titers: 300, epoch: 2 | loss: 0.0240180\n",
      "\tspeed: 0.0739s/iter; left time: 538.0663s\n",
      "Epoch: 2 cost time: 29.63765573501587\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0227515 Vali Loss: 0.0146350 Test Loss: 0.0273678\n",
      "Validation loss decreased (0.021005 --> 0.014635).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0133300\n",
      "\tspeed: 0.0747s/iter; left time: 529.4311s\n",
      "\titers: 200, epoch: 3 | loss: 0.0146618\n",
      "\tspeed: 0.0758s/iter; left time: 529.1850s\n",
      "\titers: 300, epoch: 3 | loss: 0.0172814\n",
      "\tspeed: 0.0775s/iter; left time: 533.5184s\n",
      "Epoch: 3 cost time: 30.96629762649536\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0146307 Vali Loss: 0.0100166 Test Loss: 0.0229737\n",
      "Validation loss decreased (0.014635 --> 0.010017).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0148191\n",
      "\tspeed: 0.0794s/iter; left time: 530.5345s\n",
      "\titers: 200, epoch: 4 | loss: 0.0110477\n",
      "\tspeed: 0.0751s/iter; left time: 494.7135s\n",
      "\titers: 300, epoch: 4 | loss: 0.0101879\n",
      "\tspeed: 0.0734s/iter; left time: 476.0855s\n",
      "Epoch: 4 cost time: 30.28898024559021\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0120908 Vali Loss: 0.0072391 Test Loss: 0.0243739\n",
      "Validation loss decreased (0.010017 --> 0.007239).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0105674\n",
      "\tspeed: 0.0741s/iter; left time: 465.5493s\n",
      "\titers: 200, epoch: 5 | loss: 0.0086215\n",
      "\tspeed: 0.0741s/iter; left time: 458.2023s\n",
      "\titers: 300, epoch: 5 | loss: 0.0124800\n",
      "\tspeed: 0.0763s/iter; left time: 464.0120s\n",
      "Epoch: 5 cost time: 30.506572246551514\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0100161 Vali Loss: 0.0077158 Test Loss: 0.0167809\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0102011\n",
      "\tspeed: 0.0764s/iter; left time: 449.5346s\n",
      "\titers: 200, epoch: 6 | loss: 0.0098494\n",
      "\tspeed: 0.0766s/iter; left time: 442.9907s\n",
      "\titers: 300, epoch: 6 | loss: 0.0082802\n",
      "\tspeed: 0.0781s/iter; left time: 444.3552s\n",
      "Epoch: 6 cost time: 30.508349657058716\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0094718 Vali Loss: 0.0066583 Test Loss: 0.0234577\n",
      "Validation loss decreased (0.007239 --> 0.006658).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0097856\n",
      "\tspeed: 0.0727s/iter; left time: 399.0594s\n",
      "\titers: 200, epoch: 7 | loss: 0.0091917\n",
      "\tspeed: 0.0746s/iter; left time: 402.0933s\n",
      "\titers: 300, epoch: 7 | loss: 0.0087703\n",
      "\tspeed: 0.0783s/iter; left time: 413.8760s\n",
      "Epoch: 7 cost time: 30.26770305633545\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0086566 Vali Loss: 0.0047458 Test Loss: 0.0133069\n",
      "Validation loss decreased (0.006658 --> 0.004746).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0098154\n",
      "\tspeed: 0.0761s/iter; left time: 387.0671s\n",
      "\titers: 200, epoch: 8 | loss: 0.0071158\n",
      "\tspeed: 0.0797s/iter; left time: 397.7231s\n",
      "\titers: 300, epoch: 8 | loss: 0.0064511\n",
      "\tspeed: 0.0736s/iter; left time: 359.9119s\n",
      "Epoch: 8 cost time: 30.23414421081543\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0082546 Vali Loss: 0.0044967 Test Loss: 0.0169028\n",
      "Validation loss decreased (0.004746 --> 0.004497).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0076506\n",
      "\tspeed: 0.0754s/iter; left time: 353.3420s\n",
      "\titers: 200, epoch: 9 | loss: 0.0084308\n",
      "\tspeed: 0.0746s/iter; left time: 342.1447s\n",
      "\titers: 300, epoch: 9 | loss: 0.0078590\n",
      "\tspeed: 0.0770s/iter; left time: 345.6590s\n",
      "Epoch: 9 cost time: 30.797512769699097\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0077758 Vali Loss: 0.0046270 Test Loss: 0.0120958\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.0075659\n",
      "\tspeed: 0.0753s/iter; left time: 323.1032s\n",
      "\titers: 200, epoch: 10 | loss: 0.0088213\n",
      "\tspeed: 0.0729s/iter; left time: 305.4152s\n",
      "\titers: 300, epoch: 10 | loss: 0.0056670\n",
      "\tspeed: 0.0744s/iter; left time: 304.1039s\n",
      "Epoch: 10 cost time: 29.536434650421143\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0075847 Vali Loss: 0.0058164 Test Loss: 0.0117510\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0084752\n",
      "\tspeed: 0.0733s/iter; left time: 285.3394s\n",
      "\titers: 200, epoch: 11 | loss: 0.0068905\n",
      "\tspeed: 0.0734s/iter; left time: 278.3879s\n",
      "\titers: 300, epoch: 11 | loss: 0.0087228\n",
      "\tspeed: 0.0743s/iter; left time: 274.1355s\n",
      "Epoch: 11 cost time: 29.84086585044861\n",
      "Epoch: 11, Steps: 399 | Train Loss: 0.0073335 Vali Loss: 0.0041781 Test Loss: 0.0129932\n",
      "Validation loss decreased (0.004497 --> 0.004178).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.0076596\n",
      "\tspeed: 0.0747s/iter; left time: 260.8002s\n",
      "\titers: 200, epoch: 12 | loss: 0.0077414\n",
      "\tspeed: 0.0773s/iter; left time: 262.1549s\n",
      "\titers: 300, epoch: 12 | loss: 0.0072647\n",
      "\tspeed: 0.0774s/iter; left time: 254.7379s\n",
      "Epoch: 12 cost time: 30.519620895385742\n",
      "Epoch: 12, Steps: 399 | Train Loss: 0.0073231 Vali Loss: 0.0040574 Test Loss: 0.0125202\n",
      "Validation loss decreased (0.004178 --> 0.004057).  Saving model ...\n",
      "\titers: 100, epoch: 13 | loss: 0.0072959\n",
      "\tspeed: 0.0720s/iter; left time: 222.5460s\n",
      "\titers: 200, epoch: 13 | loss: 0.0065373\n",
      "\tspeed: 0.0699s/iter; left time: 209.2962s\n",
      "\titers: 300, epoch: 13 | loss: 0.0073685\n",
      "\tspeed: 0.0700s/iter; left time: 202.5089s\n",
      "Epoch: 13 cost time: 28.468929767608643\n",
      "Epoch: 13, Steps: 399 | Train Loss: 0.0072723 Vali Loss: 0.0037810 Test Loss: 0.0132601\n",
      "Validation loss decreased (0.004057 --> 0.003781).  Saving model ...\n",
      "\titers: 100, epoch: 14 | loss: 0.0059581\n",
      "\tspeed: 0.0741s/iter; left time: 199.7011s\n",
      "\titers: 200, epoch: 14 | loss: 0.0081777\n",
      "\tspeed: 0.0759s/iter; left time: 196.8033s\n",
      "\titers: 300, epoch: 14 | loss: 0.0066879\n",
      "\tspeed: 0.0726s/iter; left time: 181.0592s\n",
      "Epoch: 14 cost time: 29.763312101364136\n",
      "Epoch: 14, Steps: 399 | Train Loss: 0.0070505 Vali Loss: 0.0039012 Test Loss: 0.0124918\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 15 | loss: 0.0066515\n",
      "\tspeed: 0.0730s/iter; left time: 167.6417s\n",
      "\titers: 200, epoch: 15 | loss: 0.0066749\n",
      "\tspeed: 0.0703s/iter; left time: 154.2431s\n",
      "\titers: 300, epoch: 15 | loss: 0.0069415\n",
      "\tspeed: 0.0711s/iter; left time: 149.0510s\n",
      "Epoch: 15 cost time: 28.682440757751465\n",
      "Epoch: 15, Steps: 399 | Train Loss: 0.0069120 Vali Loss: 0.0037907 Test Loss: 0.0138479\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 16 | loss: 0.0070865\n",
      "\tspeed: 0.0722s/iter; left time: 136.8602s\n",
      "\titers: 200, epoch: 16 | loss: 0.0068942\n",
      "\tspeed: 0.0725s/iter; left time: 130.1450s\n",
      "\titers: 300, epoch: 16 | loss: 0.0072539\n",
      "\tspeed: 0.0744s/iter; left time: 126.2529s\n",
      "Epoch: 16 cost time: 28.729031324386597\n",
      "Epoch: 16, Steps: 399 | Train Loss: 0.0069226 Vali Loss: 0.0036241 Test Loss: 0.0121781\n",
      "Validation loss decreased (0.003781 --> 0.003624).  Saving model ...\n",
      "\titers: 100, epoch: 17 | loss: 0.0061850\n",
      "\tspeed: 0.0702s/iter; left time: 105.1454s\n",
      "\titers: 200, epoch: 17 | loss: 0.0063880\n",
      "\tspeed: 0.0727s/iter; left time: 101.5188s\n",
      "\titers: 300, epoch: 17 | loss: 0.0080076\n",
      "\tspeed: 0.0691s/iter; left time: 89.6098s\n",
      "Epoch: 17 cost time: 28.6166672706604\n",
      "Epoch: 17, Steps: 399 | Train Loss: 0.0067619 Vali Loss: 0.0035492 Test Loss: 0.0124127\n",
      "Validation loss decreased (0.003624 --> 0.003549).  Saving model ...\n",
      "\titers: 100, epoch: 18 | loss: 0.0069739\n",
      "\tspeed: 0.0780s/iter; left time: 85.6279s\n",
      "\titers: 200, epoch: 18 | loss: 0.0071185\n",
      "\tspeed: 0.0773s/iter; left time: 77.1363s\n",
      "\titers: 300, epoch: 18 | loss: 0.0072601\n",
      "\tspeed: 0.0785s/iter; left time: 70.5242s\n",
      "Epoch: 18 cost time: 30.669561862945557\n",
      "Epoch: 18, Steps: 399 | Train Loss: 0.0066691 Vali Loss: 0.0042220 Test Loss: 0.0099007\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 19 | loss: 0.0063802\n",
      "\tspeed: 0.0710s/iter; left time: 49.6483s\n",
      "\titers: 200, epoch: 19 | loss: 0.0071801\n",
      "\tspeed: 0.0734s/iter; left time: 43.9761s\n",
      "\titers: 300, epoch: 19 | loss: 0.0083751\n",
      "\tspeed: 0.0744s/iter; left time: 37.1468s\n",
      "Epoch: 19 cost time: 29.273747444152832\n",
      "Epoch: 19, Steps: 399 | Train Loss: 0.0066082 Vali Loss: 0.0035918 Test Loss: 0.0138608\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 20 | loss: 0.0051233\n",
      "\tspeed: 0.0727s/iter; left time: 21.8080s\n",
      "\titers: 200, epoch: 20 | loss: 0.0071272\n",
      "\tspeed: 0.0752s/iter; left time: 15.0440s\n",
      "\titers: 300, epoch: 20 | loss: 0.0074544\n",
      "\tspeed: 0.0717s/iter; left time: 7.1714s\n",
      "Epoch: 20 cost time: 29.278475522994995\n",
      "Epoch: 20, Steps: 399 | Train Loss: 0.0065171 Vali Loss: 0.0034198 Test Loss: 0.0123240\n",
      "Validation loss decreased (0.003549 --> 0.003420).  Saving model ...\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.012323977425694466, mae:0.08608431369066238\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_il168_pl48_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.1194351\n",
      "\tspeed: 0.0772s/iter; left time: 606.8454s\n",
      "\titers: 200, epoch: 1 | loss: 0.0697670\n",
      "\tspeed: 0.0751s/iter; left time: 582.7637s\n",
      "\titers: 300, epoch: 1 | loss: 0.0411702\n",
      "\tspeed: 0.0730s/iter; left time: 558.9882s\n",
      "Epoch: 1 cost time: 30.57420325279236\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.0979707 Vali Loss: 0.0500218 Test Loss: 0.1366778\n",
      "Validation loss decreased (inf --> 0.050022).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0312452\n",
      "\tspeed: 0.0817s/iter; left time: 609.7548s\n",
      "\titers: 200, epoch: 2 | loss: 0.0224328\n",
      "\tspeed: 0.0784s/iter; left time: 577.6091s\n",
      "\titers: 300, epoch: 2 | loss: 0.0184956\n",
      "\tspeed: 0.0779s/iter; left time: 565.6420s\n",
      "Epoch: 2 cost time: 31.614471197128296\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0261732 Vali Loss: 0.0201869 Test Loss: 0.0648653\n",
      "Validation loss decreased (0.050022 --> 0.020187).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0175357\n",
      "\tspeed: 0.0738s/iter; left time: 521.0862s\n",
      "\titers: 200, epoch: 3 | loss: 0.0136318\n",
      "\tspeed: 0.0751s/iter; left time: 523.0234s\n",
      "\titers: 300, epoch: 3 | loss: 0.0210445\n",
      "\tspeed: 0.0743s/iter; left time: 509.7316s\n",
      "Epoch: 3 cost time: 29.963839054107666\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0162552 Vali Loss: 0.0117485 Test Loss: 0.0444521\n",
      "Validation loss decreased (0.020187 --> 0.011748).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0128092\n",
      "\tspeed: 0.0763s/iter; left time: 508.4263s\n",
      "\titers: 200, epoch: 4 | loss: 0.0136145\n",
      "\tspeed: 0.0786s/iter; left time: 516.3413s\n",
      "\titers: 300, epoch: 4 | loss: 0.0123893\n",
      "\tspeed: 0.0758s/iter; left time: 490.3973s\n",
      "Epoch: 4 cost time: 29.73851728439331\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0135881 Vali Loss: 0.0095955 Test Loss: 0.0364399\n",
      "Validation loss decreased (0.011748 --> 0.009595).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0134196\n",
      "\tspeed: 0.0681s/iter; left time: 426.7959s\n",
      "\titers: 200, epoch: 5 | loss: 0.0106019\n",
      "\tspeed: 0.0728s/iter; left time: 449.1118s\n",
      "\titers: 300, epoch: 5 | loss: 0.0123226\n",
      "\tspeed: 0.0745s/iter; left time: 452.2924s\n",
      "Epoch: 5 cost time: 29.047343254089355\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0116631 Vali Loss: 0.0156657 Test Loss: 0.0557290\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0133407\n",
      "\tspeed: 0.0731s/iter; left time: 429.4389s\n",
      "\titers: 200, epoch: 6 | loss: 0.0107603\n",
      "\tspeed: 0.0707s/iter; left time: 407.7213s\n",
      "\titers: 300, epoch: 6 | loss: 0.0104142\n",
      "\tspeed: 0.0740s/iter; left time: 419.8463s\n",
      "Epoch: 6 cost time: 29.126607179641724\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0106592 Vali Loss: 0.0069676 Test Loss: 0.0229140\n",
      "Validation loss decreased (0.009595 --> 0.006968).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0092050\n",
      "\tspeed: 0.0728s/iter; left time: 398.6563s\n",
      "\titers: 200, epoch: 7 | loss: 0.0100014\n",
      "\tspeed: 0.0723s/iter; left time: 388.7107s\n",
      "\titers: 300, epoch: 7 | loss: 0.0091451\n",
      "\tspeed: 0.0707s/iter; left time: 372.8991s\n",
      "Epoch: 7 cost time: 29.479753971099854\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0098952 Vali Loss: 0.0089329 Test Loss: 0.0382903\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0106173\n",
      "\tspeed: 0.0778s/iter; left time: 394.9710s\n",
      "\titers: 200, epoch: 8 | loss: 0.0101882\n",
      "\tspeed: 0.0762s/iter; left time: 379.2060s\n",
      "\titers: 300, epoch: 8 | loss: 0.0114350\n",
      "\tspeed: 0.0766s/iter; left time: 373.2637s\n",
      "Epoch: 8 cost time: 30.626588821411133\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0096105 Vali Loss: 0.0088923 Test Loss: 0.0381406\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0090219\n",
      "\tspeed: 0.0729s/iter; left time: 341.1561s\n",
      "\titers: 200, epoch: 9 | loss: 0.0092420\n",
      "\tspeed: 0.0710s/iter; left time: 324.7568s\n",
      "\titers: 300, epoch: 9 | loss: 0.0109724\n",
      "\tspeed: 0.0723s/iter; left time: 323.5690s\n",
      "Epoch: 9 cost time: 28.787538766860962\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0090186 Vali Loss: 0.0087343 Test Loss: 0.0373395\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.02291395515203476, mae:0.1189785897731781\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_il168_pl168_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.1178529\n",
      "\tspeed: 0.0789s/iter; left time: 613.5508s\n",
      "\titers: 200, epoch: 1 | loss: 0.0896747\n",
      "\tspeed: 0.0768s/iter; left time: 590.2256s\n",
      "\titers: 300, epoch: 1 | loss: 0.0589706\n",
      "\tspeed: 0.0769s/iter; left time: 582.7270s\n",
      "Epoch: 1 cost time: 30.337767124176025\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.1152622 Vali Loss: 0.0402605 Test Loss: 0.0803602\n",
      "Validation loss decreased (inf --> 0.040260).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0302392\n",
      "\tspeed: 0.0756s/iter; left time: 558.4249s\n",
      "\titers: 200, epoch: 2 | loss: 0.0302165\n",
      "\tspeed: 0.0735s/iter; left time: 535.6534s\n",
      "\titers: 300, epoch: 2 | loss: 0.0315146\n",
      "\tspeed: 0.0705s/iter; left time: 507.0142s\n",
      "Epoch: 2 cost time: 28.61496901512146\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0383066 Vali Loss: 0.0288113 Test Loss: 0.0640165\n",
      "Validation loss decreased (0.040260 --> 0.028811).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0307839\n",
      "\tspeed: 0.0703s/iter; left time: 491.7983s\n",
      "\titers: 200, epoch: 3 | loss: 0.0254219\n",
      "\tspeed: 0.0746s/iter; left time: 513.9802s\n",
      "\titers: 300, epoch: 3 | loss: 0.0277136\n",
      "\tspeed: 0.0733s/iter; left time: 497.9433s\n",
      "Epoch: 3 cost time: 28.778212785720825\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0273598 Vali Loss: 0.0274906 Test Loss: 0.0694120\n",
      "Validation loss decreased (0.028811 --> 0.027491).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0303889\n",
      "\tspeed: 0.0733s/iter; left time: 483.8094s\n",
      "\titers: 200, epoch: 4 | loss: 0.0284507\n",
      "\tspeed: 0.0749s/iter; left time: 486.6478s\n",
      "\titers: 300, epoch: 4 | loss: 0.0244191\n",
      "\tspeed: 0.0744s/iter; left time: 476.2948s\n",
      "Epoch: 4 cost time: 29.45477867126465\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0252421 Vali Loss: 0.0360868 Test Loss: 0.0811734\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0245124\n",
      "\tspeed: 0.0745s/iter; left time: 462.1202s\n",
      "\titers: 200, epoch: 5 | loss: 0.0205388\n",
      "\tspeed: 0.0774s/iter; left time: 472.5905s\n",
      "\titers: 300, epoch: 5 | loss: 0.0209495\n",
      "\tspeed: 0.0784s/iter; left time: 470.6878s\n",
      "Epoch: 5 cost time: 30.097663164138794\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0224495 Vali Loss: 0.0185376 Test Loss: 0.0339376\n",
      "Validation loss decreased (0.027491 --> 0.018538).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0209774\n",
      "\tspeed: 0.0727s/iter; left time: 422.7102s\n",
      "\titers: 200, epoch: 6 | loss: 0.0207789\n",
      "\tspeed: 0.0727s/iter; left time: 415.1973s\n",
      "\titers: 300, epoch: 6 | loss: 0.0233622\n",
      "\tspeed: 0.0751s/iter; left time: 421.6166s\n",
      "Epoch: 6 cost time: 29.246850728988647\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0216626 Vali Loss: 0.0180277 Test Loss: 0.0394763\n",
      "Validation loss decreased (0.018538 --> 0.018028).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0205533\n",
      "\tspeed: 0.0743s/iter; left time: 402.6261s\n",
      "\titers: 200, epoch: 7 | loss: 0.0194322\n",
      "\tspeed: 0.0737s/iter; left time: 391.6063s\n",
      "\titers: 300, epoch: 7 | loss: 0.0189208\n",
      "\tspeed: 0.0728s/iter; left time: 379.7826s\n",
      "Epoch: 7 cost time: 28.8174090385437\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0205651 Vali Loss: 0.0169166 Test Loss: 0.0360314\n",
      "Validation loss decreased (0.018028 --> 0.016917).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0212907\n",
      "\tspeed: 0.0689s/iter; left time: 345.9038s\n",
      "\titers: 200, epoch: 8 | loss: 0.0209891\n",
      "\tspeed: 0.0745s/iter; left time: 366.7952s\n",
      "\titers: 300, epoch: 8 | loss: 0.0233998\n",
      "\tspeed: 0.0734s/iter; left time: 353.7836s\n",
      "Epoch: 8 cost time: 28.843109130859375\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0200130 Vali Loss: 0.0215964 Test Loss: 0.0558091\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0196043\n",
      "\tspeed: 0.0779s/iter; left time: 360.5761s\n",
      "\titers: 200, epoch: 9 | loss: 0.0216495\n",
      "\tspeed: 0.0753s/iter; left time: 340.8259s\n",
      "\titers: 300, epoch: 9 | loss: 0.0185522\n",
      "\tspeed: 0.0767s/iter; left time: 339.8516s\n",
      "Epoch: 9 cost time: 30.26463770866394\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0194884 Vali Loss: 0.0178919 Test Loss: 0.0448903\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.0217666\n",
      "\tspeed: 0.0739s/iter; left time: 313.0862s\n",
      "\titers: 200, epoch: 10 | loss: 0.0212996\n",
      "\tspeed: 0.0723s/iter; left time: 299.0718s\n",
      "\titers: 300, epoch: 10 | loss: 0.0190514\n",
      "\tspeed: 0.0720s/iter; left time: 290.5012s\n",
      "Epoch: 10 cost time: 28.596482515335083\n",
      "Epoch: 10, Steps: 394 | Train Loss: 0.0191676 Vali Loss: 0.0201747 Test Loss: 0.0558576\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.03603139892220497, mae:0.15134397149085999\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_il168_pl336_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.1307186\n",
      "\tspeed: 0.0764s/iter; left time: 586.5965s\n",
      "\titers: 200, epoch: 1 | loss: 0.1176969\n",
      "\tspeed: 0.0732s/iter; left time: 554.6394s\n",
      "\titers: 300, epoch: 1 | loss: 0.0988076\n",
      "\tspeed: 0.0788s/iter; left time: 589.6574s\n",
      "Epoch: 1 cost time: 29.338987588882446\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1420676 Vali Loss: 0.0909806 Test Loss: 0.2543334\n",
      "Validation loss decreased (inf --> 0.090981).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0653851\n",
      "\tspeed: 0.0723s/iter; left time: 527.0278s\n",
      "\titers: 200, epoch: 2 | loss: 0.0537599\n",
      "\tspeed: 0.0721s/iter; left time: 518.2903s\n",
      "\titers: 300, epoch: 2 | loss: 0.0536541\n",
      "\tspeed: 0.0707s/iter; left time: 501.5726s\n",
      "Epoch: 2 cost time: 28.167932510375977\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0588868 Vali Loss: 0.0486695 Test Loss: 0.1471023\n",
      "Validation loss decreased (0.090981 --> 0.048670).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0452430\n",
      "\tspeed: 0.0777s/iter; left time: 536.6098s\n",
      "\titers: 200, epoch: 3 | loss: 0.0407993\n",
      "\tspeed: 0.0780s/iter; left time: 530.7027s\n",
      "\titers: 300, epoch: 3 | loss: 0.0412075\n",
      "\tspeed: 0.0754s/iter; left time: 505.6823s\n",
      "Epoch: 3 cost time: 29.763920307159424\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0465408 Vali Loss: 0.0614758 Test Loss: 0.1715540\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.0395526\n",
      "\tspeed: 0.0770s/iter; left time: 501.6074s\n",
      "\titers: 200, epoch: 4 | loss: 0.0340666\n",
      "\tspeed: 0.0760s/iter; left time: 487.6988s\n",
      "\titers: 300, epoch: 4 | loss: 0.0456104\n",
      "\tspeed: 0.0737s/iter; left time: 465.1044s\n",
      "Epoch: 4 cost time: 29.06734299659729\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0430061 Vali Loss: 0.0360175 Test Loss: 0.0863538\n",
      "Validation loss decreased (0.048670 --> 0.036018).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0400895\n",
      "\tspeed: 0.0704s/iter; left time: 431.2299s\n",
      "\titers: 200, epoch: 5 | loss: 0.0408810\n",
      "\tspeed: 0.0747s/iter; left time: 449.8429s\n",
      "\titers: 300, epoch: 5 | loss: 0.0387809\n",
      "\tspeed: 0.0705s/iter; left time: 417.6176s\n",
      "Epoch: 5 cost time: 28.626595973968506\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0397628 Vali Loss: 0.0399584 Test Loss: 0.1113372\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0462966\n",
      "\tspeed: 0.0732s/iter; left time: 420.0260s\n",
      "\titers: 200, epoch: 6 | loss: 0.0410774\n",
      "\tspeed: 0.0754s/iter; left time: 425.1036s\n",
      "\titers: 300, epoch: 6 | loss: 0.0347709\n",
      "\tspeed: 0.0751s/iter; left time: 415.9272s\n",
      "Epoch: 6 cost time: 28.719675540924072\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0389263 Vali Loss: 0.0450212 Test Loss: 0.1318384\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0371790\n",
      "\tspeed: 0.0699s/iter; left time: 373.8439s\n",
      "\titers: 200, epoch: 7 | loss: 0.0383304\n",
      "\tspeed: 0.0718s/iter; left time: 376.5863s\n",
      "\titers: 300, epoch: 7 | loss: 0.0386307\n",
      "\tspeed: 0.0731s/iter; left time: 376.2200s\n",
      "Epoch: 7 cost time: 28.19114089012146\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.0372337 Vali Loss: 0.0428541 Test Loss: 0.1287343\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.08635380119085312, mae:0.24093180894851685\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_il168_pl720_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.1182288\n",
      "\tspeed: 0.0815s/iter; left time: 606.1296s\n",
      "\titers: 200, epoch: 1 | loss: 0.1043780\n",
      "\tspeed: 0.0739s/iter; left time: 542.4622s\n",
      "\titers: 300, epoch: 1 | loss: 0.0873417\n",
      "\tspeed: 0.0746s/iter; left time: 540.2788s\n",
      "Epoch: 1 cost time: 28.67157530784607\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.1258055 Vali Loss: 0.0558887 Test Loss: 0.1445128\n",
      "Validation loss decreased (inf --> 0.055889).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0433831\n",
      "\tspeed: 0.0784s/iter; left time: 554.0272s\n",
      "\titers: 200, epoch: 2 | loss: 0.0429862\n",
      "\tspeed: 0.0821s/iter; left time: 571.4963s\n",
      "\titers: 300, epoch: 2 | loss: 0.0410772\n",
      "\tspeed: 0.0830s/iter; left time: 569.8170s\n",
      "Epoch: 2 cost time: 30.71515417098999\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0476711 Vali Loss: 0.0859603 Test Loss: 0.2278401\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0363429\n",
      "\tspeed: 0.0796s/iter; left time: 532.2027s\n",
      "\titers: 200, epoch: 3 | loss: 0.0370637\n",
      "\tspeed: 0.0716s/iter; left time: 471.7966s\n",
      "\titers: 300, epoch: 3 | loss: 0.0336232\n",
      "\tspeed: 0.0735s/iter; left time: 476.9557s\n",
      "Epoch: 3 cost time: 27.927745580673218\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0370791 Vali Loss: 0.0306630 Test Loss: 0.0865109\n",
      "Validation loss decreased (0.055889 --> 0.030663).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0352704\n",
      "\tspeed: 0.0767s/iter; left time: 484.2029s\n",
      "\titers: 200, epoch: 4 | loss: 0.0288626\n",
      "\tspeed: 0.0779s/iter; left time: 483.8873s\n",
      "\titers: 300, epoch: 4 | loss: 0.0305410\n",
      "\tspeed: 0.0836s/iter; left time: 510.9859s\n",
      "Epoch: 4 cost time: 30.28238010406494\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0333359 Vali Loss: 0.0420685 Test Loss: 0.1579896\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0333973\n",
      "\tspeed: 0.0808s/iter; left time: 479.3494s\n",
      "\titers: 200, epoch: 5 | loss: 0.0323831\n",
      "\tspeed: 0.0774s/iter; left time: 451.2139s\n",
      "\titers: 300, epoch: 5 | loss: 0.0306204\n",
      "\tspeed: 0.0796s/iter; left time: 456.5785s\n",
      "Epoch: 5 cost time: 29.859881162643433\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0301724 Vali Loss: 0.0367709 Test Loss: 0.1393373\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0280229\n",
      "\tspeed: 0.0789s/iter; left time: 438.5957s\n",
      "\titers: 200, epoch: 6 | loss: 0.0317993\n",
      "\tspeed: 0.0801s/iter; left time: 436.9822s\n",
      "\titers: 300, epoch: 6 | loss: 0.0280420\n",
      "\tspeed: 0.0847s/iter; left time: 453.5590s\n",
      "Epoch: 6 cost time: 30.67707848548889\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0288944 Vali Loss: 0.0464794 Test Loss: 0.1721027\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.08651088923215866, mae:0.23981966078281403\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_reversal_il168_pl24_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.1342306\n",
      "\tspeed: 0.0799s/iter; left time: 629.4235s\n",
      "\titers: 200, epoch: 1 | loss: 0.0739656\n",
      "\tspeed: 0.0730s/iter; left time: 568.0299s\n",
      "\titers: 300, epoch: 1 | loss: 0.0529118\n",
      "\tspeed: 0.0698s/iter; left time: 535.7818s\n",
      "Epoch: 1 cost time: 29.0498263835907\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.1196164 Vali Loss: 0.0497370 Test Loss: 0.0499035\n",
      "Validation loss decreased (inf --> 0.049737).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0274512\n",
      "\tspeed: 0.0719s/iter; left time: 537.6534s\n",
      "\titers: 200, epoch: 2 | loss: 0.0283933\n",
      "\tspeed: 0.0766s/iter; left time: 565.2830s\n",
      "\titers: 300, epoch: 2 | loss: 0.0288204\n",
      "\tspeed: 0.0745s/iter; left time: 542.1860s\n",
      "Epoch: 2 cost time: 29.57620358467102\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0303994 Vali Loss: 0.0278658 Test Loss: 0.0445109\n",
      "Validation loss decreased (0.049737 --> 0.027866).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0180792\n",
      "\tspeed: 0.0781s/iter; left time: 552.9141s\n",
      "\titers: 200, epoch: 3 | loss: 0.0191515\n",
      "\tspeed: 0.0733s/iter; left time: 511.7712s\n",
      "\titers: 300, epoch: 3 | loss: 0.0194708\n",
      "\tspeed: 0.0692s/iter; left time: 476.2224s\n",
      "Epoch: 3 cost time: 29.447915077209473\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0201934 Vali Loss: 0.0379320 Test Loss: 0.0694875\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.0196476\n",
      "\tspeed: 0.0733s/iter; left time: 490.0218s\n",
      "\titers: 200, epoch: 4 | loss: 0.0173951\n",
      "\tspeed: 0.0765s/iter; left time: 503.5106s\n",
      "\titers: 300, epoch: 4 | loss: 0.0199814\n",
      "\tspeed: 0.0755s/iter; left time: 489.5087s\n",
      "Epoch: 4 cost time: 30.038254499435425\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0174522 Vali Loss: 0.0285719 Test Loss: 0.0636860\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0141983\n",
      "\tspeed: 0.0755s/iter; left time: 474.8051s\n",
      "\titers: 200, epoch: 5 | loss: 0.0134099\n",
      "\tspeed: 0.0699s/iter; left time: 432.3483s\n",
      "\titers: 300, epoch: 5 | loss: 0.0173535\n",
      "\tspeed: 0.0678s/iter; left time: 412.7431s\n",
      "Epoch: 5 cost time: 27.693603992462158\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0145190 Vali Loss: 0.0257045 Test Loss: 0.0594076\n",
      "Validation loss decreased (0.027866 --> 0.025705).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0101914\n",
      "\tspeed: 0.0714s/iter; left time: 420.2714s\n",
      "\titers: 200, epoch: 6 | loss: 0.0130148\n",
      "\tspeed: 0.0733s/iter; left time: 424.3960s\n",
      "\titers: 300, epoch: 6 | loss: 0.0108975\n",
      "\tspeed: 0.0768s/iter; left time: 436.6305s\n",
      "Epoch: 6 cost time: 29.686259031295776\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0137988 Vali Loss: 0.0391436 Test Loss: 0.0840377\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0117452\n",
      "\tspeed: 0.0713s/iter; left time: 391.2524s\n",
      "\titers: 200, epoch: 7 | loss: 0.0102334\n",
      "\tspeed: 0.0698s/iter; left time: 376.1410s\n",
      "\titers: 300, epoch: 7 | loss: 0.0114183\n",
      "\tspeed: 0.0666s/iter; left time: 352.1367s\n",
      "Epoch: 7 cost time: 27.557633876800537\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0124544 Vali Loss: 0.0323093 Test Loss: 0.0727004\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0103688\n",
      "\tspeed: 0.0721s/iter; left time: 366.6093s\n",
      "\titers: 200, epoch: 8 | loss: 0.0142540\n",
      "\tspeed: 0.0823s/iter; left time: 410.4823s\n",
      "\titers: 300, epoch: 8 | loss: 0.0100488\n",
      "\tspeed: 0.0772s/iter; left time: 377.1249s\n",
      "Epoch: 8 cost time: 30.6815447807312\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0121229 Vali Loss: 0.0279415 Test Loss: 0.0647914\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.059407565742731094, mae:0.17241106927394867\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_reversal_il168_pl48_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.1749922\n",
      "\tspeed: 0.0789s/iter; left time: 620.1386s\n",
      "\titers: 200, epoch: 1 | loss: 0.0702740\n",
      "\tspeed: 0.0741s/iter; left time: 575.2482s\n",
      "\titers: 300, epoch: 1 | loss: 0.0490412\n",
      "\tspeed: 0.0700s/iter; left time: 535.9293s\n",
      "Epoch: 1 cost time: 29.4064359664917\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.1295262 Vali Loss: 0.0845736 Test Loss: 0.0710834\n",
      "Validation loss decreased (inf --> 0.084574).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0482994\n",
      "\tspeed: 0.0710s/iter; left time: 529.8990s\n",
      "\titers: 200, epoch: 2 | loss: 0.0277682\n",
      "\tspeed: 0.0710s/iter; left time: 522.6625s\n",
      "\titers: 300, epoch: 2 | loss: 0.0308374\n",
      "\tspeed: 0.0705s/iter; left time: 512.2126s\n",
      "Epoch: 2 cost time: 28.322956800460815\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0344707 Vali Loss: 0.0310311 Test Loss: 0.0401463\n",
      "Validation loss decreased (0.084574 --> 0.031031).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0205227\n",
      "\tspeed: 0.0666s/iter; left time: 470.5224s\n",
      "\titers: 200, epoch: 3 | loss: 0.0222578\n",
      "\tspeed: 0.0712s/iter; left time: 495.9880s\n",
      "\titers: 300, epoch: 3 | loss: 0.0205728\n",
      "\tspeed: 0.0720s/iter; left time: 494.1236s\n",
      "Epoch: 3 cost time: 28.206618785858154\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0235595 Vali Loss: 0.0237514 Test Loss: 0.0353193\n",
      "Validation loss decreased (0.031031 --> 0.023751).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0189655\n",
      "\tspeed: 0.0710s/iter; left time: 473.6408s\n",
      "\titers: 200, epoch: 4 | loss: 0.0209318\n",
      "\tspeed: 0.0728s/iter; left time: 478.0117s\n",
      "\titers: 300, epoch: 4 | loss: 0.0157160\n",
      "\tspeed: 0.0776s/iter; left time: 502.0803s\n",
      "Epoch: 4 cost time: 30.14117193222046\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0202087 Vali Loss: 0.0198923 Test Loss: 0.0356132\n",
      "Validation loss decreased (0.023751 --> 0.019892).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0189390\n",
      "\tspeed: 0.0732s/iter; left time: 458.7547s\n",
      "\titers: 200, epoch: 5 | loss: 0.0142040\n",
      "\tspeed: 0.0744s/iter; left time: 458.8762s\n",
      "\titers: 300, epoch: 5 | loss: 0.0188541\n",
      "\tspeed: 0.0687s/iter; left time: 417.2108s\n",
      "Epoch: 5 cost time: 28.24527406692505\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0179768 Vali Loss: 0.0266667 Test Loss: 0.0600291\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0170388\n",
      "\tspeed: 0.0681s/iter; left time: 400.0580s\n",
      "\titers: 200, epoch: 6 | loss: 0.0158755\n",
      "\tspeed: 0.0686s/iter; left time: 395.7896s\n",
      "\titers: 300, epoch: 6 | loss: 0.0213832\n",
      "\tspeed: 0.0710s/iter; left time: 402.8434s\n",
      "Epoch: 6 cost time: 28.5722553730011\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0168181 Vali Loss: 0.0222460 Test Loss: 0.0533880\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0151306\n",
      "\tspeed: 0.0735s/iter; left time: 402.3114s\n",
      "\titers: 200, epoch: 7 | loss: 0.0165977\n",
      "\tspeed: 0.0732s/iter; left time: 393.4024s\n",
      "\titers: 300, epoch: 7 | loss: 0.0167642\n",
      "\tspeed: 0.0720s/iter; left time: 379.8573s\n",
      "Epoch: 7 cost time: 28.7987539768219\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0157303 Vali Loss: 0.0452760 Test Loss: 0.1001809\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.03561323881149292, mae:0.1369045227766037\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_reversal_il168_pl168_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.2427816\n",
      "\tspeed: 0.0809s/iter; left time: 629.5142s\n",
      "\titers: 200, epoch: 1 | loss: 0.1302751\n",
      "\tspeed: 0.0746s/iter; left time: 572.7285s\n",
      "\titers: 300, epoch: 1 | loss: 0.0952536\n",
      "\tspeed: 0.0704s/iter; left time: 533.6818s\n",
      "Epoch: 1 cost time: 30.005430936813354\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.1679748 Vali Loss: 0.1149458 Test Loss: 0.0756451\n",
      "Validation loss decreased (inf --> 0.114946).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0558340\n",
      "\tspeed: 0.0751s/iter; left time: 554.6235s\n",
      "\titers: 200, epoch: 2 | loss: 0.0647682\n",
      "\tspeed: 0.0738s/iter; left time: 537.6863s\n",
      "\titers: 300, epoch: 2 | loss: 0.0606960\n",
      "\tspeed: 0.0677s/iter; left time: 486.2924s\n",
      "Epoch: 2 cost time: 28.018290281295776\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0704592 Vali Loss: 0.1381003 Test Loss: 0.0893933\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0657412\n",
      "\tspeed: 0.0688s/iter; left time: 481.0131s\n",
      "\titers: 200, epoch: 3 | loss: 0.0592280\n",
      "\tspeed: 0.0715s/iter; left time: 492.7752s\n",
      "\titers: 300, epoch: 3 | loss: 0.0671060\n",
      "\tspeed: 0.0716s/iter; left time: 486.2707s\n",
      "Epoch: 3 cost time: 28.278077602386475\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0571843 Vali Loss: 0.1053625 Test Loss: 0.0753856\n",
      "Validation loss decreased (0.114946 --> 0.105362).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0617645\n",
      "\tspeed: 0.0753s/iter; left time: 496.8940s\n",
      "\titers: 200, epoch: 4 | loss: 0.0556200\n",
      "\tspeed: 0.0742s/iter; left time: 482.2617s\n",
      "\titers: 300, epoch: 4 | loss: 0.0759482\n",
      "\tspeed: 0.0735s/iter; left time: 470.1055s\n",
      "Epoch: 4 cost time: 28.94460892677307\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0539640 Vali Loss: 0.0976206 Test Loss: 0.0631448\n",
      "Validation loss decreased (0.105362 --> 0.097621).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0497269\n",
      "\tspeed: 0.0717s/iter; left time: 445.1052s\n",
      "\titers: 200, epoch: 5 | loss: 0.0459477\n",
      "\tspeed: 0.0719s/iter; left time: 439.1708s\n",
      "\titers: 300, epoch: 5 | loss: 0.0622458\n",
      "\tspeed: 0.0696s/iter; left time: 418.1476s\n",
      "Epoch: 5 cost time: 27.990404844284058\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0488615 Vali Loss: 0.0621448 Test Loss: 0.0622676\n",
      "Validation loss decreased (0.097621 --> 0.062145).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0460008\n",
      "\tspeed: 0.0718s/iter; left time: 417.2603s\n",
      "\titers: 200, epoch: 6 | loss: 0.0361261\n",
      "\tspeed: 0.0684s/iter; left time: 390.7098s\n",
      "\titers: 300, epoch: 6 | loss: 0.0476158\n",
      "\tspeed: 0.0703s/iter; left time: 394.6866s\n",
      "Epoch: 6 cost time: 27.463178396224976\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0471497 Vali Loss: 0.0579094 Test Loss: 0.0693985\n",
      "Validation loss decreased (0.062145 --> 0.057909).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0448476\n",
      "\tspeed: 0.0695s/iter; left time: 376.4757s\n",
      "\titers: 200, epoch: 7 | loss: 0.0408297\n",
      "\tspeed: 0.0730s/iter; left time: 388.0589s\n",
      "\titers: 300, epoch: 7 | loss: 0.0507977\n",
      "\tspeed: 0.0734s/iter; left time: 382.8680s\n",
      "Epoch: 7 cost time: 28.1418776512146\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0448734 Vali Loss: 0.0547729 Test Loss: 0.0649641\n",
      "Validation loss decreased (0.057909 --> 0.054773).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0506480\n",
      "\tspeed: 0.0744s/iter; left time: 373.8244s\n",
      "\titers: 200, epoch: 8 | loss: 0.0552052\n",
      "\tspeed: 0.0734s/iter; left time: 361.2739s\n",
      "\titers: 300, epoch: 8 | loss: 0.0381875\n",
      "\tspeed: 0.0729s/iter; left time: 351.5689s\n",
      "Epoch: 8 cost time: 28.86972188949585\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0443706 Vali Loss: 0.0564317 Test Loss: 0.0826634\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0432581\n",
      "\tspeed: 0.0707s/iter; left time: 327.4399s\n",
      "\titers: 200, epoch: 9 | loss: 0.0422872\n",
      "\tspeed: 0.0716s/iter; left time: 324.3043s\n",
      "\titers: 300, epoch: 9 | loss: 0.0463232\n",
      "\tspeed: 0.0703s/iter; left time: 311.3167s\n",
      "Epoch: 9 cost time: 27.85158658027649\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0429207 Vali Loss: 0.0551989 Test Loss: 0.0725844\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.0534179\n",
      "\tspeed: 0.0762s/iter; left time: 322.5828s\n",
      "\titers: 200, epoch: 10 | loss: 0.0535765\n",
      "\tspeed: 0.0770s/iter; left time: 318.3487s\n",
      "\titers: 300, epoch: 10 | loss: 0.0450736\n",
      "\tspeed: 0.0729s/iter; left time: 294.1186s\n",
      "Epoch: 10 cost time: 29.47993564605713\n",
      "Epoch: 10, Steps: 394 | Train Loss: 0.0426609 Vali Loss: 0.0560259 Test Loss: 0.0786415\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.06496407091617584, mae:0.19071923196315765\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_reversal_il168_pl336_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.3407372\n",
      "\tspeed: 0.0770s/iter; left time: 591.5392s\n",
      "\titers: 200, epoch: 1 | loss: 0.2211269\n",
      "\tspeed: 0.0726s/iter; left time: 550.2624s\n",
      "\titers: 300, epoch: 1 | loss: 0.2027788\n",
      "\tspeed: 0.0717s/iter; left time: 536.7477s\n",
      "Epoch: 1 cost time: 28.622963190078735\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.2730929 Vali Loss: 0.2711828 Test Loss: 0.1694672\n",
      "Validation loss decreased (inf --> 0.271183).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.1653152\n",
      "\tspeed: 0.0721s/iter; left time: 525.9557s\n",
      "\titers: 200, epoch: 2 | loss: 0.1546176\n",
      "\tspeed: 0.0701s/iter; left time: 504.0487s\n",
      "\titers: 300, epoch: 2 | loss: 0.1233608\n",
      "\tspeed: 0.0732s/iter; left time: 518.9136s\n",
      "Epoch: 2 cost time: 27.943186283111572\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.1503701 Vali Loss: 0.3238467 Test Loss: 0.1864457\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1482976\n",
      "\tspeed: 0.0718s/iter; left time: 495.3231s\n",
      "\titers: 200, epoch: 3 | loss: 0.1124680\n",
      "\tspeed: 0.0752s/iter; left time: 511.8623s\n",
      "\titers: 300, epoch: 3 | loss: 0.1099090\n",
      "\tspeed: 0.0702s/iter; left time: 470.4872s\n",
      "Epoch: 3 cost time: 28.443974494934082\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.1333542 Vali Loss: 0.2716223 Test Loss: 0.1355819\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.1341502\n",
      "\tspeed: 0.0731s/iter; left time: 476.4639s\n",
      "\titers: 200, epoch: 4 | loss: 0.1241915\n",
      "\tspeed: 0.0760s/iter; left time: 487.4044s\n",
      "\titers: 300, epoch: 4 | loss: 0.1911553\n",
      "\tspeed: 0.0773s/iter; left time: 488.1171s\n",
      "Epoch: 4 cost time: 29.363478422164917\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.1305070 Vali Loss: 0.2596373 Test Loss: 0.1339623\n",
      "Validation loss decreased (0.271183 --> 0.259637).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1312908\n",
      "\tspeed: 0.0738s/iter; left time: 452.2619s\n",
      "\titers: 200, epoch: 5 | loss: 0.1356438\n",
      "\tspeed: 0.0734s/iter; left time: 441.9890s\n",
      "\titers: 300, epoch: 5 | loss: 0.0734992\n",
      "\tspeed: 0.0722s/iter; left time: 427.8449s\n",
      "Epoch: 5 cost time: 28.566768646240234\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.1225734 Vali Loss: 0.3066250 Test Loss: 0.1534048\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.1275560\n",
      "\tspeed: 0.0744s/iter; left time: 426.7809s\n",
      "\titers: 200, epoch: 6 | loss: 0.1313005\n",
      "\tspeed: 0.0782s/iter; left time: 440.7296s\n",
      "\titers: 300, epoch: 6 | loss: 0.1345262\n",
      "\tspeed: 0.0725s/iter; left time: 401.3293s\n",
      "Epoch: 6 cost time: 28.97615146636963\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.1206868 Vali Loss: 0.2791031 Test Loss: 0.1406400\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1155049\n",
      "\tspeed: 0.0705s/iter; left time: 376.9827s\n",
      "\titers: 200, epoch: 7 | loss: 0.1080657\n",
      "\tspeed: 0.0760s/iter; left time: 398.8312s\n",
      "\titers: 300, epoch: 7 | loss: 0.1273004\n",
      "\tspeed: 0.0708s/iter; left time: 364.5269s\n",
      "Epoch: 7 cost time: 28.787961721420288\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.1169762 Vali Loss: 0.2615355 Test Loss: 0.1378082\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.13396231830120087, mae:0.2737908363342285\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_reversal_il168_pl720_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.4424452\n",
      "\tspeed: 0.0779s/iter; left time: 579.6254s\n",
      "\titers: 200, epoch: 1 | loss: 0.4142405\n",
      "\tspeed: 0.0785s/iter; left time: 576.0341s\n",
      "\titers: 300, epoch: 1 | loss: 0.3424654\n",
      "\tspeed: 0.0812s/iter; left time: 588.2922s\n",
      "Epoch: 1 cost time: 29.974623918533325\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.4009457 Vali Loss: 0.8065557 Test Loss: 0.4958634\n",
      "Validation loss decreased (inf --> 0.806556).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.2666018\n",
      "\tspeed: 0.0743s/iter; left time: 524.5934s\n",
      "\titers: 200, epoch: 2 | loss: 0.2681884\n",
      "\tspeed: 0.0763s/iter; left time: 531.0277s\n",
      "\titers: 300, epoch: 2 | loss: 0.2220282\n",
      "\tspeed: 0.0753s/iter; left time: 516.9403s\n",
      "Epoch: 2 cost time: 28.828669786453247\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.2600360 Vali Loss: 0.5394601 Test Loss: 0.2633304\n",
      "Validation loss decreased (0.806556 --> 0.539460).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2462171\n",
      "\tspeed: 0.0762s/iter; left time: 509.5154s\n",
      "\titers: 200, epoch: 3 | loss: 0.2781585\n",
      "\tspeed: 0.0826s/iter; left time: 544.2386s\n",
      "\titers: 300, epoch: 3 | loss: 0.2328648\n",
      "\tspeed: 0.0811s/iter; left time: 525.8452s\n",
      "Epoch: 3 cost time: 29.948274850845337\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.2405572 Vali Loss: 0.9968938 Test Loss: 0.6052560\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.1769280\n",
      "\tspeed: 0.0800s/iter; left time: 505.0003s\n",
      "\titers: 200, epoch: 4 | loss: 0.2854016\n",
      "\tspeed: 0.0792s/iter; left time: 491.9352s\n",
      "\titers: 300, epoch: 4 | loss: 0.1665203\n",
      "\tspeed: 0.0758s/iter; left time: 462.9310s\n",
      "Epoch: 4 cost time: 29.40438413619995\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.2360841 Vali Loss: 0.7787762 Test Loss: 0.3903364\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1999949\n",
      "\tspeed: 0.0760s/iter; left time: 450.6969s\n",
      "\titers: 200, epoch: 5 | loss: 0.2080008\n",
      "\tspeed: 0.0797s/iter; left time: 465.1507s\n",
      "\titers: 300, epoch: 5 | loss: 0.2664314\n",
      "\tspeed: 0.0831s/iter; left time: 476.1957s\n",
      "Epoch: 5 cost time: 30.337859630584717\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.2306375 Vali Loss: 0.8410350 Test Loss: 0.4856997\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.2633303105831146, mae:0.4015854597091675\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_il168_pl24_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.1384192\n",
      "\tspeed: 0.0774s/iter; left time: 609.7688s\n",
      "\titers: 200, epoch: 1 | loss: 0.0690176\n",
      "\tspeed: 0.0759s/iter; left time: 590.4364s\n",
      "\titers: 300, epoch: 1 | loss: 0.0501726\n",
      "\tspeed: 0.0764s/iter; left time: 587.1513s\n",
      "Epoch: 1 cost time: 30.385377168655396\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.1160566 Vali Loss: 0.0661754 Test Loss: 0.3885521\n",
      "Validation loss decreased (inf --> 0.066175).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0305580\n",
      "\tspeed: 0.0714s/iter; left time: 533.9698s\n",
      "\titers: 200, epoch: 2 | loss: 0.0262010\n",
      "\tspeed: 0.0678s/iter; left time: 500.3545s\n",
      "\titers: 300, epoch: 2 | loss: 0.0210593\n",
      "\tspeed: 0.0646s/iter; left time: 470.1079s\n",
      "Epoch: 2 cost time: 26.947021007537842\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0277255 Vali Loss: 0.0353841 Test Loss: 0.2644592\n",
      "Validation loss decreased (0.066175 --> 0.035384).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0181451\n",
      "\tspeed: 0.0662s/iter; left time: 468.6611s\n",
      "\titers: 200, epoch: 3 | loss: 0.0165779\n",
      "\tspeed: 0.0697s/iter; left time: 486.5991s\n",
      "\titers: 300, epoch: 3 | loss: 0.0172610\n",
      "\tspeed: 0.0690s/iter; left time: 474.7629s\n",
      "Epoch: 3 cost time: 27.456932306289673\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0172143 Vali Loss: 0.0321825 Test Loss: 0.2297270\n",
      "Validation loss decreased (0.035384 --> 0.032183).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0135226\n",
      "\tspeed: 0.0758s/iter; left time: 506.3295s\n",
      "\titers: 200, epoch: 4 | loss: 0.0132826\n",
      "\tspeed: 0.0766s/iter; left time: 504.0149s\n",
      "\titers: 300, epoch: 4 | loss: 0.0169319\n",
      "\tspeed: 0.0790s/iter; left time: 512.0654s\n",
      "Epoch: 4 cost time: 30.9238760471344\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0149103 Vali Loss: 0.0212206 Test Loss: 0.1324038\n",
      "Validation loss decreased (0.032183 --> 0.021221).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0127705\n",
      "\tspeed: 0.0727s/iter; left time: 456.6396s\n",
      "\titers: 200, epoch: 5 | loss: 0.0119275\n",
      "\tspeed: 0.0740s/iter; left time: 457.7680s\n",
      "\titers: 300, epoch: 5 | loss: 0.0128656\n",
      "\tspeed: 0.0713s/iter; left time: 433.6567s\n",
      "Epoch: 5 cost time: 28.8070707321167\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0127699 Vali Loss: 0.0300039 Test Loss: 0.1829066\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0130467\n",
      "\tspeed: 0.0707s/iter; left time: 416.4303s\n",
      "\titers: 200, epoch: 6 | loss: 0.0126514\n",
      "\tspeed: 0.0734s/iter; left time: 424.4651s\n",
      "\titers: 300, epoch: 6 | loss: 0.0105603\n",
      "\tspeed: 0.0783s/iter; left time: 445.1455s\n",
      "Epoch: 6 cost time: 29.327142477035522\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0119938 Vali Loss: 0.0195779 Test Loss: 0.1466155\n",
      "Validation loss decreased (0.021221 --> 0.019578).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0095886\n",
      "\tspeed: 0.0712s/iter; left time: 390.7764s\n",
      "\titers: 200, epoch: 7 | loss: 0.0128540\n",
      "\tspeed: 0.0744s/iter; left time: 400.8141s\n",
      "\titers: 300, epoch: 7 | loss: 0.0095738\n",
      "\tspeed: 0.0741s/iter; left time: 392.0050s\n",
      "Epoch: 7 cost time: 29.278507471084595\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0107157 Vali Loss: 0.0164933 Test Loss: 0.1199514\n",
      "Validation loss decreased (0.019578 --> 0.016493).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0106320\n",
      "\tspeed: 0.0738s/iter; left time: 375.7362s\n",
      "\titers: 200, epoch: 8 | loss: 0.0104328\n",
      "\tspeed: 0.0730s/iter; left time: 364.0863s\n",
      "\titers: 300, epoch: 8 | loss: 0.0090074\n",
      "\tspeed: 0.0775s/iter; left time: 378.8850s\n",
      "Epoch: 8 cost time: 30.27237582206726\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0103528 Vali Loss: 0.0176393 Test Loss: 0.1298209\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0086389\n",
      "\tspeed: 0.0728s/iter; left time: 341.4469s\n",
      "\titers: 200, epoch: 9 | loss: 0.0115707\n",
      "\tspeed: 0.0721s/iter; left time: 330.8957s\n",
      "\titers: 300, epoch: 9 | loss: 0.0092406\n",
      "\tspeed: 0.0715s/iter; left time: 320.9695s\n",
      "Epoch: 9 cost time: 28.930203437805176\n",
      "Epoch: 9, Steps: 399 | Train Loss: 0.0097882 Vali Loss: 0.0208263 Test Loss: 0.1531308\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.0125521\n",
      "\tspeed: 0.0707s/iter; left time: 303.4064s\n",
      "\titers: 200, epoch: 10 | loss: 0.0068629\n",
      "\tspeed: 0.0710s/iter; left time: 297.4611s\n",
      "\titers: 300, epoch: 10 | loss: 0.0121972\n",
      "\tspeed: 0.0771s/iter; left time: 315.2823s\n",
      "Epoch: 10 cost time: 29.279704093933105\n",
      "Epoch: 10, Steps: 399 | Train Loss: 0.0096441 Vali Loss: 0.0190074 Test Loss: 0.1362485\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.11995144188404083, mae:0.26143091917037964\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_il168_pl48_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.1487842\n",
      "\tspeed: 0.0810s/iter; left time: 636.7277s\n",
      "\titers: 200, epoch: 1 | loss: 0.0780550\n",
      "\tspeed: 0.0761s/iter; left time: 590.8036s\n",
      "\titers: 300, epoch: 1 | loss: 0.0482371\n",
      "\tspeed: 0.0696s/iter; left time: 533.0729s\n",
      "Epoch: 1 cost time: 29.85553765296936\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.1095068 Vali Loss: 0.0892408 Test Loss: 0.3550438\n",
      "Validation loss decreased (inf --> 0.089241).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0262882\n",
      "\tspeed: 0.0695s/iter; left time: 518.8517s\n",
      "\titers: 200, epoch: 2 | loss: 0.0270189\n",
      "\tspeed: 0.0739s/iter; left time: 544.4654s\n",
      "\titers: 300, epoch: 2 | loss: 0.0326692\n",
      "\tspeed: 0.0783s/iter; left time: 568.5657s\n",
      "Epoch: 2 cost time: 29.859667539596558\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0308060 Vali Loss: 0.0409478 Test Loss: 0.1930725\n",
      "Validation loss decreased (0.089241 --> 0.040948).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0192575\n",
      "\tspeed: 0.0712s/iter; left time: 502.7592s\n",
      "\titers: 200, epoch: 3 | loss: 0.0176578\n",
      "\tspeed: 0.0716s/iter; left time: 498.8501s\n",
      "\titers: 300, epoch: 3 | loss: 0.0166799\n",
      "\tspeed: 0.0722s/iter; left time: 495.4795s\n",
      "Epoch: 3 cost time: 28.6467125415802\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0189658 Vali Loss: 0.0347945 Test Loss: 0.1361320\n",
      "Validation loss decreased (0.040948 --> 0.034795).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0152975\n",
      "\tspeed: 0.0709s/iter; left time: 472.9630s\n",
      "\titers: 200, epoch: 4 | loss: 0.0166309\n",
      "\tspeed: 0.0737s/iter; left time: 483.8687s\n",
      "\titers: 300, epoch: 4 | loss: 0.0138132\n",
      "\tspeed: 0.0749s/iter; left time: 484.6478s\n",
      "Epoch: 4 cost time: 29.577774047851562\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0163249 Vali Loss: 0.0282968 Test Loss: 0.1170741\n",
      "Validation loss decreased (0.034795 --> 0.028297).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0111159\n",
      "\tspeed: 0.0752s/iter; left time: 471.1601s\n",
      "\titers: 200, epoch: 5 | loss: 0.0145969\n",
      "\tspeed: 0.0750s/iter; left time: 462.5288s\n",
      "\titers: 300, epoch: 5 | loss: 0.0158004\n",
      "\tspeed: 0.0719s/iter; left time: 436.3491s\n",
      "Epoch: 5 cost time: 29.2919762134552\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0135730 Vali Loss: 0.0243561 Test Loss: 0.1154425\n",
      "Validation loss decreased (0.028297 --> 0.024356).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0165765\n",
      "\tspeed: 0.0730s/iter; left time: 428.6594s\n",
      "\titers: 200, epoch: 6 | loss: 0.0144394\n",
      "\tspeed: 0.0709s/iter; left time: 409.2188s\n",
      "\titers: 300, epoch: 6 | loss: 0.0106361\n",
      "\tspeed: 0.0730s/iter; left time: 414.0788s\n",
      "Epoch: 6 cost time: 28.181864500045776\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0130061 Vali Loss: 0.0206400 Test Loss: 0.1047376\n",
      "Validation loss decreased (0.024356 --> 0.020640).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0103887\n",
      "\tspeed: 0.0693s/iter; left time: 379.5299s\n",
      "\titers: 200, epoch: 7 | loss: 0.0120152\n",
      "\tspeed: 0.0745s/iter; left time: 400.0590s\n",
      "\titers: 300, epoch: 7 | loss: 0.0115781\n",
      "\tspeed: 0.0771s/iter; left time: 406.5480s\n",
      "Epoch: 7 cost time: 29.08830189704895\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0117062 Vali Loss: 0.0206983 Test Loss: 0.1041047\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0139550\n",
      "\tspeed: 0.0703s/iter; left time: 356.6663s\n",
      "\titers: 200, epoch: 8 | loss: 0.0116105\n",
      "\tspeed: 0.0691s/iter; left time: 343.6086s\n",
      "\titers: 300, epoch: 8 | loss: 0.0111975\n",
      "\tspeed: 0.0708s/iter; left time: 345.0373s\n",
      "Epoch: 8 cost time: 28.00492262840271\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0113353 Vali Loss: 0.0215153 Test Loss: 0.1073612\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0100648\n",
      "\tspeed: 0.0734s/iter; left time: 343.2620s\n",
      "\titers: 200, epoch: 9 | loss: 0.0105307\n",
      "\tspeed: 0.0731s/iter; left time: 334.5520s\n",
      "\titers: 300, epoch: 9 | loss: 0.0093763\n",
      "\tspeed: 0.0720s/iter; left time: 322.2126s\n",
      "Epoch: 9 cost time: 28.926350593566895\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0108287 Vali Loss: 0.0181968 Test Loss: 0.0978736\n",
      "Validation loss decreased (0.020640 --> 0.018197).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0083926\n",
      "\tspeed: 0.0711s/iter; left time: 304.0845s\n",
      "\titers: 200, epoch: 10 | loss: 0.0107717\n",
      "\tspeed: 0.0715s/iter; left time: 298.9168s\n",
      "\titers: 300, epoch: 10 | loss: 0.0102060\n",
      "\tspeed: 0.0704s/iter; left time: 287.0359s\n",
      "Epoch: 10 cost time: 28.538105487823486\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.0104855 Vali Loss: 0.0182008 Test Loss: 0.0971315\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0122127\n",
      "\tspeed: 0.0763s/iter; left time: 296.0532s\n",
      "\titers: 200, epoch: 11 | loss: 0.0122658\n",
      "\tspeed: 0.0750s/iter; left time: 283.4157s\n",
      "\titers: 300, epoch: 11 | loss: 0.0094061\n",
      "\tspeed: 0.0749s/iter; left time: 275.7600s\n",
      "Epoch: 11 cost time: 29.68668818473816\n",
      "Epoch: 11, Steps: 398 | Train Loss: 0.0103095 Vali Loss: 0.0177439 Test Loss: 0.0931477\n",
      "Validation loss decreased (0.018197 --> 0.017744).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.0082375\n",
      "\tspeed: 0.0712s/iter; left time: 248.0053s\n",
      "\titers: 200, epoch: 12 | loss: 0.0099555\n",
      "\tspeed: 0.0713s/iter; left time: 241.1912s\n",
      "\titers: 300, epoch: 12 | loss: 0.0110032\n",
      "\tspeed: 0.0721s/iter; left time: 236.8072s\n",
      "Epoch: 12 cost time: 28.61466932296753\n",
      "Epoch: 12, Steps: 398 | Train Loss: 0.0102047 Vali Loss: 0.0172482 Test Loss: 0.0951618\n",
      "Validation loss decreased (0.017744 --> 0.017248).  Saving model ...\n",
      "\titers: 100, epoch: 13 | loss: 0.0105589\n",
      "\tspeed: 0.0746s/iter; left time: 230.0228s\n",
      "\titers: 200, epoch: 13 | loss: 0.0098448\n",
      "\tspeed: 0.0752s/iter; left time: 224.5049s\n",
      "\titers: 300, epoch: 13 | loss: 0.0093287\n",
      "\tspeed: 0.0755s/iter; left time: 217.7966s\n",
      "Epoch: 13 cost time: 29.998866081237793\n",
      "Epoch: 13, Steps: 398 | Train Loss: 0.0100080 Vali Loss: 0.0167120 Test Loss: 0.0933158\n",
      "Validation loss decreased (0.017248 --> 0.016712).  Saving model ...\n",
      "\titers: 100, epoch: 14 | loss: 0.0105628\n",
      "\tspeed: 0.0681s/iter; left time: 183.0803s\n",
      "\titers: 200, epoch: 14 | loss: 0.0105404\n",
      "\tspeed: 0.0679s/iter; left time: 175.5595s\n",
      "\titers: 300, epoch: 14 | loss: 0.0090711\n",
      "\tspeed: 0.0704s/iter; left time: 175.1131s\n",
      "Epoch: 14 cost time: 27.769719123840332\n",
      "Epoch: 14, Steps: 398 | Train Loss: 0.0098965 Vali Loss: 0.0169965 Test Loss: 0.0940110\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 15 | loss: 0.0099179\n",
      "\tspeed: 0.0738s/iter; left time: 168.9530s\n",
      "\titers: 200, epoch: 15 | loss: 0.0098430\n",
      "\tspeed: 0.0722s/iter; left time: 158.1414s\n",
      "\titers: 300, epoch: 15 | loss: 0.0089548\n",
      "\tspeed: 0.0699s/iter; left time: 146.0864s\n",
      "Epoch: 15 cost time: 28.353420972824097\n",
      "Epoch: 15, Steps: 398 | Train Loss: 0.0098662 Vali Loss: 0.0188596 Test Loss: 0.0995237\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 16 | loss: 0.0092817\n",
      "\tspeed: 0.0664s/iter; left time: 125.4885s\n",
      "\titers: 200, epoch: 16 | loss: 0.0120292\n",
      "\tspeed: 0.0656s/iter; left time: 117.4226s\n",
      "\titers: 300, epoch: 16 | loss: 0.0099781\n",
      "\tspeed: 0.0680s/iter; left time: 115.0699s\n",
      "Epoch: 16 cost time: 27.178019523620605\n",
      "Epoch: 16, Steps: 398 | Train Loss: 0.0097027 Vali Loss: 0.0184102 Test Loss: 0.0997940\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.09331576526165009, mae:0.23401139676570892\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_il168_pl168_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.2005235\n",
      "\tspeed: 0.0810s/iter; left time: 630.3418s\n",
      "\titers: 200, epoch: 1 | loss: 0.1028793\n",
      "\tspeed: 0.0770s/iter; left time: 591.7851s\n",
      "\titers: 300, epoch: 1 | loss: 0.0639844\n",
      "\tspeed: 0.0717s/iter; left time: 543.6521s\n",
      "Epoch: 1 cost time: 29.198737621307373\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.1382559 Vali Loss: 0.1857696 Test Loss: 0.8199171\n",
      "Validation loss decreased (inf --> 0.185770).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0410169\n",
      "\tspeed: 0.0679s/iter; left time: 501.8572s\n",
      "\titers: 200, epoch: 2 | loss: 0.0375469\n",
      "\tspeed: 0.0708s/iter; left time: 516.1738s\n",
      "\titers: 300, epoch: 2 | loss: 0.0610902\n",
      "\tspeed: 0.0711s/iter; left time: 511.1713s\n",
      "Epoch: 2 cost time: 27.64522385597229\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0460357 Vali Loss: 0.1345965 Test Loss: 0.7234505\n",
      "Validation loss decreased (0.185770 --> 0.134597).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0304075\n",
      "\tspeed: 0.0720s/iter; left time: 503.8398s\n",
      "\titers: 200, epoch: 3 | loss: 0.0249627\n",
      "\tspeed: 0.0735s/iter; left time: 506.5439s\n",
      "\titers: 300, epoch: 3 | loss: 0.0327373\n",
      "\tspeed: 0.0734s/iter; left time: 498.8895s\n",
      "Epoch: 3 cost time: 28.477220058441162\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0325041 Vali Loss: 0.1447018 Test Loss: 0.7697189\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.0281532\n",
      "\tspeed: 0.0675s/iter; left time: 445.1310s\n",
      "\titers: 200, epoch: 4 | loss: 0.0294670\n",
      "\tspeed: 0.0714s/iter; left time: 464.0186s\n",
      "\titers: 300, epoch: 4 | loss: 0.0283169\n",
      "\tspeed: 0.0730s/iter; left time: 467.3724s\n",
      "Epoch: 4 cost time: 27.78290104866028\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0296687 Vali Loss: 0.1049925 Test Loss: 0.6493870\n",
      "Validation loss decreased (0.134597 --> 0.104993).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0223114\n",
      "\tspeed: 0.0731s/iter; left time: 453.3096s\n",
      "\titers: 200, epoch: 5 | loss: 0.0248939\n",
      "\tspeed: 0.0743s/iter; left time: 453.4654s\n",
      "\titers: 300, epoch: 5 | loss: 0.0251567\n",
      "\tspeed: 0.0760s/iter; left time: 456.2495s\n",
      "Epoch: 5 cost time: 29.375346660614014\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0255754 Vali Loss: 0.0994286 Test Loss: 0.6509121\n",
      "Validation loss decreased (0.104993 --> 0.099429).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0267350\n",
      "\tspeed: 0.0739s/iter; left time: 429.4536s\n",
      "\titers: 200, epoch: 6 | loss: 0.0214772\n",
      "\tspeed: 0.0724s/iter; left time: 413.6225s\n",
      "\titers: 300, epoch: 6 | loss: 0.0237782\n",
      "\tspeed: 0.0729s/iter; left time: 409.1471s\n",
      "Epoch: 6 cost time: 28.73067617416382\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0242280 Vali Loss: 0.1182779 Test Loss: 0.7419793\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0282568\n",
      "\tspeed: 0.0724s/iter; left time: 392.2766s\n",
      "\titers: 200, epoch: 7 | loss: 0.0214000\n",
      "\tspeed: 0.0740s/iter; left time: 393.4135s\n",
      "\titers: 300, epoch: 7 | loss: 0.0239205\n",
      "\tspeed: 0.0753s/iter; left time: 392.9529s\n",
      "Epoch: 7 cost time: 29.249760389328003\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0225506 Vali Loss: 0.1446595 Test Loss: 0.8142862\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0242775\n",
      "\tspeed: 0.0739s/iter; left time: 371.2117s\n",
      "\titers: 200, epoch: 8 | loss: 0.0182272\n",
      "\tspeed: 0.0719s/iter; left time: 353.8491s\n",
      "\titers: 300, epoch: 8 | loss: 0.0217983\n",
      "\tspeed: 0.0723s/iter; left time: 348.6375s\n",
      "Epoch: 8 cost time: 28.599382877349854\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0220073 Vali Loss: 0.1433087 Test Loss: 0.7736367\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.6509121060371399, mae:0.7008762955665588\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_il168_pl336_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.1814051\n",
      "\tspeed: 0.0747s/iter; left time: 573.8459s\n",
      "\titers: 200, epoch: 1 | loss: 0.1687503\n",
      "\tspeed: 0.0759s/iter; left time: 575.1277s\n",
      "\titers: 300, epoch: 1 | loss: 0.0914184\n",
      "\tspeed: 0.0771s/iter; left time: 576.4740s\n",
      "Epoch: 1 cost time: 29.625210285186768\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1701984 Vali Loss: 0.3782315 Test Loss: 1.4136693\n",
      "Validation loss decreased (inf --> 0.378232).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0721046\n",
      "\tspeed: 0.0759s/iter; left time: 553.1777s\n",
      "\titers: 200, epoch: 2 | loss: 0.0618689\n",
      "\tspeed: 0.0762s/iter; left time: 547.8659s\n",
      "\titers: 300, epoch: 2 | loss: 0.0511262\n",
      "\tspeed: 0.0778s/iter; left time: 551.8559s\n",
      "Epoch: 2 cost time: 29.95227336883545\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0721556 Vali Loss: 0.2986014 Test Loss: 1.0449003\n",
      "Validation loss decreased (0.378232 --> 0.298601).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0503224\n",
      "\tspeed: 0.0743s/iter; left time: 512.9528s\n",
      "\titers: 200, epoch: 3 | loss: 0.0624504\n",
      "\tspeed: 0.0719s/iter; left time: 489.4477s\n",
      "\titers: 300, epoch: 3 | loss: 0.0594589\n",
      "\tspeed: 0.0695s/iter; left time: 466.0789s\n",
      "Epoch: 3 cost time: 27.950429677963257\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0572808 Vali Loss: 0.2218699 Test Loss: 0.7493693\n",
      "Validation loss decreased (0.298601 --> 0.221870).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0394913\n",
      "\tspeed: 0.0734s/iter; left time: 478.3887s\n",
      "\titers: 200, epoch: 4 | loss: 0.0467953\n",
      "\tspeed: 0.0758s/iter; left time: 486.4643s\n",
      "\titers: 300, epoch: 4 | loss: 0.0545982\n",
      "\tspeed: 0.0713s/iter; left time: 449.8910s\n",
      "Epoch: 4 cost time: 28.59605312347412\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0505001 Vali Loss: 0.1388578 Test Loss: 0.4282341\n",
      "Validation loss decreased (0.221870 --> 0.138858).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0463465\n",
      "\tspeed: 0.0707s/iter; left time: 432.9272s\n",
      "\titers: 200, epoch: 5 | loss: 0.0467977\n",
      "\tspeed: 0.0726s/iter; left time: 437.5553s\n",
      "\titers: 300, epoch: 5 | loss: 0.0363475\n",
      "\tspeed: 0.0722s/iter; left time: 427.7455s\n",
      "Epoch: 5 cost time: 28.00079321861267\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0451822 Vali Loss: 0.2017891 Test Loss: 0.6739563\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0395433\n",
      "\tspeed: 0.0753s/iter; left time: 431.7893s\n",
      "\titers: 200, epoch: 6 | loss: 0.0385110\n",
      "\tspeed: 0.0814s/iter; left time: 458.8366s\n",
      "\titers: 300, epoch: 6 | loss: 0.0440358\n",
      "\tspeed: 0.0784s/iter; left time: 434.0255s\n",
      "Epoch: 6 cost time: 29.834609270095825\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0421377 Vali Loss: 0.1382716 Test Loss: 0.5295435\n",
      "Validation loss decreased (0.138858 --> 0.138272).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0431788\n",
      "\tspeed: 0.0700s/iter; left time: 374.5470s\n",
      "\titers: 200, epoch: 7 | loss: 0.0406417\n",
      "\tspeed: 0.0675s/iter; left time: 354.3090s\n",
      "\titers: 300, epoch: 7 | loss: 0.0324224\n",
      "\tspeed: 0.0712s/iter; left time: 366.6901s\n",
      "Epoch: 7 cost time: 27.823232650756836\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.0388866 Vali Loss: 0.1671543 Test Loss: 0.6323011\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0410512\n",
      "\tspeed: 0.0802s/iter; left time: 397.8561s\n",
      "\titers: 200, epoch: 8 | loss: 0.0380351\n",
      "\tspeed: 0.0767s/iter; left time: 372.7134s\n",
      "\titers: 300, epoch: 8 | loss: 0.0390141\n",
      "\tspeed: 0.0768s/iter; left time: 365.4631s\n",
      "Epoch: 8 cost time: 29.817676544189453\n",
      "Epoch: 8, Steps: 389 | Train Loss: 0.0381396 Vali Loss: 0.1150685 Test Loss: 0.4656753\n",
      "Validation loss decreased (0.138272 --> 0.115069).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0417415\n",
      "\tspeed: 0.0707s/iter; left time: 322.9724s\n",
      "\titers: 200, epoch: 9 | loss: 0.0381772\n",
      "\tspeed: 0.0767s/iter; left time: 342.7526s\n",
      "\titers: 300, epoch: 9 | loss: 0.0394820\n",
      "\tspeed: 0.0745s/iter; left time: 325.4024s\n",
      "Epoch: 9 cost time: 29.250955820083618\n",
      "Epoch: 9, Steps: 389 | Train Loss: 0.0362698 Vali Loss: 0.1334532 Test Loss: 0.5782330\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.0402445\n",
      "\tspeed: 0.0768s/iter; left time: 320.8750s\n",
      "\titers: 200, epoch: 10 | loss: 0.0359349\n",
      "\tspeed: 0.0780s/iter; left time: 318.2490s\n",
      "\titers: 300, epoch: 10 | loss: 0.0334349\n",
      "\tspeed: 0.0789s/iter; left time: 314.1331s\n",
      "Epoch: 10 cost time: 30.249662160873413\n",
      "Epoch: 10, Steps: 389 | Train Loss: 0.0351428 Vali Loss: 0.1412345 Test Loss: 0.6134349\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0392843\n",
      "\tspeed: 0.0748s/iter; left time: 283.7485s\n",
      "\titers: 200, epoch: 11 | loss: 0.0349193\n",
      "\tspeed: 0.0748s/iter; left time: 275.9359s\n",
      "\titers: 300, epoch: 11 | loss: 0.0347396\n",
      "\tspeed: 0.0746s/iter; left time: 267.7155s\n",
      "Epoch: 11 cost time: 28.853510856628418\n",
      "Epoch: 11, Steps: 389 | Train Loss: 0.0344182 Vali Loss: 0.1453941 Test Loss: 0.6377333\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:0.46567532420158386, mae:0.5394874811172485\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_il168_pl720_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.1623980\n",
      "\tspeed: 0.0792s/iter; left time: 589.2857s\n",
      "\titers: 200, epoch: 1 | loss: 0.1412407\n",
      "\tspeed: 0.0751s/iter; left time: 551.3882s\n",
      "\titers: 300, epoch: 1 | loss: 0.1182354\n",
      "\tspeed: 0.0793s/iter; left time: 573.9924s\n",
      "Epoch: 1 cost time: 29.778582096099854\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.1705445 Vali Loss: 0.4344852 Test Loss: 1.6360876\n",
      "Validation loss decreased (inf --> 0.434485).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0657545\n",
      "\tspeed: 0.0716s/iter; left time: 505.9484s\n",
      "\titers: 200, epoch: 2 | loss: 0.0628652\n",
      "\tspeed: 0.0757s/iter; left time: 527.1575s\n",
      "\titers: 300, epoch: 2 | loss: 0.0568128\n",
      "\tspeed: 0.0769s/iter; left time: 528.0387s\n",
      "Epoch: 2 cost time: 28.818552255630493\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.0630251 Vali Loss: 0.1675967 Test Loss: 0.6102452\n",
      "Validation loss decreased (0.434485 --> 0.167597).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0612649\n",
      "\tspeed: 0.0843s/iter; left time: 563.6564s\n",
      "\titers: 200, epoch: 3 | loss: 0.0410621\n",
      "\tspeed: 0.0827s/iter; left time: 544.7356s\n",
      "\titers: 300, epoch: 3 | loss: 0.0500977\n",
      "\tspeed: 0.0803s/iter; left time: 520.9983s\n",
      "Epoch: 3 cost time: 31.1182804107666\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0479965 Vali Loss: 0.1316321 Test Loss: 0.5542533\n",
      "Validation loss decreased (0.167597 --> 0.131632).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0460044\n",
      "\tspeed: 0.0777s/iter; left time: 490.5991s\n",
      "\titers: 200, epoch: 4 | loss: 0.0391314\n",
      "\tspeed: 0.0789s/iter; left time: 490.2545s\n",
      "\titers: 300, epoch: 4 | loss: 0.0464551\n",
      "\tspeed: 0.0778s/iter; left time: 475.5929s\n",
      "Epoch: 4 cost time: 29.57031273841858\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0414189 Vali Loss: 0.1233824 Test Loss: 0.5971326\n",
      "Validation loss decreased (0.131632 --> 0.123382).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0391645\n",
      "\tspeed: 0.0842s/iter; left time: 499.5868s\n",
      "\titers: 200, epoch: 5 | loss: 0.0334144\n",
      "\tspeed: 0.0858s/iter; left time: 500.5560s\n",
      "\titers: 300, epoch: 5 | loss: 0.0341866\n",
      "\tspeed: 0.0801s/iter; left time: 459.1011s\n",
      "Epoch: 5 cost time: 31.269537687301636\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0368388 Vali Loss: 0.1139064 Test Loss: 0.5640854\n",
      "Validation loss decreased (0.123382 --> 0.113906).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0334101\n",
      "\tspeed: 0.0773s/iter; left time: 429.6426s\n",
      "\titers: 200, epoch: 6 | loss: 0.0356026\n",
      "\tspeed: 0.0764s/iter; left time: 416.5925s\n",
      "\titers: 300, epoch: 6 | loss: 0.0280519\n",
      "\tspeed: 0.0759s/iter; left time: 406.5141s\n",
      "Epoch: 6 cost time: 29.412517309188843\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0350215 Vali Loss: 0.1841841 Test Loss: 0.7625967\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0310605\n",
      "\tspeed: 0.0809s/iter; left time: 418.9443s\n",
      "\titers: 200, epoch: 7 | loss: 0.0297175\n",
      "\tspeed: 0.0842s/iter; left time: 427.5557s\n",
      "\titers: 300, epoch: 7 | loss: 0.0348278\n",
      "\tspeed: 0.0867s/iter; left time: 431.7155s\n",
      "Epoch: 7 cost time: 31.241669416427612\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0328241 Vali Loss: 0.1281535 Test Loss: 0.6098992\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0331080\n",
      "\tspeed: 0.0730s/iter; left time: 350.4395s\n",
      "\titers: 200, epoch: 8 | loss: 0.0344004\n",
      "\tspeed: 0.0788s/iter; left time: 370.3722s\n",
      "\titers: 300, epoch: 8 | loss: 0.0295809\n",
      "\tspeed: 0.0816s/iter; left time: 375.3276s\n",
      "Epoch: 8 cost time: 30.13423442840576\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.0318151 Vali Loss: 0.1547990 Test Loss: 0.6912416\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:0.5640854239463806, mae:0.6110429167747498\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 24, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il168_pl24_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12769\n",
      "val 2137\n",
      "test 2137\n",
      "\titers: 100, epoch: 1 | loss: 0.1893932\n",
      "\tspeed: 0.0854s/iter; left time: 672.8045s\n",
      "\titers: 200, epoch: 1 | loss: 0.0891593\n",
      "\tspeed: 0.0820s/iter; left time: 637.6926s\n",
      "\titers: 300, epoch: 1 | loss: 0.0495706\n",
      "\tspeed: 0.0758s/iter; left time: 581.8772s\n",
      "Epoch: 1 cost time: 30.98083996772766\n",
      "Epoch: 1, Steps: 399 | Train Loss: 0.1237547 Vali Loss: 0.1266231 Test Loss: 0.4266951\n",
      "Validation loss decreased (inf --> 0.126623).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0291803\n",
      "\tspeed: 0.0715s/iter; left time: 535.1160s\n",
      "\titers: 200, epoch: 2 | loss: 0.0392174\n",
      "\tspeed: 0.0701s/iter; left time: 517.5792s\n",
      "\titers: 300, epoch: 2 | loss: 0.0201109\n",
      "\tspeed: 0.0739s/iter; left time: 537.8918s\n",
      "Epoch: 2 cost time: 28.95396900177002\n",
      "Epoch: 2, Steps: 399 | Train Loss: 0.0303103 Vali Loss: 0.1099976 Test Loss: 0.3041088\n",
      "Validation loss decreased (0.126623 --> 0.109998).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0167139\n",
      "\tspeed: 0.0760s/iter; left time: 538.2745s\n",
      "\titers: 200, epoch: 3 | loss: 0.0276701\n",
      "\tspeed: 0.0724s/iter; left time: 505.4049s\n",
      "\titers: 300, epoch: 3 | loss: 0.0284240\n",
      "\tspeed: 0.0810s/iter; left time: 557.3259s\n",
      "Epoch: 3 cost time: 30.37531042098999\n",
      "Epoch: 3, Steps: 399 | Train Loss: 0.0199624 Vali Loss: 0.1023156 Test Loss: 0.2920100\n",
      "Validation loss decreased (0.109998 --> 0.102316).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0145160\n",
      "\tspeed: 0.0743s/iter; left time: 496.6377s\n",
      "\titers: 200, epoch: 4 | loss: 0.0201837\n",
      "\tspeed: 0.0701s/iter; left time: 461.3068s\n",
      "\titers: 300, epoch: 4 | loss: 0.0140483\n",
      "\tspeed: 0.0644s/iter; left time: 417.8377s\n",
      "Epoch: 4 cost time: 28.258167505264282\n",
      "Epoch: 4, Steps: 399 | Train Loss: 0.0179024 Vali Loss: 0.0931192 Test Loss: 0.2868989\n",
      "Validation loss decreased (0.102316 --> 0.093119).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0123816\n",
      "\tspeed: 0.0743s/iter; left time: 466.9779s\n",
      "\titers: 200, epoch: 5 | loss: 0.0128160\n",
      "\tspeed: 0.0716s/iter; left time: 442.7425s\n",
      "\titers: 300, epoch: 5 | loss: 0.0102411\n",
      "\tspeed: 0.0716s/iter; left time: 435.6412s\n",
      "Epoch: 5 cost time: 28.443035125732422\n",
      "Epoch: 5, Steps: 399 | Train Loss: 0.0147529 Vali Loss: 0.0925157 Test Loss: 0.2723124\n",
      "Validation loss decreased (0.093119 --> 0.092516).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0147092\n",
      "\tspeed: 0.0693s/iter; left time: 407.8369s\n",
      "\titers: 200, epoch: 6 | loss: 0.0111388\n",
      "\tspeed: 0.0725s/iter; left time: 419.7172s\n",
      "\titers: 300, epoch: 6 | loss: 0.0217956\n",
      "\tspeed: 0.0691s/iter; left time: 393.0322s\n",
      "Epoch: 6 cost time: 28.671282529830933\n",
      "Epoch: 6, Steps: 399 | Train Loss: 0.0136976 Vali Loss: 0.0935785 Test Loss: 0.2751040\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0119355\n",
      "\tspeed: 0.0750s/iter; left time: 411.4727s\n",
      "\titers: 200, epoch: 7 | loss: 0.0095009\n",
      "\tspeed: 0.0746s/iter; left time: 401.8194s\n",
      "\titers: 300, epoch: 7 | loss: 0.0135632\n",
      "\tspeed: 0.0756s/iter; left time: 399.6782s\n",
      "Epoch: 7 cost time: 29.71143889427185\n",
      "Epoch: 7, Steps: 399 | Train Loss: 0.0124921 Vali Loss: 0.0932252 Test Loss: 0.2846130\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0103761\n",
      "\tspeed: 0.0685s/iter; left time: 348.6493s\n",
      "\titers: 200, epoch: 8 | loss: 0.0079710\n",
      "\tspeed: 0.0717s/iter; left time: 357.6355s\n",
      "\titers: 300, epoch: 8 | loss: 0.0097591\n",
      "\tspeed: 0.0712s/iter; left time: 347.8321s\n",
      "Epoch: 8 cost time: 28.24418616294861\n",
      "Epoch: 8, Steps: 399 | Train Loss: 0.0121851 Vali Loss: 0.0935352 Test Loss: 0.2772370\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2137\n",
      "test shape: (66, 32, 24, 1) (66, 32, 24, 1)\n",
      "test shape: (2112, 24, 1) (2112, 24, 1)\n",
      "mse:0.27231237292289734, mae:0.3495611250400543\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 48, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il168_pl48_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12745\n",
      "val 2113\n",
      "test 2113\n",
      "\titers: 100, epoch: 1 | loss: 0.1346157\n",
      "\tspeed: 0.0805s/iter; left time: 632.9198s\n",
      "\titers: 200, epoch: 1 | loss: 0.0890886\n",
      "\tspeed: 0.0746s/iter; left time: 578.9111s\n",
      "\titers: 300, epoch: 1 | loss: 0.0640697\n",
      "\tspeed: 0.0760s/iter; left time: 582.5537s\n",
      "Epoch: 1 cost time: 30.82263469696045\n",
      "Epoch: 1, Steps: 398 | Train Loss: 0.1251063 Vali Loss: 0.1859557 Test Loss: 0.5198763\n",
      "Validation loss decreased (inf --> 0.185956).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0521696\n",
      "\tspeed: 0.0699s/iter; left time: 521.9238s\n",
      "\titers: 200, epoch: 2 | loss: 0.0402204\n",
      "\tspeed: 0.0755s/iter; left time: 555.6388s\n",
      "\titers: 300, epoch: 2 | loss: 0.0237822\n",
      "\tspeed: 0.0750s/iter; left time: 545.0182s\n",
      "Epoch: 2 cost time: 28.954461812973022\n",
      "Epoch: 2, Steps: 398 | Train Loss: 0.0342356 Vali Loss: 0.1501851 Test Loss: 0.3794832\n",
      "Validation loss decreased (0.185956 --> 0.150185).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0321564\n",
      "\tspeed: 0.0695s/iter; left time: 490.9425s\n",
      "\titers: 200, epoch: 3 | loss: 0.0216310\n",
      "\tspeed: 0.0706s/iter; left time: 491.8418s\n",
      "\titers: 300, epoch: 3 | loss: 0.0381585\n",
      "\tspeed: 0.0752s/iter; left time: 516.0963s\n",
      "Epoch: 3 cost time: 29.05304455757141\n",
      "Epoch: 3, Steps: 398 | Train Loss: 0.0232245 Vali Loss: 0.1450154 Test Loss: 0.3903406\n",
      "Validation loss decreased (0.150185 --> 0.145015).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0159617\n",
      "\tspeed: 0.0748s/iter; left time: 498.6664s\n",
      "\titers: 200, epoch: 4 | loss: 0.0165980\n",
      "\tspeed: 0.0688s/iter; left time: 451.6382s\n",
      "\titers: 300, epoch: 4 | loss: 0.0130431\n",
      "\tspeed: 0.0669s/iter; left time: 432.3365s\n",
      "Epoch: 4 cost time: 27.77726721763611\n",
      "Epoch: 4, Steps: 398 | Train Loss: 0.0200309 Vali Loss: 0.1382815 Test Loss: 0.3780093\n",
      "Validation loss decreased (0.145015 --> 0.138282).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0131608\n",
      "\tspeed: 0.0722s/iter; left time: 452.6047s\n",
      "\titers: 200, epoch: 5 | loss: 0.0147873\n",
      "\tspeed: 0.0741s/iter; left time: 456.8494s\n",
      "\titers: 300, epoch: 5 | loss: 0.0151239\n",
      "\tspeed: 0.0727s/iter; left time: 441.0247s\n",
      "Epoch: 5 cost time: 28.741018772125244\n",
      "Epoch: 5, Steps: 398 | Train Loss: 0.0171745 Vali Loss: 0.1362744 Test Loss: 0.3517471\n",
      "Validation loss decreased (0.138282 --> 0.136274).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0185203\n",
      "\tspeed: 0.0670s/iter; left time: 393.6026s\n",
      "\titers: 200, epoch: 6 | loss: 0.0167605\n",
      "\tspeed: 0.0692s/iter; left time: 399.4533s\n",
      "\titers: 300, epoch: 6 | loss: 0.0160689\n",
      "\tspeed: 0.0687s/iter; left time: 389.4969s\n",
      "Epoch: 6 cost time: 27.14854598045349\n",
      "Epoch: 6, Steps: 398 | Train Loss: 0.0163552 Vali Loss: 0.1393596 Test Loss: 0.3885160\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0131207\n",
      "\tspeed: 0.0723s/iter; left time: 395.8716s\n",
      "\titers: 200, epoch: 7 | loss: 0.0117685\n",
      "\tspeed: 0.0745s/iter; left time: 400.4340s\n",
      "\titers: 300, epoch: 7 | loss: 0.0136590\n",
      "\tspeed: 0.0764s/iter; left time: 402.5985s\n",
      "Epoch: 7 cost time: 29.8338725566864\n",
      "Epoch: 7, Steps: 398 | Train Loss: 0.0149573 Vali Loss: 0.1341290 Test Loss: 0.3773073\n",
      "Validation loss decreased (0.136274 --> 0.134129).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0122434\n",
      "\tspeed: 0.0714s/iter; left time: 362.4710s\n",
      "\titers: 200, epoch: 8 | loss: 0.0121516\n",
      "\tspeed: 0.0679s/iter; left time: 337.8862s\n",
      "\titers: 300, epoch: 8 | loss: 0.0126672\n",
      "\tspeed: 0.0720s/iter; left time: 351.1761s\n",
      "Epoch: 8 cost time: 28.01939034461975\n",
      "Epoch: 8, Steps: 398 | Train Loss: 0.0144417 Vali Loss: 0.1385269 Test Loss: 0.3858832\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0200046\n",
      "\tspeed: 0.0720s/iter; left time: 336.8781s\n",
      "\titers: 200, epoch: 9 | loss: 0.0187270\n",
      "\tspeed: 0.0741s/iter; left time: 339.1150s\n",
      "\titers: 300, epoch: 9 | loss: 0.0112998\n",
      "\tspeed: 0.0745s/iter; left time: 333.3227s\n",
      "Epoch: 9 cost time: 29.51776361465454\n",
      "Epoch: 9, Steps: 398 | Train Loss: 0.0138974 Vali Loss: 0.1312829 Test Loss: 0.3495497\n",
      "Validation loss decreased (0.134129 --> 0.131283).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0103946\n",
      "\tspeed: 0.0754s/iter; left time: 322.5088s\n",
      "\titers: 200, epoch: 10 | loss: 0.0123242\n",
      "\tspeed: 0.0667s/iter; left time: 278.6751s\n",
      "\titers: 300, epoch: 10 | loss: 0.0138197\n",
      "\tspeed: 0.0685s/iter; left time: 279.2330s\n",
      "Epoch: 10 cost time: 27.858771800994873\n",
      "Epoch: 10, Steps: 398 | Train Loss: 0.0137695 Vali Loss: 0.1293607 Test Loss: 0.3565175\n",
      "Validation loss decreased (0.131283 --> 0.129361).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0094052\n",
      "\tspeed: 0.0699s/iter; left time: 271.2174s\n",
      "\titers: 200, epoch: 11 | loss: 0.0303960\n",
      "\tspeed: 0.0731s/iter; left time: 276.4490s\n",
      "\titers: 300, epoch: 11 | loss: 0.0141699\n",
      "\tspeed: 0.0731s/iter; left time: 268.9356s\n",
      "Epoch: 11 cost time: 29.67056679725647\n",
      "Epoch: 11, Steps: 398 | Train Loss: 0.0133691 Vali Loss: 0.1330933 Test Loss: 0.3710159\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.0105995\n",
      "\tspeed: 0.0821s/iter; left time: 286.0152s\n",
      "\titers: 200, epoch: 12 | loss: 0.0124247\n",
      "\tspeed: 0.0751s/iter; left time: 253.9114s\n",
      "\titers: 300, epoch: 12 | loss: 0.0118132\n",
      "\tspeed: 0.0689s/iter; left time: 226.2454s\n",
      "Epoch: 12 cost time: 29.264158964157104\n",
      "Epoch: 12, Steps: 398 | Train Loss: 0.0133390 Vali Loss: 0.1312447 Test Loss: 0.3609110\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.0105953\n",
      "\tspeed: 0.0720s/iter; left time: 222.0185s\n",
      "\titers: 200, epoch: 13 | loss: 0.0106712\n",
      "\tspeed: 0.0752s/iter; left time: 224.5600s\n",
      "\titers: 300, epoch: 13 | loss: 0.0162884\n",
      "\tspeed: 0.0764s/iter; left time: 220.2926s\n",
      "Epoch: 13 cost time: 29.88281750679016\n",
      "Epoch: 13, Steps: 398 | Train Loss: 0.0130264 Vali Loss: 0.1306532 Test Loss: 0.3657453\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2113\n",
      "test shape: (66, 32, 48, 1) (66, 32, 48, 1)\n",
      "test shape: (2112, 48, 1) (2112, 48, 1)\n",
      "mse:0.35651758313179016, mae:0.4040328860282898\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 168, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il168_pl168_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12625\n",
      "val 1993\n",
      "test 1993\n",
      "\titers: 100, epoch: 1 | loss: 0.1994845\n",
      "\tspeed: 0.0817s/iter; left time: 636.0447s\n",
      "\titers: 200, epoch: 1 | loss: 0.0895837\n",
      "\tspeed: 0.0772s/iter; left time: 593.1426s\n",
      "\titers: 300, epoch: 1 | loss: 0.0905014\n",
      "\tspeed: 0.0782s/iter; left time: 592.8542s\n",
      "Epoch: 1 cost time: 31.179078340530396\n",
      "Epoch: 1, Steps: 394 | Train Loss: 0.1507863 Vali Loss: 0.4295081 Test Loss: 0.9968956\n",
      "Validation loss decreased (inf --> 0.429508).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0596942\n",
      "\tspeed: 0.0812s/iter; left time: 600.1732s\n",
      "\titers: 200, epoch: 2 | loss: 0.0657553\n",
      "\tspeed: 0.0789s/iter; left time: 574.9234s\n",
      "\titers: 300, epoch: 2 | loss: 0.0384628\n",
      "\tspeed: 0.0740s/iter; left time: 531.5006s\n",
      "Epoch: 2 cost time: 30.080511569976807\n",
      "Epoch: 2, Steps: 394 | Train Loss: 0.0571623 Vali Loss: 0.3807106 Test Loss: 0.7918897\n",
      "Validation loss decreased (0.429508 --> 0.380711).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0521064\n",
      "\tspeed: 0.0697s/iter; left time: 487.4453s\n",
      "\titers: 200, epoch: 3 | loss: 0.0317242\n",
      "\tspeed: 0.0666s/iter; left time: 459.0578s\n",
      "\titers: 300, epoch: 3 | loss: 0.0316103\n",
      "\tspeed: 0.0672s/iter; left time: 456.4564s\n",
      "Epoch: 3 cost time: 26.642126083374023\n",
      "Epoch: 3, Steps: 394 | Train Loss: 0.0434512 Vali Loss: 0.3416093 Test Loss: 0.7784678\n",
      "Validation loss decreased (0.380711 --> 0.341609).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0369486\n",
      "\tspeed: 0.0731s/iter; left time: 482.2743s\n",
      "\titers: 200, epoch: 4 | loss: 0.0251537\n",
      "\tspeed: 0.0699s/iter; left time: 454.0690s\n",
      "\titers: 300, epoch: 4 | loss: 0.0535794\n",
      "\tspeed: 0.0708s/iter; left time: 453.0220s\n",
      "Epoch: 4 cost time: 28.484702110290527\n",
      "Epoch: 4, Steps: 394 | Train Loss: 0.0392063 Vali Loss: 0.3432398 Test Loss: 0.7731035\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0371027\n",
      "\tspeed: 0.0747s/iter; left time: 463.8043s\n",
      "\titers: 200, epoch: 5 | loss: 0.0299851\n",
      "\tspeed: 0.0760s/iter; left time: 464.1231s\n",
      "\titers: 300, epoch: 5 | loss: 0.0286240\n",
      "\tspeed: 0.0740s/iter; left time: 444.5926s\n",
      "Epoch: 5 cost time: 28.944694995880127\n",
      "Epoch: 5, Steps: 394 | Train Loss: 0.0354120 Vali Loss: 0.3241448 Test Loss: 0.7573218\n",
      "Validation loss decreased (0.341609 --> 0.324145).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0299369\n",
      "\tspeed: 0.0700s/iter; left time: 406.7336s\n",
      "\titers: 200, epoch: 6 | loss: 0.0241493\n",
      "\tspeed: 0.0688s/iter; left time: 392.8716s\n",
      "\titers: 300, epoch: 6 | loss: 0.0768943\n",
      "\tspeed: 0.0682s/iter; left time: 382.4962s\n",
      "Epoch: 6 cost time: 27.371288061141968\n",
      "Epoch: 6, Steps: 394 | Train Loss: 0.0341171 Vali Loss: 0.3233466 Test Loss: 0.8137344\n",
      "Validation loss decreased (0.324145 --> 0.323347).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0296494\n",
      "\tspeed: 0.0700s/iter; left time: 379.3473s\n",
      "\titers: 200, epoch: 7 | loss: 0.0330102\n",
      "\tspeed: 0.0714s/iter; left time: 379.4144s\n",
      "\titers: 300, epoch: 7 | loss: 0.0399764\n",
      "\tspeed: 0.0721s/iter; left time: 376.1654s\n",
      "Epoch: 7 cost time: 27.821857690811157\n",
      "Epoch: 7, Steps: 394 | Train Loss: 0.0320821 Vali Loss: 0.3351404 Test Loss: 0.8580726\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0247617\n",
      "\tspeed: 0.0720s/iter; left time: 361.6139s\n",
      "\titers: 200, epoch: 8 | loss: 0.0469708\n",
      "\tspeed: 0.0729s/iter; left time: 359.0214s\n",
      "\titers: 300, epoch: 8 | loss: 0.0335968\n",
      "\tspeed: 0.0756s/iter; left time: 364.6541s\n",
      "Epoch: 8 cost time: 28.869215726852417\n",
      "Epoch: 8, Steps: 394 | Train Loss: 0.0316900 Vali Loss: 0.3329998 Test Loss: 0.9190569\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0284161\n",
      "\tspeed: 0.0728s/iter; left time: 337.0506s\n",
      "\titers: 200, epoch: 9 | loss: 0.0316822\n",
      "\tspeed: 0.0693s/iter; left time: 313.9775s\n",
      "\titers: 300, epoch: 9 | loss: 0.0215556\n",
      "\tspeed: 0.0687s/iter; left time: 304.2602s\n",
      "Epoch: 9 cost time: 27.890861988067627\n",
      "Epoch: 9, Steps: 394 | Train Loss: 0.0301912 Vali Loss: 0.3502219 Test Loss: 0.9615166\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1993\n",
      "test shape: (62, 32, 168, 1) (62, 32, 168, 1)\n",
      "test shape: (1984, 168, 1) (1984, 168, 1)\n",
      "mse:0.8137343525886536, mae:0.6756566762924194\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 336, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il168_pl336_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12457\n",
      "val 1825\n",
      "test 1825\n",
      "\titers: 100, epoch: 1 | loss: 0.1929683\n",
      "\tspeed: 0.0787s/iter; left time: 604.7789s\n",
      "\titers: 200, epoch: 1 | loss: 0.1643808\n",
      "\tspeed: 0.0732s/iter; left time: 554.9339s\n",
      "\titers: 300, epoch: 1 | loss: 0.0935069\n",
      "\tspeed: 0.0672s/iter; left time: 502.7447s\n",
      "Epoch: 1 cost time: 27.784743547439575\n",
      "Epoch: 1, Steps: 389 | Train Loss: 0.1909912 Vali Loss: 0.6137574 Test Loss: 1.1831891\n",
      "Validation loss decreased (inf --> 0.613757).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0874932\n",
      "\tspeed: 0.0680s/iter; left time: 495.8329s\n",
      "\titers: 200, epoch: 2 | loss: 0.0929366\n",
      "\tspeed: 0.0692s/iter; left time: 497.4161s\n",
      "\titers: 300, epoch: 2 | loss: 0.0838979\n",
      "\tspeed: 0.0743s/iter; left time: 527.2204s\n",
      "Epoch: 2 cost time: 27.47812843322754\n",
      "Epoch: 2, Steps: 389 | Train Loss: 0.0957297 Vali Loss: 0.6087268 Test Loss: 1.2262739\n",
      "Validation loss decreased (0.613757 --> 0.608727).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0830394\n",
      "\tspeed: 0.0705s/iter; left time: 486.9992s\n",
      "\titers: 200, epoch: 3 | loss: 0.0679747\n",
      "\tspeed: 0.0699s/iter; left time: 475.4345s\n",
      "\titers: 300, epoch: 3 | loss: 0.0725677\n",
      "\tspeed: 0.0704s/iter; left time: 471.8938s\n",
      "Epoch: 3 cost time: 27.63121771812439\n",
      "Epoch: 3, Steps: 389 | Train Loss: 0.0779458 Vali Loss: 0.5617673 Test Loss: 1.2977348\n",
      "Validation loss decreased (0.608727 --> 0.561767).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0826777\n",
      "\tspeed: 0.0737s/iter; left time: 480.3745s\n",
      "\titers: 200, epoch: 4 | loss: 0.0409828\n",
      "\tspeed: 0.0746s/iter; left time: 478.5755s\n",
      "\titers: 300, epoch: 4 | loss: 0.0500925\n",
      "\tspeed: 0.0774s/iter; left time: 488.7952s\n",
      "Epoch: 4 cost time: 29.40574884414673\n",
      "Epoch: 4, Steps: 389 | Train Loss: 0.0702710 Vali Loss: 0.5041552 Test Loss: 1.1763824\n",
      "Validation loss decreased (0.561767 --> 0.504155).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1099950\n",
      "\tspeed: 0.0705s/iter; left time: 431.7437s\n",
      "\titers: 200, epoch: 5 | loss: 0.0505563\n",
      "\tspeed: 0.0722s/iter; left time: 435.1845s\n",
      "\titers: 300, epoch: 5 | loss: 0.0437982\n",
      "\tspeed: 0.0693s/iter; left time: 410.6874s\n",
      "Epoch: 5 cost time: 28.100297212600708\n",
      "Epoch: 5, Steps: 389 | Train Loss: 0.0637332 Vali Loss: 0.5340148 Test Loss: 1.4698656\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0495499\n",
      "\tspeed: 0.0753s/iter; left time: 431.8341s\n",
      "\titers: 200, epoch: 6 | loss: 0.0498490\n",
      "\tspeed: 0.0726s/iter; left time: 409.1007s\n",
      "\titers: 300, epoch: 6 | loss: 0.0533296\n",
      "\tspeed: 0.0731s/iter; left time: 404.6251s\n",
      "Epoch: 6 cost time: 28.710012912750244\n",
      "Epoch: 6, Steps: 389 | Train Loss: 0.0612944 Vali Loss: 0.5362660 Test Loss: 1.4747054\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0498164\n",
      "\tspeed: 0.0715s/iter; left time: 382.1480s\n",
      "\titers: 200, epoch: 7 | loss: 0.0995790\n",
      "\tspeed: 0.0709s/iter; left time: 372.2704s\n",
      "\titers: 300, epoch: 7 | loss: 0.0566757\n",
      "\tspeed: 0.0711s/iter; left time: 365.9595s\n",
      "Epoch: 7 cost time: 27.88698697090149\n",
      "Epoch: 7, Steps: 389 | Train Loss: 0.0573487 Vali Loss: 0.5449299 Test Loss: 1.5843431\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1825\n",
      "test shape: (57, 32, 336, 1) (57, 32, 336, 1)\n",
      "test shape: (1824, 336, 1) (1824, 336, 1)\n",
      "mse:1.1763824224472046, mae:0.8556719422340393\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './checkpoints/', 'seq_len': 168, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'itr': 3, 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 20, 'batch_size': 32, 'pred_len': 720, 'iter': 3, 'data_split': [12960, 2160, 2160]}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il168_pl720_sl6_win2_fa10_dm256_nh4_el3_iter3>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12073\n",
      "val 1441\n",
      "test 1441\n",
      "\titers: 100, epoch: 1 | loss: 0.2409011\n",
      "\tspeed: 0.0868s/iter; left time: 645.9347s\n",
      "\titers: 200, epoch: 1 | loss: 0.1664995\n",
      "\tspeed: 0.0825s/iter; left time: 605.9689s\n",
      "\titers: 300, epoch: 1 | loss: 0.1423212\n",
      "\tspeed: 0.0771s/iter; left time: 558.4192s\n",
      "Epoch: 1 cost time: 30.647605895996094\n",
      "Epoch: 1, Steps: 377 | Train Loss: 0.2082491 Vali Loss: 1.1773595 Test Loss: 2.0136483\n",
      "Validation loss decreased (inf --> 1.177360).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.1281473\n",
      "\tspeed: 0.0835s/iter; left time: 590.1509s\n",
      "\titers: 200, epoch: 2 | loss: 0.1223911\n",
      "\tspeed: 0.0775s/iter; left time: 539.7127s\n",
      "\titers: 300, epoch: 2 | loss: 0.0878153\n",
      "\tspeed: 0.0775s/iter; left time: 532.0510s\n",
      "Epoch: 2 cost time: 29.600268125534058\n",
      "Epoch: 2, Steps: 377 | Train Loss: 0.1039402 Vali Loss: 1.0585232 Test Loss: 1.7614528\n",
      "Validation loss decreased (1.177360 --> 1.058523).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0774504\n",
      "\tspeed: 0.0834s/iter; left time: 557.9522s\n",
      "\titers: 200, epoch: 3 | loss: 0.0966347\n",
      "\tspeed: 0.0846s/iter; left time: 557.4903s\n",
      "\titers: 300, epoch: 3 | loss: 0.0585769\n",
      "\tspeed: 0.0844s/iter; left time: 547.3778s\n",
      "Epoch: 3 cost time: 31.61089539527893\n",
      "Epoch: 3, Steps: 377 | Train Loss: 0.0863545 Vali Loss: 1.0889805 Test Loss: 1.8356121\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.0636179\n",
      "\tspeed: 0.0825s/iter; left time: 520.8857s\n",
      "\titers: 200, epoch: 4 | loss: 0.0757733\n",
      "\tspeed: 0.0873s/iter; left time: 542.3058s\n",
      "\titers: 300, epoch: 4 | loss: 0.0810759\n",
      "\tspeed: 0.0810s/iter; left time: 494.6635s\n",
      "Epoch: 4 cost time: 31.361101388931274\n",
      "Epoch: 4, Steps: 377 | Train Loss: 0.0783355 Vali Loss: 1.0471816 Test Loss: 1.6999066\n",
      "Validation loss decreased (1.058523 --> 1.047182).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0720655\n",
      "\tspeed: 0.0800s/iter; left time: 474.8097s\n",
      "\titers: 200, epoch: 5 | loss: 0.0612973\n",
      "\tspeed: 0.0812s/iter; left time: 473.6626s\n",
      "\titers: 300, epoch: 5 | loss: 0.0517253\n",
      "\tspeed: 0.0777s/iter; left time: 445.6175s\n",
      "Epoch: 5 cost time: 30.01080584526062\n",
      "Epoch: 5, Steps: 377 | Train Loss: 0.0714935 Vali Loss: 1.0441120 Test Loss: 1.6982980\n",
      "Validation loss decreased (1.047182 --> 1.044112).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0460473\n",
      "\tspeed: 0.0787s/iter; left time: 437.1760s\n",
      "\titers: 200, epoch: 6 | loss: 0.0630049\n",
      "\tspeed: 0.0842s/iter; left time: 459.2084s\n",
      "\titers: 300, epoch: 6 | loss: 0.0717604\n",
      "\tspeed: 0.0824s/iter; left time: 441.4562s\n",
      "Epoch: 6 cost time: 30.848661184310913\n",
      "Epoch: 6, Steps: 377 | Train Loss: 0.0686798 Vali Loss: 0.9847157 Test Loss: 1.6670982\n",
      "Validation loss decreased (1.044112 --> 0.984716).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0502056\n",
      "\tspeed: 0.0795s/iter; left time: 411.6225s\n",
      "\titers: 200, epoch: 7 | loss: 0.0580267\n",
      "\tspeed: 0.0807s/iter; left time: 409.9376s\n",
      "\titers: 300, epoch: 7 | loss: 0.0507981\n",
      "\tspeed: 0.0823s/iter; left time: 409.6271s\n",
      "Epoch: 7 cost time: 30.77225112915039\n",
      "Epoch: 7, Steps: 377 | Train Loss: 0.0662101 Vali Loss: 0.9948406 Test Loss: 1.7843446\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0419199\n",
      "\tspeed: 0.0823s/iter; left time: 395.1866s\n",
      "\titers: 200, epoch: 8 | loss: 0.0498298\n",
      "\tspeed: 0.0827s/iter; left time: 388.8196s\n",
      "\titers: 300, epoch: 8 | loss: 0.0805821\n",
      "\tspeed: 0.0853s/iter; left time: 392.4106s\n",
      "Epoch: 8 cost time: 31.432708501815796\n",
      "Epoch: 8, Steps: 377 | Train Loss: 0.0655115 Vali Loss: 0.9809183 Test Loss: 1.7056968\n",
      "Validation loss decreased (0.984716 --> 0.980918).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0943693\n",
      "\tspeed: 0.0842s/iter; left time: 372.7026s\n",
      "\titers: 200, epoch: 9 | loss: 0.0536581\n",
      "\tspeed: 0.0822s/iter; left time: 355.4561s\n",
      "\titers: 300, epoch: 9 | loss: 0.0394316\n",
      "\tspeed: 0.0795s/iter; left time: 336.0861s\n",
      "Epoch: 9 cost time: 30.69710111618042\n",
      "Epoch: 9, Steps: 377 | Train Loss: 0.0633966 Vali Loss: 0.9730509 Test Loss: 1.6870302\n",
      "Validation loss decreased (0.980918 --> 0.973051).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0494792\n",
      "\tspeed: 0.0752s/iter; left time: 304.5327s\n",
      "\titers: 200, epoch: 10 | loss: 0.0871742\n",
      "\tspeed: 0.0786s/iter; left time: 310.3577s\n",
      "\titers: 300, epoch: 10 | loss: 0.0449239\n",
      "\tspeed: 0.0741s/iter; left time: 285.2228s\n",
      "Epoch: 10 cost time: 28.702465534210205\n",
      "Epoch: 10, Steps: 377 | Train Loss: 0.0633161 Vali Loss: 0.9653139 Test Loss: 1.6892942\n",
      "Validation loss decreased (0.973051 --> 0.965314).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1025227\n",
      "\tspeed: 0.0778s/iter; left time: 285.7089s\n",
      "\titers: 200, epoch: 11 | loss: 0.0550976\n",
      "\tspeed: 0.0765s/iter; left time: 273.0793s\n",
      "\titers: 300, epoch: 11 | loss: 0.0831733\n",
      "\tspeed: 0.0766s/iter; left time: 265.7707s\n",
      "Epoch: 11 cost time: 29.450364112854004\n",
      "Epoch: 11, Steps: 377 | Train Loss: 0.0626190 Vali Loss: 1.0117006 Test Loss: 1.7529914\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.0411341\n",
      "\tspeed: 0.0752s/iter; left time: 247.7305s\n",
      "\titers: 200, epoch: 12 | loss: 0.0782755\n",
      "\tspeed: 0.0738s/iter; left time: 235.6826s\n",
      "\titers: 300, epoch: 12 | loss: 0.0678072\n",
      "\tspeed: 0.0761s/iter; left time: 235.5893s\n",
      "Epoch: 12 cost time: 28.43866276741028\n",
      "Epoch: 12, Steps: 377 | Train Loss: 0.0620727 Vali Loss: 0.9792301 Test Loss: 1.7593187\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.0566545\n",
      "\tspeed: 0.0867s/iter; left time: 252.7915s\n",
      "\titers: 200, epoch: 13 | loss: 0.0462291\n",
      "\tspeed: 0.0826s/iter; left time: 232.6352s\n",
      "\titers: 300, epoch: 13 | loss: 0.0411618\n",
      "\tspeed: 0.0829s/iter; left time: 225.2331s\n",
      "Epoch: 13 cost time: 31.365370988845825\n",
      "Epoch: 13, Steps: 377 | Train Loss: 0.0618562 Vali Loss: 0.9798088 Test Loss: 1.7466705\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 1441\n",
      "test shape: (45, 32, 720, 1) (45, 32, 720, 1)\n",
      "test shape: (1440, 720, 1) (1440, 720, 1)\n",
      "mse:1.6892940998077393, mae:1.076270341873169\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "CPU times: user 10h 16min, sys: 9min 55s, total: 10h 25min 56s\n",
      "Wall time: 7h 11min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "\n",
    "    for iter in range(model.args.itr):\n",
    "        for dataset_name, dataset_path in datasets.items():\n",
    "            for pred_len in pred_lens:\n",
    "                print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "                # High amount of epochs to accomodate all models\n",
    "                # Early stopping should kick in anyways\n",
    "                model.fit(\n",
    "                    iter = iter +1,\n",
    "                    data=dataset_name,\n",
    "                    data_root_path=dataset_path,\n",
    "                    batch_size=32,\n",
    "                    epochs=20, \n",
    "                    pred_len=pred_len\n",
    "                )    \n",
    "\n",
    "                predictions = model.predict()\n",
    "\n",
    "                print(f'\\nMoving to next...\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'ETTh1': ['./ETTDataset/' , 'M', 'OT' ,96] ,\n",
    "    'DEWINDh_small': ['./WINDataset/' , 'S' , 'TARGET' , 168] ,\n",
    "    'SYNTHh1': ['./SYNTHDataset/', 'S' , 'TARGET' , 168] ,\n",
    "    'SYNTH_additive' : ['./SYNTHDataset/', 'S', 'TARGET' , 168] ,\n",
    "    'SYNTH_additive_reversal' : ['./SYNTHDataset/', 'S', 'TARGET' , 168] ,\n",
    "    'SYNTH_multiplicative' : ['./SYNTHDataset/', 'S', 'TARGET' , 168] ,\n",
    "    'SYNTH_multiplicative_reversal' : ['./SYNTHDataset/' , 'S', 'TARGET' , 168]\n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "\n",
    "models = [TSMixer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: LogsparseTS\n",
      "Training LogsparseTS on ETTh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Logsparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'ETTh1', 'root_path': './ETTDataset/', 'data_path': 'ETTh1.csv', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'features': 'M', 'seq_len': 768, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'Logsparse_Synth1_24', 'num_workers': 0, 'itr': 3, 'train_epochs': 20, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'iter': 1}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Logsparse_ETTh1_ftM_sl768_ll48_pl24_dm512_nh8_dl1_df2048_fc3_ebtimeF_dtTrue_destest_iter1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7849\n",
      "val 2857\n",
      "test 2857\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Logsparse:\n\tsize mismatch for enc_embedding.value_embedding.tokenConv.weight: copying a param with shape torch.Size([512, 7, 3]) from checkpoint, the shape in current model is torch.Size([512, 1, 3]).\n\tsize mismatch for dec_embedding.value_embedding.tokenConv.weight: copying a param with shape torch.Size([512, 7, 3]) from checkpoint, the shape in current model is torch.Size([512, 1, 3]).\n\tsize mismatch for decoder.projection.weight: copying a param with shape torch.Size([7, 512]) from checkpoint, the shape in current model is torch.Size([1, 512]).\n\tsize mismatch for decoder.projection.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/Schreibtisch/Github/TransformersEnergyTS/LogSparseAPI.py:2227\u001b[0m, in \u001b[0;36mLogsparseTS.fit\u001b[0;34m(self, data, data_root_path, batch_size, epochs, pred_len, seq_len, features, target, enc_in, dec_in, c_out, iter)\u001b[0m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m   2226\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>start training : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetting))\n\u001b[0;32m-> 2227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetting\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Schreibtisch/Github/TransformersEnergyTS/LogSparseAPI.py:1748\u001b[0m, in \u001b[0;36mExp_Logsparse.train\u001b[0;34m(self, setting)\u001b[0m\n\u001b[1;32m   1746\u001b[0m load_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(load_path) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_check(path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_setup.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m))):\n\u001b[0;32m-> 1748\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m     epoch_info \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m   1750\u001b[0m         \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./checkpoints/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m setting, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_loss.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1751\u001b[0m     start_epoch \u001b[38;5;241m=\u001b[39m epoch_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Logsparse:\n\tsize mismatch for enc_embedding.value_embedding.tokenConv.weight: copying a param with shape torch.Size([512, 7, 3]) from checkpoint, the shape in current model is torch.Size([512, 1, 3]).\n\tsize mismatch for dec_embedding.value_embedding.tokenConv.weight: copying a param with shape torch.Size([512, 7, 3]) from checkpoint, the shape in current model is torch.Size([512, 1, 3]).\n\tsize mismatch for decoder.projection.weight: copying a param with shape torch.Size([7, 512]) from checkpoint, the shape in current model is torch.Size([1, 512]).\n\tsize mismatch for decoder.projection.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([1])."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Simple loop\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "    for iter in range(model.args.itr):\n",
    "        for dataset_name, dataset_params in datasets.items():\n",
    "            for pred_len in pred_lens:\n",
    "                print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "                    # High amount of epochs to accomodate all models\n",
    "                    # Early stopping should kick in anyways\n",
    "                model.fit(\n",
    "                    iter = iter + 1,\n",
    "                    data=dataset_name,\n",
    "                    data_root_path=dataset_params[0],\n",
    "                    batch_size=32,\n",
    "                    epochs=20, # very high\n",
    "                    pred_len=pred_len,\n",
    "                    features = dataset_params[1],\n",
    "                    target = dataset_params[2],\n",
    "                    seq_len = dataset_params[3],\n",
    "                )\n",
    "\n",
    "                predictions = model.predict()\n",
    "\n",
    "                print(f'\\nMoving to next...\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'SYNTHh1': './SYNTHDataset/',\n",
    "    'DEWINDh_small': './WINDataset/' ,\n",
    "    'SYNTH_additive' : './SYNTHDataset/' ,\n",
    "    'SYNTH_additive_reversal' : './SYNTHDataset/' ,\n",
    "    'SYNTH_multiplicative' : './SYNTHDataset/',\n",
    "    'SYNTH_multiplicative_reversal' : './SYNTHDataset/' \n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "\n",
    "models = [PyraformerTS]\n",
    "\n",
    "#result_dict_pyraformer = {}\n",
    "\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "\n",
    "    for dataset_name, dataset_path in datasets.items():\n",
    "        for pred_len in pred_lens:\n",
    "            print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "            # High amount of epochs to accomodate all models\n",
    "            # Early stopping should kick in anyways\n",
    "            model.fit(\n",
    "                data=dataset_name,\n",
    "                data_root_path=dataset_path,\n",
    "                batch_size=32,\n",
    "                epochs=8, \n",
    "                pred_len=pred_len\n",
    "            )\n",
    "\n",
    "            #pred_name = 'prediction_' + f'{transformermodel.__name__}_{dataset_name}_{pred_len}'\n",
    "            #true_name = 'true_' + f'{transformermodel.__name__}_{dataset_name}_{pred_len}'\n",
    "            \n",
    "\n",
    "            predictions , trues = model.predict()\n",
    "\n",
    "            #result_dict_pyraformer[pred_name] = predictions\n",
    "            #result_dict_pyraformer[true_name] = trues\n",
    "            \n",
    "\n",
    "            print(f'\\nMoving to next...\\n')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ansb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
