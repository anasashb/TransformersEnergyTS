{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('seaborn-v0_8')\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# MSE function \n",
    "def MSE(pred, true):\n",
    "    return np.mean((pred-true)**2)\n",
    "\n",
    "random_seed = 100\n",
    "torch.manual_seed = 100\n",
    "np.random.seed = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InformerAPI import InformerTS\n",
    "from CrossformerAPI import CrossformerTS\n",
    "from AutoformerAPI import AutoformerTS\n",
    "from FedformerAPI import FedformerTS\n",
    "from PyraformerAPI import PyraformerTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping models in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'SYNTHh1': './SYNTHDataset/',\n",
    "    'DEWINDh_small': './WINDataset/' ,\n",
    "    'SYNTH_additive' : './SYNTHDataset/' , \n",
    "    'SYNTH_additive_reversal' : './SYNTHDataset/' ,\n",
    "    'SYNTH_multiplicative' : './SYNTHDataset/' ,\n",
    "    'SYNTH_multiplicative_reversal' : './SYNTHDataset/'\n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "\n",
    "models = [AutoformerTS, FedformerTS]\n",
    "\n",
    "result_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: FedformerTS\n",
      "Training FedformerTS on SYNTHh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl24_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "Epoch: 1 cost time: 65.16380763053894\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.2622758 Vali Loss: 0.0958696 Test Loss: 0.0979099\n",
      "Validation loss decreased (inf --> 0.095870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 62.752004861831665\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.1016251 Vali Loss: 0.0833852 Test Loss: 0.0804521\n",
      "Validation loss decreased (0.095870 --> 0.083385).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 66.24701738357544\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.0882184 Vali Loss: 0.0720649 Test Loss: 0.0703608\n",
      "Validation loss decreased (0.083385 --> 0.072065).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 67.67151832580566\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.0800565 Vali Loss: 0.0701968 Test Loss: 0.0707113\n",
      "Validation loss decreased (0.072065 --> 0.070197).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 68.2637414932251\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.0747900 Vali Loss: 0.0641990 Test Loss: 0.0651344\n",
      "Validation loss decreased (0.070197 --> 0.064199).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 60.942933082580566\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.0718720 Vali Loss: 0.0651201 Test Loss: 0.0683536\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 70.8675377368927\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.0705077 Vali Loss: 0.0631342 Test Loss: 0.0658791\n",
      "Validation loss decreased (0.064199 --> 0.063134).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 74.24222350120544\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.0695275 Vali Loss: 0.0627513 Test Loss: 0.0653452\n",
      "Validation loss decreased (0.063134 --> 0.062751).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 74.18263983726501\n",
      "Epoch: 9, Steps: 266 | Train Loss: 0.0692555 Vali Loss: 0.0627041 Test Loss: 0.0654047\n",
      "Validation loss decreased (0.062751 --> 0.062704).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 69.2740786075592\n",
      "Epoch: 10, Steps: 266 | Train Loss: 0.0690241 Vali Loss: 0.0625783 Test Loss: 0.0652340\n",
      "Validation loss decreased (0.062704 --> 0.062578).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 66.56735253334045\n",
      "Epoch: 11, Steps: 266 | Train Loss: 0.0687436 Vali Loss: 0.0626013 Test Loss: 0.0652615\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 71.59506297111511\n",
      "Epoch: 12, Steps: 266 | Train Loss: 0.0686818 Vali Loss: 0.0625492 Test Loss: 0.0652689\n",
      "Validation loss decreased (0.062578 --> 0.062549).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 75.96273517608643\n",
      "Epoch: 13, Steps: 266 | Train Loss: 0.0688638 Vali Loss: 0.0626125 Test Loss: 0.0652519\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 67.62385320663452\n",
      "Epoch: 14, Steps: 266 | Train Loss: 0.0686548 Vali Loss: 0.0624748 Test Loss: 0.0652507\n",
      "Validation loss decreased (0.062549 --> 0.062475).  Saving model ...\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 67.02317714691162\n",
      "Epoch: 15, Steps: 266 | Train Loss: 0.0685920 Vali Loss: 0.0624342 Test Loss: 0.0652520\n",
      "Validation loss decreased (0.062475 --> 0.062434).  Saving model ...\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 69.63558053970337\n",
      "Epoch: 16, Steps: 266 | Train Loss: 0.0689014 Vali Loss: 0.0625766 Test Loss: 0.0652526\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.0517578125e-09\n",
      "Epoch: 17 cost time: 78.88778495788574\n",
      "Epoch: 17, Steps: 266 | Train Loss: 0.0686534 Vali Loss: 0.0625213 Test Loss: 0.0652519\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.52587890625e-09\n",
      "Epoch: 18 cost time: 67.18537974357605\n",
      "Epoch: 18, Steps: 266 | Train Loss: 0.0687823 Vali Loss: 0.0624668 Test Loss: 0.0652518\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 1) (89, 32, 24, 1)\n",
      "test shape: (2848, 24, 1) (2848, 24, 1)\n",
      "mse:0.06525204330682755, mae:0.21210964024066925\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl48_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "Epoch: 1 cost time: 85.43302178382874\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.2961777 Vali Loss: 0.1074879 Test Loss: 0.1124147\n",
      "Validation loss decreased (inf --> 0.107488).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 82.71987724304199\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.1159050 Vali Loss: 0.0940088 Test Loss: 0.1005454\n",
      "Validation loss decreased (0.107488 --> 0.094009).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 83.55789017677307\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.0911122 Vali Loss: 0.1160430 Test Loss: 0.1056600\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 82.2547287940979\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.0412276 Vali Loss: 0.1170206 Test Loss: 0.1084039\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 82.77264380455017\n",
      "Epoch: 5, Steps: 265 | Train Loss: 0.0384163 Vali Loss: 0.1198215 Test Loss: 0.1115995\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 1) (88, 32, 48, 1)\n",
      "test shape: (2816, 48, 1) (2816, 48, 1)\n",
      "mse:0.10054542869329453, mae:0.2656591534614563\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 9, 12, 13, 14, 15, 16, 17, 19, 20, 22, 24, 25, 26, 30, 32, 34, 36, 37, 42, 45, 47, 48, 52, 54, 55, 57, 61, 64, 65, 68, 69, 70, 71, 72, 73, 75, 76, 77, 79, 80, 82, 83, 84, 85, 90, 91, 92, 94, 95, 96, 98, 99, 100, 103, 105, 106]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 3, 5, 6, 9, 11, 13, 14, 15, 18, 19, 20, 24, 25, 27, 28, 30, 31, 32, 33, 37, 38, 39, 42, 44, 46, 47, 49, 50, 52, 53, 55, 56, 58, 60, 62, 64, 66, 67, 69, 70, 77, 78, 80, 81, 82, 83, 84, 86, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl168_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "Epoch: 1 cost time: 86.81678175926208\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.3380231 Vali Loss: 0.2696996 Test Loss: 0.3962550\n",
      "Validation loss decreased (inf --> 0.269700).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 96.68281483650208\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.2006405 Vali Loss: 0.2288464 Test Loss: 0.3212085\n",
      "Validation loss decreased (0.269700 --> 0.228846).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 100.87942695617676\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.1030630 Vali Loss: 0.3240111 Test Loss: 0.3204749\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 94.61479115486145\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.0676818 Vali Loss: 0.3299393 Test Loss: 0.3219820\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 94.50968170166016\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.0634867 Vali Loss: 0.3332740 Test Loss: 0.3234389\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 1) (84, 32, 168, 1)\n",
      "test shape: (2688, 168, 1) (2688, 168, 1)\n",
      "mse:0.32120853662490845, mae:0.46684420108795166\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[3, 7, 8, 11, 14, 18, 19, 21, 24, 26, 29, 35, 36, 37, 39, 40, 42, 44, 51, 56, 64, 65, 71, 72, 74, 76, 77, 80, 82, 83, 84, 85, 86, 88, 94, 95, 101, 106, 107, 112, 115, 118, 119, 120, 122, 125, 132, 136, 139, 145, 146, 149, 150, 156, 157, 162, 166, 173, 175, 176, 179, 181, 182, 184]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 3, 4, 7, 11, 17, 18, 20, 22, 24, 25, 29, 36, 38, 41, 42, 45, 46, 48, 52, 60, 64, 67, 68, 74, 76, 86, 90, 92, 96, 97, 100, 101, 103, 104, 105, 111, 115, 122, 123, 126, 130, 131, 134, 137, 138, 140, 143, 145, 146, 148, 151, 157, 162, 165, 169, 171, 174, 176, 177, 178, 179, 182, 191]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl336_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 136.74567246437073\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.6448343 Vali Loss: 0.5773084 Test Loss: 0.9059082\n",
      "Validation loss decreased (inf --> 0.577308).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 138.09175515174866\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.3290007 Vali Loss: 0.5133174 Test Loss: 0.8582950\n",
      "Validation loss decreased (0.577308 --> 0.513317).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 134.61821722984314\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.2994984 Vali Loss: 0.5038191 Test Loss: 0.8561960\n",
      "Validation loss decreased (0.513317 --> 0.503819).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 144.55647802352905\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.2920069 Vali Loss: 0.4927976 Test Loss: 0.8476861\n",
      "Validation loss decreased (0.503819 --> 0.492798).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 138.14357542991638\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.2879341 Vali Loss: 0.4807726 Test Loss: 0.8320661\n",
      "Validation loss decreased (0.492798 --> 0.480773).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 140.39829564094543\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.2848465 Vali Loss: 0.4775362 Test Loss: 0.8332866\n",
      "Validation loss decreased (0.480773 --> 0.477536).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 132.41144371032715\n",
      "Epoch: 7, Steps: 256 | Train Loss: 0.2838261 Vali Loss: 0.4787838 Test Loss: 0.8348544\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 137.89564657211304\n",
      "Epoch: 8, Steps: 256 | Train Loss: 0.2833602 Vali Loss: 0.4777366 Test Loss: 0.8337955\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 136.2236864566803\n",
      "Epoch: 9, Steps: 256 | Train Loss: 0.2823350 Vali Loss: 0.4785407 Test Loss: 0.8333014\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 1) (79, 32, 336, 1)\n",
      "test shape: (2528, 336, 1) (2528, 336, 1)\n",
      "mse:0.8332867622375488, mae:0.7153301239013672\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 15, 16, 22, 29, 30, 33, 40, 49, 55, 56, 57, 61, 69, 70, 74, 75, 81, 82, 84, 106, 107, 111, 125, 127, 130, 131, 140, 144, 148, 153, 155, 160, 161, 176, 186, 194, 202, 219, 222, 227, 247, 248, 253, 257, 258, 259, 270, 283, 286, 294, 296, 306, 327, 331, 338, 340, 343, 350, 365, 368, 369, 370, 383]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[7, 11, 13, 16, 22, 23, 27, 32, 36, 48, 49, 55, 63, 65, 66, 78, 90, 96, 97, 102, 105, 108, 114, 115, 126, 132, 133, 134, 136, 161, 164, 166, 177, 179, 188, 189, 190, 195, 216, 225, 227, 231, 232, 242, 243, 250, 253, 254, 262, 273, 288, 294, 319, 320, 322, 327, 329, 338, 341, 348, 357, 358, 379, 380]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl720_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 155.4706552028656\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.4897954 Vali Loss: 0.2999372 Test Loss: 0.6046879\n",
      "Validation loss decreased (inf --> 0.299937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 154.00870513916016\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.1331194 Vali Loss: 0.2868610 Test Loss: 0.6266771\n",
      "Validation loss decreased (0.299937 --> 0.286861).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 154.89499139785767\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.1080418 Vali Loss: 0.2732387 Test Loss: 0.6049472\n",
      "Validation loss decreased (0.286861 --> 0.273239).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 152.15872359275818\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.1023389 Vali Loss: 0.2575334 Test Loss: 0.5830230\n",
      "Validation loss decreased (0.273239 --> 0.257533).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 154.80844449996948\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.1005052 Vali Loss: 0.2683795 Test Loss: 0.6003717\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 154.23212957382202\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.0997536 Vali Loss: 0.2739580 Test Loss: 0.6109940\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 153.46481704711914\n",
      "Epoch: 7, Steps: 244 | Train Loss: 0.0993424 Vali Loss: 0.2694975 Test Loss: 0.6025179\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 1) (67, 32, 720, 1)\n",
      "test shape: (2144, 720, 1) (2144, 720, 1)\n",
      "mse:0.5830230116844177, mae:0.6152520775794983\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl24_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "Epoch: 1 cost time: 72.37522506713867\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.2114821 Vali Loss: 0.1721330 Test Loss: 0.1754460\n",
      "Validation loss decreased (inf --> 0.172133).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 69.36662220954895\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.1479469 Vali Loss: 0.1574086 Test Loss: 0.1616093\n",
      "Validation loss decreased (0.172133 --> 0.157409).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 69.05121278762817\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.1293245 Vali Loss: 0.1515991 Test Loss: 0.1488951\n",
      "Validation loss decreased (0.157409 --> 0.151599).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 70.27343893051147\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.1240935 Vali Loss: 0.1496561 Test Loss: 0.1461690\n",
      "Validation loss decreased (0.151599 --> 0.149656).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 70.37175345420837\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.1216244 Vali Loss: 0.1465813 Test Loss: 0.1444247\n",
      "Validation loss decreased (0.149656 --> 0.146581).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 73.60788369178772\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.1203851 Vali Loss: 0.1465245 Test Loss: 0.1436537\n",
      "Validation loss decreased (0.146581 --> 0.146525).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 64.40801477432251\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.1197325 Vali Loss: 0.1462581 Test Loss: 0.1430382\n",
      "Validation loss decreased (0.146525 --> 0.146258).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 72.39297080039978\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.1193276 Vali Loss: 0.1464056 Test Loss: 0.1424594\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 77.23398017883301\n",
      "Epoch: 9, Steps: 266 | Train Loss: 0.1190036 Vali Loss: 0.1457477 Test Loss: 0.1425107\n",
      "Validation loss decreased (0.146258 --> 0.145748).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 75.30889296531677\n",
      "Epoch: 10, Steps: 266 | Train Loss: 0.1189171 Vali Loss: 0.1464164 Test Loss: 0.1427033\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 76.40240502357483\n",
      "Epoch: 11, Steps: 266 | Train Loss: 0.1190182 Vali Loss: 0.1461212 Test Loss: 0.1424635\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 66.84464526176453\n",
      "Epoch: 12, Steps: 266 | Train Loss: 0.1188472 Vali Loss: 0.1460604 Test Loss: 0.1424270\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 1) (89, 32, 24, 1)\n",
      "test shape: (2848, 24, 1) (2848, 24, 1)\n",
      "mse:0.14251071214675903, mae:0.2431260049343109\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl48_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "Epoch: 1 cost time: 82.68609857559204\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.2398062 Vali Loss: 0.1913295 Test Loss: 0.1926833\n",
      "Validation loss decreased (inf --> 0.191329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 80.61324048042297\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.1704890 Vali Loss: 0.1738000 Test Loss: 0.1810771\n",
      "Validation loss decreased (0.191329 --> 0.173800).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 76.70012331008911\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.1543370 Vali Loss: 0.1676580 Test Loss: 0.1713296\n",
      "Validation loss decreased (0.173800 --> 0.167658).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 81.129812002182\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.1496196 Vali Loss: 0.1630197 Test Loss: 0.1709165\n",
      "Validation loss decreased (0.167658 --> 0.163020).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 82.08459877967834\n",
      "Epoch: 5, Steps: 265 | Train Loss: 0.1472327 Vali Loss: 0.1646764 Test Loss: 0.1709053\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 77.71331930160522\n",
      "Epoch: 6, Steps: 265 | Train Loss: 0.1464615 Vali Loss: 0.1612807 Test Loss: 0.1679323\n",
      "Validation loss decreased (0.163020 --> 0.161281).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 73.55619144439697\n",
      "Epoch: 7, Steps: 265 | Train Loss: 0.1457253 Vali Loss: 0.1627410 Test Loss: 0.1685767\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 77.71450066566467\n",
      "Epoch: 8, Steps: 265 | Train Loss: 0.1453644 Vali Loss: 0.1615711 Test Loss: 0.1675281\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 70.3328104019165\n",
      "Epoch: 9, Steps: 265 | Train Loss: 0.1450566 Vali Loss: 0.1616879 Test Loss: 0.1673708\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 1) (88, 32, 48, 1)\n",
      "test shape: (2816, 48, 1) (2816, 48, 1)\n",
      "mse:0.16793231666088104, mae:0.26156046986579895\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 4, 6, 8, 9, 11, 13, 15, 16, 17, 18, 19, 23, 25, 26, 28, 29, 31, 36, 37, 38, 39, 40, 46, 47, 49, 50, 51, 54, 55, 57, 59, 61, 62, 64, 65, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 80, 82, 83, 85, 86, 87, 89, 90, 91, 95, 97, 98, 99, 101, 102, 104, 106, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 2, 4, 6, 7, 8, 10, 11, 12, 17, 18, 20, 22, 24, 28, 29, 31, 32, 35, 37, 38, 40, 41, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 74, 76, 78, 79, 82, 83, 85, 87, 88, 92, 93, 94, 95, 96, 98, 99, 100, 103, 105, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl168_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "Epoch: 1 cost time: 94.93490862846375\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.2745222 Vali Loss: 0.2098569 Test Loss: 0.2543777\n",
      "Validation loss decreased (inf --> 0.209857).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 97.88841915130615\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.1953471 Vali Loss: 0.1924711 Test Loss: 0.2247242\n",
      "Validation loss decreased (0.209857 --> 0.192471).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 95.92441177368164\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.1805659 Vali Loss: 0.1887467 Test Loss: 0.2116429\n",
      "Validation loss decreased (0.192471 --> 0.188747).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 90.3724684715271\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.1755724 Vali Loss: 0.1875851 Test Loss: 0.2080587\n",
      "Validation loss decreased (0.188747 --> 0.187585).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 93.48627400398254\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.1732709 Vali Loss: 0.1846453 Test Loss: 0.2064762\n",
      "Validation loss decreased (0.187585 --> 0.184645).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 101.04886054992676\n",
      "Epoch: 6, Steps: 261 | Train Loss: 0.1722411 Vali Loss: 0.1857036 Test Loss: 0.2056105\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 97.431147813797\n",
      "Epoch: 7, Steps: 261 | Train Loss: 0.1715618 Vali Loss: 0.1846945 Test Loss: 0.2047290\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 97.73316025733948\n",
      "Epoch: 8, Steps: 261 | Train Loss: 0.1712891 Vali Loss: 0.1842525 Test Loss: 0.2044976\n",
      "Validation loss decreased (0.184645 --> 0.184253).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 92.30036044120789\n",
      "Epoch: 9, Steps: 261 | Train Loss: 0.1711024 Vali Loss: 0.1845036 Test Loss: 0.2045136\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 95.33031940460205\n",
      "Epoch: 10, Steps: 261 | Train Loss: 0.1709727 Vali Loss: 0.1838423 Test Loss: 0.2043479\n",
      "Validation loss decreased (0.184253 --> 0.183842).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 100.75438523292542\n",
      "Epoch: 11, Steps: 261 | Train Loss: 0.1710100 Vali Loss: 0.1838636 Test Loss: 0.2044161\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 94.86922645568848\n",
      "Epoch: 12, Steps: 261 | Train Loss: 0.1710386 Vali Loss: 0.1841805 Test Loss: 0.2044540\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 97.8796603679657\n",
      "Epoch: 13, Steps: 261 | Train Loss: 0.1708163 Vali Loss: 0.1840257 Test Loss: 0.2044422\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 1) (84, 32, 168, 1)\n",
      "test shape: (2688, 168, 1) (2688, 168, 1)\n",
      "mse:0.20434793829917908, mae:0.2872311472892761\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[5, 6, 8, 16, 18, 21, 22, 27, 30, 31, 35, 37, 41, 44, 49, 51, 56, 60, 62, 63, 68, 71, 76, 79, 83, 86, 87, 88, 89, 93, 94, 96, 101, 104, 106, 107, 108, 112, 114, 115, 118, 120, 121, 123, 124, 125, 126, 127, 132, 137, 144, 145, 150, 152, 156, 157, 159, 160, 162, 171, 173, 176, 178, 186]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 4, 8, 10, 11, 19, 22, 25, 27, 29, 30, 31, 37, 38, 46, 51, 53, 56, 59, 60, 61, 63, 66, 67, 70, 71, 73, 83, 85, 86, 87, 88, 90, 91, 93, 100, 102, 103, 105, 106, 113, 114, 116, 118, 121, 126, 133, 135, 137, 138, 140, 142, 146, 156, 163, 164, 172, 173, 176, 179, 183, 187, 188]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl336_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 137.5448637008667\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.2794518 Vali Loss: 0.2239798 Test Loss: 0.2531980\n",
      "Validation loss decreased (inf --> 0.223980).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 138.03746604919434\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.2040735 Vali Loss: 0.2087817 Test Loss: 0.2273964\n",
      "Validation loss decreased (0.223980 --> 0.208782).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 136.30613660812378\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.1892859 Vali Loss: 0.2050861 Test Loss: 0.2197302\n",
      "Validation loss decreased (0.208782 --> 0.205086).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 136.5584523677826\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.1851019 Vali Loss: 0.2049639 Test Loss: 0.2185452\n",
      "Validation loss decreased (0.205086 --> 0.204964).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 138.26207208633423\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.1828691 Vali Loss: 0.2008395 Test Loss: 0.2144005\n",
      "Validation loss decreased (0.204964 --> 0.200839).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 136.67724227905273\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.1817489 Vali Loss: 0.2006952 Test Loss: 0.2139032\n",
      "Validation loss decreased (0.200839 --> 0.200695).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 137.36968350410461\n",
      "Epoch: 7, Steps: 256 | Train Loss: 0.1812256 Vali Loss: 0.2008900 Test Loss: 0.2141913\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 137.30261611938477\n",
      "Epoch: 8, Steps: 256 | Train Loss: 0.1810299 Vali Loss: 0.2008907 Test Loss: 0.2137832\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 137.29151439666748\n",
      "Epoch: 9, Steps: 256 | Train Loss: 0.1807842 Vali Loss: 0.2006801 Test Loss: 0.2136833\n",
      "Validation loss decreased (0.200695 --> 0.200680).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 135.76942467689514\n",
      "Epoch: 10, Steps: 256 | Train Loss: 0.1808086 Vali Loss: 0.2012542 Test Loss: 0.2137917\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 134.9397096633911\n",
      "Epoch: 11, Steps: 256 | Train Loss: 0.1807386 Vali Loss: 0.2010848 Test Loss: 0.2136818\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 135.7372510433197\n",
      "Epoch: 12, Steps: 256 | Train Loss: 0.1807032 Vali Loss: 0.2007398 Test Loss: 0.2135633\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 1) (79, 32, 336, 1)\n",
      "test shape: (2528, 336, 1) (2528, 336, 1)\n",
      "mse:0.21368330717086792, mae:0.2933596670627594\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[5, 7, 14, 15, 19, 28, 29, 32, 41, 70, 72, 78, 92, 95, 107, 111, 125, 136, 141, 142, 143, 144, 147, 148, 161, 166, 193, 207, 218, 220, 224, 225, 227, 238, 241, 248, 255, 257, 259, 264, 268, 270, 295, 310, 317, 321, 324, 325, 327, 328, 330, 334, 336, 340, 346, 348, 352, 358, 368, 370, 371, 372, 373, 383]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[6, 12, 13, 20, 30, 37, 44, 45, 50, 51, 54, 68, 73, 89, 97, 106, 110, 118, 121, 124, 125, 127, 129, 140, 143, 147, 155, 159, 161, 164, 167, 173, 174, 175, 193, 194, 195, 204, 217, 218, 221, 225, 226, 242, 249, 255, 256, 273, 283, 289, 294, 296, 301, 305, 314, 315, 319, 336, 338, 340, 345, 347, 356, 366]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl720_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 156.19643640518188\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.3164566 Vali Loss: 0.2410156 Test Loss: 0.2578015\n",
      "Validation loss decreased (inf --> 0.241016).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 154.18176746368408\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.2299838 Vali Loss: 0.2263319 Test Loss: 0.2225166\n",
      "Validation loss decreased (0.241016 --> 0.226332).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 152.73677945137024\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.2144654 Vali Loss: 0.2258151 Test Loss: 0.2145904\n",
      "Validation loss decreased (0.226332 --> 0.225815).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 155.5624635219574\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.2087077 Vali Loss: 0.2264275 Test Loss: 0.2124823\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 154.6022527217865\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.2072666 Vali Loss: 0.2284970 Test Loss: 0.2127695\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 151.8677213191986\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.2064574 Vali Loss: 0.2277032 Test Loss: 0.2132132\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 1) (67, 32, 720, 1)\n",
      "test shape: (2144, 720, 1) (2144, 720, 1)\n",
      "mse:0.21459044516086578, mae:0.3042219281196594\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl24_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "Epoch: 1 cost time: 74.73909330368042\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.0427485 Vali Loss: 0.0142050 Test Loss: 0.0156709\n",
      "Validation loss decreased (inf --> 0.014205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 69.94323301315308\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.0170757 Vali Loss: 0.0127911 Test Loss: 0.0131940\n",
      "Validation loss decreased (0.014205 --> 0.012791).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 68.74501371383667\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.0153608 Vali Loss: 0.0132927 Test Loss: 0.0142198\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 70.74430441856384\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.0145853 Vali Loss: 0.0117667 Test Loss: 0.0127431\n",
      "Validation loss decreased (0.012791 --> 0.011767).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 70.42110276222229\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.0141812 Vali Loss: 0.0115002 Test Loss: 0.0124220\n",
      "Validation loss decreased (0.011767 --> 0.011500).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 71.71730923652649\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.0139335 Vali Loss: 0.0118488 Test Loss: 0.0129903\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 69.67986297607422\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.0138513 Vali Loss: 0.0116860 Test Loss: 0.0128233\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 71.06742453575134\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.0137176 Vali Loss: 0.0116691 Test Loss: 0.0128467\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 1) (89, 32, 24, 1)\n",
      "test shape: (2848, 24, 1) (2848, 24, 1)\n",
      "mse:0.012421983294188976, mae:0.09499217569828033\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl48_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "Epoch: 1 cost time: 82.62886786460876\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.0509854 Vali Loss: 0.0180286 Test Loss: 0.0199440\n",
      "Validation loss decreased (inf --> 0.018029).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 75.52333950996399\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.0198787 Vali Loss: 0.0185629 Test Loss: 0.0212041\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 84.1139485836029\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.0123281 Vali Loss: 0.0210622 Test Loss: 0.0228689\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 81.28150939941406\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.0052759 Vali Loss: 0.0212576 Test Loss: 0.0227869\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 1) (88, 32, 48, 1)\n",
      "test shape: (2816, 48, 1) (2816, 48, 1)\n",
      "mse:0.019944023340940475, mae:0.11941598355770111\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 3, 5, 6, 9, 10, 11, 15, 16, 19, 22, 23, 24, 25, 27, 30, 31, 32, 35, 36, 37, 38, 39, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 63, 65, 66, 68, 70, 72, 73, 74, 76, 77, 78, 80, 81, 82, 90, 91, 92, 93, 95, 97, 100, 104, 105, 106]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 5, 7, 9, 10, 11, 13, 14, 16, 17, 18, 20, 23, 26, 27, 28, 29, 32, 33, 34, 35, 37, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 55, 58, 61, 62, 63, 64, 65, 66, 67, 68, 74, 75, 76, 77, 80, 81, 82, 85, 86, 88, 90, 91, 92, 94, 97, 99, 100, 101, 103, 104, 105]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl168_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "Epoch: 1 cost time: 101.84913969039917\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.0728098 Vali Loss: 0.0524281 Test Loss: 0.0772704\n",
      "Validation loss decreased (inf --> 0.052428).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 87.40538740158081\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.0378373 Vali Loss: 0.0468810 Test Loss: 0.0699481\n",
      "Validation loss decreased (0.052428 --> 0.046881).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 94.67370581626892\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.0354153 Vali Loss: 0.0482819 Test Loss: 0.0742178\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 99.83035564422607\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.0346010 Vali Loss: 0.0482900 Test Loss: 0.0741721\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 97.09888434410095\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.0343237 Vali Loss: 0.0470955 Test Loss: 0.0734261\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 1) (84, 32, 168, 1)\n",
      "test shape: (2688, 168, 1) (2688, 168, 1)\n",
      "mse:0.06994808465242386, mae:0.21107102930545807\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 5, 6, 7, 10, 11, 14, 16, 25, 26, 52, 55, 56, 57, 61, 63, 64, 66, 67, 69, 70, 72, 74, 75, 79, 80, 82, 89, 90, 93, 96, 97, 100, 101, 104, 106, 107, 109, 112, 115, 119, 122, 130, 136, 138, 141, 142, 143, 145, 149, 150, 151, 160, 162, 166, 169, 170, 175, 178, 179, 181, 186, 187, 189]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[6, 7, 8, 10, 14, 16, 19, 21, 24, 25, 26, 29, 30, 31, 34, 36, 38, 43, 45, 48, 50, 51, 52, 53, 55, 56, 57, 59, 60, 67, 70, 75, 80, 82, 88, 89, 92, 93, 94, 100, 102, 108, 113, 114, 120, 121, 129, 132, 139, 143, 145, 148, 149, 154, 159, 161, 164, 168, 169, 172, 175, 177, 182, 184]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl336_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 139.30432415008545\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.0890444 Vali Loss: 0.0804638 Test Loss: 0.1426802\n",
      "Validation loss decreased (inf --> 0.080464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 142.93336248397827\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.0406087 Vali Loss: 0.0782275 Test Loss: 0.1404223\n",
      "Validation loss decreased (0.080464 --> 0.078228).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 139.75560426712036\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.0372293 Vali Loss: 0.0703895 Test Loss: 0.1348318\n",
      "Validation loss decreased (0.078228 --> 0.070390).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 137.24430894851685\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.0360870 Vali Loss: 0.0727980 Test Loss: 0.1379151\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 132.64594292640686\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.0355033 Vali Loss: 0.0711329 Test Loss: 0.1348898\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 133.64660000801086\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.0351970 Vali Loss: 0.0719441 Test Loss: 0.1357211\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 1) (79, 32, 336, 1)\n",
      "test shape: (2528, 336, 1) (2528, 336, 1)\n",
      "mse:0.13483181595802307, mae:0.2947820723056793\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 5, 9, 15, 19, 24, 30, 37, 42, 50, 51, 53, 65, 68, 69, 74, 76, 89, 106, 111, 117, 126, 130, 133, 136, 139, 141, 143, 147, 148, 152, 165, 168, 169, 188, 195, 202, 214, 229, 231, 234, 238, 243, 259, 261, 266, 270, 276, 280, 283, 289, 296, 301, 302, 323, 326, 347, 354, 355, 360, 361, 369, 376, 383]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 8, 12, 17, 28, 48, 52, 54, 74, 82, 84, 89, 90, 95, 96, 102, 104, 113, 118, 124, 128, 133, 140, 154, 175, 180, 183, 188, 189, 194, 195, 200, 220, 221, 222, 228, 229, 236, 256, 262, 267, 268, 270, 276, 284, 301, 305, 307, 309, 310, 313, 316, 319, 326, 332, 335, 343, 344, 352, 360, 361, 364, 366, 382]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl720_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 152.01621532440186\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.1149296 Vali Loss: 0.1129449 Test Loss: 0.1426805\n",
      "Validation loss decreased (inf --> 0.112945).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 152.62825512886047\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.0826839 Vali Loss: 0.1087984 Test Loss: 0.1381708\n",
      "Validation loss decreased (0.112945 --> 0.108798).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 155.14176273345947\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.0778196 Vali Loss: 0.1021451 Test Loss: 0.1311690\n",
      "Validation loss decreased (0.108798 --> 0.102145).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 153.52900218963623\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.0742535 Vali Loss: 0.1013670 Test Loss: 0.1308442\n",
      "Validation loss decreased (0.102145 --> 0.101367).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 155.54235672950745\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.0732651 Vali Loss: 0.1009897 Test Loss: 0.1304703\n",
      "Validation loss decreased (0.101367 --> 0.100990).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 153.7102701663971\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.0729032 Vali Loss: 0.1005441 Test Loss: 0.1300553\n",
      "Validation loss decreased (0.100990 --> 0.100544).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 157.08018803596497\n",
      "Epoch: 7, Steps: 244 | Train Loss: 0.0727855 Vali Loss: 0.1004793 Test Loss: 0.1300315\n",
      "Validation loss decreased (0.100544 --> 0.100479).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 153.98673152923584\n",
      "Epoch: 8, Steps: 244 | Train Loss: 0.0726516 Vali Loss: 0.1004297 Test Loss: 0.1300295\n",
      "Validation loss decreased (0.100479 --> 0.100430).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 153.56844282150269\n",
      "Epoch: 9, Steps: 244 | Train Loss: 0.0726203 Vali Loss: 0.1003894 Test Loss: 0.1299749\n",
      "Validation loss decreased (0.100430 --> 0.100389).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 150.32253098487854\n",
      "Epoch: 10, Steps: 244 | Train Loss: 0.0725249 Vali Loss: 0.1003381 Test Loss: 0.1299667\n",
      "Validation loss decreased (0.100389 --> 0.100338).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 154.49593114852905\n",
      "Epoch: 11, Steps: 244 | Train Loss: 0.0725807 Vali Loss: 0.1004587 Test Loss: 0.1299633\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 152.85793685913086\n",
      "Epoch: 12, Steps: 244 | Train Loss: 0.0725438 Vali Loss: 0.1002700 Test Loss: 0.1299639\n",
      "Validation loss decreased (0.100338 --> 0.100270).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 153.1916687488556\n",
      "Epoch: 13, Steps: 244 | Train Loss: 0.0725751 Vali Loss: 0.1003772 Test Loss: 0.1299638\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 155.80803203582764\n",
      "Epoch: 14, Steps: 244 | Train Loss: 0.0725399 Vali Loss: 0.1002643 Test Loss: 0.1299623\n",
      "Validation loss decreased (0.100270 --> 0.100264).  Saving model ...\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 152.84141516685486\n",
      "Epoch: 15, Steps: 244 | Train Loss: 0.0725505 Vali Loss: 0.1004451 Test Loss: 0.1299612\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 152.402583360672\n",
      "Epoch: 16, Steps: 244 | Train Loss: 0.0725537 Vali Loss: 0.1003396 Test Loss: 0.1299620\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.0517578125e-09\n",
      "Epoch: 17 cost time: 153.3291425704956\n",
      "Epoch: 17, Steps: 244 | Train Loss: 0.0725756 Vali Loss: 0.1004241 Test Loss: 0.1299624\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 1) (67, 32, 720, 1)\n",
      "test shape: (2144, 720, 1) (2144, 720, 1)\n",
      "mse:0.12996231019496918, mae:0.2956447899341583\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl24_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "Epoch: 1 cost time: 69.95051741600037\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.1308087 Vali Loss: 0.1202727 Test Loss: 0.2491716\n",
      "Validation loss decreased (inf --> 0.120273).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 75.98225975036621\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.0472134 Vali Loss: 0.0901750 Test Loss: 0.1861937\n",
      "Validation loss decreased (0.120273 --> 0.090175).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 72.48815751075745\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.0376528 Vali Loss: 0.0732488 Test Loss: 0.1485894\n",
      "Validation loss decreased (0.090175 --> 0.073249).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 73.27530145645142\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.0320956 Vali Loss: 0.0780246 Test Loss: 0.1474594\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 71.00189542770386\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.0265166 Vali Loss: 0.0689728 Test Loss: 0.1251354\n",
      "Validation loss decreased (0.073249 --> 0.068973).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 78.45705270767212\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.0213420 Vali Loss: 0.0712450 Test Loss: 0.1276719\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 77.5700056552887\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.0189030 Vali Loss: 0.0723299 Test Loss: 0.1305963\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 73.12382864952087\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.0179049 Vali Loss: 0.0702129 Test Loss: 0.1280869\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 1) (89, 32, 24, 1)\n",
      "test shape: (2848, 24, 1) (2848, 24, 1)\n",
      "mse:0.1251353770494461, mae:0.2924322783946991\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl48_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "Epoch: 1 cost time: 77.13046360015869\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.1540633 Vali Loss: 0.1575222 Test Loss: 0.3175133\n",
      "Validation loss decreased (inf --> 0.157522).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 77.72132277488708\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.0538236 Vali Loss: 0.1161437 Test Loss: 0.2342350\n",
      "Validation loss decreased (0.157522 --> 0.116144).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 77.67883443832397\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.0477480 Vali Loss: 0.1100016 Test Loss: 0.2162289\n",
      "Validation loss decreased (0.116144 --> 0.110002).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 82.24772596359253\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.0436436 Vali Loss: 0.0931480 Test Loss: 0.1790547\n",
      "Validation loss decreased (0.110002 --> 0.093148).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 74.94528245925903\n",
      "Epoch: 5, Steps: 265 | Train Loss: 0.0414734 Vali Loss: 0.0993660 Test Loss: 0.1896061\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 79.74053049087524\n",
      "Epoch: 6, Steps: 265 | Train Loss: 0.0405198 Vali Loss: 0.0971202 Test Loss: 0.1836738\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 80.32368326187134\n",
      "Epoch: 7, Steps: 265 | Train Loss: 0.0400684 Vali Loss: 0.0940984 Test Loss: 0.1789153\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 1) (88, 32, 48, 1)\n",
      "test shape: (2816, 48, 1) (2816, 48, 1)\n",
      "mse:0.17905473709106445, mae:0.3451704978942871\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 3, 4, 5, 7, 10, 11, 12, 13, 15, 16, 18, 20, 23, 24, 25, 28, 30, 31, 32, 35, 38, 40, 42, 43, 45, 46, 47, 49, 51, 53, 55, 57, 59, 62, 63, 67, 68, 70, 72, 74, 75, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 97, 98, 99, 100, 103, 104]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 21, 22, 23, 27, 28, 30, 32, 34, 36, 37, 38, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 55, 60, 61, 63, 65, 66, 67, 70, 71, 73, 74, 75, 76, 77, 79, 81, 85, 86, 87, 90, 94, 95, 96, 98, 100, 102, 103, 104, 105, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl168_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "Epoch: 1 cost time: 97.97330641746521\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.1976855 Vali Loss: 0.2421027 Test Loss: 0.4928890\n",
      "Validation loss decreased (inf --> 0.242103).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 97.70791506767273\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.0966737 Vali Loss: 0.2249172 Test Loss: 0.4601704\n",
      "Validation loss decreased (0.242103 --> 0.224917).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 95.0511064529419\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.0908570 Vali Loss: 0.2199885 Test Loss: 0.4547435\n",
      "Validation loss decreased (0.224917 --> 0.219988).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 92.14805817604065\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.0881951 Vali Loss: 0.2156846 Test Loss: 0.4412629\n",
      "Validation loss decreased (0.219988 --> 0.215685).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 99.12911248207092\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.0867915 Vali Loss: 0.2125939 Test Loss: 0.4389615\n",
      "Validation loss decreased (0.215685 --> 0.212594).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 96.9781174659729\n",
      "Epoch: 6, Steps: 261 | Train Loss: 0.0862095 Vali Loss: 0.2153750 Test Loss: 0.4408803\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 95.90998911857605\n",
      "Epoch: 7, Steps: 261 | Train Loss: 0.0857665 Vali Loss: 0.2133033 Test Loss: 0.4383859\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 94.16781067848206\n",
      "Epoch: 8, Steps: 261 | Train Loss: 0.0856569 Vali Loss: 0.2118819 Test Loss: 0.4364480\n",
      "Validation loss decreased (0.212594 --> 0.211882).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 96.5242006778717\n",
      "Epoch: 9, Steps: 261 | Train Loss: 0.0854081 Vali Loss: 0.2117544 Test Loss: 0.4362144\n",
      "Validation loss decreased (0.211882 --> 0.211754).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 100.98290276527405\n",
      "Epoch: 10, Steps: 261 | Train Loss: 0.0854207 Vali Loss: 0.2114740 Test Loss: 0.4361405\n",
      "Validation loss decreased (0.211754 --> 0.211474).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 98.0153796672821\n",
      "Epoch: 11, Steps: 261 | Train Loss: 0.0853832 Vali Loss: 0.2111922 Test Loss: 0.4361334\n",
      "Validation loss decreased (0.211474 --> 0.211192).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 95.2564446926117\n",
      "Epoch: 12, Steps: 261 | Train Loss: 0.0853101 Vali Loss: 0.2113579 Test Loss: 0.4359778\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 95.11027312278748\n",
      "Epoch: 13, Steps: 261 | Train Loss: 0.0852479 Vali Loss: 0.2117306 Test Loss: 0.4360789\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 93.91485071182251\n",
      "Epoch: 14, Steps: 261 | Train Loss: 0.0854514 Vali Loss: 0.2113732 Test Loss: 0.4360234\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 1) (84, 32, 168, 1)\n",
      "test shape: (2688, 168, 1) (2688, 168, 1)\n",
      "mse:0.43613341450691223, mae:0.5329356789588928\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 6, 8, 11, 15, 17, 20, 23, 24, 25, 27, 28, 40, 41, 42, 43, 45, 48, 50, 54, 55, 60, 63, 64, 66, 70, 80, 82, 85, 87, 88, 90, 93, 95, 96, 98, 100, 107, 116, 117, 119, 124, 125, 126, 130, 133, 137, 141, 142, 148, 155, 158, 159, 160, 161, 164, 167, 171, 172, 173, 178, 183, 186, 189]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 3, 4, 9, 11, 18, 19, 23, 29, 32, 33, 36, 38, 41, 44, 48, 49, 54, 61, 62, 64, 69, 73, 74, 81, 85, 86, 88, 89, 97, 101, 106, 107, 110, 112, 113, 114, 120, 123, 124, 127, 130, 135, 136, 140, 141, 142, 144, 145, 148, 152, 153, 159, 164, 167, 172, 176, 179, 181, 183, 184, 186, 189, 190]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl336_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 132.79359936714172\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.2648095 Vali Loss: 0.4463544 Test Loss: 0.9264024\n",
      "Validation loss decreased (inf --> 0.446354).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 135.37095761299133\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.1390502 Vali Loss: 0.4360401 Test Loss: 0.9363617\n",
      "Validation loss decreased (0.446354 --> 0.436040).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 136.57585835456848\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.1275753 Vali Loss: 0.3993294 Test Loss: 0.8908439\n",
      "Validation loss decreased (0.436040 --> 0.399329).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 138.5202395915985\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.1243966 Vali Loss: 0.4040039 Test Loss: 0.8927992\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 137.71836233139038\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.1228903 Vali Loss: 0.4035740 Test Loss: 0.8934826\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 138.93694853782654\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.1223115 Vali Loss: 0.3986278 Test Loss: 0.8875377\n",
      "Validation loss decreased (0.399329 --> 0.398628).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 138.18405675888062\n",
      "Epoch: 7, Steps: 256 | Train Loss: 0.1219799 Vali Loss: 0.3952074 Test Loss: 0.8812578\n",
      "Validation loss decreased (0.398628 --> 0.395207).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 139.1338140964508\n",
      "Epoch: 8, Steps: 256 | Train Loss: 0.1216923 Vali Loss: 0.3965352 Test Loss: 0.8837749\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 134.12413716316223\n",
      "Epoch: 9, Steps: 256 | Train Loss: 0.1216193 Vali Loss: 0.3953349 Test Loss: 0.8836628\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 142.48729133605957\n",
      "Epoch: 10, Steps: 256 | Train Loss: 0.1214878 Vali Loss: 0.3963095 Test Loss: 0.8835412\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 1) (79, 32, 336, 1)\n",
      "test shape: (2528, 336, 1) (2528, 336, 1)\n",
      "mse:0.8812577128410339, mae:0.7729610800743103\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[5, 6, 18, 24, 25, 34, 35, 45, 46, 54, 58, 60, 61, 64, 66, 67, 68, 78, 84, 85, 103, 104, 113, 114, 120, 144, 169, 183, 198, 203, 205, 216, 217, 220, 223, 224, 225, 228, 247, 251, 258, 261, 267, 270, 272, 273, 276, 277, 278, 289, 290, 291, 307, 312, 313, 321, 324, 328, 355, 359, 360, 361, 372, 378]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[2, 5, 7, 13, 20, 28, 41, 46, 47, 51, 55, 65, 69, 70, 72, 77, 85, 91, 92, 96, 104, 121, 137, 148, 155, 158, 173, 174, 177, 188, 192, 195, 198, 199, 200, 206, 216, 229, 233, 235, 236, 245, 248, 249, 250, 257, 263, 277, 280, 283, 308, 311, 312, 327, 329, 331, 336, 338, 344, 346, 347, 367, 378, 379]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl720_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 154.30475854873657\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.2981822 Vali Loss: 0.5248169 Test Loss: 0.8918412\n",
      "Validation loss decreased (inf --> 0.524817).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 151.5878803730011\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.2168004 Vali Loss: 0.5172841 Test Loss: 0.8857162\n",
      "Validation loss decreased (0.524817 --> 0.517284).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 155.86179161071777\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.2104494 Vali Loss: 0.4971302 Test Loss: 0.8563406\n",
      "Validation loss decreased (0.517284 --> 0.497130).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 155.36655807495117\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.2077307 Vali Loss: 0.4916374 Test Loss: 0.8524553\n",
      "Validation loss decreased (0.497130 --> 0.491637).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 159.1189353466034\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.2060099 Vali Loss: 0.4916977 Test Loss: 0.8526605\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 154.90611910820007\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.2050318 Vali Loss: 0.4901105 Test Loss: 0.8516530\n",
      "Validation loss decreased (0.491637 --> 0.490110).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 159.2449939250946\n",
      "Epoch: 7, Steps: 244 | Train Loss: 0.2045908 Vali Loss: 0.4890855 Test Loss: 0.8493210\n",
      "Validation loss decreased (0.490110 --> 0.489085).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 151.5310025215149\n",
      "Epoch: 8, Steps: 244 | Train Loss: 0.2044672 Vali Loss: 0.4893708 Test Loss: 0.8503516\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 153.23761630058289\n",
      "Epoch: 9, Steps: 244 | Train Loss: 0.2044165 Vali Loss: 0.4884796 Test Loss: 0.8495947\n",
      "Validation loss decreased (0.489085 --> 0.488480).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 156.00878167152405\n",
      "Epoch: 10, Steps: 244 | Train Loss: 0.2042772 Vali Loss: 0.4883519 Test Loss: 0.8493519\n",
      "Validation loss decreased (0.488480 --> 0.488352).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 152.8715627193451\n",
      "Epoch: 11, Steps: 244 | Train Loss: 0.2041214 Vali Loss: 0.4890001 Test Loss: 0.8491154\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 153.7130789756775\n",
      "Epoch: 12, Steps: 244 | Train Loss: 0.2042466 Vali Loss: 0.4883972 Test Loss: 0.8491007\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 155.35788297653198\n",
      "Epoch: 13, Steps: 244 | Train Loss: 0.2042806 Vali Loss: 0.4886141 Test Loss: 0.8490444\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 1) (67, 32, 720, 1)\n",
      "test shape: (2144, 720, 1) (2144, 720, 1)\n",
      "mse:0.8493518829345703, mae:0.7480064630508423\n",
      "\n",
      "Moving to next...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple loop\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "\n",
    "    for dataset_name, dataset_path in datasets.items():\n",
    "        for pred_len in pred_lens:\n",
    "            print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "            # High amount of epochs to accomodate all models\n",
    "            # Early stopping should kick in anyways\n",
    "            model.fit(\n",
    "                data=dataset_name,\n",
    "                data_root_path=dataset_path,\n",
    "                batch_size=32,\n",
    "                epochs=50, # very high\n",
    "                pred_len=pred_len\n",
    "            )\n",
    "\n",
    "            predictions = model.predict()\n",
    "\n",
    "            print(f'\\nMoving to next...\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: CrossformerTS\n",
      "Training CrossformerTS on SYNTH_additive_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './crossformer_checkpoints/', 'seq_len': 96, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 50, 'batch_size': 32, 'pred_len': 24, 'data_split': []}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_reversal_il96_pl24_sl6_win2_fa10_dm256_nh4_el3_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "\titers: 100, epoch: 1 | loss: 0.2611816\n",
      "\tspeed: 0.0722s/iter; left time: 952.8185s\n",
      "\titers: 200, epoch: 1 | loss: 0.0783861\n",
      "\tspeed: 0.0733s/iter; left time: 960.1668s\n",
      "Epoch: 1 cost time: 19.428747415542603\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.2354491 Vali Loss: 0.0315770 Test Loss: 0.0353855\n",
      "Validation loss decreased (inf --> 0.031577).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0690140\n",
      "\tspeed: 0.0712s/iter; left time: 920.6898s\n",
      "\titers: 200, epoch: 2 | loss: 0.0767597\n",
      "\tspeed: 0.0741s/iter; left time: 950.4407s\n",
      "Epoch: 2 cost time: 19.420167446136475\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.0679285 Vali Loss: 0.0273725 Test Loss: 0.0280605\n",
      "Validation loss decreased (0.031577 --> 0.027373).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0510108\n",
      "\tspeed: 0.0769s/iter; left time: 974.4444s\n",
      "\titers: 200, epoch: 3 | loss: 0.0496973\n",
      "\tspeed: 0.0738s/iter; left time: 928.0976s\n",
      "Epoch: 3 cost time: 19.99821162223816\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.0523283 Vali Loss: 0.0213094 Test Loss: 0.0233069\n",
      "Validation loss decreased (0.027373 --> 0.021309).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0458728\n",
      "\tspeed: 0.0734s/iter; left time: 910.4504s\n",
      "\titers: 200, epoch: 4 | loss: 0.0419732\n",
      "\tspeed: 0.0704s/iter; left time: 866.5485s\n",
      "Epoch: 4 cost time: 19.020975589752197\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.0465454 Vali Loss: 0.0192442 Test Loss: 0.0213113\n",
      "Validation loss decreased (0.021309 --> 0.019244).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0424716\n",
      "\tspeed: 0.0722s/iter; left time: 876.0362s\n",
      "\titers: 200, epoch: 5 | loss: 0.0364851\n",
      "\tspeed: 0.0725s/iter; left time: 872.5649s\n",
      "Epoch: 5 cost time: 19.314037561416626\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.0418224 Vali Loss: 0.0210610 Test Loss: 0.0226057\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.0546936\n",
      "\tspeed: 0.0731s/iter; left time: 868.2748s\n",
      "\titers: 200, epoch: 6 | loss: 0.0324285\n",
      "\tspeed: 0.0755s/iter; left time: 889.0376s\n",
      "Epoch: 6 cost time: 19.91880440711975\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.0405669 Vali Loss: 0.0194213 Test Loss: 0.0214662\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0356054\n",
      "\tspeed: 0.0767s/iter; left time: 890.2427s\n",
      "\titers: 200, epoch: 7 | loss: 0.0388432\n",
      "\tspeed: 0.0762s/iter; left time: 876.3151s\n",
      "Epoch: 7 cost time: 19.944432258605957\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.0383395 Vali Loss: 0.0227809 Test Loss: 0.0232090\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 1) (89, 32, 24, 1)\n",
      "test shape: (2848, 24, 1) (2848, 24, 1)\n",
      "mse:0.021311255171895027, mae:0.1126098558306694\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './crossformer_checkpoints/', 'seq_len': 96, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 50, 'batch_size': 32, 'pred_len': 48, 'data_split': []}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_reversal_il96_pl48_sl6_win2_fa10_dm256_nh4_el3_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "\titers: 100, epoch: 1 | loss: 0.1917688\n",
      "\tspeed: 0.0745s/iter; left time: 979.4546s\n",
      "\titers: 200, epoch: 1 | loss: 0.1408689\n",
      "\tspeed: 0.0754s/iter; left time: 984.0537s\n",
      "Epoch: 1 cost time: 19.82872486114502\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.3132558 Vali Loss: 0.0520877 Test Loss: 0.0602846\n",
      "Validation loss decreased (inf --> 0.052088).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0975558\n",
      "\tspeed: 0.0735s/iter; left time: 946.4855s\n",
      "\titers: 200, epoch: 2 | loss: 0.0849627\n",
      "\tspeed: 0.0759s/iter; left time: 969.8787s\n",
      "Epoch: 2 cost time: 19.93082046508789\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.0971203 Vali Loss: 0.0579900 Test Loss: 0.0563961\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0716193\n",
      "\tspeed: 0.0757s/iter; left time: 954.8295s\n",
      "\titers: 200, epoch: 3 | loss: 0.0615129\n",
      "\tspeed: 0.0717s/iter; left time: 897.7679s\n",
      "Epoch: 3 cost time: 19.598798036575317\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.0772514 Vali Loss: 0.0400323 Test Loss: 0.0444136\n",
      "Validation loss decreased (0.052088 --> 0.040032).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0660363\n",
      "\tspeed: 0.0738s/iter; left time: 911.9310s\n",
      "\titers: 200, epoch: 4 | loss: 0.0690726\n",
      "\tspeed: 0.0756s/iter; left time: 926.4057s\n",
      "Epoch: 4 cost time: 19.807183027267456\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.0699329 Vali Loss: 0.0436085 Test Loss: 0.0474864\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0676810\n",
      "\tspeed: 0.0736s/iter; left time: 890.2199s\n",
      "\titers: 200, epoch: 5 | loss: 0.0774923\n",
      "\tspeed: 0.0740s/iter; left time: 887.3562s\n",
      "Epoch: 5 cost time: 19.564363479614258\n",
      "Epoch: 5, Steps: 265 | Train Loss: 0.0630359 Vali Loss: 0.0355220 Test Loss: 0.0402946\n",
      "Validation loss decreased (0.040032 --> 0.035522).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0469907\n",
      "\tspeed: 0.0741s/iter; left time: 876.2087s\n",
      "\titers: 200, epoch: 6 | loss: 0.0741477\n",
      "\tspeed: 0.0740s/iter; left time: 867.5856s\n",
      "Epoch: 6 cost time: 19.748271226882935\n",
      "Epoch: 6, Steps: 265 | Train Loss: 0.0604579 Vali Loss: 0.0378928 Test Loss: 0.0406510\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0502334\n",
      "\tspeed: 0.0744s/iter; left time: 860.6963s\n",
      "\titers: 200, epoch: 7 | loss: 0.0526761\n",
      "\tspeed: 0.0740s/iter; left time: 847.7823s\n",
      "Epoch: 7 cost time: 19.80362606048584\n",
      "Epoch: 7, Steps: 265 | Train Loss: 0.0565944 Vali Loss: 0.0351714 Test Loss: 0.0403788\n",
      "Validation loss decreased (0.035522 --> 0.035171).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0548466\n",
      "\tspeed: 0.0741s/iter; left time: 837.3403s\n",
      "\titers: 200, epoch: 8 | loss: 0.0515104\n",
      "\tspeed: 0.0742s/iter; left time: 830.6298s\n",
      "Epoch: 8 cost time: 19.54268789291382\n",
      "Epoch: 8, Steps: 265 | Train Loss: 0.0564507 Vali Loss: 0.0433564 Test Loss: 0.0465886\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0614914\n",
      "\tspeed: 0.0748s/iter; left time: 824.9197s\n",
      "\titers: 200, epoch: 9 | loss: 0.0583435\n",
      "\tspeed: 0.0712s/iter; left time: 777.7951s\n",
      "Epoch: 9 cost time: 19.317435264587402\n",
      "Epoch: 9, Steps: 265 | Train Loss: 0.0546675 Vali Loss: 0.0338133 Test Loss: 0.0382501\n",
      "Validation loss decreased (0.035171 --> 0.033813).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.0570869\n",
      "\tspeed: 0.0713s/iter; left time: 767.0857s\n",
      "\titers: 200, epoch: 10 | loss: 0.0497690\n",
      "\tspeed: 0.0744s/iter; left time: 793.1121s\n",
      "Epoch: 10 cost time: 19.25618624687195\n",
      "Epoch: 10, Steps: 265 | Train Loss: 0.0537139 Vali Loss: 0.0329082 Test Loss: 0.0377052\n",
      "Validation loss decreased (0.033813 --> 0.032908).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0463174\n",
      "\tspeed: 0.0720s/iter; left time: 755.7833s\n",
      "\titers: 200, epoch: 11 | loss: 0.0501431\n",
      "\tspeed: 0.0722s/iter; left time: 751.2598s\n",
      "Epoch: 11 cost time: 19.012004613876343\n",
      "Epoch: 11, Steps: 265 | Train Loss: 0.0532022 Vali Loss: 0.0347854 Test Loss: 0.0382614\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.0563894\n",
      "\tspeed: 0.0711s/iter; left time: 728.0543s\n",
      "\titers: 200, epoch: 12 | loss: 0.0596397\n",
      "\tspeed: 0.0721s/iter; left time: 730.6513s\n",
      "Epoch: 12 cost time: 18.959689378738403\n",
      "Epoch: 12, Steps: 265 | Train Loss: 0.0527557 Vali Loss: 0.0336873 Test Loss: 0.0372015\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.0545259\n",
      "\tspeed: 0.0712s/iter; left time: 709.5795s\n",
      "\titers: 200, epoch: 13 | loss: 0.0592799\n",
      "\tspeed: 0.0785s/iter; left time: 774.8333s\n",
      "Epoch: 13 cost time: 19.62196969985962\n",
      "Epoch: 13, Steps: 265 | Train Loss: 0.0524735 Vali Loss: 0.0328266 Test Loss: 0.0379637\n",
      "Validation loss decreased (0.032908 --> 0.032827).  Saving model ...\n",
      "\titers: 100, epoch: 14 | loss: 0.0492246\n",
      "\tspeed: 0.0765s/iter; left time: 742.4446s\n",
      "\titers: 200, epoch: 14 | loss: 0.0526971\n",
      "\tspeed: 0.0776s/iter; left time: 745.6358s\n",
      "Epoch: 14 cost time: 20.204269886016846\n",
      "Epoch: 14, Steps: 265 | Train Loss: 0.0521537 Vali Loss: 0.0354461 Test Loss: 0.0388546\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 15 | loss: 0.0516626\n",
      "\tspeed: 0.0724s/iter; left time: 683.8802s\n",
      "\titers: 200, epoch: 15 | loss: 0.0431749\n",
      "\tspeed: 0.0705s/iter; left time: 658.8502s\n",
      "Epoch: 15 cost time: 18.95773220062256\n",
      "Epoch: 15, Steps: 265 | Train Loss: 0.0516793 Vali Loss: 0.0325826 Test Loss: 0.0371368\n",
      "Validation loss decreased (0.032827 --> 0.032583).  Saving model ...\n",
      "\titers: 100, epoch: 16 | loss: 0.0427392\n",
      "\tspeed: 0.0747s/iter; left time: 684.9916s\n",
      "\titers: 200, epoch: 16 | loss: 0.0588699\n",
      "\tspeed: 0.0743s/iter; left time: 674.6377s\n",
      "Epoch: 16 cost time: 19.751352787017822\n",
      "Epoch: 16, Steps: 265 | Train Loss: 0.0519254 Vali Loss: 0.0324279 Test Loss: 0.0376638\n",
      "Validation loss decreased (0.032583 --> 0.032428).  Saving model ...\n",
      "\titers: 100, epoch: 17 | loss: 0.0723651\n",
      "\tspeed: 0.0742s/iter; left time: 661.4328s\n",
      "\titers: 200, epoch: 17 | loss: 0.0443795\n",
      "\tspeed: 0.0721s/iter; left time: 635.4725s\n",
      "Epoch: 17 cost time: 19.396069288253784\n",
      "Epoch: 17, Steps: 265 | Train Loss: 0.0514441 Vali Loss: 0.0337645 Test Loss: 0.0382522\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 18 | loss: 0.0496230\n",
      "\tspeed: 0.0741s/iter; left time: 640.3991s\n",
      "\titers: 200, epoch: 18 | loss: 0.0557818\n",
      "\tspeed: 0.0703s/iter; left time: 601.1673s\n",
      "Epoch: 18 cost time: 19.05156707763672\n",
      "Epoch: 18, Steps: 265 | Train Loss: 0.0511485 Vali Loss: 0.0334752 Test Loss: 0.0378792\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 19 | loss: 0.0514847\n",
      "\tspeed: 0.0739s/iter; left time: 618.9581s\n",
      "\titers: 200, epoch: 19 | loss: 0.0356386\n",
      "\tspeed: 0.0752s/iter; left time: 622.9412s\n",
      "Epoch: 19 cost time: 19.70971393585205\n",
      "Epoch: 19, Steps: 265 | Train Loss: 0.0505493 Vali Loss: 0.0334900 Test Loss: 0.0382254\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 1) (88, 32, 48, 1)\n",
      "test shape: (2816, 48, 1) (2816, 48, 1)\n",
      "mse:0.037663765251636505, mae:0.1426456868648529\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './crossformer_checkpoints/', 'seq_len': 96, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 50, 'batch_size': 32, 'pred_len': 168, 'data_split': []}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_reversal_il96_pl168_sl6_win2_fa10_dm256_nh4_el3_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "\titers: 100, epoch: 1 | loss: 0.3505759\n",
      "\tspeed: 0.0738s/iter; left time: 955.8281s\n",
      "\titers: 200, epoch: 1 | loss: 0.2955280\n",
      "\tspeed: 0.0716s/iter; left time: 920.7501s\n",
      "Epoch: 1 cost time: 18.963943481445312\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.4050135 Vali Loss: 0.1653706 Test Loss: 0.1935295\n",
      "Validation loss decreased (inf --> 0.165371).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.2495595\n",
      "\tspeed: 0.0710s/iter; left time: 901.5188s\n",
      "\titers: 200, epoch: 2 | loss: 0.1717547\n",
      "\tspeed: 0.0780s/iter; left time: 981.9497s\n",
      "Epoch: 2 cost time: 19.475087881088257\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.2148378 Vali Loss: 0.1259108 Test Loss: 0.1617821\n",
      "Validation loss decreased (0.165371 --> 0.125911).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1752309\n",
      "\tspeed: 0.0725s/iter; left time: 900.6548s\n",
      "\titers: 200, epoch: 3 | loss: 0.1567846\n",
      "\tspeed: 0.0721s/iter; left time: 888.5429s\n",
      "Epoch: 3 cost time: 18.80099582672119\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.1803609 Vali Loss: 0.1139951 Test Loss: 0.1609534\n",
      "Validation loss decreased (0.125911 --> 0.113995).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.1701834\n",
      "\tspeed: 0.0706s/iter; left time: 859.1762s\n",
      "\titers: 200, epoch: 4 | loss: 0.1442288\n",
      "\tspeed: 0.0728s/iter; left time: 877.9634s\n",
      "Epoch: 4 cost time: 18.545772552490234\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.1675195 Vali Loss: 0.1092723 Test Loss: 0.1399493\n",
      "Validation loss decreased (0.113995 --> 0.109272).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1216111\n",
      "\tspeed: 0.0846s/iter; left time: 1007.8614s\n",
      "\titers: 200, epoch: 5 | loss: 0.2024281\n",
      "\tspeed: 0.0692s/iter; left time: 817.0904s\n",
      "Epoch: 5 cost time: 19.51428508758545\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.1536994 Vali Loss: 0.1261463 Test Loss: 0.1335278\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.1409702\n",
      "\tspeed: 0.0675s/iter; left time: 785.6345s\n",
      "\titers: 200, epoch: 6 | loss: 0.1384561\n",
      "\tspeed: 0.0695s/iter; left time: 802.8749s\n",
      "Epoch: 6 cost time: 18.40120244026184\n",
      "Epoch: 6, Steps: 261 | Train Loss: 0.1503002 Vali Loss: 0.1129406 Test Loss: 0.1285838\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1414699\n",
      "\tspeed: 0.0690s/iter; left time: 785.9549s\n",
      "\titers: 200, epoch: 7 | loss: 0.1162625\n",
      "\tspeed: 0.0708s/iter; left time: 798.5324s\n",
      "Epoch: 7 cost time: 18.228092670440674\n",
      "Epoch: 7, Steps: 261 | Train Loss: 0.1436686 Vali Loss: 0.0991678 Test Loss: 0.1324897\n",
      "Validation loss decreased (0.109272 --> 0.099168).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.1199784\n",
      "\tspeed: 0.0703s/iter; left time: 782.1461s\n",
      "\titers: 200, epoch: 8 | loss: 0.1311698\n",
      "\tspeed: 0.0687s/iter; left time: 757.7473s\n",
      "Epoch: 8 cost time: 18.179551124572754\n",
      "Epoch: 8, Steps: 261 | Train Loss: 0.1397896 Vali Loss: 0.1017879 Test Loss: 0.1171681\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1418416\n",
      "\tspeed: 0.0676s/iter; left time: 734.1823s\n",
      "\titers: 200, epoch: 9 | loss: 0.1183709\n",
      "\tspeed: 0.0684s/iter; left time: 735.9622s\n",
      "Epoch: 9 cost time: 17.78325915336609\n",
      "Epoch: 9, Steps: 261 | Train Loss: 0.1366941 Vali Loss: 0.0988531 Test Loss: 0.1242531\n",
      "Validation loss decreased (0.099168 --> 0.098853).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.1556056\n",
      "\tspeed: 0.0717s/iter; left time: 759.7462s\n",
      "\titers: 200, epoch: 10 | loss: 0.1469735\n",
      "\tspeed: 0.0739s/iter; left time: 775.8203s\n",
      "Epoch: 10 cost time: 18.747687339782715\n",
      "Epoch: 10, Steps: 261 | Train Loss: 0.1350608 Vali Loss: 0.0932539 Test Loss: 0.1221254\n",
      "Validation loss decreased (0.098853 --> 0.093254).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1503020\n",
      "\tspeed: 0.0666s/iter; left time: 688.4252s\n",
      "\titers: 200, epoch: 11 | loss: 0.1341909\n",
      "\tspeed: 0.0671s/iter; left time: 687.2589s\n",
      "Epoch: 11 cost time: 17.608741521835327\n",
      "Epoch: 11, Steps: 261 | Train Loss: 0.1329802 Vali Loss: 0.0974887 Test Loss: 0.1178541\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.1246330\n",
      "\tspeed: 0.0696s/iter; left time: 701.2301s\n",
      "\titers: 200, epoch: 12 | loss: 0.1117318\n",
      "\tspeed: 0.0691s/iter; left time: 689.6703s\n",
      "Epoch: 12 cost time: 18.21906328201294\n",
      "Epoch: 12, Steps: 261 | Train Loss: 0.1332912 Vali Loss: 0.0946346 Test Loss: 0.1157671\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 13 | loss: 0.1238493\n",
      "\tspeed: 0.0693s/iter; left time: 680.2657s\n",
      "\titers: 200, epoch: 13 | loss: 0.0957312\n",
      "\tspeed: 0.0699s/iter; left time: 679.3482s\n",
      "Epoch: 13 cost time: 18.243611335754395\n",
      "Epoch: 13, Steps: 261 | Train Loss: 0.1323508 Vali Loss: 0.0951849 Test Loss: 0.1210698\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 1) (84, 32, 168, 1)\n",
      "test shape: (2688, 168, 1) (2688, 168, 1)\n",
      "mse:0.12212537229061127, mae:0.2644437253475189\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './crossformer_checkpoints/', 'seq_len': 96, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 50, 'batch_size': 32, 'pred_len': 336, 'data_split': []}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_reversal_il96_pl336_sl6_win2_fa10_dm256_nh4_el3_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.6178566\n",
      "\tspeed: 0.0671s/iter; left time: 852.1682s\n",
      "\titers: 200, epoch: 1 | loss: 0.3787122\n",
      "\tspeed: 0.0756s/iter; left time: 952.4659s\n",
      "Epoch: 1 cost time: 18.574339866638184\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.5885424 Vali Loss: 0.3126877 Test Loss: 0.3247581\n",
      "Validation loss decreased (inf --> 0.312688).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.3405474\n",
      "\tspeed: 0.0744s/iter; left time: 925.9662s\n",
      "\titers: 200, epoch: 2 | loss: 0.3712553\n",
      "\tspeed: 0.0726s/iter; left time: 895.7438s\n",
      "Epoch: 2 cost time: 18.853681802749634\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.3628582 Vali Loss: 0.2608804 Test Loss: 0.3453558\n",
      "Validation loss decreased (0.312688 --> 0.260880).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3790315\n",
      "\tspeed: 0.0714s/iter; left time: 870.6812s\n",
      "\titers: 200, epoch: 3 | loss: 0.3941154\n",
      "\tspeed: 0.0744s/iter; left time: 899.1330s\n",
      "Epoch: 3 cost time: 18.798726797103882\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.3329417 Vali Loss: 0.2247868 Test Loss: 0.3209021\n",
      "Validation loss decreased (0.260880 --> 0.224787).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.2682068\n",
      "\tspeed: 0.0701s/iter; left time: 836.8833s\n",
      "\titers: 200, epoch: 4 | loss: 0.3583926\n",
      "\tspeed: 0.0706s/iter; left time: 835.8955s\n",
      "Epoch: 4 cost time: 18.065171480178833\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.3219670 Vali Loss: 0.2283315 Test Loss: 0.3003721\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2831704\n",
      "\tspeed: 0.0688s/iter; left time: 803.1693s\n",
      "\titers: 200, epoch: 5 | loss: 0.2919349\n",
      "\tspeed: 0.0679s/iter; left time: 785.6591s\n",
      "Epoch: 5 cost time: 17.522078275680542\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.3092578 Vali Loss: 0.2144335 Test Loss: 0.3018636\n",
      "Validation loss decreased (0.224787 --> 0.214433).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.3135468\n",
      "\tspeed: 0.0708s/iter; left time: 808.6049s\n",
      "\titers: 200, epoch: 6 | loss: 0.4071989\n",
      "\tspeed: 0.0708s/iter; left time: 801.9531s\n",
      "Epoch: 6 cost time: 18.10314106941223\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.3029735 Vali Loss: 0.2465529 Test Loss: 0.2703490\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3139885\n",
      "\tspeed: 0.0689s/iter; left time: 769.2168s\n",
      "\titers: 200, epoch: 7 | loss: 0.3854073\n",
      "\tspeed: 0.0682s/iter; left time: 754.9020s\n",
      "Epoch: 7 cost time: 17.661603450775146\n",
      "Epoch: 7, Steps: 256 | Train Loss: 0.2955395 Vali Loss: 0.2194697 Test Loss: 0.2744973\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.2564847\n",
      "\tspeed: 0.0686s/iter; left time: 748.1016s\n",
      "\titers: 200, epoch: 8 | loss: 0.2686823\n",
      "\tspeed: 0.0710s/iter; left time: 767.5681s\n",
      "Epoch: 8 cost time: 17.91048765182495\n",
      "Epoch: 8, Steps: 256 | Train Loss: 0.2927456 Vali Loss: 0.2195547 Test Loss: 0.2771063\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 1) (79, 32, 336, 1)\n",
      "test shape: (2528, 336, 1) (2528, 336, 1)\n",
      "mse:0.3018636703491211, mae:0.4331677556037903\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_additive_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './crossformer_checkpoints/', 'seq_len': 96, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_additive_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive_reversal.csv', 'train_epochs': 50, 'batch_size': 32, 'pred_len': 720, 'data_split': []}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_additive_reversal_il96_pl720_sl6_win2_fa10_dm256_nh4_el3_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "\titers: 100, epoch: 1 | loss: 0.6914052\n",
      "\tspeed: 0.0733s/iter; left time: 887.4799s\n",
      "\titers: 200, epoch: 1 | loss: 0.4589005\n",
      "\tspeed: 0.0758s/iter; left time: 909.8756s\n",
      "Epoch: 1 cost time: 18.23123574256897\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.6714631 Vali Loss: 0.2651816 Test Loss: 0.5469815\n",
      "Validation loss decreased (inf --> 0.265182).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.4025124\n",
      "\tspeed: 0.0738s/iter; left time: 874.5745s\n",
      "\titers: 200, epoch: 2 | loss: 0.4524536\n",
      "\tspeed: 0.0757s/iter; left time: 890.3878s\n",
      "Epoch: 2 cost time: 18.300265073776245\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.4165806 Vali Loss: 0.2795911 Test Loss: 0.4508693\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3636915\n",
      "\tspeed: 0.0788s/iter; left time: 914.7629s\n",
      "\titers: 200, epoch: 3 | loss: 0.3867765\n",
      "\tspeed: 0.0752s/iter; left time: 865.7393s\n",
      "Epoch: 3 cost time: 18.73155379295349\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.3904007 Vali Loss: 0.2910040 Test Loss: 0.4246654\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.3637017\n",
      "\tspeed: 0.0740s/iter; left time: 840.7563s\n",
      "\titers: 200, epoch: 4 | loss: 0.3696530\n",
      "\tspeed: 0.0753s/iter; left time: 848.1908s\n",
      "Epoch: 4 cost time: 18.32002067565918\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.3846323 Vali Loss: 0.2988103 Test Loss: 0.4211014\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 1) (67, 32, 720, 1)\n",
      "test shape: (2144, 720, 1) (2144, 720, 1)\n",
      "mse:0.5469815135002136, mae:0.6026365756988525\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './crossformer_checkpoints/', 'seq_len': 96, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 50, 'batch_size': 32, 'pred_len': 24, 'data_split': []}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il96_pl24_sl6_win2_fa10_dm256_nh4_el3_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "\titers: 100, epoch: 1 | loss: 0.1751133\n",
      "\tspeed: 0.0657s/iter; left time: 867.6246s\n",
      "\titers: 200, epoch: 1 | loss: 0.1269769\n",
      "\tspeed: 0.0679s/iter; left time: 890.1197s\n",
      "Epoch: 1 cost time: 17.809616327285767\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.2848741 Vali Loss: 0.1037830 Test Loss: 0.1520535\n",
      "Validation loss decreased (inf --> 0.103783).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0781197\n",
      "\tspeed: 0.0714s/iter; left time: 924.0158s\n",
      "\titers: 200, epoch: 2 | loss: 0.0823714\n",
      "\tspeed: 0.0655s/iter; left time: 841.2099s\n",
      "Epoch: 2 cost time: 18.13638210296631\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.0863006 Vali Loss: 0.1282984 Test Loss: 0.1729605\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0637376\n",
      "\tspeed: 0.0696s/iter; left time: 882.1401s\n",
      "\titers: 200, epoch: 3 | loss: 0.0613444\n",
      "\tspeed: 0.0659s/iter; left time: 828.1335s\n",
      "Epoch: 3 cost time: 18.161828756332397\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.0642712 Vali Loss: 0.0690994 Test Loss: 0.0929268\n",
      "Validation loss decreased (0.103783 --> 0.069099).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0722884\n",
      "\tspeed: 0.0684s/iter; left time: 848.2773s\n",
      "\titers: 200, epoch: 4 | loss: 0.0467562\n",
      "\tspeed: 0.0719s/iter; left time: 885.0959s\n",
      "Epoch: 4 cost time: 18.808563709259033\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.0586410 Vali Loss: 0.0747106 Test Loss: 0.1049849\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0438476\n",
      "\tspeed: 0.0679s/iter; left time: 824.2202s\n",
      "\titers: 200, epoch: 5 | loss: 0.0537959\n",
      "\tspeed: 0.0695s/iter; left time: 837.0981s\n",
      "Epoch: 5 cost time: 18.56865930557251\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.0521325 Vali Loss: 0.0679850 Test Loss: 0.0894143\n",
      "Validation loss decreased (0.069099 --> 0.067985).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0504406\n",
      "\tspeed: 0.0785s/iter; left time: 932.2700s\n",
      "\titers: 200, epoch: 6 | loss: 0.0611764\n",
      "\tspeed: 0.0667s/iter; left time: 784.7825s\n",
      "Epoch: 6 cost time: 19.168436527252197\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.0498635 Vali Loss: 0.0713007 Test Loss: 0.0806750\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0379449\n",
      "\tspeed: 0.0672s/iter; left time: 780.4236s\n",
      "\titers: 200, epoch: 7 | loss: 0.0420541\n",
      "\tspeed: 0.0673s/iter; left time: 774.2251s\n",
      "Epoch: 7 cost time: 17.943280935287476\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.0473458 Vali Loss: 0.0688056 Test Loss: 0.0798041\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0371243\n",
      "\tspeed: 0.0654s/iter; left time: 741.0918s\n",
      "\titers: 200, epoch: 8 | loss: 0.0796933\n",
      "\tspeed: 0.0652s/iter; left time: 732.9847s\n",
      "Epoch: 8 cost time: 17.54969573020935\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.0461424 Vali Loss: 0.0718239 Test Loss: 0.0899395\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 1) (89, 32, 24, 1)\n",
      "test shape: (2848, 24, 1) (2848, 24, 1)\n",
      "mse:0.08941426128149033, mae:0.17854322493076324\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './crossformer_checkpoints/', 'seq_len': 96, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 50, 'batch_size': 32, 'pred_len': 48, 'data_split': []}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il96_pl48_sl6_win2_fa10_dm256_nh4_el3_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "\titers: 100, epoch: 1 | loss: 0.2308898\n",
      "\tspeed: 0.0631s/iter; left time: 829.7840s\n",
      "\titers: 200, epoch: 1 | loss: 0.1397934\n",
      "\tspeed: 0.0729s/iter; left time: 951.4694s\n",
      "Epoch: 1 cost time: 18.374540090560913\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.3133814 Vali Loss: 0.1495217 Test Loss: 0.1981197\n",
      "Validation loss decreased (inf --> 0.149522).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.1201756\n",
      "\tspeed: 0.0733s/iter; left time: 944.5376s\n",
      "\titers: 200, epoch: 2 | loss: 0.1542145\n",
      "\tspeed: 0.0715s/iter; left time: 914.2273s\n",
      "Epoch: 2 cost time: 19.293612957000732\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.1207188 Vali Loss: 0.1718367 Test Loss: 0.1935357\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0840381\n",
      "\tspeed: 0.0673s/iter; left time: 848.8658s\n",
      "\titers: 200, epoch: 3 | loss: 0.1035264\n",
      "\tspeed: 0.0674s/iter; left time: 844.3213s\n",
      "Epoch: 3 cost time: 17.82914090156555\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.0953516 Vali Loss: 0.1536415 Test Loss: 0.1846206\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.1092615\n",
      "\tspeed: 0.0662s/iter; left time: 818.0719s\n",
      "\titers: 200, epoch: 4 | loss: 0.0713671\n",
      "\tspeed: 0.0662s/iter; left time: 810.9966s\n",
      "Epoch: 4 cost time: 17.63092303276062\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.0869081 Vali Loss: 0.1516329 Test Loss: 0.1540639\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 1) (88, 32, 48, 1)\n",
      "test shape: (2816, 48, 1) (2816, 48, 1)\n",
      "mse:0.19811968505382538, mae:0.3040810525417328\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './crossformer_checkpoints/', 'seq_len': 96, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 50, 'batch_size': 32, 'pred_len': 168, 'data_split': []}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il96_pl168_sl6_win2_fa10_dm256_nh4_el3_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "\titers: 100, epoch: 1 | loss: 0.4601372\n",
      "\tspeed: 0.0739s/iter; left time: 957.4596s\n",
      "\titers: 200, epoch: 1 | loss: 0.3096033\n",
      "\tspeed: 0.0669s/iter; left time: 859.5958s\n",
      "Epoch: 1 cost time: 18.172160863876343\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.5095397 Vali Loss: 0.4594743 Test Loss: 0.5773609\n",
      "Validation loss decreased (inf --> 0.459474).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.2098146\n",
      "\tspeed: 0.0693s/iter; left time: 879.1232s\n",
      "\titers: 200, epoch: 2 | loss: 0.2813829\n",
      "\tspeed: 0.0669s/iter; left time: 842.2553s\n",
      "Epoch: 2 cost time: 17.76401138305664\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.2742126 Vali Loss: 0.4872995 Test Loss: 0.6574984\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1744477\n",
      "\tspeed: 0.0680s/iter; left time: 844.8405s\n",
      "\titers: 200, epoch: 3 | loss: 0.1693865\n",
      "\tspeed: 0.0668s/iter; left time: 823.2753s\n",
      "Epoch: 3 cost time: 17.68243908882141\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.2097015 Vali Loss: 0.4171520 Test Loss: 0.6278446\n",
      "Validation loss decreased (0.459474 --> 0.417152).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.1728295\n",
      "\tspeed: 0.0673s/iter; left time: 818.4623s\n",
      "\titers: 200, epoch: 4 | loss: 0.1602891\n",
      "\tspeed: 0.0661s/iter; left time: 797.3282s\n",
      "Epoch: 4 cost time: 17.52962875366211\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.1911500 Vali Loss: 0.3991170 Test Loss: 0.5808852\n",
      "Validation loss decreased (0.417152 --> 0.399117).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2227007\n",
      "\tspeed: 0.0672s/iter; left time: 800.5149s\n",
      "\titers: 200, epoch: 5 | loss: 0.1264927\n",
      "\tspeed: 0.0681s/iter; left time: 803.8077s\n",
      "Epoch: 5 cost time: 17.89373278617859\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.1727890 Vali Loss: 0.3410281 Test Loss: 0.5233444\n",
      "Validation loss decreased (0.399117 --> 0.341028).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.1985843\n",
      "\tspeed: 0.0798s/iter; left time: 928.8421s\n",
      "\titers: 200, epoch: 6 | loss: 0.1420148\n",
      "\tspeed: 0.0685s/iter; left time: 790.6696s\n",
      "Epoch: 6 cost time: 18.907011032104492\n",
      "Epoch: 6, Steps: 261 | Train Loss: 0.1664427 Vali Loss: 0.3207892 Test Loss: 0.4996638\n",
      "Validation loss decreased (0.341028 --> 0.320789).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1969826\n",
      "\tspeed: 0.0706s/iter; left time: 803.4276s\n",
      "\titers: 200, epoch: 7 | loss: 0.2188935\n",
      "\tspeed: 0.0677s/iter; left time: 764.3349s\n",
      "Epoch: 7 cost time: 18.190349817276\n",
      "Epoch: 7, Steps: 261 | Train Loss: 0.1585533 Vali Loss: 0.3437111 Test Loss: 0.5280804\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.1880207\n",
      "\tspeed: 0.0678s/iter; left time: 754.4734s\n",
      "\titers: 200, epoch: 8 | loss: 0.1563002\n",
      "\tspeed: 0.0721s/iter; left time: 795.1425s\n",
      "Epoch: 8 cost time: 18.522624254226685\n",
      "Epoch: 8, Steps: 261 | Train Loss: 0.1549927 Vali Loss: 0.3519609 Test Loss: 0.5198490\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1457804\n",
      "\tspeed: 0.0731s/iter; left time: 793.9022s\n",
      "\titers: 200, epoch: 9 | loss: 0.1581459\n",
      "\tspeed: 0.0720s/iter; left time: 775.2717s\n",
      "Epoch: 9 cost time: 19.041908264160156\n",
      "Epoch: 9, Steps: 261 | Train Loss: 0.1508499 Vali Loss: 0.3456305 Test Loss: 0.5227121\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 1) (84, 32, 168, 1)\n",
      "test shape: (2688, 168, 1) (2688, 168, 1)\n",
      "mse:0.49966371059417725, mae:0.506384551525116\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './crossformer_checkpoints/', 'seq_len': 96, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 50, 'batch_size': 32, 'pred_len': 336, 'data_split': []}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il96_pl336_sl6_win2_fa10_dm256_nh4_el3_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.6742159\n",
      "\tspeed: 0.0710s/iter; left time: 901.1757s\n",
      "\titers: 200, epoch: 1 | loss: 0.4212921\n",
      "\tspeed: 0.0691s/iter; left time: 870.1401s\n",
      "Epoch: 1 cost time: 17.89431667327881\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.6601811 Vali Loss: 0.9494607 Test Loss: 1.2590936\n",
      "Validation loss decreased (inf --> 0.949461).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.2626663\n",
      "\tspeed: 0.0746s/iter; left time: 928.5243s\n",
      "\titers: 200, epoch: 2 | loss: 0.4631708\n",
      "\tspeed: 0.0755s/iter; left time: 932.1752s\n",
      "Epoch: 2 cost time: 19.113226175308228\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.3819508 Vali Loss: 0.7958412 Test Loss: 1.0704675\n",
      "Validation loss decreased (0.949461 --> 0.795841).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2669344\n",
      "\tspeed: 0.0726s/iter; left time: 884.8650s\n",
      "\titers: 200, epoch: 3 | loss: 0.3679341\n",
      "\tspeed: 0.0685s/iter; left time: 828.4620s\n",
      "Epoch: 3 cost time: 18.171984434127808\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.3168348 Vali Loss: 0.7816096 Test Loss: 1.0641203\n",
      "Validation loss decreased (0.795841 --> 0.781610).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.2678368\n",
      "\tspeed: 0.0737s/iter; left time: 878.8784s\n",
      "\titers: 200, epoch: 4 | loss: 0.2266817\n",
      "\tspeed: 0.0680s/iter; left time: 804.4927s\n",
      "Epoch: 4 cost time: 18.080470323562622\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.2908038 Vali Loss: 0.6372617 Test Loss: 1.0000680\n",
      "Validation loss decreased (0.781610 --> 0.637262).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2214874\n",
      "\tspeed: 0.0745s/iter; left time: 869.6109s\n",
      "\titers: 200, epoch: 5 | loss: 0.2708155\n",
      "\tspeed: 0.0694s/iter; left time: 802.8903s\n",
      "Epoch: 5 cost time: 18.38738703727722\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.2535447 Vali Loss: 0.6504655 Test Loss: 0.9186308\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.2127506\n",
      "\tspeed: 0.0697s/iter; left time: 796.0303s\n",
      "\titers: 200, epoch: 6 | loss: 0.2375511\n",
      "\tspeed: 0.0701s/iter; left time: 793.2818s\n",
      "Epoch: 6 cost time: 17.87769341468811\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.2401272 Vali Loss: 0.6209000 Test Loss: 0.9191648\n",
      "Validation loss decreased (0.637262 --> 0.620900).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1989628\n",
      "\tspeed: 0.0764s/iter; left time: 852.9294s\n",
      "\titers: 200, epoch: 7 | loss: 0.1820146\n",
      "\tspeed: 0.0706s/iter; left time: 781.0055s\n",
      "Epoch: 7 cost time: 18.60134220123291\n",
      "Epoch: 7, Steps: 256 | Train Loss: 0.2248894 Vali Loss: 0.6073796 Test Loss: 0.8908033\n",
      "Validation loss decreased (0.620900 --> 0.607380).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.2471929\n",
      "\tspeed: 0.0670s/iter; left time: 730.8973s\n",
      "\titers: 200, epoch: 8 | loss: 0.2695198\n",
      "\tspeed: 0.0684s/iter; left time: 739.5570s\n",
      "Epoch: 8 cost time: 17.499814748764038\n",
      "Epoch: 8, Steps: 256 | Train Loss: 0.2168052 Vali Loss: 0.6298349 Test Loss: 0.9081693\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1526903\n",
      "\tspeed: 0.0662s/iter; left time: 705.5405s\n",
      "\titers: 200, epoch: 9 | loss: 0.1831732\n",
      "\tspeed: 0.0663s/iter; left time: 699.9526s\n",
      "Epoch: 9 cost time: 17.04209542274475\n",
      "Epoch: 9, Steps: 256 | Train Loss: 0.2073972 Vali Loss: 0.5482360 Test Loss: 0.8455657\n",
      "Validation loss decreased (0.607380 --> 0.548236).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.2005072\n",
      "\tspeed: 0.0668s/iter; left time: 694.1762s\n",
      "\titers: 200, epoch: 10 | loss: 0.2130346\n",
      "\tspeed: 0.0688s/iter; left time: 708.7222s\n",
      "Epoch: 10 cost time: 17.651384353637695\n",
      "Epoch: 10, Steps: 256 | Train Loss: 0.2070949 Vali Loss: 0.5950987 Test Loss: 0.8707140\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1704761\n",
      "\tspeed: 0.0706s/iter; left time: 716.3289s\n",
      "\titers: 200, epoch: 11 | loss: 0.2223033\n",
      "\tspeed: 0.0773s/iter; left time: 775.7386s\n",
      "Epoch: 11 cost time: 19.079925537109375\n",
      "Epoch: 11, Steps: 256 | Train Loss: 0.2031252 Vali Loss: 0.5871920 Test Loss: 0.8579856\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 12 | loss: 0.2379216\n",
      "\tspeed: 0.0691s/iter; left time: 682.8478s\n",
      "\titers: 200, epoch: 12 | loss: 0.1858564\n",
      "\tspeed: 0.0743s/iter; left time: 726.8862s\n",
      "Epoch: 12 cost time: 18.326619386672974\n",
      "Epoch: 12, Steps: 256 | Train Loss: 0.2008728 Vali Loss: 0.5544165 Test Loss: 0.8436658\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 1) (79, 32, 336, 1)\n",
      "test shape: (2528, 336, 1) (2528, 336, 1)\n",
      "mse:0.8455656170845032, mae:0.6893524527549744\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './crossformer_checkpoints/', 'seq_len': 96, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'save_pred': True, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 50, 'batch_size': 32, 'pred_len': 720, 'data_split': []}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il96_pl720_sl6_win2_fa10_dm256_nh4_el3_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "\titers: 100, epoch: 1 | loss: 0.6809568\n",
      "\tspeed: 0.0755s/iter; left time: 913.1061s\n",
      "\titers: 200, epoch: 1 | loss: 0.4603246\n",
      "\tspeed: 0.0764s/iter; left time: 917.0914s\n",
      "Epoch: 1 cost time: 18.63644027709961\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.7042890 Vali Loss: 1.0915201 Test Loss: 1.5827521\n",
      "Validation loss decreased (inf --> 1.091520).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.3432640\n",
      "\tspeed: 0.0774s/iter; left time: 917.4366s\n",
      "\titers: 200, epoch: 2 | loss: 0.4450567\n",
      "\tspeed: 0.0766s/iter; left time: 900.2234s\n",
      "Epoch: 2 cost time: 19.160502672195435\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.3973775 Vali Loss: 1.0468098 Test Loss: 1.5651269\n",
      "Validation loss decreased (1.091520 --> 1.046810).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3892049\n",
      "\tspeed: 0.0787s/iter; left time: 914.3158s\n",
      "\titers: 200, epoch: 3 | loss: 0.4021516\n",
      "\tspeed: 0.0758s/iter; left time: 873.1273s\n",
      "Epoch: 3 cost time: 18.835811376571655\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.3605535 Vali Loss: 0.9826884 Test Loss: 1.4995134\n",
      "Validation loss decreased (1.046810 --> 0.982688).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.3416696\n",
      "\tspeed: 0.0808s/iter; left time: 918.1872s\n",
      "\titers: 200, epoch: 4 | loss: 0.2630205\n",
      "\tspeed: 0.0748s/iter; left time: 842.4667s\n",
      "Epoch: 4 cost time: 18.836008071899414\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.3299711 Vali Loss: 0.9536030 Test Loss: 1.4313759\n",
      "Validation loss decreased (0.982688 --> 0.953603).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3394025\n",
      "\tspeed: 0.0741s/iter; left time: 823.8076s\n",
      "\titers: 200, epoch: 5 | loss: 0.3056203\n",
      "\tspeed: 0.0736s/iter; left time: 811.1567s\n",
      "Epoch: 5 cost time: 18.045185804367065\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.3051573 Vali Loss: 1.0056454 Test Loss: 1.5263226\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 6 | loss: 0.3281847\n",
      "\tspeed: 0.0720s/iter; left time: 783.7922s\n",
      "\titers: 200, epoch: 6 | loss: 0.2734567\n",
      "\tspeed: 0.0746s/iter; left time: 804.2357s\n",
      "Epoch: 6 cost time: 18.15618872642517\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.2931126 Vali Loss: 1.0103567 Test Loss: 1.4705327\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2716510\n",
      "\tspeed: 0.0783s/iter; left time: 833.3904s\n",
      "\titers: 200, epoch: 7 | loss: 0.3157644\n",
      "\tspeed: 0.0761s/iter; left time: 802.0379s\n",
      "Epoch: 7 cost time: 18.9662446975708\n",
      "Epoch: 7, Steps: 244 | Train Loss: 0.2827424 Vali Loss: 0.9234978 Test Loss: 1.4135005\n",
      "Validation loss decreased (0.953603 --> 0.923498).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.3198293\n",
      "\tspeed: 0.0766s/iter; left time: 796.4997s\n",
      "\titers: 200, epoch: 8 | loss: 0.2825864\n",
      "\tspeed: 0.0772s/iter; left time: 795.0023s\n",
      "Epoch: 8 cost time: 18.808608531951904\n",
      "Epoch: 8, Steps: 244 | Train Loss: 0.2770245 Vali Loss: 0.9080386 Test Loss: 1.4027228\n",
      "Validation loss decreased (0.923498 --> 0.908039).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.2708693\n",
      "\tspeed: 0.0777s/iter; left time: 788.8466s\n",
      "\titers: 200, epoch: 9 | loss: 0.2300629\n",
      "\tspeed: 0.0792s/iter; left time: 795.9076s\n",
      "Epoch: 9 cost time: 19.139073848724365\n",
      "Epoch: 9, Steps: 244 | Train Loss: 0.2680495 Vali Loss: 0.8663304 Test Loss: 1.4164159\n",
      "Validation loss decreased (0.908039 --> 0.866330).  Saving model ...\n",
      "\titers: 100, epoch: 10 | loss: 0.2597822\n",
      "\tspeed: 0.0773s/iter; left time: 765.6421s\n",
      "\titers: 200, epoch: 10 | loss: 0.2982321\n",
      "\tspeed: 0.0752s/iter; left time: 737.2407s\n",
      "Epoch: 10 cost time: 18.378385305404663\n",
      "Epoch: 10, Steps: 244 | Train Loss: 0.2645968 Vali Loss: 0.8608647 Test Loss: 1.3783368\n",
      "Validation loss decreased (0.866330 --> 0.860865).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.2711927\n",
      "\tspeed: 0.0743s/iter; left time: 717.8969s\n",
      "\titers: 200, epoch: 11 | loss: 0.2577450\n",
      "\tspeed: 0.0752s/iter; left time: 718.7057s\n",
      "Epoch: 11 cost time: 18.342252254486084\n",
      "Epoch: 11, Steps: 244 | Train Loss: 0.2608988 Vali Loss: 0.8472231 Test Loss: 1.3774216\n",
      "Validation loss decreased (0.860865 --> 0.847223).  Saving model ...\n",
      "\titers: 100, epoch: 12 | loss: 0.2972504\n",
      "\tspeed: 0.0756s/iter; left time: 712.3136s\n",
      "\titers: 200, epoch: 12 | loss: 0.2462232\n",
      "\tspeed: 0.0745s/iter; left time: 694.3492s\n",
      "Epoch: 12 cost time: 18.316632509231567\n",
      "Epoch: 12, Steps: 244 | Train Loss: 0.2577717 Vali Loss: 0.8431054 Test Loss: 1.3547262\n",
      "Validation loss decreased (0.847223 --> 0.843105).  Saving model ...\n",
      "\titers: 100, epoch: 13 | loss: 0.2828492\n",
      "\tspeed: 0.0797s/iter; left time: 731.3401s\n",
      "\titers: 200, epoch: 13 | loss: 0.2556635\n",
      "\tspeed: 0.0782s/iter; left time: 709.7794s\n",
      "Epoch: 13 cost time: 19.266804933547974\n",
      "Epoch: 13, Steps: 244 | Train Loss: 0.2579926 Vali Loss: 0.8412653 Test Loss: 1.3682815\n",
      "Validation loss decreased (0.843105 --> 0.841265).  Saving model ...\n",
      "\titers: 100, epoch: 14 | loss: 0.2704043\n",
      "\tspeed: 0.0776s/iter; left time: 693.2665s\n",
      "\titers: 200, epoch: 14 | loss: 0.2492000\n",
      "\tspeed: 0.0758s/iter; left time: 668.8355s\n",
      "Epoch: 14 cost time: 18.639381647109985\n",
      "Epoch: 14, Steps: 244 | Train Loss: 0.2562767 Vali Loss: 0.8139351 Test Loss: 1.3339384\n",
      "Validation loss decreased (0.841265 --> 0.813935).  Saving model ...\n",
      "\titers: 100, epoch: 15 | loss: 0.3261905\n",
      "\tspeed: 0.0765s/iter; left time: 663.9849s\n",
      "\titers: 200, epoch: 15 | loss: 0.2591085\n",
      "\tspeed: 0.0760s/iter; left time: 652.6561s\n",
      "Epoch: 15 cost time: 18.6231791973114\n",
      "Epoch: 15, Steps: 244 | Train Loss: 0.2540902 Vali Loss: 0.8472874 Test Loss: 1.3519214\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 16 | loss: 0.2869460\n",
      "\tspeed: 0.0778s/iter; left time: 656.6347s\n",
      "\titers: 200, epoch: 16 | loss: 0.2751093\n",
      "\tspeed: 0.0742s/iter; left time: 618.9068s\n",
      "Epoch: 16 cost time: 18.57058572769165\n",
      "Epoch: 16, Steps: 244 | Train Loss: 0.2519433 Vali Loss: 0.8778079 Test Loss: 1.3747682\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 17 | loss: 0.2717316\n",
      "\tspeed: 0.0770s/iter; left time: 631.4319s\n",
      "\titers: 200, epoch: 17 | loss: 0.2431477\n",
      "\tspeed: 0.0780s/iter; left time: 631.2686s\n",
      "Epoch: 17 cost time: 19.12213110923767\n",
      "Epoch: 17, Steps: 244 | Train Loss: 0.2494605 Vali Loss: 0.8380948 Test Loss: 1.3567026\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 1) (67, 32, 720, 1)\n",
      "test shape: (2144, 720, 1) (2144, 720, 1)\n",
      "mse:1.3339383602142334, mae:0.885800302028656\n",
      "\n",
      "Moving to next...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    'SYNTHh1': './SYNTHDataset/',\n",
    "    'DEWINDh_small': './WINDataset/' ,\n",
    "    'SYNTH_additive' : './SYNTHDataset/' ,\n",
    "    'SYNTH_additive_reversal' : './SYNTHDataset/' ,\n",
    "    'SYNTH_multiplicative' : './SYNTHDataset/',\n",
    "    'SYNTH_multiplicative_reversal' : './SYNTHDataset/' \n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "\n",
    "models = [CrossformerTS , InformerTS]\n",
    "\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "\n",
    "    for dataset_name, dataset_path in datasets.items():\n",
    "        for pred_len in pred_lens:\n",
    "            print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "            # High amount of epochs to accomodate all models\n",
    "            # Early stopping should kick in anyways\n",
    "            model.fit(\n",
    "                data=dataset_name,\n",
    "                data_root_path=dataset_path,\n",
    "                batch_size=32,\n",
    "                epochs=50, # very high\n",
    "                pred_len=pred_len\n",
    "            )\n",
    "\n",
    "            predictions = model.predict()\n",
    "\n",
    "\n",
    "            print(f'\\nMoving to next...\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: PyraformerTS\n",
      "Training PyraformerTS on SYNTH_additive_reversal with pred_len 24\n",
      "[Info] Number of parameters: 8964864\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11329\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2857\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.12463elapse: 0.227 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 0, mse:0.030385686084628105, mae:0.13630013167858124, rmse:0.17431490123271942, mape:3.138979911804199, mspe:22122.99609375\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05554elapse: 0.229 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 1, mse:0.016809288412332535, mae:0.10002177208662033, rmse:0.12965063750743866, mape:1.862982153892517, mspe:5758.51513671875\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05259elapse: 0.229 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 2, mse:0.015744563192129135, mae:0.0970994159579277, rmse:0.12547734379768372, mape:1.779593825340271, mspe:4450.25927734375\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05276elapse: 0.229 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 3, mse:0.015939801931381226, mae:0.09775789827108383, rmse:0.1262529343366623, mape:1.6245791912078857, mspe:3689.981201171875\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05256elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 4, mse:0.015748687088489532, mae:0.09707029908895493, rmse:0.12549377977848053, mape:1.6747183799743652, mspe:3977.848876953125\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05244elapse: 0.231 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 5, mse:0.015779705718159676, mae:0.09709719568490982, rmse:0.12561729550361633, mape:1.6458181142807007, mspe:3838.58056640625\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05224elapse: 0.232 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 6, mse:0.015798337757587433, mae:0.09722108393907547, rmse:0.12569144368171692, mape:1.7109215259552002, mspe:4189.31494140625\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05245elapse: 0.231 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 7, mse:0.015932029113173485, mae:0.0977240651845932, rmse:0.1262221485376358, mape:1.6414316892623901, mspe:3742.52685546875\n",
      "Iteration best metrics: [0.015744563192129135, 0.0970994159579277, 0.12547734379768372, 1.779593825340271, 4450.25927734375]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11329\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2857\n",
      "168 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2857, 24, 1) (2857, 24, 1)\n",
      "test shape: (2857, 24, 1) (2857, 24, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_additive_reversal with pred_len 48\n",
      "[Info] Number of parameters: 9014016\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11305\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2833\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.13415elapse: 0.222 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 0, mse:0.0697070062160492, mae:0.21135735511779785, rmse:0.2640208303928375, mape:5.129183292388916, mspe:58126.41796875\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06059elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 1, mse:0.026616008952260017, mae:0.1254148930311203, rmse:0.16314414143562317, mape:2.0004866123199463, mspe:5714.72900390625\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05737elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 2, mse:0.026246333494782448, mae:0.12385740876197815, rmse:0.1620071977376938, mape:1.8583953380584717, mspe:4094.958251953125\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05686elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 3, mse:0.025997931137681007, mae:0.1237110048532486, rmse:0.16123874485492706, mape:1.9344335794448853, mspe:4448.75634765625\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05663elapse: 0.228 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 4, mse:0.026126159355044365, mae:0.12406444549560547, rmse:0.1616358906030655, mape:1.9380528926849365, mspe:4569.642578125\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05712elapse: 0.229 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 5, mse:0.026116741821169853, mae:0.12342649698257446, rmse:0.16160674393177032, mape:1.8813027143478394, mspe:4036.623046875\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05684elapse: 0.229 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 6, mse:0.026046544313430786, mae:0.12357837706804276, rmse:0.16138942539691925, mape:1.9508745670318604, mspe:4999.951171875\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05657elapse: 0.228 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 7, mse:0.026299066841602325, mae:0.12422481924295425, rmse:0.16216987371444702, mape:1.9965087175369263, mspe:4748.71728515625\n",
      "Iteration best metrics: [0.025997931137681007, 0.1237110048532486, 0.16123874485492706, 1.9344335794448853, 4448.75634765625]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11305\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2833\n",
      "168 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2833, 48, 1) (2833, 48, 1)\n",
      "test shape: (2833, 48, 1) (2833, 48, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_additive_reversal with pred_len 168\n",
      "[Info] Number of parameters: 9259776\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11185\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2713\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17034elapse: 0.225 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 0, mse:0.09959065914154053, mae:0.24190039932727814, rmse:0.315579891204834, mape:3.7987680435180664, mspe:32583.453125\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08012elapse: 0.228 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 1, mse:0.0874062031507492, mae:0.2243581861257553, rmse:0.29564541578292847, mape:3.1772444248199463, mspe:20136.69921875\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.07677elapse: 0.229 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 2, mse:0.0827343687415123, mae:0.22030457854270935, rmse:0.28763583302497864, mape:2.699228048324585, mspe:10867.5927734375\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.07552elapse: 0.228 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 3, mse:0.0813506543636322, mae:0.2167675644159317, rmse:0.28522035479545593, mape:2.921388864517212, mspe:14878.18359375\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.07581elapse: 0.225 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 4, mse:0.08174850046634674, mae:0.2179768979549408, rmse:0.2859169542789459, mape:2.7961714267730713, mspe:13040.0126953125\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.07511elapse: 0.227 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 5, mse:0.08163559436798096, mae:0.21824462711811066, rmse:0.2857194244861603, mape:2.8293404579162598, mspe:13305.9462890625\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.07570elapse: 0.227 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 6, mse:0.0796409398317337, mae:0.214540496468544, rmse:0.2822072505950928, mape:2.9900929927825928, mspe:16925.130859375\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.07522elapse: 0.227 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 7, mse:0.08167192339897156, mae:0.21764682233333588, rmse:0.28578299283981323, mape:2.783440589904785, mspe:12732.796875\n",
      "Iteration best metrics: [0.0796409398317337, 0.214540496468544, 0.2822072505950928, 2.9900929927825928, 16925.130859375]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11185\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2713\n",
      "168 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2713, 168, 1) (2713, 168, 1)\n",
      "test shape: (2713, 168, 1) (2713, 168, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_additive_reversal with pred_len 336\n",
      "[Info] Number of parameters: 9603840\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11017\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2545\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.24618elapse: 0.227 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 0, mse:0.19123807549476624, mae:0.332663357257843, rmse:0.437307745218277, mape:2.7197160720825195, mspe:11053.802734375\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11839elapse: 0.220 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 1, mse:0.15539543330669403, mae:0.2972487807273865, rmse:0.39420226216316223, mape:2.5726444721221924, mspe:9929.3896484375\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11013elapse: 0.218 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 2, mse:0.1538497507572174, mae:0.2965002655982971, rmse:0.3922368586063385, mape:2.5661983489990234, mspe:9364.037109375\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11039elapse: 0.219 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 3, mse:0.16378247737884521, mae:0.3057706952095032, rmse:0.40470048785209656, mape:2.6945366859436035, mspe:11085.5732421875\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11060elapse: 0.219 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 4, mse:0.15124011039733887, mae:0.29394593834877014, rmse:0.38889601826667786, mape:2.4927594661712646, mspe:8008.88623046875\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11072elapse: 0.222 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 5, mse:0.17005744576454163, mae:0.31181952357292175, rmse:0.4123802185058594, mape:2.7008631229400635, mspe:10744.0625\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.10960elapse: 0.221 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 6, mse:0.15033385157585144, mae:0.2937151789665222, rmse:0.38772910833358765, mape:2.6726443767547607, mspe:12522.8515625\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11096elapse: 0.223 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 7, mse:0.16574986279010773, mae:0.30783772468566895, rmse:0.4071238934993744, mape:2.642529249191284, mspe:9635.74609375\n",
      "Iteration best metrics: [0.15033385157585144, 0.2937151789665222, 0.38772910833358765, 2.6726443767547607, 12522.8515625]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11017\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2545\n",
      "168 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2545, 336, 1) (2545, 336, 1)\n",
      "test shape: (2545, 336, 1) (2545, 336, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_additive_reversal with pred_len 720\n",
      "[Info] Number of parameters: 10390272\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 10633\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2161\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.31751elapse: 0.214 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 0, mse:0.2598359286785126, mae:0.4123225808143616, rmse:0.5097410678863525, mape:2.610276460647583, mspe:8338.197265625\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.18244elapse: 0.215 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 1, mse:0.23470550775527954, mae:0.3865637183189392, rmse:0.4844641387462616, mape:2.4669830799102783, mspe:7919.4853515625\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17466elapse: 0.213 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 2, mse:0.2273368090391159, mae:0.38025975227355957, rmse:0.47679850459098816, mape:2.3190901279449463, mspe:5948.630859375\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17204elapse: 0.215 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 3, mse:0.23853810131549835, mae:0.38759320974349976, rmse:0.4884036183357239, mape:2.3877744674682617, mspe:6089.75\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17267elapse: 0.215 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 4, mse:0.2241462767124176, mae:0.3777919411659241, rmse:0.47344088554382324, mape:2.4224069118499756, mspe:7935.583984375\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17231elapse: 0.215 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 5, mse:0.22697235643863678, mae:0.3803538978099823, rmse:0.4764161705970764, mape:2.3714301586151123, mspe:6502.134765625\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17366elapse: 0.216 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 6, mse:0.22778771817684174, mae:0.38016459345817566, rmse:0.47727110981941223, mape:2.372667074203491, mspe:6597.09130859375\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17266elapse: 0.207 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 7, mse:0.23308710753917694, mae:0.38352033495903015, rmse:0.4827909469604492, mape:2.3808655738830566, mspe:6743.40185546875\n",
      "Iteration best metrics: [0.2241462767124176, 0.3777919411659241, 0.47344088554382324, 2.4224069118499756, 7935.583984375]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 10633\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2161\n",
      "168 720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2161, 720, 1) (2161, 720, 1)\n",
      "test shape: (2161, 720, 1) (2161, 720, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_multiplicative_reversal with pred_len 24\n",
      "[Info] Number of parameters: 8964864\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11329\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2857\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.13487elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 0, mse:0.054423604160547256, mae:0.13550762832164764, rmse:0.23328867554664612, mape:0.6528280377388, mspe:24.20671272277832\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06188elapse: 0.233 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 1, mse:0.04200853034853935, mae:0.09745132923126221, rmse:0.20495982468128204, mape:0.4180735647678375, mspe:7.893537998199463\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05881elapse: 0.231 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 2, mse:0.041169315576553345, mae:0.09249523282051086, rmse:0.20290222764015198, mape:0.3735812306404114, mspe:5.595581531524658\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05859elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 3, mse:0.04146444797515869, mae:0.09313356131315231, rmse:0.20362821221351624, mape:0.3749549090862274, mspe:5.80863618850708\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05867elapse: 0.234 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 4, mse:0.04175661504268646, mae:0.09365979582071304, rmse:0.20434434711933136, mape:0.37234562635421753, mspe:5.5688157081604\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05868elapse: 0.233 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 5, mse:0.041568219661712646, mae:0.09364305436611176, rmse:0.2038828581571579, mape:0.3737034201622009, mspe:5.684425354003906\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05831elapse: 0.231 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 6, mse:0.04141351208090782, mae:0.09295229613780975, rmse:0.2035031020641327, mape:0.37631526589393616, mspe:5.867162227630615\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05823elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 7, mse:0.041744083166122437, mae:0.09336172044277191, rmse:0.20431369543075562, mape:0.38358572125434875, mspe:6.170446395874023\n",
      "Iteration best metrics: [0.041169315576553345, 0.09249523282051086, 0.20290222764015198, 0.3735812306404114, 5.595581531524658]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11329\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2857\n",
      "168 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2857, 24, 1) (2857, 24, 1)\n",
      "test shape: (2857, 24, 1) (2857, 24, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_multiplicative_reversal with pred_len 48\n",
      "[Info] Number of parameters: 9014016\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11305\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2833\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.13674elapse: 0.233 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 0, mse:0.07826147973537445, mae:0.15847347676753998, rmse:0.2797525227069855, mape:0.7057083249092102, mspe:26.324426651000977\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06511elapse: 0.236 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 1, mse:0.06394663453102112, mae:0.11742383986711502, rmse:0.25287672877311707, mape:0.5093844532966614, mspe:12.771432876586914\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06198elapse: 0.231 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 2, mse:0.06367592513561249, mae:0.11577551066875458, rmse:0.2523408830165863, mape:0.49530237913131714, mspe:12.196273803710938\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06137elapse: 0.228 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 3, mse:0.06391394883394241, mae:0.11685985326766968, rmse:0.25281208753585815, mape:0.493716835975647, mspe:11.875568389892578\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06163elapse: 0.232 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 4, mse:0.06372152268886566, mae:0.11548488587141037, rmse:0.2524312138557434, mape:0.5059415698051453, mspe:12.683375358581543\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06186elapse: 0.234 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 5, mse:0.06410426646471024, mae:0.11693796515464783, rmse:0.25318819284439087, mape:0.5195851922035217, mspe:13.584539413452148\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06201elapse: 0.232 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 6, mse:0.06317388266324997, mae:0.11452432721853256, rmse:0.25134414434432983, mape:0.4975792169570923, mspe:12.339132308959961\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06185elapse: 0.226 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 7, mse:0.06376206874847412, mae:0.11562452465295792, rmse:0.25251153111457825, mape:0.4909589886665344, mspe:11.7764253616333\n",
      "Iteration best metrics: [0.06317388266324997, 0.11452432721853256, 0.25134414434432983, 0.4975792169570923, 12.339132308959961]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11305\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2833\n",
      "168 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2833, 48, 1) (2833, 48, 1)\n",
      "test shape: (2833, 48, 1) (2833, 48, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_multiplicative_reversal with pred_len 168\n",
      "[Info] Number of parameters: 9259776\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11185\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2713\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.19146elapse: 0.219 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 0, mse:0.15904486179351807, mae:0.2546915113925934, rmse:0.39880427718162537, mape:1.0831661224365234, mspe:61.763282775878906\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08991elapse: 0.225 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 1, mse:0.14652018249034882, mae:0.21758978068828583, rmse:0.3827795386314392, mape:0.9284117817878723, mspe:44.9482536315918\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08458elapse: 0.226 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 2, mse:0.14761093258857727, mae:0.22236545383930206, rmse:0.38420167565345764, mape:0.9272558689117432, mspe:43.12239456176758\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08414elapse: 0.226 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 3, mse:0.14822155237197876, mae:0.22390177845954895, rmse:0.3849955201148987, mape:0.9314299821853638, mspe:43.224945068359375\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08358elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 4, mse:0.14861448109149933, mae:0.2237560898065567, rmse:0.3855054974555969, mape:0.9393736124038696, mspe:43.61248016357422\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08385elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 5, mse:0.14899884164333344, mae:0.2233242243528366, rmse:0.38600367307662964, mape:0.9427894949913025, mspe:43.61598587036133\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08487elapse: 0.226 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 6, mse:0.14924786984920502, mae:0.2232416570186615, rmse:0.3863261044025421, mape:0.9240940809249878, mspe:42.65793228149414\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08458elapse: 0.223 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 7, mse:0.14722491800785065, mae:0.22305436432361603, rmse:0.3836989998817444, mape:0.9215201139450073, mspe:42.7718391418457\n",
      "Iteration best metrics: [0.14652018249034882, 0.21758978068828583, 0.3827795386314392, 0.9284117817878723, 44.9482536315918]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11185\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2713\n",
      "168 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2713, 168, 1) (2713, 168, 1)\n",
      "test shape: (2713, 168, 1) (2713, 168, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_multiplicative_reversal with pred_len 336\n",
      "[Info] Number of parameters: 9603840\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11017\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2545\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.25724elapse: 0.218 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 0, mse:0.28819847106933594, mae:0.3737311363220215, rmse:0.5368412137031555, mape:1.5292261838912964, mspe:115.9893798828125\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.12704elapse: 0.221 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 1, mse:0.2723865807056427, mae:0.35819289088249207, rmse:0.5219066739082336, mape:1.5517406463623047, mspe:147.53271484375\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11925elapse: 0.220 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 2, mse:0.26373937726020813, mae:0.3464130163192749, rmse:0.513555645942688, mape:1.5004504919052124, mspe:135.27224731445312\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11942elapse: 0.222 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 3, mse:0.2650873064994812, mae:0.35032814741134644, rmse:0.514866292476654, mape:1.4832241535186768, mspe:129.9745330810547\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11805elapse: 0.220 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 4, mse:0.2642129063606262, mae:0.3479629456996918, rmse:0.5140164494514465, mape:1.4832603931427002, mspe:129.56068420410156\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11854elapse: 0.223 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 5, mse:0.2637527287006378, mae:0.34717226028442383, rmse:0.513568639755249, mape:1.4694819450378418, mspe:125.35221862792969\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11826elapse: 0.223 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 6, mse:0.2639804482460022, mae:0.3492424190044403, rmse:0.5137902498245239, mape:1.499796748161316, mspe:133.3153839111328\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11877elapse: 0.218 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 7, mse:0.2629651725292206, mae:0.3474605977535248, rmse:0.5128012895584106, mape:1.5031629800796509, mspe:134.48031616210938\n",
      "Iteration best metrics: [0.2629651725292206, 0.3474605977535248, 0.5128012895584106, 1.5031629800796509, 134.48031616210938]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11017\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2545\n",
      "168 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2545, 336, 1) (2545, 336, 1)\n",
      "test shape: (2545, 336, 1) (2545, 336, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_multiplicative_reversal with pred_len 720\n",
      "[Info] Number of parameters: 10390272\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 10633\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2161\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.31085elapse: 0.214 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 0, mse:0.6224310398101807, mae:0.6275787949562073, rmse:0.7889429926872253, mape:2.1987266540527344, mspe:185.2793731689453\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17705elapse: 0.214 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 1, mse:0.5888988971710205, mae:0.6019185781478882, rmse:0.7673974633216858, mape:2.164628267288208, mspe:173.62136840820312\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17005elapse: 0.216 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 2, mse:0.5720503330230713, mae:0.5886484980583191, rmse:0.7563400864601135, mape:2.0985002517700195, mspe:167.5712432861328\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.16839elapse: 0.209 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 3, mse:0.5643194913864136, mae:0.5801877975463867, rmse:0.7512120008468628, mape:2.0586233139038086, mspe:163.13470458984375\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.16848elapse: 0.223 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 4, mse:0.5737432241439819, mae:0.5893834829330444, rmse:0.7574583888053894, mape:2.118617296218872, mspe:173.4226531982422\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.16842elapse: 0.216 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 5, mse:0.5743357539176941, mae:0.5904881358146667, rmse:0.7578494548797607, mape:2.1150894165039062, mspe:169.11839294433594\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.16955elapse: 0.217 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 6, mse:0.5727700591087341, mae:0.5890669822692871, rmse:0.7568157315254211, mape:2.124436616897583, mspe:177.35447692871094\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.16892elapse: 0.215 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 7, mse:0.5688241720199585, mae:0.5847705006599426, rmse:0.7542043328285217, mape:2.081162691116333, mspe:164.38644409179688\n",
      "Iteration best metrics: [0.5643194913864136, 0.5801877975463867, 0.7512120008468628, 2.0586233139038086, 163.13470458984375]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 10633\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2161\n",
      "168 720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2161, 720, 1) (2161, 720, 1)\n",
      "test shape: (2161, 720, 1) (2161, 720, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    'SYNTHh1': './SYNTHDataset/',\n",
    "    'DEWINDh_small': './WINDataset/' ,\n",
    "    'SYNTH_additive' : './SYNTHDataset/' ,\n",
    "    'SYNTH_additive_reversal' : './SYNTHDataset/' ,\n",
    "    'SYNTH_multiplicative' : './SYNTHDataset/',\n",
    "    'SYNTH_multiplicative_reversal' : './SYNTHDataset/' \n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "\n",
    "models = [PyraformerTS]\n",
    "\n",
    "#result_dict_pyraformer = {}\n",
    "\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "\n",
    "    for dataset_name, dataset_path in datasets.items():\n",
    "        for pred_len in pred_lens:\n",
    "            print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "            # High amount of epochs to accomodate all models\n",
    "            # Early stopping should kick in anyways\n",
    "            model.fit(\n",
    "                data=dataset_name,\n",
    "                data_root_path=dataset_path,\n",
    "                batch_size=32,\n",
    "                epochs=8, \n",
    "                pred_len=pred_len\n",
    "            )\n",
    "\n",
    "            #pred_name = 'prediction_' + f'{transformermodel.__name__}_{dataset_name}_{pred_len}'\n",
    "            #true_name = 'true_' + f'{transformermodel.__name__}_{dataset_name}_{pred_len}'\n",
    "            \n",
    "\n",
    "            predictions , trues = model.predict()\n",
    "\n",
    "            #result_dict_pyraformer[pred_name] = predictions\n",
    "            #result_dict_pyraformer[true_name] = trues\n",
    "            \n",
    "\n",
    "            print(f'\\nMoving to next...\\n')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ansb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
