{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from exp.exp_main import Exp_Main\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    fix_seed = 2022\n",
    "    random.seed(fix_seed)\n",
    "    torch.manual_seed(fix_seed)\n",
    "    np.random.seed(fix_seed)\n",
    "    args = dotdict()\n",
    "    # basic config\n",
    "    args.model = 'LogSparse'\n",
    "    args.plot_flat = 0\n",
    "    args.verbose = 1\n",
    "    args.is_training = 1\n",
    "    args.inverse = False\n",
    "    # data loader\n",
    "    args.data = 'Wind'\n",
    "    args.root_path = './dataset_example/WindData/dataset/'\n",
    "    args.data_path ='wind_data.csv' \n",
    "    args.target = 'KVITEBJØRNFELTET'\n",
    "    args.freq = '10min'\n",
    "    args.checkpoints = './checkpoints/'\n",
    "    args.checkpoint_flag = 1\n",
    "    args.n_closet = None\n",
    "    args.all_stations = 0\n",
    "    args.data_step = 1\n",
    "    args.min_num_nodes = 2\n",
    "    # forecasting task\n",
    "    args.features = 'M' #univariate\n",
    "    args.seq_len = 96\n",
    "    args.label_len = 48\n",
    "    args.pred_len = 90\n",
    "    args.enc_in = 1\n",
    "    args.dec_in =1\n",
    "    args.c_out = 1\n",
    "    # model define\n",
    "    args.d_model = 512\n",
    "    args.n_heads = 8\n",
    "    args.e_layers = 2\n",
    "    args.d_layers = 1\n",
    "    args.d_ff = 2048\n",
    "    args.factor = 3\n",
    "    args.distil = True\n",
    "    args.dropout = 0.05\n",
    "    args.embed = 'timeF'\n",
    "    args.activation = 'gelu'\n",
    "    args.output_attention = False\n",
    "    args.win_len = 6\n",
    "    args.res_len = None\n",
    "    args.qk_ker = 4\n",
    "    args.v_conv = 0\n",
    "    args.sparse_flag = 1\n",
    "    args.top_keys = 0\n",
    "    args.kernel_size = 3\n",
    "    args.train_strat_lstm = 'recursive'\n",
    "    args.model_id= args.model + '_' + str(args.data) + '_' + str(args.pred_len)\n",
    "    args.test_dir = ''\n",
    "    # Optimization\n",
    "    args.num_workers = 0\n",
    "    args.itr = 1\n",
    "    args.train_epochs = 10\n",
    "    args.batch_size = 32\n",
    "    args.patience= 5\n",
    "    args.learning_rate = 0.001\n",
    "    args.lr_decay_rate = 0.8\n",
    "    args.des = 'test'\n",
    "    args.loss = 'mse'\n",
    "    args.lradj = 'type1'\n",
    "    # GPU\n",
    "    args.use_gpu = False \n",
    "    args.gpu = 0\n",
    "    args.use_multi_gpu = False\n",
    "    args.devices = '0,1,2,3'\n",
    "\n",
    "    args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "    if args.use_gpu and args.use_multi_gpu: \n",
    "        args.devices = args.devices.replace(' ', '')\n",
    "        device_ids = args.devices.split(',')\n",
    "        args.device_ids = [int(id_) for id_ in device_ids]\n",
    "        args.gpu = args.device_ids[0]\n",
    "\n",
    "    print('Args in experiment:')\n",
    "    print(args)\n",
    "\n",
    "    Exp = Exp_Main\n",
    "\n",
    "    if args.is_training:\n",
    "        for ii in range(args.itr):\n",
    "            # setting record of experiments\n",
    "            setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_{}'.format(\n",
    "                args.model_id,\n",
    "                args.model,\n",
    "                args.data,\n",
    "                args.features,\n",
    "                args.seq_len,\n",
    "                args.label_len,\n",
    "                args.pred_len,\n",
    "                ii)\n",
    "\n",
    "            exp = Exp(args)  # set experiments\n",
    "            print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "            exp.train(setting)\n",
    "\n",
    "            print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "            exp.test(setting, base_dir=args.test_dir)\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "    else:\n",
    "        ii = 0\n",
    "        setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_{}'.format(\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.data,\n",
    "            args.features,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            ii)\n",
    "\n",
    "        exp = Exp(args)  # set experiments\n",
    "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting, test=1)\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "{'model': 'LogSparse', 'plot_flat': 0, 'verbose': 1, 'is_training': 1, 'inverse': False, 'data': 'Wind', 'root_path': './dataset_example/WindData/dataset/', 'data_path': 'wind_data.csv', 'target': 'KVITEBJØRNFELTET', 'freq': '10min', 'checkpoints': './checkpoints/', 'checkpoint_flag': 1, 'n_closet': None, 'all_stations': 0, 'data_step': 1, 'min_num_nodes': 2, 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 90, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 3, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'win_len': 6, 'res_len': None, 'qk_ker': 4, 'v_conv': 0, 'sparse_flag': 1, 'top_keys': 0, 'kernel_size': 3, 'train_strat_lstm': 'recursive', 'model_id': 'LogSparse_Wind_90', 'num_workers': 0, 'itr': 1, 'train_epochs': 10, 'batch_size': 32, 'patience': 5, 'learning_rate': 0.001, 'lr_decay_rate': 0.8, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': False, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3'}\n",
      "Use CPU\n",
      ">>>>>>>start training : LogSparse_Wind_90_LogSparse_Wind_ftM_sl96_ll48_pl90_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 13\n",
      "val 13\n",
      "test 13\n",
      "Could not load best model\n",
      "Updating learning rate to 0.001\n",
      "Epoch: 1 cost time: 0.0004799365997314453\n",
      "Epoch: 1, Steps: 0 | Train Loss: nan Vali Loss: nan\n",
      "Validation loss decreased (inf --> nan).  Saving model ...\n",
      "Updating learning rate to 0.0008\n",
      "Epoch: 2 cost time: 0.00018095970153808594\n",
      "Epoch: 2, Steps: 0 | Train Loss: nan Vali Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 0.0006400000000000002\n",
      "Epoch: 3 cost time: 0.0003170967102050781\n",
      "Epoch: 3, Steps: 0 | Train Loss: nan Vali Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 0.0005120000000000001\n",
      "Epoch: 4 cost time: 0.00017118453979492188\n",
      "Epoch: 4, Steps: 0 | Train Loss: nan Vali Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 0.0004096000000000001\n",
      "Epoch: 5 cost time: 0.0002739429473876953\n",
      "Epoch: 5, Steps: 0 | Train Loss: nan Vali Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 0.0003276800000000001\n",
      "Epoch: 6 cost time: 0.00016689300537109375\n",
      "Epoch: 6, Steps: 0 | Train Loss: nan Vali Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 0.0002621440000000001\n",
      "Epoch: 7 cost time: 0.0003349781036376953\n",
      "Epoch: 7, Steps: 0 | Train Loss: nan Vali Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 0.0002097152000000001\n",
      "Epoch: 8 cost time: 0.00017523765563964844\n",
      "Epoch: 8, Steps: 0 | Train Loss: nan Vali Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 0.0001677721600000001\n",
      "Epoch: 9 cost time: 0.0002868175506591797\n",
      "Epoch: 9, Steps: 0 | Train Loss: nan Vali Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "Updating learning rate to 0.00013421772800000008\n",
      "Epoch: 10 cost time: 0.00015878677368164062\n",
      "Epoch: 10, Steps: 0 | Train Loss: nan Vali Loss: nan\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      ">>>>>>>testing : LogSparse_Wind_90_LogSparse_Wind_ftM_sl96_ll48_pl90_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 13\n",
      "loading model\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 101\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m         exp\u001b[38;5;241m.\u001b[39mtrain(setting)\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>testing : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(setting))\n\u001b[0;32m--> 101\u001b[0m         \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m         torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Github/IS_Seminar/TransformersEnergyTS/LogSparse/exp/exp_main.py:396\u001b[0m, in \u001b[0;36mExp_Main.test\u001b[0;34m(self, setting, test, base_dir, save_dir, ignore_paths, save_flag)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test:\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    397\u001b[0m         load_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./checkpoints/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m setting, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
