{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('seaborn-v0_8')\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# MSE function \n",
    "def MSE(pred, true):\n",
    "    return np.mean((pred-true)**2)\n",
    "\n",
    "random_seed = 100\n",
    "torch.manual_seed = 100\n",
    "np.random.seed = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InformerAPI import InformerTS\n",
    "from CrossformerAPI import CrossformerTS\n",
    "from AutoformerAPI import AutoformerTS\n",
    "from FedformerAPI import FedformerTS\n",
    "from PyraformerAPI import PyraformerTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping models in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'SYNTHh1': './SYNTHDataset/',\n",
    "    'DEWINDh_small': './WINDataset/' ,\n",
    "    'SYNTH_additive' : './SYNTHDataset/' , \n",
    "    'SYNTH_additive_reversal' : './SYNTHDataset/' ,\n",
    "    'SYNTH_multiplicative' : './SYNTHDataset/' ,\n",
    "    'SYNTH_multiplicative_reversal' : './SYNTHDataset/'\n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "\n",
    "models = [AutoformerTS, FedformerTS]\n",
    "\n",
    "result_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: FedformerTS\n",
      "Training FedformerTS on SYNTHh1 with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl24_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "Epoch: 1 cost time: 65.16380763053894\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.2622758 Vali Loss: 0.0958696 Test Loss: 0.0979099\n",
      "Validation loss decreased (inf --> 0.095870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 62.752004861831665\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.1016251 Vali Loss: 0.0833852 Test Loss: 0.0804521\n",
      "Validation loss decreased (0.095870 --> 0.083385).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 66.24701738357544\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.0882184 Vali Loss: 0.0720649 Test Loss: 0.0703608\n",
      "Validation loss decreased (0.083385 --> 0.072065).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 67.67151832580566\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.0800565 Vali Loss: 0.0701968 Test Loss: 0.0707113\n",
      "Validation loss decreased (0.072065 --> 0.070197).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 68.2637414932251\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.0747900 Vali Loss: 0.0641990 Test Loss: 0.0651344\n",
      "Validation loss decreased (0.070197 --> 0.064199).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 60.942933082580566\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.0718720 Vali Loss: 0.0651201 Test Loss: 0.0683536\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 70.8675377368927\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.0705077 Vali Loss: 0.0631342 Test Loss: 0.0658791\n",
      "Validation loss decreased (0.064199 --> 0.063134).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 74.24222350120544\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.0695275 Vali Loss: 0.0627513 Test Loss: 0.0653452\n",
      "Validation loss decreased (0.063134 --> 0.062751).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 74.18263983726501\n",
      "Epoch: 9, Steps: 266 | Train Loss: 0.0692555 Vali Loss: 0.0627041 Test Loss: 0.0654047\n",
      "Validation loss decreased (0.062751 --> 0.062704).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 69.2740786075592\n",
      "Epoch: 10, Steps: 266 | Train Loss: 0.0690241 Vali Loss: 0.0625783 Test Loss: 0.0652340\n",
      "Validation loss decreased (0.062704 --> 0.062578).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 66.56735253334045\n",
      "Epoch: 11, Steps: 266 | Train Loss: 0.0687436 Vali Loss: 0.0626013 Test Loss: 0.0652615\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 71.59506297111511\n",
      "Epoch: 12, Steps: 266 | Train Loss: 0.0686818 Vali Loss: 0.0625492 Test Loss: 0.0652689\n",
      "Validation loss decreased (0.062578 --> 0.062549).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 75.96273517608643\n",
      "Epoch: 13, Steps: 266 | Train Loss: 0.0688638 Vali Loss: 0.0626125 Test Loss: 0.0652519\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 67.62385320663452\n",
      "Epoch: 14, Steps: 266 | Train Loss: 0.0686548 Vali Loss: 0.0624748 Test Loss: 0.0652507\n",
      "Validation loss decreased (0.062549 --> 0.062475).  Saving model ...\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 67.02317714691162\n",
      "Epoch: 15, Steps: 266 | Train Loss: 0.0685920 Vali Loss: 0.0624342 Test Loss: 0.0652520\n",
      "Validation loss decreased (0.062475 --> 0.062434).  Saving model ...\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 69.63558053970337\n",
      "Epoch: 16, Steps: 266 | Train Loss: 0.0689014 Vali Loss: 0.0625766 Test Loss: 0.0652526\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.0517578125e-09\n",
      "Epoch: 17 cost time: 78.88778495788574\n",
      "Epoch: 17, Steps: 266 | Train Loss: 0.0686534 Vali Loss: 0.0625213 Test Loss: 0.0652519\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.52587890625e-09\n",
      "Epoch: 18 cost time: 67.18537974357605\n",
      "Epoch: 18, Steps: 266 | Train Loss: 0.0687823 Vali Loss: 0.0624668 Test Loss: 0.0652518\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 1) (89, 32, 24, 1)\n",
      "test shape: (2848, 24, 1) (2848, 24, 1)\n",
      "mse:0.06525204330682755, mae:0.21210964024066925\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl48_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "Epoch: 1 cost time: 85.43302178382874\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.2961777 Vali Loss: 0.1074879 Test Loss: 0.1124147\n",
      "Validation loss decreased (inf --> 0.107488).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 82.71987724304199\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.1159050 Vali Loss: 0.0940088 Test Loss: 0.1005454\n",
      "Validation loss decreased (0.107488 --> 0.094009).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 83.55789017677307\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.0911122 Vali Loss: 0.1160430 Test Loss: 0.1056600\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 82.2547287940979\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.0412276 Vali Loss: 0.1170206 Test Loss: 0.1084039\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 82.77264380455017\n",
      "Epoch: 5, Steps: 265 | Train Loss: 0.0384163 Vali Loss: 0.1198215 Test Loss: 0.1115995\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 1) (88, 32, 48, 1)\n",
      "test shape: (2816, 48, 1) (2816, 48, 1)\n",
      "mse:0.10054542869329453, mae:0.2656591534614563\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 9, 12, 13, 14, 15, 16, 17, 19, 20, 22, 24, 25, 26, 30, 32, 34, 36, 37, 42, 45, 47, 48, 52, 54, 55, 57, 61, 64, 65, 68, 69, 70, 71, 72, 73, 75, 76, 77, 79, 80, 82, 83, 84, 85, 90, 91, 92, 94, 95, 96, 98, 99, 100, 103, 105, 106]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 3, 5, 6, 9, 11, 13, 14, 15, 18, 19, 20, 24, 25, 27, 28, 30, 31, 32, 33, 37, 38, 39, 42, 44, 46, 47, 49, 50, 52, 53, 55, 56, 58, 60, 62, 64, 66, 67, 69, 70, 77, 78, 80, 81, 82, 83, 84, 86, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl168_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "Epoch: 1 cost time: 86.81678175926208\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.3380231 Vali Loss: 0.2696996 Test Loss: 0.3962550\n",
      "Validation loss decreased (inf --> 0.269700).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 96.68281483650208\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.2006405 Vali Loss: 0.2288464 Test Loss: 0.3212085\n",
      "Validation loss decreased (0.269700 --> 0.228846).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 100.87942695617676\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.1030630 Vali Loss: 0.3240111 Test Loss: 0.3204749\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 94.61479115486145\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.0676818 Vali Loss: 0.3299393 Test Loss: 0.3219820\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 94.50968170166016\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.0634867 Vali Loss: 0.3332740 Test Loss: 0.3234389\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 1) (84, 32, 168, 1)\n",
      "test shape: (2688, 168, 1) (2688, 168, 1)\n",
      "mse:0.32120853662490845, mae:0.46684420108795166\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[3, 7, 8, 11, 14, 18, 19, 21, 24, 26, 29, 35, 36, 37, 39, 40, 42, 44, 51, 56, 64, 65, 71, 72, 74, 76, 77, 80, 82, 83, 84, 85, 86, 88, 94, 95, 101, 106, 107, 112, 115, 118, 119, 120, 122, 125, 132, 136, 139, 145, 146, 149, 150, 156, 157, 162, 166, 173, 175, 176, 179, 181, 182, 184]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 3, 4, 7, 11, 17, 18, 20, 22, 24, 25, 29, 36, 38, 41, 42, 45, 46, 48, 52, 60, 64, 67, 68, 74, 76, 86, 90, 92, 96, 97, 100, 101, 103, 104, 105, 111, 115, 122, 123, 126, 130, 131, 134, 137, 138, 140, 143, 145, 146, 148, 151, 157, 162, 165, 169, 171, 174, 176, 177, 178, 179, 182, 191]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl336_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 136.74567246437073\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.6448343 Vali Loss: 0.5773084 Test Loss: 0.9059082\n",
      "Validation loss decreased (inf --> 0.577308).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 138.09175515174866\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.3290007 Vali Loss: 0.5133174 Test Loss: 0.8582950\n",
      "Validation loss decreased (0.577308 --> 0.513317).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 134.61821722984314\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.2994984 Vali Loss: 0.5038191 Test Loss: 0.8561960\n",
      "Validation loss decreased (0.513317 --> 0.503819).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 144.55647802352905\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.2920069 Vali Loss: 0.4927976 Test Loss: 0.8476861\n",
      "Validation loss decreased (0.503819 --> 0.492798).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 138.14357542991638\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.2879341 Vali Loss: 0.4807726 Test Loss: 0.8320661\n",
      "Validation loss decreased (0.492798 --> 0.480773).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 140.39829564094543\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.2848465 Vali Loss: 0.4775362 Test Loss: 0.8332866\n",
      "Validation loss decreased (0.480773 --> 0.477536).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 132.41144371032715\n",
      "Epoch: 7, Steps: 256 | Train Loss: 0.2838261 Vali Loss: 0.4787838 Test Loss: 0.8348544\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 137.89564657211304\n",
      "Epoch: 8, Steps: 256 | Train Loss: 0.2833602 Vali Loss: 0.4777366 Test Loss: 0.8337955\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 136.2236864566803\n",
      "Epoch: 9, Steps: 256 | Train Loss: 0.2823350 Vali Loss: 0.4785407 Test Loss: 0.8333014\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 1) (79, 32, 336, 1)\n",
      "test shape: (2528, 336, 1) (2528, 336, 1)\n",
      "mse:0.8332867622375488, mae:0.7153301239013672\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTHh1 with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTHh1', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTHh1.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 15, 16, 22, 29, 30, 33, 40, 49, 55, 56, 57, 61, 69, 70, 74, 75, 81, 82, 84, 106, 107, 111, 125, 127, 130, 131, 140, 144, 148, 153, 155, 160, 161, 176, 186, 194, 202, 219, 222, 227, 247, 248, 253, 257, 258, 259, 270, 283, 286, 294, 296, 306, 327, 331, 338, 340, 343, 350, 365, 368, 369, 370, 383]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[7, 11, 13, 16, 22, 23, 27, 32, 36, 48, 49, 55, 63, 65, 66, 78, 90, 96, 97, 102, 105, 108, 114, 115, 126, 132, 133, 134, 136, 161, 164, 166, 177, 179, 188, 189, 190, 195, 216, 225, 227, 231, 232, 242, 243, 250, 253, 254, 262, 273, 288, 294, 319, 320, 322, 327, 329, 338, 341, 348, 357, 358, 379, 380]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTHh1_ftS_sl96_ll48_pl720_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 155.4706552028656\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.4897954 Vali Loss: 0.2999372 Test Loss: 0.6046879\n",
      "Validation loss decreased (inf --> 0.299937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 154.00870513916016\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.1331194 Vali Loss: 0.2868610 Test Loss: 0.6266771\n",
      "Validation loss decreased (0.299937 --> 0.286861).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 154.89499139785767\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.1080418 Vali Loss: 0.2732387 Test Loss: 0.6049472\n",
      "Validation loss decreased (0.286861 --> 0.273239).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 152.15872359275818\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.1023389 Vali Loss: 0.2575334 Test Loss: 0.5830230\n",
      "Validation loss decreased (0.273239 --> 0.257533).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 154.80844449996948\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.1005052 Vali Loss: 0.2683795 Test Loss: 0.6003717\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 154.23212957382202\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.0997536 Vali Loss: 0.2739580 Test Loss: 0.6109940\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 153.46481704711914\n",
      "Epoch: 7, Steps: 244 | Train Loss: 0.0993424 Vali Loss: 0.2694975 Test Loss: 0.6025179\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 1) (67, 32, 720, 1)\n",
      "test shape: (2144, 720, 1) (2144, 720, 1)\n",
      "mse:0.5830230116844177, mae:0.6152520775794983\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl24_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "Epoch: 1 cost time: 72.37522506713867\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.2114821 Vali Loss: 0.1721330 Test Loss: 0.1754460\n",
      "Validation loss decreased (inf --> 0.172133).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 69.36662220954895\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.1479469 Vali Loss: 0.1574086 Test Loss: 0.1616093\n",
      "Validation loss decreased (0.172133 --> 0.157409).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 69.05121278762817\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.1293245 Vali Loss: 0.1515991 Test Loss: 0.1488951\n",
      "Validation loss decreased (0.157409 --> 0.151599).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 70.27343893051147\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.1240935 Vali Loss: 0.1496561 Test Loss: 0.1461690\n",
      "Validation loss decreased (0.151599 --> 0.149656).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 70.37175345420837\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.1216244 Vali Loss: 0.1465813 Test Loss: 0.1444247\n",
      "Validation loss decreased (0.149656 --> 0.146581).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 73.60788369178772\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.1203851 Vali Loss: 0.1465245 Test Loss: 0.1436537\n",
      "Validation loss decreased (0.146581 --> 0.146525).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 64.40801477432251\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.1197325 Vali Loss: 0.1462581 Test Loss: 0.1430382\n",
      "Validation loss decreased (0.146525 --> 0.146258).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 72.39297080039978\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.1193276 Vali Loss: 0.1464056 Test Loss: 0.1424594\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 77.23398017883301\n",
      "Epoch: 9, Steps: 266 | Train Loss: 0.1190036 Vali Loss: 0.1457477 Test Loss: 0.1425107\n",
      "Validation loss decreased (0.146258 --> 0.145748).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 75.30889296531677\n",
      "Epoch: 10, Steps: 266 | Train Loss: 0.1189171 Vali Loss: 0.1464164 Test Loss: 0.1427033\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 76.40240502357483\n",
      "Epoch: 11, Steps: 266 | Train Loss: 0.1190182 Vali Loss: 0.1461212 Test Loss: 0.1424635\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 66.84464526176453\n",
      "Epoch: 12, Steps: 266 | Train Loss: 0.1188472 Vali Loss: 0.1460604 Test Loss: 0.1424270\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 1) (89, 32, 24, 1)\n",
      "test shape: (2848, 24, 1) (2848, 24, 1)\n",
      "mse:0.14251071214675903, mae:0.2431260049343109\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl48_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "Epoch: 1 cost time: 82.68609857559204\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.2398062 Vali Loss: 0.1913295 Test Loss: 0.1926833\n",
      "Validation loss decreased (inf --> 0.191329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 80.61324048042297\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.1704890 Vali Loss: 0.1738000 Test Loss: 0.1810771\n",
      "Validation loss decreased (0.191329 --> 0.173800).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 76.70012331008911\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.1543370 Vali Loss: 0.1676580 Test Loss: 0.1713296\n",
      "Validation loss decreased (0.173800 --> 0.167658).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 81.129812002182\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.1496196 Vali Loss: 0.1630197 Test Loss: 0.1709165\n",
      "Validation loss decreased (0.167658 --> 0.163020).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 82.08459877967834\n",
      "Epoch: 5, Steps: 265 | Train Loss: 0.1472327 Vali Loss: 0.1646764 Test Loss: 0.1709053\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 77.71331930160522\n",
      "Epoch: 6, Steps: 265 | Train Loss: 0.1464615 Vali Loss: 0.1612807 Test Loss: 0.1679323\n",
      "Validation loss decreased (0.163020 --> 0.161281).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 73.55619144439697\n",
      "Epoch: 7, Steps: 265 | Train Loss: 0.1457253 Vali Loss: 0.1627410 Test Loss: 0.1685767\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 77.71450066566467\n",
      "Epoch: 8, Steps: 265 | Train Loss: 0.1453644 Vali Loss: 0.1615711 Test Loss: 0.1675281\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 70.3328104019165\n",
      "Epoch: 9, Steps: 265 | Train Loss: 0.1450566 Vali Loss: 0.1616879 Test Loss: 0.1673708\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 1) (88, 32, 48, 1)\n",
      "test shape: (2816, 48, 1) (2816, 48, 1)\n",
      "mse:0.16793231666088104, mae:0.26156046986579895\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 4, 6, 8, 9, 11, 13, 15, 16, 17, 18, 19, 23, 25, 26, 28, 29, 31, 36, 37, 38, 39, 40, 46, 47, 49, 50, 51, 54, 55, 57, 59, 61, 62, 64, 65, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 80, 82, 83, 85, 86, 87, 89, 90, 91, 95, 97, 98, 99, 101, 102, 104, 106, 107]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 2, 4, 6, 7, 8, 10, 11, 12, 17, 18, 20, 22, 24, 28, 29, 31, 32, 35, 37, 38, 40, 41, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 74, 76, 78, 79, 82, 83, 85, 87, 88, 92, 93, 94, 95, 96, 98, 99, 100, 103, 105, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl168_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "Epoch: 1 cost time: 94.93490862846375\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.2745222 Vali Loss: 0.2098569 Test Loss: 0.2543777\n",
      "Validation loss decreased (inf --> 0.209857).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 97.88841915130615\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.1953471 Vali Loss: 0.1924711 Test Loss: 0.2247242\n",
      "Validation loss decreased (0.209857 --> 0.192471).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 95.92441177368164\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.1805659 Vali Loss: 0.1887467 Test Loss: 0.2116429\n",
      "Validation loss decreased (0.192471 --> 0.188747).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 90.3724684715271\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.1755724 Vali Loss: 0.1875851 Test Loss: 0.2080587\n",
      "Validation loss decreased (0.188747 --> 0.187585).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 93.48627400398254\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.1732709 Vali Loss: 0.1846453 Test Loss: 0.2064762\n",
      "Validation loss decreased (0.187585 --> 0.184645).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 101.04886054992676\n",
      "Epoch: 6, Steps: 261 | Train Loss: 0.1722411 Vali Loss: 0.1857036 Test Loss: 0.2056105\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 97.431147813797\n",
      "Epoch: 7, Steps: 261 | Train Loss: 0.1715618 Vali Loss: 0.1846945 Test Loss: 0.2047290\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 97.73316025733948\n",
      "Epoch: 8, Steps: 261 | Train Loss: 0.1712891 Vali Loss: 0.1842525 Test Loss: 0.2044976\n",
      "Validation loss decreased (0.184645 --> 0.184253).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 92.30036044120789\n",
      "Epoch: 9, Steps: 261 | Train Loss: 0.1711024 Vali Loss: 0.1845036 Test Loss: 0.2045136\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 95.33031940460205\n",
      "Epoch: 10, Steps: 261 | Train Loss: 0.1709727 Vali Loss: 0.1838423 Test Loss: 0.2043479\n",
      "Validation loss decreased (0.184253 --> 0.183842).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 100.75438523292542\n",
      "Epoch: 11, Steps: 261 | Train Loss: 0.1710100 Vali Loss: 0.1838636 Test Loss: 0.2044161\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 94.86922645568848\n",
      "Epoch: 12, Steps: 261 | Train Loss: 0.1710386 Vali Loss: 0.1841805 Test Loss: 0.2044540\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 97.8796603679657\n",
      "Epoch: 13, Steps: 261 | Train Loss: 0.1708163 Vali Loss: 0.1840257 Test Loss: 0.2044422\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 1) (84, 32, 168, 1)\n",
      "test shape: (2688, 168, 1) (2688, 168, 1)\n",
      "mse:0.20434793829917908, mae:0.2872311472892761\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[5, 6, 8, 16, 18, 21, 22, 27, 30, 31, 35, 37, 41, 44, 49, 51, 56, 60, 62, 63, 68, 71, 76, 79, 83, 86, 87, 88, 89, 93, 94, 96, 101, 104, 106, 107, 108, 112, 114, 115, 118, 120, 121, 123, 124, 125, 126, 127, 132, 137, 144, 145, 150, 152, 156, 157, 159, 160, 162, 171, 173, 176, 178, 186]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 4, 8, 10, 11, 19, 22, 25, 27, 29, 30, 31, 37, 38, 46, 51, 53, 56, 59, 60, 61, 63, 66, 67, 70, 71, 73, 83, 85, 86, 87, 88, 90, 91, 93, 100, 102, 103, 105, 106, 113, 114, 116, 118, 121, 126, 133, 135, 137, 138, 140, 142, 146, 156, 163, 164, 172, 173, 176, 179, 183, 187, 188]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl336_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 137.5448637008667\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.2794518 Vali Loss: 0.2239798 Test Loss: 0.2531980\n",
      "Validation loss decreased (inf --> 0.223980).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 138.03746604919434\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.2040735 Vali Loss: 0.2087817 Test Loss: 0.2273964\n",
      "Validation loss decreased (0.223980 --> 0.208782).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 136.30613660812378\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.1892859 Vali Loss: 0.2050861 Test Loss: 0.2197302\n",
      "Validation loss decreased (0.208782 --> 0.205086).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 136.5584523677826\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.1851019 Vali Loss: 0.2049639 Test Loss: 0.2185452\n",
      "Validation loss decreased (0.205086 --> 0.204964).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 138.26207208633423\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.1828691 Vali Loss: 0.2008395 Test Loss: 0.2144005\n",
      "Validation loss decreased (0.204964 --> 0.200839).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 136.67724227905273\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.1817489 Vali Loss: 0.2006952 Test Loss: 0.2139032\n",
      "Validation loss decreased (0.200839 --> 0.200695).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 137.36968350410461\n",
      "Epoch: 7, Steps: 256 | Train Loss: 0.1812256 Vali Loss: 0.2008900 Test Loss: 0.2141913\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 137.30261611938477\n",
      "Epoch: 8, Steps: 256 | Train Loss: 0.1810299 Vali Loss: 0.2008907 Test Loss: 0.2137832\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 137.29151439666748\n",
      "Epoch: 9, Steps: 256 | Train Loss: 0.1807842 Vali Loss: 0.2006801 Test Loss: 0.2136833\n",
      "Validation loss decreased (0.200695 --> 0.200680).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 135.76942467689514\n",
      "Epoch: 10, Steps: 256 | Train Loss: 0.1808086 Vali Loss: 0.2012542 Test Loss: 0.2137917\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 134.9397096633911\n",
      "Epoch: 11, Steps: 256 | Train Loss: 0.1807386 Vali Loss: 0.2010848 Test Loss: 0.2136818\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 135.7372510433197\n",
      "Epoch: 12, Steps: 256 | Train Loss: 0.1807032 Vali Loss: 0.2007398 Test Loss: 0.2135633\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 1) (79, 32, 336, 1)\n",
      "test shape: (2528, 336, 1) (2528, 336, 1)\n",
      "mse:0.21368330717086792, mae:0.2933596670627594\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on DEWINDh_small with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'DEWINDh_small', 'root_path': './WINDataset/', 'data_path': 'DEWINDh_small.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[5, 7, 14, 15, 19, 28, 29, 32, 41, 70, 72, 78, 92, 95, 107, 111, 125, 136, 141, 142, 143, 144, 147, 148, 161, 166, 193, 207, 218, 220, 224, 225, 227, 238, 241, 248, 255, 257, 259, 264, 268, 270, 295, 310, 317, 321, 324, 325, 327, 328, 330, 334, 336, 340, 346, 348, 352, 358, 368, 370, 371, 372, 373, 383]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[6, 12, 13, 20, 30, 37, 44, 45, 50, 51, 54, 68, 73, 89, 97, 106, 110, 118, 121, 124, 125, 127, 129, 140, 143, 147, 155, 159, 161, 164, 167, 173, 174, 175, 193, 194, 195, 204, 217, 218, 221, 225, 226, 242, 249, 255, 256, 273, 283, 289, 294, 296, 301, 305, 314, 315, 319, 336, 338, 340, 345, 347, 356, 366]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_DEWINDh_small_ftS_sl96_ll48_pl720_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 156.19643640518188\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.3164566 Vali Loss: 0.2410156 Test Loss: 0.2578015\n",
      "Validation loss decreased (inf --> 0.241016).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 154.18176746368408\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.2299838 Vali Loss: 0.2263319 Test Loss: 0.2225166\n",
      "Validation loss decreased (0.241016 --> 0.226332).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 152.73677945137024\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.2144654 Vali Loss: 0.2258151 Test Loss: 0.2145904\n",
      "Validation loss decreased (0.226332 --> 0.225815).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 155.5624635219574\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.2087077 Vali Loss: 0.2264275 Test Loss: 0.2124823\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 154.6022527217865\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.2072666 Vali Loss: 0.2284970 Test Loss: 0.2127695\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 151.8677213191986\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.2064574 Vali Loss: 0.2277032 Test Loss: 0.2132132\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 1) (67, 32, 720, 1)\n",
      "test shape: (2144, 720, 1) (2144, 720, 1)\n",
      "mse:0.21459044516086578, mae:0.3042219281196594\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl24_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "Epoch: 1 cost time: 74.73909330368042\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.0427485 Vali Loss: 0.0142050 Test Loss: 0.0156709\n",
      "Validation loss decreased (inf --> 0.014205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 69.94323301315308\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.0170757 Vali Loss: 0.0127911 Test Loss: 0.0131940\n",
      "Validation loss decreased (0.014205 --> 0.012791).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 68.74501371383667\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.0153608 Vali Loss: 0.0132927 Test Loss: 0.0142198\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 70.74430441856384\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.0145853 Vali Loss: 0.0117667 Test Loss: 0.0127431\n",
      "Validation loss decreased (0.012791 --> 0.011767).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 70.42110276222229\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.0141812 Vali Loss: 0.0115002 Test Loss: 0.0124220\n",
      "Validation loss decreased (0.011767 --> 0.011500).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 71.71730923652649\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.0139335 Vali Loss: 0.0118488 Test Loss: 0.0129903\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 69.67986297607422\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.0138513 Vali Loss: 0.0116860 Test Loss: 0.0128233\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 71.06742453575134\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.0137176 Vali Loss: 0.0116691 Test Loss: 0.0128467\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 1) (89, 32, 24, 1)\n",
      "test shape: (2848, 24, 1) (2848, 24, 1)\n",
      "mse:0.012421983294188976, mae:0.09499217569828033\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl48_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "Epoch: 1 cost time: 82.62886786460876\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.0509854 Vali Loss: 0.0180286 Test Loss: 0.0199440\n",
      "Validation loss decreased (inf --> 0.018029).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 75.52333950996399\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.0198787 Vali Loss: 0.0185629 Test Loss: 0.0212041\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 84.1139485836029\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.0123281 Vali Loss: 0.0210622 Test Loss: 0.0228689\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 81.28150939941406\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.0052759 Vali Loss: 0.0212576 Test Loss: 0.0227869\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 1) (88, 32, 48, 1)\n",
      "test shape: (2816, 48, 1) (2816, 48, 1)\n",
      "mse:0.019944023340940475, mae:0.11941598355770111\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 3, 5, 6, 9, 10, 11, 15, 16, 19, 22, 23, 24, 25, 27, 30, 31, 32, 35, 36, 37, 38, 39, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 63, 65, 66, 68, 70, 72, 73, 74, 76, 77, 78, 80, 81, 82, 90, 91, 92, 93, 95, 97, 100, 104, 105, 106]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 5, 7, 9, 10, 11, 13, 14, 16, 17, 18, 20, 23, 26, 27, 28, 29, 32, 33, 34, 35, 37, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 55, 58, 61, 62, 63, 64, 65, 66, 67, 68, 74, 75, 76, 77, 80, 81, 82, 85, 86, 88, 90, 91, 92, 94, 97, 99, 100, 101, 103, 104, 105]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl168_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "Epoch: 1 cost time: 101.84913969039917\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.0728098 Vali Loss: 0.0524281 Test Loss: 0.0772704\n",
      "Validation loss decreased (inf --> 0.052428).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 87.40538740158081\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.0378373 Vali Loss: 0.0468810 Test Loss: 0.0699481\n",
      "Validation loss decreased (0.052428 --> 0.046881).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 94.67370581626892\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.0354153 Vali Loss: 0.0482819 Test Loss: 0.0742178\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 99.83035564422607\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.0346010 Vali Loss: 0.0482900 Test Loss: 0.0741721\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 97.09888434410095\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.0343237 Vali Loss: 0.0470955 Test Loss: 0.0734261\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 1) (84, 32, 168, 1)\n",
      "test shape: (2688, 168, 1) (2688, 168, 1)\n",
      "mse:0.06994808465242386, mae:0.21107102930545807\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 5, 6, 7, 10, 11, 14, 16, 25, 26, 52, 55, 56, 57, 61, 63, 64, 66, 67, 69, 70, 72, 74, 75, 79, 80, 82, 89, 90, 93, 96, 97, 100, 101, 104, 106, 107, 109, 112, 115, 119, 122, 130, 136, 138, 141, 142, 143, 145, 149, 150, 151, 160, 162, 166, 169, 170, 175, 178, 179, 181, 186, 187, 189]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[6, 7, 8, 10, 14, 16, 19, 21, 24, 25, 26, 29, 30, 31, 34, 36, 38, 43, 45, 48, 50, 51, 52, 53, 55, 56, 57, 59, 60, 67, 70, 75, 80, 82, 88, 89, 92, 93, 94, 100, 102, 108, 113, 114, 120, 121, 129, 132, 139, 143, 145, 148, 149, 154, 159, 161, 164, 168, 169, 172, 175, 177, 182, 184]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl336_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 139.30432415008545\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.0890444 Vali Loss: 0.0804638 Test Loss: 0.1426802\n",
      "Validation loss decreased (inf --> 0.080464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 142.93336248397827\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.0406087 Vali Loss: 0.0782275 Test Loss: 0.1404223\n",
      "Validation loss decreased (0.080464 --> 0.078228).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 139.75560426712036\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.0372293 Vali Loss: 0.0703895 Test Loss: 0.1348318\n",
      "Validation loss decreased (0.078228 --> 0.070390).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 137.24430894851685\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.0360870 Vali Loss: 0.0727980 Test Loss: 0.1379151\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 132.64594292640686\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.0355033 Vali Loss: 0.0711329 Test Loss: 0.1348898\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 133.64660000801086\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.0351970 Vali Loss: 0.0719441 Test Loss: 0.1357211\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 1) (79, 32, 336, 1)\n",
      "test shape: (2528, 336, 1) (2528, 336, 1)\n",
      "mse:0.13483181595802307, mae:0.2947820723056793\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_additive with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_additive', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_additive.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 5, 9, 15, 19, 24, 30, 37, 42, 50, 51, 53, 65, 68, 69, 74, 76, 89, 106, 111, 117, 126, 130, 133, 136, 139, 141, 143, 147, 148, 152, 165, 168, 169, 188, 195, 202, 214, 229, 231, 234, 238, 243, 259, 261, 266, 270, 276, 280, 283, 289, 296, 301, 302, 323, 326, 347, 354, 355, 360, 361, 369, 376, 383]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 8, 12, 17, 28, 48, 52, 54, 74, 82, 84, 89, 90, 95, 96, 102, 104, 113, 118, 124, 128, 133, 140, 154, 175, 180, 183, 188, 189, 194, 195, 200, 220, 221, 222, 228, 229, 236, 256, 262, 267, 268, 270, 276, 284, 301, 305, 307, 309, 310, 313, 316, 319, 326, 332, 335, 343, 344, 352, 360, 361, 364, 366, 382]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_additive_ftS_sl96_ll48_pl720_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 152.01621532440186\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.1149296 Vali Loss: 0.1129449 Test Loss: 0.1426805\n",
      "Validation loss decreased (inf --> 0.112945).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 152.62825512886047\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.0826839 Vali Loss: 0.1087984 Test Loss: 0.1381708\n",
      "Validation loss decreased (0.112945 --> 0.108798).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 155.14176273345947\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.0778196 Vali Loss: 0.1021451 Test Loss: 0.1311690\n",
      "Validation loss decreased (0.108798 --> 0.102145).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 153.52900218963623\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.0742535 Vali Loss: 0.1013670 Test Loss: 0.1308442\n",
      "Validation loss decreased (0.102145 --> 0.101367).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 155.54235672950745\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.0732651 Vali Loss: 0.1009897 Test Loss: 0.1304703\n",
      "Validation loss decreased (0.101367 --> 0.100990).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 153.7102701663971\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.0729032 Vali Loss: 0.1005441 Test Loss: 0.1300553\n",
      "Validation loss decreased (0.100990 --> 0.100544).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 157.08018803596497\n",
      "Epoch: 7, Steps: 244 | Train Loss: 0.0727855 Vali Loss: 0.1004793 Test Loss: 0.1300315\n",
      "Validation loss decreased (0.100544 --> 0.100479).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 153.98673152923584\n",
      "Epoch: 8, Steps: 244 | Train Loss: 0.0726516 Vali Loss: 0.1004297 Test Loss: 0.1300295\n",
      "Validation loss decreased (0.100479 --> 0.100430).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 153.56844282150269\n",
      "Epoch: 9, Steps: 244 | Train Loss: 0.0726203 Vali Loss: 0.1003894 Test Loss: 0.1299749\n",
      "Validation loss decreased (0.100430 --> 0.100389).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 150.32253098487854\n",
      "Epoch: 10, Steps: 244 | Train Loss: 0.0725249 Vali Loss: 0.1003381 Test Loss: 0.1299667\n",
      "Validation loss decreased (0.100389 --> 0.100338).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 154.49593114852905\n",
      "Epoch: 11, Steps: 244 | Train Loss: 0.0725807 Vali Loss: 0.1004587 Test Loss: 0.1299633\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 152.85793685913086\n",
      "Epoch: 12, Steps: 244 | Train Loss: 0.0725438 Vali Loss: 0.1002700 Test Loss: 0.1299639\n",
      "Validation loss decreased (0.100338 --> 0.100270).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 153.1916687488556\n",
      "Epoch: 13, Steps: 244 | Train Loss: 0.0725751 Vali Loss: 0.1003772 Test Loss: 0.1299638\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 155.80803203582764\n",
      "Epoch: 14, Steps: 244 | Train Loss: 0.0725399 Vali Loss: 0.1002643 Test Loss: 0.1299623\n",
      "Validation loss decreased (0.100270 --> 0.100264).  Saving model ...\n",
      "Updating learning rate to 1.220703125e-08\n",
      "Epoch: 15 cost time: 152.84141516685486\n",
      "Epoch: 15, Steps: 244 | Train Loss: 0.0725505 Vali Loss: 0.1004451 Test Loss: 0.1299612\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.103515625e-09\n",
      "Epoch: 16 cost time: 152.402583360672\n",
      "Epoch: 16, Steps: 244 | Train Loss: 0.0725537 Vali Loss: 0.1003396 Test Loss: 0.1299620\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.0517578125e-09\n",
      "Epoch: 17 cost time: 153.3291425704956\n",
      "Epoch: 17, Steps: 244 | Train Loss: 0.0725756 Vali Loss: 0.1004241 Test Loss: 0.1299624\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 1) (67, 32, 720, 1)\n",
      "test shape: (2144, 720, 1) (2144, 720, 1)\n",
      "mse:0.12996231019496918, mae:0.2956447899341583\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 36\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl24_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "Epoch: 1 cost time: 69.95051741600037\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.1308087 Vali Loss: 0.1202727 Test Loss: 0.2491716\n",
      "Validation loss decreased (inf --> 0.120273).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 75.98225975036621\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.0472134 Vali Loss: 0.0901750 Test Loss: 0.1861937\n",
      "Validation loss decreased (0.120273 --> 0.090175).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 72.48815751075745\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.0376528 Vali Loss: 0.0732488 Test Loss: 0.1485894\n",
      "Validation loss decreased (0.090175 --> 0.073249).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 73.27530145645142\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.0320956 Vali Loss: 0.0780246 Test Loss: 0.1474594\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 71.00189542770386\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.0265166 Vali Loss: 0.0689728 Test Loss: 0.1251354\n",
      "Validation loss decreased (0.073249 --> 0.068973).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 78.45705270767212\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.0213420 Vali Loss: 0.0712450 Test Loss: 0.1276719\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 77.5700056552887\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.0189030 Vali Loss: 0.0723299 Test Loss: 0.1305963\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 73.12382864952087\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.0179049 Vali Loss: 0.0702129 Test Loss: 0.1280869\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 1) (89, 32, 24, 1)\n",
      "test shape: (2848, 24, 1) (2848, 24, 1)\n",
      "mse:0.1251353770494461, mae:0.2924322783946991\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 48, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=48, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 48\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl48_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "Epoch: 1 cost time: 77.13046360015869\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.1540633 Vali Loss: 0.1575222 Test Loss: 0.3175133\n",
      "Validation loss decreased (inf --> 0.157522).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 77.72132277488708\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.0538236 Vali Loss: 0.1161437 Test Loss: 0.2342350\n",
      "Validation loss decreased (0.157522 --> 0.116144).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 77.67883443832397\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.0477480 Vali Loss: 0.1100016 Test Loss: 0.2162289\n",
      "Validation loss decreased (0.116144 --> 0.110002).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 82.24772596359253\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.0436436 Vali Loss: 0.0931480 Test Loss: 0.1790547\n",
      "Validation loss decreased (0.110002 --> 0.093148).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 74.94528245925903\n",
      "Epoch: 5, Steps: 265 | Train Loss: 0.0414734 Vali Loss: 0.0993660 Test Loss: 0.1896061\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 79.74053049087524\n",
      "Epoch: 6, Steps: 265 | Train Loss: 0.0405198 Vali Loss: 0.0971202 Test Loss: 0.1836738\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 80.32368326187134\n",
      "Epoch: 7, Steps: 265 | Train Loss: 0.0400684 Vali Loss: 0.0940984 Test Loss: 0.1789153\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 1) (88, 32, 48, 1)\n",
      "test shape: (2816, 48, 1) (2816, 48, 1)\n",
      "mse:0.17905473709106445, mae:0.3451704978942871\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 168, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 3, 4, 5, 7, 10, 11, 12, 13, 15, 16, 18, 20, 23, 24, 25, 28, 30, 31, 32, 35, 38, 40, 42, 43, 45, 46, 47, 49, 51, 53, 55, 57, 59, 62, 63, 67, 68, 70, 72, 74, 75, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 97, 98, 99, 100, 103, 104]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 21, 22, 23, 27, 28, 30, 32, 34, 36, 37, 38, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 55, 60, 61, 63, 65, 66, 67, 70, 71, 73, 74, 75, 76, 77, 79, 81, 85, 86, 87, 90, 94, 95, 96, 98, 100, 102, 103, 104, 105, 107]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl168_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "Epoch: 1 cost time: 97.97330641746521\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.1976855 Vali Loss: 0.2421027 Test Loss: 0.4928890\n",
      "Validation loss decreased (inf --> 0.242103).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 97.70791506767273\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.0966737 Vali Loss: 0.2249172 Test Loss: 0.4601704\n",
      "Validation loss decreased (0.242103 --> 0.224917).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 95.0511064529419\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.0908570 Vali Loss: 0.2199885 Test Loss: 0.4547435\n",
      "Validation loss decreased (0.224917 --> 0.219988).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 92.14805817604065\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.0881951 Vali Loss: 0.2156846 Test Loss: 0.4412629\n",
      "Validation loss decreased (0.219988 --> 0.215685).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 99.12911248207092\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.0867915 Vali Loss: 0.2125939 Test Loss: 0.4389615\n",
      "Validation loss decreased (0.215685 --> 0.212594).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 96.9781174659729\n",
      "Epoch: 6, Steps: 261 | Train Loss: 0.0862095 Vali Loss: 0.2153750 Test Loss: 0.4408803\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 95.90998911857605\n",
      "Epoch: 7, Steps: 261 | Train Loss: 0.0857665 Vali Loss: 0.2133033 Test Loss: 0.4383859\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 94.16781067848206\n",
      "Epoch: 8, Steps: 261 | Train Loss: 0.0856569 Vali Loss: 0.2118819 Test Loss: 0.4364480\n",
      "Validation loss decreased (0.212594 --> 0.211882).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 96.5242006778717\n",
      "Epoch: 9, Steps: 261 | Train Loss: 0.0854081 Vali Loss: 0.2117544 Test Loss: 0.4362144\n",
      "Validation loss decreased (0.211882 --> 0.211754).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 100.98290276527405\n",
      "Epoch: 10, Steps: 261 | Train Loss: 0.0854207 Vali Loss: 0.2114740 Test Loss: 0.4361405\n",
      "Validation loss decreased (0.211754 --> 0.211474).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 98.0153796672821\n",
      "Epoch: 11, Steps: 261 | Train Loss: 0.0853832 Vali Loss: 0.2111922 Test Loss: 0.4361334\n",
      "Validation loss decreased (0.211474 --> 0.211192).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 95.2564446926117\n",
      "Epoch: 12, Steps: 261 | Train Loss: 0.0853101 Vali Loss: 0.2113579 Test Loss: 0.4359778\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 95.11027312278748\n",
      "Epoch: 13, Steps: 261 | Train Loss: 0.0852479 Vali Loss: 0.2117306 Test Loss: 0.4360789\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.44140625e-08\n",
      "Epoch: 14 cost time: 93.91485071182251\n",
      "Epoch: 14, Steps: 261 | Train Loss: 0.0854514 Vali Loss: 0.2113732 Test Loss: 0.4360234\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 1) (84, 32, 168, 1)\n",
      "test shape: (2688, 168, 1) (2688, 168, 1)\n",
      "mse:0.43613341450691223, mae:0.5329356789588928\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 336, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 6, 8, 11, 15, 17, 20, 23, 24, 25, 27, 28, 40, 41, 42, 43, 45, 48, 50, 54, 55, 60, 63, 64, 66, 70, 80, 82, 85, 87, 88, 90, 93, 95, 96, 98, 100, 107, 116, 117, 119, 124, 125, 126, 130, 133, 137, 141, 142, 148, 155, 158, 159, 160, 161, 164, 167, 171, 172, 173, 178, 183, 186, 189]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 3, 4, 9, 11, 18, 19, 23, 29, 32, 33, 36, 38, 41, 44, 48, 49, 54, 61, 62, 64, 69, 73, 74, 81, 85, 86, 88, 89, 97, 101, 106, 107, 110, 112, 113, 114, 120, 123, 124, 127, 130, 135, 136, 140, 141, 142, 144, 145, 148, 152, 153, 159, 164, 167, 172, 176, 179, 181, 183, 184, 186, 189, 190]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl336_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 132.79359936714172\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.2648095 Vali Loss: 0.4463544 Test Loss: 0.9264024\n",
      "Validation loss decreased (inf --> 0.446354).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 135.37095761299133\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.1390502 Vali Loss: 0.4360401 Test Loss: 0.9363617\n",
      "Validation loss decreased (0.446354 --> 0.436040).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 136.57585835456848\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.1275753 Vali Loss: 0.3993294 Test Loss: 0.8908439\n",
      "Validation loss decreased (0.436040 --> 0.399329).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 138.5202395915985\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.1243966 Vali Loss: 0.4040039 Test Loss: 0.8927992\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 137.71836233139038\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.1228903 Vali Loss: 0.4035740 Test Loss: 0.8934826\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 138.93694853782654\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.1223115 Vali Loss: 0.3986278 Test Loss: 0.8875377\n",
      "Validation loss decreased (0.399329 --> 0.398628).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 138.18405675888062\n",
      "Epoch: 7, Steps: 256 | Train Loss: 0.1219799 Vali Loss: 0.3952074 Test Loss: 0.8812578\n",
      "Validation loss decreased (0.398628 --> 0.395207).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 139.1338140964508\n",
      "Epoch: 8, Steps: 256 | Train Loss: 0.1216923 Vali Loss: 0.3965352 Test Loss: 0.8837749\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 134.12413716316223\n",
      "Epoch: 9, Steps: 256 | Train Loss: 0.1216193 Vali Loss: 0.3953349 Test Loss: 0.8836628\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 142.48729133605957\n",
      "Epoch: 10, Steps: 256 | Train Loss: 0.1214878 Vali Loss: 0.3963095 Test Loss: 0.8835412\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 1) (79, 32, 336, 1)\n",
      "test shape: (2528, 336, 1) (2528, 336, 1)\n",
      "mse:0.8812577128410339, mae:0.7729610800743103\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training FedformerTS on SYNTH_multiplicative with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'model': 'Fedformer', 'version': 'Fourier', 'mode_select': 'random', 'modes': 64, 'L': 3, 'base': 'legendre', 'cross_activation': 'tanh', 'data': 'SYNTH_multiplicative', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative.csv', 'target': 'TARGET', 'checkpoints': './checkpoints/', 'features': 'S', 'freq': 'h', 'detail_freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 720, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 50, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'gpu': 0, 'devices': '0,1,2,3', 'use_multi_gpu': False, 'use_gpu': True}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[5, 6, 18, 24, 25, 34, 35, 45, 46, 54, 58, 60, 61, 64, 66, 67, 68, 78, 84, 85, 103, 104, 113, 114, 120, 144, 169, 183, 198, 203, 205, 216, 217, 220, 223, 224, 225, 228, 247, 251, 258, 261, 267, 270, 272, 273, 276, 277, 278, 289, 290, 291, 307, 312, 313, 321, 324, 328, 355, 359, 360, 361, 372, 378]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[2, 5, 7, 13, 20, 28, 41, 46, 47, 51, 55, 65, 69, 70, 72, 77, 85, 91, 92, 96, 104, 121, 137, 148, 155, 158, 173, 174, 177, 188, 192, 195, 198, 199, 200, 206, 216, 229, 233, 235, 236, 245, 248, 249, 250, 257, 263, 277, 280, 283, 308, 311, 312, 327, 329, 331, 336, 338, 344, 346, 347, 367, 378, 379]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Fedformer_SYNTH_multiplicative_ftS_sl96_ll48_pl720_dm512_nh8_elNone_dl1_df2048_atNone_fc1_ebtimeF_dtTrue_mxNone_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 154.30475854873657\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.2981822 Vali Loss: 0.5248169 Test Loss: 0.8918412\n",
      "Validation loss decreased (inf --> 0.524817).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 151.5878803730011\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.2168004 Vali Loss: 0.5172841 Test Loss: 0.8857162\n",
      "Validation loss decreased (0.524817 --> 0.517284).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 155.86179161071777\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.2104494 Vali Loss: 0.4971302 Test Loss: 0.8563406\n",
      "Validation loss decreased (0.517284 --> 0.497130).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 155.36655807495117\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.2077307 Vali Loss: 0.4916374 Test Loss: 0.8524553\n",
      "Validation loss decreased (0.497130 --> 0.491637).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 159.1189353466034\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.2060099 Vali Loss: 0.4916977 Test Loss: 0.8526605\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 154.90611910820007\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.2050318 Vali Loss: 0.4901105 Test Loss: 0.8516530\n",
      "Validation loss decreased (0.491637 --> 0.490110).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 159.2449939250946\n",
      "Epoch: 7, Steps: 244 | Train Loss: 0.2045908 Vali Loss: 0.4890855 Test Loss: 0.8493210\n",
      "Validation loss decreased (0.490110 --> 0.489085).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 151.5310025215149\n",
      "Epoch: 8, Steps: 244 | Train Loss: 0.2044672 Vali Loss: 0.4893708 Test Loss: 0.8503516\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 153.23761630058289\n",
      "Epoch: 9, Steps: 244 | Train Loss: 0.2044165 Vali Loss: 0.4884796 Test Loss: 0.8495947\n",
      "Validation loss decreased (0.489085 --> 0.488480).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 156.00878167152405\n",
      "Epoch: 10, Steps: 244 | Train Loss: 0.2042772 Vali Loss: 0.4883519 Test Loss: 0.8493519\n",
      "Validation loss decreased (0.488480 --> 0.488352).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "Epoch: 11 cost time: 152.8715627193451\n",
      "Epoch: 11, Steps: 244 | Train Loss: 0.2041214 Vali Loss: 0.4890001 Test Loss: 0.8491154\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "Epoch: 12 cost time: 153.7130789756775\n",
      "Epoch: 12, Steps: 244 | Train Loss: 0.2042466 Vali Loss: 0.4883972 Test Loss: 0.8491007\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      "Epoch: 13 cost time: 155.35788297653198\n",
      "Epoch: 13, Steps: 244 | Train Loss: 0.2042806 Vali Loss: 0.4886141 Test Loss: 0.8490444\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 1) (67, 32, 720, 1)\n",
      "test shape: (2144, 720, 1) (2144, 720, 1)\n",
      "mse:0.8493518829345703, mae:0.7480064630508423\n",
      "\n",
      "Moving to next...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple loop\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "\n",
    "    for dataset_name, dataset_path in datasets.items():\n",
    "        for pred_len in pred_lens:\n",
    "            print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "            # High amount of epochs to accomodate all models\n",
    "            # Early stopping should kick in anyways\n",
    "            model.fit(\n",
    "                data=dataset_name,\n",
    "                data_root_path=dataset_path,\n",
    "                batch_size=32,\n",
    "                epochs=50, # very high\n",
    "                pred_len=pred_len\n",
    "            )\n",
    "\n",
    "            predictions = model.predict()\n",
    "\n",
    "            print(f'\\nMoving to next...\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: CrossformerTS\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 24\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './crossformer_checkpoints/', 'seq_len': 96, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'save_pred': False, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 50, 'batch_size': 32, 'pred_len': 24, 'data_split': []}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il96_pl24_sl6_win2_fa10_dm256_nh4_el3_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8521\n",
      "val 2857\n",
      "test 2857\n",
      "\titers: 100, epoch: 1 | loss: 0.1372332\n",
      "\tspeed: 0.0766s/iter; left time: 1010.8598s\n",
      "\titers: 200, epoch: 1 | loss: 0.1311666\n",
      "\tspeed: 0.0742s/iter; left time: 972.6003s\n",
      "Epoch: 1 cost time: 20.07825517654419\n",
      "Epoch: 1, Steps: 266 | Train Loss: 0.2563401 Vali Loss: 0.1007042 Test Loss: 0.1484783\n",
      "Validation loss decreased (inf --> 0.100704).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.0683965\n",
      "\tspeed: 0.0737s/iter; left time: 953.8516s\n",
      "\titers: 200, epoch: 2 | loss: 0.0610715\n",
      "\tspeed: 0.0747s/iter; left time: 959.3185s\n",
      "Epoch: 2 cost time: 19.79440426826477\n",
      "Epoch: 2, Steps: 266 | Train Loss: 0.0789914 Vali Loss: 0.0913151 Test Loss: 0.1269142\n",
      "Validation loss decreased (0.100704 --> 0.091315).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0563138\n",
      "\tspeed: 0.0752s/iter; left time: 952.2959s\n",
      "\titers: 200, epoch: 3 | loss: 0.0488296\n",
      "\tspeed: 0.0748s/iter; left time: 940.4874s\n",
      "Epoch: 3 cost time: 19.927748203277588\n",
      "Epoch: 3, Steps: 266 | Train Loss: 0.0615342 Vali Loss: 0.0695391 Test Loss: 0.1015732\n",
      "Validation loss decreased (0.091315 --> 0.069539).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0434804\n",
      "\tspeed: 0.0738s/iter; left time: 915.4239s\n",
      "\titers: 200, epoch: 4 | loss: 0.0535503\n",
      "\tspeed: 0.0736s/iter; left time: 905.0108s\n",
      "Epoch: 4 cost time: 19.306107759475708\n",
      "Epoch: 4, Steps: 266 | Train Loss: 0.0553506 Vali Loss: 0.0766990 Test Loss: 0.1056818\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0637141\n",
      "\tspeed: 0.0733s/iter; left time: 890.0270s\n",
      "\titers: 200, epoch: 5 | loss: 0.0430022\n",
      "\tspeed: 0.0756s/iter; left time: 910.5613s\n",
      "Epoch: 5 cost time: 19.5534451007843\n",
      "Epoch: 5, Steps: 266 | Train Loss: 0.0496269 Vali Loss: 0.0650933 Test Loss: 0.0844050\n",
      "Validation loss decreased (0.069539 --> 0.065093).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0399168\n",
      "\tspeed: 0.0727s/iter; left time: 863.1203s\n",
      "\titers: 200, epoch: 6 | loss: 0.0362923\n",
      "\tspeed: 0.0747s/iter; left time: 879.0078s\n",
      "Epoch: 6 cost time: 19.704785585403442\n",
      "Epoch: 6, Steps: 266 | Train Loss: 0.0480967 Vali Loss: 0.0699826 Test Loss: 0.0927615\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0417918\n",
      "\tspeed: 0.0733s/iter; left time: 851.0138s\n",
      "\titers: 200, epoch: 7 | loss: 0.0386099\n",
      "\tspeed: 0.0716s/iter; left time: 823.3760s\n",
      "Epoch: 7 cost time: 19.498841762542725\n",
      "Epoch: 7, Steps: 266 | Train Loss: 0.0459328 Vali Loss: 0.0724447 Test Loss: 0.0980180\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.0428910\n",
      "\tspeed: 0.0749s/iter; left time: 849.0596s\n",
      "\titers: 200, epoch: 8 | loss: 0.0407234\n",
      "\tspeed: 0.0758s/iter; left time: 852.0632s\n",
      "Epoch: 8 cost time: 20.099920749664307\n",
      "Epoch: 8, Steps: 266 | Train Loss: 0.0443025 Vali Loss: 0.0667857 Test Loss: 0.0875885\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2857\n",
      "test shape: (89, 32, 24, 1) (89, 32, 24, 1)\n",
      "test shape: (2848, 24, 1) (2848, 24, 1)\n",
      "mse:0.08440504223108292, mae:0.1718091517686844\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 48\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './crossformer_checkpoints/', 'seq_len': 96, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'save_pred': False, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 50, 'batch_size': 32, 'pred_len': 48, 'data_split': []}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il96_pl48_sl6_win2_fa10_dm256_nh4_el3_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8497\n",
      "val 2833\n",
      "test 2833\n",
      "\titers: 100, epoch: 1 | loss: 0.2591613\n",
      "\tspeed: 0.0732s/iter; left time: 963.2178s\n",
      "\titers: 200, epoch: 1 | loss: 0.1499406\n",
      "\tspeed: 0.0743s/iter; left time: 969.7927s\n",
      "Epoch: 1 cost time: 19.56189227104187\n",
      "Epoch: 1, Steps: 265 | Train Loss: 0.3239502 Vali Loss: 0.1420108 Test Loss: 0.1946825\n",
      "Validation loss decreased (inf --> 0.142011).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.1593498\n",
      "\tspeed: 0.0725s/iter; left time: 934.1123s\n",
      "\titers: 200, epoch: 2 | loss: 0.1017608\n",
      "\tspeed: 0.0733s/iter; left time: 936.7806s\n",
      "Epoch: 2 cost time: 19.444911241531372\n",
      "Epoch: 2, Steps: 265 | Train Loss: 0.1159800 Vali Loss: 0.1317221 Test Loss: 0.1687772\n",
      "Validation loss decreased (0.142011 --> 0.131722).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0955931\n",
      "\tspeed: 0.0739s/iter; left time: 932.8274s\n",
      "\titers: 200, epoch: 3 | loss: 0.0673736\n",
      "\tspeed: 0.0748s/iter; left time: 936.2943s\n",
      "Epoch: 3 cost time: 19.798332691192627\n",
      "Epoch: 3, Steps: 265 | Train Loss: 0.0910935 Vali Loss: 0.1279417 Test Loss: 0.1605184\n",
      "Validation loss decreased (0.131722 --> 0.127942).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.0775049\n",
      "\tspeed: 0.0708s/iter; left time: 874.4908s\n",
      "\titers: 200, epoch: 4 | loss: 0.1040558\n",
      "\tspeed: 0.0731s/iter; left time: 895.6401s\n",
      "Epoch: 4 cost time: 18.88910722732544\n",
      "Epoch: 4, Steps: 265 | Train Loss: 0.0832930 Vali Loss: 0.1298423 Test Loss: 0.1469755\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0703991\n",
      "\tspeed: 0.0674s/iter; left time: 815.0789s\n",
      "\titers: 200, epoch: 5 | loss: 0.0625869\n",
      "\tspeed: 0.0717s/iter; left time: 860.0848s\n",
      "Epoch: 5 cost time: 18.296584606170654\n",
      "Epoch: 5, Steps: 265 | Train Loss: 0.0756678 Vali Loss: 0.1227080 Test Loss: 0.1500967\n",
      "Validation loss decreased (0.127942 --> 0.122708).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.0718990\n",
      "\tspeed: 0.0707s/iter; left time: 835.6117s\n",
      "\titers: 200, epoch: 6 | loss: 0.0604656\n",
      "\tspeed: 0.0685s/iter; left time: 802.7792s\n",
      "Epoch: 6 cost time: 18.227718114852905\n",
      "Epoch: 6, Steps: 265 | Train Loss: 0.0740079 Vali Loss: 0.1408094 Test Loss: 0.1674426\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748897\n",
      "\tspeed: 0.0747s/iter; left time: 863.5334s\n",
      "\titers: 200, epoch: 7 | loss: 0.0696058\n",
      "\tspeed: 0.0658s/iter; left time: 754.3002s\n",
      "Epoch: 7 cost time: 18.315259218215942\n",
      "Epoch: 7, Steps: 265 | Train Loss: 0.0699575 Vali Loss: 0.1192146 Test Loss: 0.1307198\n",
      "Validation loss decreased (0.122708 --> 0.119215).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.0719396\n",
      "\tspeed: 0.0658s/iter; left time: 743.5362s\n",
      "\titers: 200, epoch: 8 | loss: 0.0851566\n",
      "\tspeed: 0.0640s/iter; left time: 716.6422s\n",
      "Epoch: 8 cost time: 17.38996124267578\n",
      "Epoch: 8, Steps: 265 | Train Loss: 0.0686676 Vali Loss: 0.1217416 Test Loss: 0.1340501\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0549300\n",
      "\tspeed: 0.0653s/iter; left time: 719.8990s\n",
      "\titers: 200, epoch: 9 | loss: 0.0554188\n",
      "\tspeed: 0.0669s/iter; left time: 731.4346s\n",
      "Epoch: 9 cost time: 17.587017059326172\n",
      "Epoch: 9, Steps: 265 | Train Loss: 0.0663993 Vali Loss: 0.1238716 Test Loss: 0.1417243\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.0584002\n",
      "\tspeed: 0.0635s/iter; left time: 684.1071s\n",
      "\titers: 200, epoch: 10 | loss: 0.0695905\n",
      "\tspeed: 0.0653s/iter; left time: 696.1912s\n",
      "Epoch: 10 cost time: 17.267526388168335\n",
      "Epoch: 10, Steps: 265 | Train Loss: 0.0664200 Vali Loss: 0.1256605 Test Loss: 0.1443545\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2833\n",
      "test shape: (88, 32, 48, 1) (88, 32, 48, 1)\n",
      "test shape: (2816, 48, 1) (2816, 48, 1)\n",
      "mse:0.13071976602077484, mae:0.21613837778568268\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 168\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './crossformer_checkpoints/', 'seq_len': 96, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'save_pred': False, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 50, 'batch_size': 32, 'pred_len': 168, 'data_split': []}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il96_pl168_sl6_win2_fa10_dm256_nh4_el3_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8377\n",
      "val 2713\n",
      "test 2713\n",
      "\titers: 100, epoch: 1 | loss: 0.5525728\n",
      "\tspeed: 0.0675s/iter; left time: 873.5956s\n",
      "\titers: 200, epoch: 1 | loss: 0.3431511\n",
      "\tspeed: 0.0719s/iter; left time: 923.3646s\n",
      "Epoch: 1 cost time: 18.216936826705933\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.5098711 Vali Loss: 0.5114564 Test Loss: 0.6789024\n",
      "Validation loss decreased (inf --> 0.511456).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.2574176\n",
      "\tspeed: 0.0655s/iter; left time: 831.2292s\n",
      "\titers: 200, epoch: 2 | loss: 0.2512056\n",
      "\tspeed: 0.0688s/iter; left time: 866.4970s\n",
      "Epoch: 2 cost time: 17.94235110282898\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.2590981 Vali Loss: 0.4561979 Test Loss: 0.6346806\n",
      "Validation loss decreased (0.511456 --> 0.456198).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1902020\n",
      "\tspeed: 0.0719s/iter; left time: 893.7800s\n",
      "\titers: 200, epoch: 3 | loss: 0.3172642\n",
      "\tspeed: 0.0720s/iter; left time: 887.6303s\n",
      "Epoch: 3 cost time: 18.64726710319519\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.2047948 Vali Loss: 0.4233374 Test Loss: 0.5847525\n",
      "Validation loss decreased (0.456198 --> 0.423337).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.1617891\n",
      "\tspeed: 0.0728s/iter; left time: 886.0944s\n",
      "\titers: 200, epoch: 4 | loss: 0.1939152\n",
      "\tspeed: 0.0722s/iter; left time: 871.5486s\n",
      "Epoch: 4 cost time: 18.746713399887085\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.1896982 Vali Loss: 0.3253390 Test Loss: 0.4603467\n",
      "Validation loss decreased (0.423337 --> 0.325339).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1329379\n",
      "\tspeed: 0.0730s/iter; left time: 869.6758s\n",
      "\titers: 200, epoch: 5 | loss: 0.1769761\n",
      "\tspeed: 0.0726s/iter; left time: 856.8117s\n",
      "Epoch: 5 cost time: 19.066603899002075\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.1686162 Vali Loss: 0.2953365 Test Loss: 0.4425389\n",
      "Validation loss decreased (0.325339 --> 0.295336).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.1648638\n",
      "\tspeed: 0.0746s/iter; left time: 868.2435s\n",
      "\titers: 200, epoch: 6 | loss: 0.1757729\n",
      "\tspeed: 0.0691s/iter; left time: 798.1930s\n",
      "Epoch: 6 cost time: 18.473276615142822\n",
      "Epoch: 6, Steps: 261 | Train Loss: 0.1605314 Vali Loss: 0.3150438 Test Loss: 0.4459486\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1961616\n",
      "\tspeed: 0.0643s/iter; left time: 731.9154s\n",
      "\titers: 200, epoch: 7 | loss: 0.1719840\n",
      "\tspeed: 0.0686s/iter; left time: 773.8981s\n",
      "Epoch: 7 cost time: 17.534626007080078\n",
      "Epoch: 7, Steps: 261 | Train Loss: 0.1523436 Vali Loss: 0.3484446 Test Loss: 0.4955004\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 8 | loss: 0.1815556\n",
      "\tspeed: 0.0698s/iter; left time: 776.9688s\n",
      "\titers: 200, epoch: 8 | loss: 0.1169973\n",
      "\tspeed: 0.0664s/iter; left time: 732.1451s\n",
      "Epoch: 8 cost time: 17.74186873435974\n",
      "Epoch: 8, Steps: 261 | Train Loss: 0.1484358 Vali Loss: 0.3001147 Test Loss: 0.4432831\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2713\n",
      "test shape: (84, 32, 168, 1) (84, 32, 168, 1)\n",
      "test shape: (2688, 168, 1) (2688, 168, 1)\n",
      "mse:0.44253888726234436, mae:0.48141375184059143\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 336\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './crossformer_checkpoints/', 'seq_len': 96, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'save_pred': False, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 50, 'batch_size': 32, 'pred_len': 336, 'data_split': []}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il96_pl336_sl6_win2_fa10_dm256_nh4_el3_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.5523604\n",
      "\tspeed: 0.0774s/iter; left time: 982.6430s\n",
      "\titers: 200, epoch: 1 | loss: 0.4467474\n",
      "\tspeed: 0.0765s/iter; left time: 964.0371s\n",
      "Epoch: 1 cost time: 19.5779390335083\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.6548744 Vali Loss: 0.9196478 Test Loss: 1.2190945\n",
      "Validation loss decreased (inf --> 0.919648).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.3721115\n",
      "\tspeed: 0.0706s/iter; left time: 878.6605s\n",
      "\titers: 200, epoch: 2 | loss: 0.3409413\n",
      "\tspeed: 0.0747s/iter; left time: 922.1945s\n",
      "Epoch: 2 cost time: 18.58264708518982\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.3820671 Vali Loss: 0.7678183 Test Loss: 1.1394139\n",
      "Validation loss decreased (0.919648 --> 0.767818).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3856960\n",
      "\tspeed: 0.0662s/iter; left time: 807.4774s\n",
      "\titers: 200, epoch: 3 | loss: 0.3270268\n",
      "\tspeed: 0.0689s/iter; left time: 832.9904s\n",
      "Epoch: 3 cost time: 17.54443120956421\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.3170293 Vali Loss: 0.7201280 Test Loss: 1.1240318\n",
      "Validation loss decreased (0.767818 --> 0.720128).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.2954416\n",
      "\tspeed: 0.0691s/iter; left time: 823.9778s\n",
      "\titers: 200, epoch: 4 | loss: 0.3466381\n",
      "\tspeed: 0.0674s/iter; left time: 797.1140s\n",
      "Epoch: 4 cost time: 17.687923431396484\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.2875998 Vali Loss: 0.7343543 Test Loss: 1.0324146\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2930903\n",
      "\tspeed: 0.0742s/iter; left time: 866.9152s\n",
      "\titers: 200, epoch: 5 | loss: 0.2713572\n",
      "\tspeed: 0.0749s/iter; left time: 866.6615s\n",
      "Epoch: 5 cost time: 18.778618574142456\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.2534396 Vali Loss: 0.7187121 Test Loss: 0.9889066\n",
      "Validation loss decreased (0.720128 --> 0.718712).  Saving model ...\n",
      "\titers: 100, epoch: 6 | loss: 0.2402057\n",
      "\tspeed: 0.0711s/iter; left time: 811.4731s\n",
      "\titers: 200, epoch: 6 | loss: 0.3114623\n",
      "\tspeed: 0.0743s/iter; left time: 841.5200s\n",
      "Epoch: 6 cost time: 18.614478588104248\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.2406531 Vali Loss: 0.6040548 Test Loss: 0.9085436\n",
      "Validation loss decreased (0.718712 --> 0.604055).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1872773\n",
      "\tspeed: 0.0699s/iter; left time: 780.8940s\n",
      "\titers: 200, epoch: 7 | loss: 0.2159448\n",
      "\tspeed: 0.0699s/iter; left time: 773.9051s\n",
      "Epoch: 7 cost time: 18.022939920425415\n",
      "Epoch: 7, Steps: 256 | Train Loss: 0.2227239 Vali Loss: 0.5794318 Test Loss: 0.9058700\n",
      "Validation loss decreased (0.604055 --> 0.579432).  Saving model ...\n",
      "\titers: 100, epoch: 8 | loss: 0.2168759\n",
      "\tspeed: 0.0664s/iter; left time: 724.2986s\n",
      "\titers: 200, epoch: 8 | loss: 0.2112832\n",
      "\tspeed: 0.0699s/iter; left time: 755.6465s\n",
      "Epoch: 8 cost time: 17.54457974433899\n",
      "Epoch: 8, Steps: 256 | Train Loss: 0.2176785 Vali Loss: 0.5452434 Test Loss: 0.8538077\n",
      "Validation loss decreased (0.579432 --> 0.545243).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1926647\n",
      "\tspeed: 0.0673s/iter; left time: 716.7097s\n",
      "\titers: 200, epoch: 9 | loss: 0.1694006\n",
      "\tspeed: 0.0714s/iter; left time: 753.3102s\n",
      "Epoch: 9 cost time: 17.908084392547607\n",
      "Epoch: 9, Steps: 256 | Train Loss: 0.2076528 Vali Loss: 0.5663862 Test Loss: 0.8973247\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 10 | loss: 0.2055292\n",
      "\tspeed: 0.0684s/iter; left time: 711.3386s\n",
      "\titers: 200, epoch: 10 | loss: 0.2107670\n",
      "\tspeed: 0.0643s/iter; left time: 662.3903s\n",
      "Epoch: 10 cost time: 17.03303027153015\n",
      "Epoch: 10, Steps: 256 | Train Loss: 0.2021255 Vali Loss: 0.5497861 Test Loss: 0.8519279\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.2021399\n",
      "\tspeed: 0.0635s/iter; left time: 643.7760s\n",
      "\titers: 200, epoch: 11 | loss: 0.2383559\n",
      "\tspeed: 0.0713s/iter; left time: 716.3815s\n",
      "Epoch: 11 cost time: 17.751514196395874\n",
      "Epoch: 11, Steps: 256 | Train Loss: 0.2001290 Vali Loss: 0.5508402 Test Loss: 0.8571444\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 1) (79, 32, 336, 1)\n",
      "test shape: (2528, 336, 1) (2528, 336, 1)\n",
      "mse:0.8538077473640442, mae:0.6914862394332886\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training CrossformerTS on SYNTH_multiplicative_reversal with pred_len 720\n",
      "Beginning to fit the model with the following arguments:\n",
      "{'checkpoints': './crossformer_checkpoints/', 'seq_len': 96, 'seg_len': 6, 'win_size': 2, 'factor': 10, 'data_dim': 1, 'd_model': 256, 'd_ff': 512, 'n_heads': 4, 'e_layers': 3, 'dropout': 0.2, 'baseline': False, 'num_workers': 0, 'lradj': 'type1', 'save_pred': False, 'use_gpu': True, 'use_multi_gpu': False, 'gpu': 0, 'devices': '0,1,2,3', 'inverse': False, 'learning_rate': 0.0001, 'loss': 'mse', 'patience': 3, 'data': 'SYNTH_multiplicative_reversal', 'root_path': './SYNTHDataset/', 'data_path': 'SYNTH_multiplicative_reversal.csv', 'train_epochs': 50, 'batch_size': 32, 'pred_len': 720, 'data_split': []}\n",
      "======================================================================================================================================================\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Crossformer_SYNTH_multiplicative_reversal_il96_pl720_sl6_win2_fa10_dm256_nh4_el3_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "\titers: 100, epoch: 1 | loss: 0.6274670\n",
      "\tspeed: 0.0834s/iter; left time: 1008.8403s\n",
      "\titers: 200, epoch: 1 | loss: 0.4410718\n",
      "\tspeed: 0.0820s/iter; left time: 983.5918s\n",
      "Epoch: 1 cost time: 20.178656816482544\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.6901372 Vali Loss: 1.0094092 Test Loss: 1.5194842\n",
      "Validation loss decreased (inf --> 1.009409).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.4036339\n",
      "\tspeed: 0.0805s/iter; left time: 954.9056s\n",
      "\titers: 200, epoch: 2 | loss: 0.3681915\n",
      "\tspeed: 0.0739s/iter; left time: 868.6086s\n",
      "Epoch: 2 cost time: 18.64782404899597\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.3996327 Vali Loss: 1.0841294 Test Loss: 1.4988105\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3806881\n",
      "\tspeed: 0.0723s/iter; left time: 839.1748s\n",
      "\titers: 200, epoch: 3 | loss: 0.2900640\n",
      "\tspeed: 0.0731s/iter; left time: 842.0278s\n",
      "Epoch: 3 cost time: 17.839799642562866\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.3715245 Vali Loss: 1.0175222 Test Loss: 1.5098428\n",
      "EarlyStopping counter: 2 out of 3\n",
      "\titers: 100, epoch: 4 | loss: 0.4109842\n",
      "\tspeed: 0.0789s/iter; left time: 897.2893s\n",
      "\titers: 200, epoch: 4 | loss: 0.2802838\n",
      "\tspeed: 0.0728s/iter; left time: 820.1317s\n",
      "Epoch: 4 cost time: 18.436434030532837\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.3590165 Vali Loss: 1.0681267 Test Loss: 1.4845307\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 1) (67, 32, 720, 1)\n",
      "test shape: (2144, 720, 1) (2144, 720, 1)\n",
      "mse:1.519484281539917, mae:0.9742183685302734\n",
      "\n",
      "Moving to next...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    'SYNTHh1': './SYNTHDataset/',\n",
    "    'DEWINDh_small': './WINDataset/' ,\n",
    "    'SYNTH_additive' : './SYNTHDataset/' ,\n",
    "    'SYNTH_additive_reversal' : './SYNTHDataset/' ,\n",
    "    'SYNTH_multiplicative' : './SYNTHDataset/',\n",
    "    'SYNTH_multiplicative_reversal' : './SYNTHDataset/' \n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "\n",
    "models = [CrossformerTS , InformerTS]\n",
    "\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "\n",
    "    for dataset_name, dataset_path in datasets.items():\n",
    "        for pred_len in pred_lens:\n",
    "            print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "            # High amount of epochs to accomodate all models\n",
    "            # Early stopping should kick in anyways\n",
    "            model.fit(\n",
    "                data=dataset_name,\n",
    "                data_root_path=dataset_path,\n",
    "                batch_size=32,\n",
    "                epochs=50, # very high\n",
    "                pred_len=pred_len\n",
    "            )\n",
    "\n",
    "            predictions = model.predict()\n",
    "\n",
    "\n",
    "            print(f'\\nMoving to next...\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in use: PyraformerTS\n",
      "Training PyraformerTS on SYNTH_additive_reversal with pred_len 24\n",
      "[Info] Number of parameters: 8964864\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11329\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2857\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.12463elapse: 0.227 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 0, mse:0.030385686084628105, mae:0.13630013167858124, rmse:0.17431490123271942, mape:3.138979911804199, mspe:22122.99609375\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05554elapse: 0.229 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 1, mse:0.016809288412332535, mae:0.10002177208662033, rmse:0.12965063750743866, mape:1.862982153892517, mspe:5758.51513671875\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05259elapse: 0.229 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 2, mse:0.015744563192129135, mae:0.0970994159579277, rmse:0.12547734379768372, mape:1.779593825340271, mspe:4450.25927734375\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05276elapse: 0.229 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 3, mse:0.015939801931381226, mae:0.09775789827108383, rmse:0.1262529343366623, mape:1.6245791912078857, mspe:3689.981201171875\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05256elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 4, mse:0.015748687088489532, mae:0.09707029908895493, rmse:0.12549377977848053, mape:1.6747183799743652, mspe:3977.848876953125\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05244elapse: 0.231 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 5, mse:0.015779705718159676, mae:0.09709719568490982, rmse:0.12561729550361633, mape:1.6458181142807007, mspe:3838.58056640625\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05224elapse: 0.232 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 6, mse:0.015798337757587433, mae:0.09722108393907547, rmse:0.12569144368171692, mape:1.7109215259552002, mspe:4189.31494140625\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05245elapse: 0.231 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 7, mse:0.015932029113173485, mae:0.0977240651845932, rmse:0.1262221485376358, mape:1.6414316892623901, mspe:3742.52685546875\n",
      "Iteration best metrics: [0.015744563192129135, 0.0970994159579277, 0.12547734379768372, 1.779593825340271, 4450.25927734375]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11329\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2857\n",
      "168 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2857, 24, 1) (2857, 24, 1)\n",
      "test shape: (2857, 24, 1) (2857, 24, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_additive_reversal with pred_len 48\n",
      "[Info] Number of parameters: 9014016\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11305\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2833\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.13415elapse: 0.222 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 0, mse:0.0697070062160492, mae:0.21135735511779785, rmse:0.2640208303928375, mape:5.129183292388916, mspe:58126.41796875\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06059elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 1, mse:0.026616008952260017, mae:0.1254148930311203, rmse:0.16314414143562317, mape:2.0004866123199463, mspe:5714.72900390625\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05737elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 2, mse:0.026246333494782448, mae:0.12385740876197815, rmse:0.1620071977376938, mape:1.8583953380584717, mspe:4094.958251953125\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05686elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 3, mse:0.025997931137681007, mae:0.1237110048532486, rmse:0.16123874485492706, mape:1.9344335794448853, mspe:4448.75634765625\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05663elapse: 0.228 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 4, mse:0.026126159355044365, mae:0.12406444549560547, rmse:0.1616358906030655, mape:1.9380528926849365, mspe:4569.642578125\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05712elapse: 0.229 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 5, mse:0.026116741821169853, mae:0.12342649698257446, rmse:0.16160674393177032, mape:1.8813027143478394, mspe:4036.623046875\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05684elapse: 0.229 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 6, mse:0.026046544313430786, mae:0.12357837706804276, rmse:0.16138942539691925, mape:1.9508745670318604, mspe:4999.951171875\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05657elapse: 0.228 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 7, mse:0.026299066841602325, mae:0.12422481924295425, rmse:0.16216987371444702, mape:1.9965087175369263, mspe:4748.71728515625\n",
      "Iteration best metrics: [0.025997931137681007, 0.1237110048532486, 0.16123874485492706, 1.9344335794448853, 4448.75634765625]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11305\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2833\n",
      "168 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2833, 48, 1) (2833, 48, 1)\n",
      "test shape: (2833, 48, 1) (2833, 48, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_additive_reversal with pred_len 168\n",
      "[Info] Number of parameters: 9259776\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11185\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2713\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17034elapse: 0.225 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 0, mse:0.09959065914154053, mae:0.24190039932727814, rmse:0.315579891204834, mape:3.7987680435180664, mspe:32583.453125\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08012elapse: 0.228 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 1, mse:0.0874062031507492, mae:0.2243581861257553, rmse:0.29564541578292847, mape:3.1772444248199463, mspe:20136.69921875\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.07677elapse: 0.229 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 2, mse:0.0827343687415123, mae:0.22030457854270935, rmse:0.28763583302497864, mape:2.699228048324585, mspe:10867.5927734375\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.07552elapse: 0.228 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 3, mse:0.0813506543636322, mae:0.2167675644159317, rmse:0.28522035479545593, mape:2.921388864517212, mspe:14878.18359375\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.07581elapse: 0.225 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 4, mse:0.08174850046634674, mae:0.2179768979549408, rmse:0.2859169542789459, mape:2.7961714267730713, mspe:13040.0126953125\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.07511elapse: 0.227 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 5, mse:0.08163559436798096, mae:0.21824462711811066, rmse:0.2857194244861603, mape:2.8293404579162598, mspe:13305.9462890625\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.07570elapse: 0.227 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 6, mse:0.0796409398317337, mae:0.214540496468544, rmse:0.2822072505950928, mape:2.9900929927825928, mspe:16925.130859375\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.07522elapse: 0.227 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 7, mse:0.08167192339897156, mae:0.21764682233333588, rmse:0.28578299283981323, mape:2.783440589904785, mspe:12732.796875\n",
      "Iteration best metrics: [0.0796409398317337, 0.214540496468544, 0.2822072505950928, 2.9900929927825928, 16925.130859375]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11185\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2713\n",
      "168 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2713, 168, 1) (2713, 168, 1)\n",
      "test shape: (2713, 168, 1) (2713, 168, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_additive_reversal with pred_len 336\n",
      "[Info] Number of parameters: 9603840\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11017\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2545\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.24618elapse: 0.227 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 0, mse:0.19123807549476624, mae:0.332663357257843, rmse:0.437307745218277, mape:2.7197160720825195, mspe:11053.802734375\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11839elapse: 0.220 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 1, mse:0.15539543330669403, mae:0.2972487807273865, rmse:0.39420226216316223, mape:2.5726444721221924, mspe:9929.3896484375\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11013elapse: 0.218 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 2, mse:0.1538497507572174, mae:0.2965002655982971, rmse:0.3922368586063385, mape:2.5661983489990234, mspe:9364.037109375\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11039elapse: 0.219 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 3, mse:0.16378247737884521, mae:0.3057706952095032, rmse:0.40470048785209656, mape:2.6945366859436035, mspe:11085.5732421875\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11060elapse: 0.219 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 4, mse:0.15124011039733887, mae:0.29394593834877014, rmse:0.38889601826667786, mape:2.4927594661712646, mspe:8008.88623046875\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11072elapse: 0.222 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 5, mse:0.17005744576454163, mae:0.31181952357292175, rmse:0.4123802185058594, mape:2.7008631229400635, mspe:10744.0625\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.10960elapse: 0.221 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 6, mse:0.15033385157585144, mae:0.2937151789665222, rmse:0.38772910833358765, mape:2.6726443767547607, mspe:12522.8515625\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11096elapse: 0.223 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 7, mse:0.16574986279010773, mae:0.30783772468566895, rmse:0.4071238934993744, mape:2.642529249191284, mspe:9635.74609375\n",
      "Iteration best metrics: [0.15033385157585144, 0.2937151789665222, 0.38772910833358765, 2.6726443767547607, 12522.8515625]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11017\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2545\n",
      "168 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2545, 336, 1) (2545, 336, 1)\n",
      "test shape: (2545, 336, 1) (2545, 336, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_additive_reversal with pred_len 720\n",
      "[Info] Number of parameters: 10390272\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 10633\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2161\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.31751elapse: 0.214 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 0, mse:0.2598359286785126, mae:0.4123225808143616, rmse:0.5097410678863525, mape:2.610276460647583, mspe:8338.197265625\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.18244elapse: 0.215 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 1, mse:0.23470550775527954, mae:0.3865637183189392, rmse:0.4844641387462616, mape:2.4669830799102783, mspe:7919.4853515625\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17466elapse: 0.213 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 2, mse:0.2273368090391159, mae:0.38025975227355957, rmse:0.47679850459098816, mape:2.3190901279449463, mspe:5948.630859375\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17204elapse: 0.215 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 3, mse:0.23853810131549835, mae:0.38759320974349976, rmse:0.4884036183357239, mape:2.3877744674682617, mspe:6089.75\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17267elapse: 0.215 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 4, mse:0.2241462767124176, mae:0.3777919411659241, rmse:0.47344088554382324, mape:2.4224069118499756, mspe:7935.583984375\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17231elapse: 0.215 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 5, mse:0.22697235643863678, mae:0.3803538978099823, rmse:0.4764161705970764, mape:2.3714301586151123, mspe:6502.134765625\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17366elapse: 0.216 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 6, mse:0.22778771817684174, mae:0.38016459345817566, rmse:0.47727110981941223, mape:2.372667074203491, mspe:6597.09130859375\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17266elapse: 0.207 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 7, mse:0.23308710753917694, mae:0.38352033495903015, rmse:0.4827909469604492, mape:2.3808655738830566, mspe:6743.40185546875\n",
      "Iteration best metrics: [0.2241462767124176, 0.3777919411659241, 0.47344088554382324, 2.4224069118499756, 7935.583984375]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 10633\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2161\n",
      "168 720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2161, 720, 1) (2161, 720, 1)\n",
      "test shape: (2161, 720, 1) (2161, 720, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_multiplicative_reversal with pred_len 24\n",
      "[Info] Number of parameters: 8964864\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11329\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2857\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.13487elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 0, mse:0.054423604160547256, mae:0.13550762832164764, rmse:0.23328867554664612, mape:0.6528280377388, mspe:24.20671272277832\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06188elapse: 0.233 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 1, mse:0.04200853034853935, mae:0.09745132923126221, rmse:0.20495982468128204, mape:0.4180735647678375, mspe:7.893537998199463\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05881elapse: 0.231 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 2, mse:0.041169315576553345, mae:0.09249523282051086, rmse:0.20290222764015198, mape:0.3735812306404114, mspe:5.595581531524658\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05859elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 3, mse:0.04146444797515869, mae:0.09313356131315231, rmse:0.20362821221351624, mape:0.3749549090862274, mspe:5.80863618850708\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05867elapse: 0.234 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 4, mse:0.04175661504268646, mae:0.09365979582071304, rmse:0.20434434711933136, mape:0.37234562635421753, mspe:5.5688157081604\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05868elapse: 0.233 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 5, mse:0.041568219661712646, mae:0.09364305436611176, rmse:0.2038828581571579, mape:0.3737034201622009, mspe:5.684425354003906\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05831elapse: 0.231 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 6, mse:0.04141351208090782, mae:0.09295229613780975, rmse:0.2035031020641327, mape:0.37631526589393616, mspe:5.867162227630615\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.05823elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2848, 24, 1)\n",
      "Epoch 7, mse:0.041744083166122437, mae:0.09336172044277191, rmse:0.20431369543075562, mape:0.38358572125434875, mspe:6.170446395874023\n",
      "Iteration best metrics: [0.041169315576553345, 0.09249523282051086, 0.20290222764015198, 0.3735812306404114, 5.595581531524658]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11329\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2857\n",
      "168 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2857, 24, 1) (2857, 24, 1)\n",
      "test shape: (2857, 24, 1) (2857, 24, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_multiplicative_reversal with pred_len 48\n",
      "[Info] Number of parameters: 9014016\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11305\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2833\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.13674elapse: 0.233 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 0, mse:0.07826147973537445, mae:0.15847347676753998, rmse:0.2797525227069855, mape:0.7057083249092102, mspe:26.324426651000977\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06511elapse: 0.236 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 1, mse:0.06394663453102112, mae:0.11742383986711502, rmse:0.25287672877311707, mape:0.5093844532966614, mspe:12.771432876586914\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06198elapse: 0.231 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 2, mse:0.06367592513561249, mae:0.11577551066875458, rmse:0.2523408830165863, mape:0.49530237913131714, mspe:12.196273803710938\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06137elapse: 0.228 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 3, mse:0.06391394883394241, mae:0.11685985326766968, rmse:0.25281208753585815, mape:0.493716835975647, mspe:11.875568389892578\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06163elapse: 0.232 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 4, mse:0.06372152268886566, mae:0.11548488587141037, rmse:0.2524312138557434, mape:0.5059415698051453, mspe:12.683375358581543\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06186elapse: 0.234 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 5, mse:0.06410426646471024, mae:0.11693796515464783, rmse:0.25318819284439087, mape:0.5195851922035217, mspe:13.584539413452148\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06201elapse: 0.232 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 6, mse:0.06317388266324997, mae:0.11452432721853256, rmse:0.25134414434432983, mape:0.4975792169570923, mspe:12.339132308959961\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.06185elapse: 0.226 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2816, 48, 1)\n",
      "Epoch 7, mse:0.06376206874847412, mae:0.11562452465295792, rmse:0.25251153111457825, mape:0.4909589886665344, mspe:11.7764253616333\n",
      "Iteration best metrics: [0.06317388266324997, 0.11452432721853256, 0.25134414434432983, 0.4975792169570923, 12.339132308959961]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11305\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2833\n",
      "168 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2833, 48, 1) (2833, 48, 1)\n",
      "test shape: (2833, 48, 1) (2833, 48, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_multiplicative_reversal with pred_len 168\n",
      "[Info] Number of parameters: 9259776\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11185\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2713\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.19146elapse: 0.219 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 0, mse:0.15904486179351807, mae:0.2546915113925934, rmse:0.39880427718162537, mape:1.0831661224365234, mspe:61.763282775878906\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08991elapse: 0.225 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 1, mse:0.14652018249034882, mae:0.21758978068828583, rmse:0.3827795386314392, mape:0.9284117817878723, mspe:44.9482536315918\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08458elapse: 0.226 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 2, mse:0.14761093258857727, mae:0.22236545383930206, rmse:0.38420167565345764, mape:0.9272558689117432, mspe:43.12239456176758\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08414elapse: 0.226 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 3, mse:0.14822155237197876, mae:0.22390177845954895, rmse:0.3849955201148987, mape:0.9314299821853638, mspe:43.224945068359375\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08358elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 4, mse:0.14861448109149933, mae:0.2237560898065567, rmse:0.3855054974555969, mape:0.9393736124038696, mspe:43.61248016357422\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08385elapse: 0.230 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 5, mse:0.14899884164333344, mae:0.2233242243528366, rmse:0.38600367307662964, mape:0.9427894949913025, mspe:43.61598587036133\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08487elapse: 0.226 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 6, mse:0.14924786984920502, mae:0.2232416570186615, rmse:0.3863261044025421, mape:0.9240940809249878, mspe:42.65793228149414\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.08458elapse: 0.223 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2688, 168, 1)\n",
      "Epoch 7, mse:0.14722491800785065, mae:0.22305436432361603, rmse:0.3836989998817444, mape:0.9215201139450073, mspe:42.7718391418457\n",
      "Iteration best metrics: [0.14652018249034882, 0.21758978068828583, 0.3827795386314392, 0.9284117817878723, 44.9482536315918]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11185\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2713\n",
      "168 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2713, 168, 1) (2713, 168, 1)\n",
      "test shape: (2713, 168, 1) (2713, 168, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_multiplicative_reversal with pred_len 336\n",
      "[Info] Number of parameters: 9603840\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11017\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2545\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.25724elapse: 0.218 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 0, mse:0.28819847106933594, mae:0.3737311363220215, rmse:0.5368412137031555, mape:1.5292261838912964, mspe:115.9893798828125\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.12704elapse: 0.221 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 1, mse:0.2723865807056427, mae:0.35819289088249207, rmse:0.5219066739082336, mape:1.5517406463623047, mspe:147.53271484375\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11925elapse: 0.220 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 2, mse:0.26373937726020813, mae:0.3464130163192749, rmse:0.513555645942688, mape:1.5004504919052124, mspe:135.27224731445312\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11942elapse: 0.222 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 3, mse:0.2650873064994812, mae:0.35032814741134644, rmse:0.514866292476654, mape:1.4832241535186768, mspe:129.9745330810547\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11805elapse: 0.220 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 4, mse:0.2642129063606262, mae:0.3479629456996918, rmse:0.5140164494514465, mape:1.4832603931427002, mspe:129.56068420410156\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11854elapse: 0.223 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 5, mse:0.2637527287006378, mae:0.34717226028442383, rmse:0.513568639755249, mape:1.4694819450378418, mspe:125.35221862792969\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11826elapse: 0.223 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 6, mse:0.2639804482460022, mae:0.3492424190044403, rmse:0.5137902498245239, mape:1.499796748161316, mspe:133.3153839111328\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.11877elapse: 0.218 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2528, 336, 1)\n",
      "Epoch 7, mse:0.2629651725292206, mae:0.3474605977535248, rmse:0.5128012895584106, mape:1.5031629800796509, mspe:134.48031616210938\n",
      "Iteration best metrics: [0.2629651725292206, 0.3474605977535248, 0.5128012895584106, 1.5031629800796509, 134.48031616210938]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 11017\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2545\n",
      "168 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2545, 336, 1) (2545, 336, 1)\n",
      "test shape: (2545, 336, 1) (2545, 336, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n",
      "Training PyraformerTS on SYNTH_multiplicative_reversal with pred_len 720\n",
      "[Info] Number of parameters: 10390272\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 10633\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2161\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.31085elapse: 0.214 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 0, mse:0.6224310398101807, mae:0.6275787949562073, rmse:0.7889429926872253, mape:2.1987266540527344, mspe:185.2793731689453\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17705elapse: 0.214 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 1, mse:0.5888988971710205, mae:0.6019185781478882, rmse:0.7673974633216858, mape:2.164628267288208, mspe:173.62136840820312\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.17005elapse: 0.216 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 2, mse:0.5720503330230713, mae:0.5886484980583191, rmse:0.7563400864601135, mape:2.0985002517700195, mspe:167.5712432861328\n",
      "[ Epoch 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.16839elapse: 0.209 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 3, mse:0.5643194913864136, mae:0.5801877975463867, rmse:0.7512120008468628, mape:2.0586233139038086, mspe:163.13470458984375\n",
      "[ Epoch 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.16848elapse: 0.223 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 4, mse:0.5737432241439819, mae:0.5893834829330444, rmse:0.7574583888053894, mape:2.118617296218872, mspe:173.4226531982422\n",
      "[ Epoch 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.16842elapse: 0.216 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 5, mse:0.5743357539176941, mae:0.5904881358146667, rmse:0.7578494548797607, mape:2.1150894165039062, mspe:169.11839294433594\n",
      "[ Epoch 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.16955elapse: 0.217 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 6, mse:0.5727700591087341, mae:0.5890669822692871, rmse:0.7568157315254211, mape:2.124436616897583, mspe:177.35447692871094\n",
      "[ Epoch 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training) MSE:  0.16892elapse: 0.215 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape:(2144, 720, 1)\n",
      "Epoch 7, mse:0.5688241720199585, mae:0.5847705006599426, rmse:0.7542043328285217, mape:2.081162691116333, mspe:164.38644409179688\n",
      "Iteration best metrics: [0.5643194913864136, 0.5801877975463867, 0.7512120008468628, 2.0586233139038086, 163.13470458984375]\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "train 10633\n",
      "Data Length: 17420\n",
      "Train Length: 11520\n",
      "Test Length:3048\n",
      "test 2161\n",
      "168 720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (2161, 720, 1) (2161, 720, 1)\n",
      "test shape: (2161, 720, 1) (2161, 720, 1)\n",
      "\n",
      "Moving to next...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    #'SYNTHh1': './SYNTHDataset/',\n",
    "    #'DEWINDh_small': './WINDataset/' ,\n",
    "    #'SYNTH_additive' : './SYNTHDataset/' ,\n",
    "    'SYNTH_additive_reversal' : './SYNTHDataset/' ,\n",
    "    #'SYNTH_multiplicative' : './SYNTHDataset/',\n",
    "    'SYNTH_multiplicative_reversal' : './SYNTHDataset/' \n",
    "}\n",
    "pred_lens = [24, 48, 168, 336, 720]\n",
    "\n",
    "models = [PyraformerTS]\n",
    "\n",
    "#result_dict_pyraformer = {}\n",
    "\n",
    "for transformermodel in models:\n",
    "    print(f'Model in use: {transformermodel.__name__}')\n",
    "    model = transformermodel()\n",
    "    model.compile(learning_rate=1e-4, loss='mse', early_stopping_patience=3)\n",
    "\n",
    "    for dataset_name, dataset_path in datasets.items():\n",
    "        for pred_len in pred_lens:\n",
    "            print(f\"Training {transformermodel.__name__} on {dataset_name} with pred_len {pred_len}\")\n",
    "\n",
    "            # High amount of epochs to accomodate all models\n",
    "            # Early stopping should kick in anyways\n",
    "            model.fit(\n",
    "                data=dataset_name,\n",
    "                data_root_path=dataset_path,\n",
    "                batch_size=32,\n",
    "                epochs=8, \n",
    "                pred_len=pred_len\n",
    "            )\n",
    "\n",
    "            #pred_name = 'prediction_' + f'{transformermodel.__name__}_{dataset_name}_{pred_len}'\n",
    "            #true_name = 'true_' + f'{transformermodel.__name__}_{dataset_name}_{pred_len}'\n",
    "            \n",
    "\n",
    "            predictions = model.predict()\n",
    "\n",
    "            #result_dict_pyraformer[pred_name] = predictions\n",
    "            #result_dict_pyraformer[true_name] = trues\n",
    "            \n",
    "\n",
    "            print(f'\\nMoving to next...\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data_dict_pyraformer.pickle'\n",
    "\n",
    "with open(file_path , 'wb') as file:\n",
    "    pickle.dump(result_dict_pyraformer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5110, 24, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_pyraformer['prediction_PyraformerTS_DEWINDh_small_24'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './results/Pyraformer_results/'\n",
    "os.mkdir(folder_path)\n",
    "\n",
    "for name , array in result_dict_pyraformer.items():\n",
    "    np.save(folder_path+ name + '_pred.npy', array)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ansb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
